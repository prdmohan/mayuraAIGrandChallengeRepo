{"cells":[{"cell_type":"code","execution_count":1,"id":"c2983c8e","metadata":{},"outputs":[],"source":"#jupyter notebook --notebook-dir=D:"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"id":"3528335d","metadata":{},"outputs":[],"source":"index_list = range(10)"},{"cell_type":"code","execution_count":3,"id":"c75592ad","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.09477698802948  \n","Epoch:1/50     Step:2|6   loss:7.984550476074219  \n","Epoch:1/50     Step:3|6   loss:3.615652561187744  \n","Epoch:1/50     Step:4|6   loss:7.015923976898193  \n","Epoch:1/50     Step:5|6   loss:3.1350951194763184  \n","Epoch:1/50     Step:6|6   loss:5.987396240234375  \n","Epoch:1/50     Step:7|6   loss:2.577540397644043  \n","Accuracy on test_set: 55.14 %\n","Accuracy on train_set: 52.69 %\n","current max accuracy\t test set:55.14%\t train set:52.69%\n","Epoch:2/50     Step:1|6   loss:4.795645713806152  \n","Epoch:2/50     Step:2|6   loss:6.675957679748535  \n","Epoch:2/50     Step:3|6   loss:7.224100112915039  \n","Epoch:2/50     Step:4|6   loss:4.454677581787109  \n","Epoch:2/50     Step:5|6   loss:1.4029422998428345  \n","Epoch:2/50     Step:6|6   loss:2.8929271697998047  \n","Epoch:2/50     Step:7|6   loss:4.618320465087891  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 32.32 %\n","current max accuracy\t test set:55.14%\t train set:52.69%\n","Epoch:3/50     Step:1|6   loss:4.549102783203125  \n","Epoch:3/50     Step:2|6   loss:4.79597282409668  \n","Epoch:3/50     Step:3|6   loss:2.5033578872680664  \n","Epoch:3/50     Step:4|6   loss:1.0678479671478271  \n","Epoch:3/50     Step:5|6   loss:2.603668451309204  \n","Epoch:3/50     Step:6|6   loss:3.529470443725586  \n","Epoch:3/50     Step:7|6   loss:2.876694679260254  \n","Accuracy on test_set: 59.81 %\n","Accuracy on train_set: 59.25 %\n","current max accuracy\t test set:59.81%\t train set:59.25%\n","Epoch:4/50     Step:1|6   loss:2.5541863441467285  \n","Epoch:4/50     Step:2|6   loss:1.8668605089187622  \n","Epoch:4/50     Step:3|6   loss:2.4825081825256348  \n","Epoch:4/50     Step:4|6   loss:1.3753818273544312  \n","Epoch:4/50     Step:5|6   loss:1.379326343536377  \n","Epoch:4/50     Step:6|6   loss:1.6752164363861084  \n","Epoch:4/50     Step:7|6   loss:1.4703116416931152  \n","Accuracy on test_set: 57.94 %\n","Accuracy on train_set: 55.04 %\n","current max accuracy\t test set:59.81%\t train set:59.25%\n","Epoch:5/50     Step:1|6   loss:1.7850441932678223  \n","Epoch:5/50     Step:2|6   loss:1.616053581237793  \n","Epoch:5/50     Step:3|6   loss:0.9663333892822266  \n","Epoch:5/50     Step:4|6   loss:0.8618320226669312  \n","Epoch:5/50     Step:5|6   loss:1.5212949514389038  \n","Epoch:5/50     Step:6|6   loss:1.3345320224761963  \n","Epoch:5/50     Step:7|6   loss:0.9585764408111572  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 74.71 %\n","current max accuracy\t test set:68.22%\t train set:74.71%\n","Epoch:6/50     Step:1|6   loss:0.9059942364692688  \n","Epoch:6/50     Step:2|6   loss:1.1858558654785156  \n","Epoch:6/50     Step:3|6   loss:1.1551074981689453  \n","Epoch:6/50     Step:4|6   loss:1.0931622982025146  \n","Epoch:6/50     Step:5|6   loss:0.7187544107437134  \n","Epoch:6/50     Step:6|6   loss:0.8493818044662476  \n","Epoch:6/50     Step:7|6   loss:0.8649708032608032  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 79.39 %\n","current max accuracy\t test set:72.9%\t train set:79.39%\n","Epoch:7/50     Step:1|6   loss:0.8849791288375854  \n","Epoch:7/50     Step:2|6   loss:0.7609701156616211  \n","Epoch:7/50     Step:3|6   loss:0.8760862350463867  \n","Epoch:7/50     Step:4|6   loss:0.8577637672424316  \n","Epoch:7/50     Step:5|6   loss:0.7291049957275391  \n","Epoch:7/50     Step:6|6   loss:0.6777172088623047  \n","Epoch:7/50     Step:7|6   loss:0.8914000988006592  \n","Accuracy on test_set: 69.16 %\n","Accuracy on train_set: 77.99 %\n","current max accuracy\t test set:72.9%\t train set:79.39%\n","Epoch:8/50     Step:1|6   loss:0.7745975852012634  \n","Epoch:8/50     Step:2|6   loss:0.7332898378372192  \n","Epoch:8/50     Step:3|6   loss:0.7007057070732117  \n","Epoch:8/50     Step:4|6   loss:0.7292487621307373  \n","Epoch:8/50     Step:5|6   loss:0.6576011180877686  \n","Epoch:8/50     Step:6|6   loss:0.7121698260307312  \n","Epoch:8/50     Step:7|6   loss:0.7139708995819092  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 81.26 %\n","current max accuracy\t test set:72.9%\t train set:81.26%\n","Epoch:9/50     Step:1|6   loss:0.7532058358192444  \n","Epoch:9/50     Step:2|6   loss:0.6367974877357483  \n","Epoch:9/50     Step:3|6   loss:0.7023419141769409  \n","Epoch:9/50     Step:4|6   loss:0.6796224117279053  \n","Epoch:9/50     Step:5|6   loss:0.6262558698654175  \n","Epoch:9/50     Step:6|6   loss:0.6301305294036865  \n","Epoch:9/50     Step:7|6   loss:0.633055567741394  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 89.93 %\n","current max accuracy\t test set:85.05%\t train set:89.93%\n","Epoch:10/50     Step:1|6   loss:0.7260785698890686  \n","Epoch:10/50     Step:2|6   loss:0.6556413173675537  \n","Epoch:10/50     Step:3|6   loss:0.6115095615386963  \n","Epoch:10/50     Step:4|6   loss:0.659171998500824  \n","Epoch:10/50     Step:5|6   loss:0.6574399471282959  \n","Epoch:10/50     Step:6|6   loss:0.7193818092346191  \n","Epoch:10/50     Step:7|6   loss:0.7058374881744385  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:85.05%\t train set:90.16%\n","Epoch:11/50     Step:1|6   loss:0.7146986722946167  \n","Epoch:11/50     Step:2|6   loss:0.665277361869812  \n","Epoch:11/50     Step:3|6   loss:0.623725175857544  \n","Epoch:11/50     Step:4|6   loss:0.6193184852600098  \n","Epoch:11/50     Step:5|6   loss:0.6582292318344116  \n","Epoch:11/50     Step:6|6   loss:0.616214394569397  \n","Epoch:11/50     Step:7|6   loss:0.6857056021690369  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:85.05%\t train set:90.87%\n","Epoch:12/50     Step:1|6   loss:0.7085663080215454  \n","Epoch:12/50     Step:2|6   loss:0.6141526699066162  \n","Epoch:12/50     Step:3|6   loss:0.6470574736595154  \n","Epoch:12/50     Step:4|6   loss:0.7023324370384216  \n","Epoch:12/50     Step:5|6   loss:0.6284947991371155  \n","Epoch:12/50     Step:6|6   loss:0.6629003286361694  \n","Epoch:12/50     Step:7|6   loss:0.6995603442192078  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:90.65%\t train set:95.32%\n","Epoch:13/50     Step:1|6   loss:0.6164376735687256  \n","Epoch:13/50     Step:2|6   loss:0.6348451375961304  \n","Epoch:13/50     Step:3|6   loss:0.7210628986358643  \n","Epoch:13/50     Step:4|6   loss:0.672227144241333  \n","Epoch:13/50     Step:5|6   loss:0.6745144724845886  \n","Epoch:13/50     Step:6|6   loss:0.659774661064148  \n","Epoch:13/50     Step:7|6   loss:0.6101731657981873  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:91.59%\t train set:95.32%\n","Epoch:14/50     Step:1|6   loss:0.5753946900367737  \n","Epoch:14/50     Step:2|6   loss:0.613371729850769  \n","Epoch:14/50     Step:3|6   loss:0.6495658159255981  \n","Epoch:14/50     Step:4|6   loss:0.681413471698761  \n","Epoch:14/50     Step:5|6   loss:0.6703124046325684  \n","Epoch:14/50     Step:6|6   loss:0.6631147861480713  \n","Epoch:14/50     Step:7|6   loss:0.6229144334793091  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:95.32%\n","Epoch:15/50     Step:1|6   loss:0.5918906927108765  \n","Epoch:15/50     Step:2|6   loss:0.6363988518714905  \n","Epoch:15/50     Step:3|6   loss:0.5962584018707275  \n","Epoch:15/50     Step:4|6   loss:0.6557705402374268  \n","Epoch:15/50     Step:5|6   loss:0.6078950762748718  \n","Epoch:15/50     Step:6|6   loss:0.5976492166519165  \n","Epoch:15/50     Step:7|6   loss:0.5960756540298462  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:95.32%\n","Epoch:16/50     Step:1|6   loss:0.5996856093406677  \n","Epoch:16/50     Step:2|6   loss:0.5813601016998291  \n","Epoch:16/50     Step:3|6   loss:0.5765533447265625  \n","Epoch:16/50     Step:4|6   loss:0.6392785310745239  \n","Epoch:16/50     Step:5|6   loss:0.5962241888046265  \n","Epoch:16/50     Step:6|6   loss:0.6114369630813599  \n","Epoch:16/50     Step:7|6   loss:0.6377133131027222  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:95.32%\n","Epoch:17/50     Step:1|6   loss:0.6167443990707397  \n","Epoch:17/50     Step:2|6   loss:0.5758345127105713  \n","Epoch:17/50     Step:3|6   loss:0.589824378490448  \n","Epoch:17/50     Step:4|6   loss:0.6293976306915283  \n","Epoch:17/50     Step:5|6   loss:0.6184731721878052  \n","Epoch:17/50     Step:6|6   loss:0.6041796207427979  \n","Epoch:17/50     Step:7|6   loss:0.5822387337684631  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:91.59%\t train set:95.32%\n","Epoch:18/50     Step:1|6   loss:0.6322569251060486  \n","Epoch:18/50     Step:2|6   loss:0.5994394421577454  \n","Epoch:18/50     Step:3|6   loss:0.57660311460495  \n","Epoch:18/50     Step:4|6   loss:0.6296838521957397  \n","Epoch:18/50     Step:5|6   loss:0.5799550414085388  \n","Epoch:18/50     Step:6|6   loss:0.6025564670562744  \n","Epoch:18/50     Step:7|6   loss:0.5715374946594238  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:91.59%\t train set:97.42%\n","Epoch:19/50     Step:1|6   loss:0.5725234746932983  \n","Epoch:19/50     Step:2|6   loss:0.6213695406913757  \n","Epoch:19/50     Step:3|6   loss:0.6035232543945312  \n","Epoch:19/50     Step:4|6   loss:0.5984601974487305  \n","Epoch:19/50     Step:5|6   loss:0.5615386366844177  \n","Epoch:19/50     Step:6|6   loss:0.5701372623443604  \n","Epoch:19/50     Step:7|6   loss:0.5719003677368164  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:20/50     Step:1|6   loss:0.5830199718475342  \n","Epoch:20/50     Step:2|6   loss:0.6087890267372131  \n","Epoch:20/50     Step:3|6   loss:0.5984010696411133  \n","Epoch:20/50     Step:4|6   loss:0.5899112224578857  \n","Epoch:20/50     Step:5|6   loss:0.5733472108840942  \n","Epoch:20/50     Step:6|6   loss:0.569601833820343  \n","Epoch:20/50     Step:7|6   loss:0.5753451585769653  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:21/50     Step:1|6   loss:0.5713043212890625  \n","Epoch:21/50     Step:2|6   loss:0.631455659866333  \n","Epoch:21/50     Step:3|6   loss:0.5664235353469849  \n","Epoch:21/50     Step:4|6   loss:0.5785507559776306  \n","Epoch:21/50     Step:5|6   loss:0.6299914121627808  \n","Epoch:21/50     Step:6|6   loss:0.6122713088989258  \n","Epoch:21/50     Step:7|6   loss:0.6061936616897583  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:22/50     Step:1|6   loss:0.6815980672836304  \n","Epoch:22/50     Step:2|6   loss:0.5790891647338867  \n","Epoch:22/50     Step:3|6   loss:0.605318546295166  \n","Epoch:22/50     Step:4|6   loss:0.646618127822876  \n","Epoch:22/50     Step:5|6   loss:0.6178436279296875  \n","Epoch:22/50     Step:6|6   loss:0.6261732578277588  \n","Epoch:22/50     Step:7|6   loss:0.6308959722518921  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:23/50     Step:1|6   loss:0.5697219967842102  \n","Epoch:23/50     Step:2|6   loss:0.61979740858078  \n","Epoch:23/50     Step:3|6   loss:0.5953682065010071  \n","Epoch:23/50     Step:4|6   loss:0.5690754652023315  \n","Epoch:23/50     Step:5|6   loss:0.6607946157455444  \n","Epoch:23/50     Step:6|6   loss:0.553768515586853  \n","Epoch:23/50     Step:7|6   loss:0.598018229007721  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:24/50     Step:1|6   loss:0.6057757139205933  \n","Epoch:24/50     Step:2|6   loss:0.588197648525238  \n","Epoch:24/50     Step:3|6   loss:0.6181325316429138  \n","Epoch:24/50     Step:4|6   loss:0.5573921799659729  \n","Epoch:24/50     Step:5|6   loss:0.5890670418739319  \n","Epoch:24/50     Step:6|6   loss:0.5481982231140137  \n","Epoch:24/50     Step:7|6   loss:0.572650671005249  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:25/50     Step:1|6   loss:0.5707035064697266  \n","Epoch:25/50     Step:2|6   loss:0.5595703125  \n","Epoch:25/50     Step:3|6   loss:0.603390097618103  \n","Epoch:25/50     Step:4|6   loss:0.5730200409889221  \n","Epoch:25/50     Step:5|6   loss:0.583727240562439  \n","Epoch:25/50     Step:6|6   loss:0.5673832893371582  \n","Epoch:25/50     Step:7|6   loss:0.5756940841674805  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:26/50     Step:1|6   loss:0.5836164355278015  \n","Epoch:26/50     Step:2|6   loss:0.5754177570343018  \n","Epoch:26/50     Step:3|6   loss:0.5967665910720825  \n","Epoch:26/50     Step:4|6   loss:0.5687344074249268  \n","Epoch:26/50     Step:5|6   loss:0.5821212530136108  \n","Epoch:26/50     Step:6|6   loss:0.5632519721984863  \n","Epoch:26/50     Step:7|6   loss:0.5458074808120728  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:94.39%\t train set:98.83%\n","Epoch:27/50     Step:1|6   loss:0.5600602626800537  \n","Epoch:27/50     Step:2|6   loss:0.5664241313934326  \n","Epoch:27/50     Step:3|6   loss:0.5804502367973328  \n","Epoch:27/50     Step:4|6   loss:0.5792585015296936  \n","Epoch:27/50     Step:5|6   loss:0.5359973311424255  \n","Epoch:27/50     Step:6|6   loss:0.5457536578178406  \n","Epoch:27/50     Step:7|6   loss:0.5697222352027893  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:28/50     Step:1|6   loss:0.5528403520584106  \n","Epoch:28/50     Step:2|6   loss:0.5365058183670044  \n","Epoch:28/50     Step:3|6   loss:0.582918643951416  \n","Epoch:28/50     Step:4|6   loss:0.5672816634178162  \n","Epoch:28/50     Step:5|6   loss:0.5774902105331421  \n","Epoch:28/50     Step:6|6   loss:0.5777248740196228  \n","Epoch:28/50     Step:7|6   loss:0.5685554146766663  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:29/50     Step:1|6   loss:0.5773051977157593  \n","Epoch:29/50     Step:2|6   loss:0.5557681322097778  \n","Epoch:29/50     Step:3|6   loss:0.5636141300201416  \n","Epoch:29/50     Step:4|6   loss:0.5675316452980042  \n","Epoch:29/50     Step:5|6   loss:0.5585987567901611  \n","Epoch:29/50     Step:6|6   loss:0.5458900928497314  \n","Epoch:29/50     Step:7|6   loss:0.5453234910964966  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:30/50     Step:1|6   loss:0.5411888360977173  \n","Epoch:30/50     Step:2|6   loss:0.5624685287475586  \n","Epoch:30/50     Step:3|6   loss:0.5569517016410828  \n","Epoch:30/50     Step:4|6   loss:0.5556106567382812  \n","Epoch:30/50     Step:5|6   loss:0.5551004409790039  \n","Epoch:30/50     Step:6|6   loss:0.5322089195251465  \n","Epoch:30/50     Step:7|6   loss:0.5527780652046204  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:31/50     Step:1|6   loss:0.5425307154655457  \n","Epoch:31/50     Step:2|6   loss:0.5600266456604004  \n","Epoch:31/50     Step:3|6   loss:0.5468385219573975  \n","Epoch:31/50     Step:4|6   loss:0.5458067059516907  \n","Epoch:31/50     Step:5|6   loss:0.552128255367279  \n","Epoch:31/50     Step:6|6   loss:0.554140031337738  \n","Epoch:31/50     Step:7|6   loss:0.5557065606117249  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:32/50     Step:1|6   loss:0.5681333541870117  \n","Epoch:32/50     Step:2|6   loss:0.5542005300521851  \n","Epoch:32/50     Step:3|6   loss:0.5428083539009094  \n","Epoch:32/50     Step:4|6   loss:0.5349090695381165  \n","Epoch:32/50     Step:5|6   loss:0.544457197189331  \n","Epoch:32/50     Step:6|6   loss:0.5385742783546448  \n","Epoch:32/50     Step:7|6   loss:0.5636873245239258  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:33/50     Step:1|6   loss:0.5383976101875305  \n","Epoch:33/50     Step:2|6   loss:0.541344165802002  \n","Epoch:33/50     Step:3|6   loss:0.5321233868598938  \n","Epoch:33/50     Step:4|6   loss:0.5705165266990662  \n","Epoch:33/50     Step:5|6   loss:0.5506969094276428  \n","Epoch:33/50     Step:6|6   loss:0.5479466319084167  \n","Epoch:33/50     Step:7|6   loss:0.5812796354293823  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:34/50     Step:1|6   loss:0.5427792072296143  \n","Epoch:34/50     Step:2|6   loss:0.5535308718681335  \n","Epoch:34/50     Step:3|6   loss:0.5532513856887817  \n","Epoch:34/50     Step:4|6   loss:0.576511800289154  \n","Epoch:34/50     Step:5|6   loss:0.5487616658210754  \n","Epoch:34/50     Step:6|6   loss:0.5532232522964478  \n","Epoch:34/50     Step:7|6   loss:0.5715538263320923  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:35/50     Step:1|6   loss:0.5308236479759216  \n","Epoch:35/50     Step:2|6   loss:0.5613300800323486  \n","Epoch:35/50     Step:3|6   loss:0.5593247413635254  \n","Epoch:35/50     Step:4|6   loss:0.5337412357330322  \n","Epoch:35/50     Step:5|6   loss:0.5595710277557373  \n","Epoch:35/50     Step:6|6   loss:0.5427014231681824  \n","Epoch:35/50     Step:7|6   loss:0.5636404752731323  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:36/50     Step:1|6   loss:0.5548453330993652  \n","Epoch:36/50     Step:2|6   loss:0.5394232869148254  \n","Epoch:36/50     Step:3|6   loss:0.5436469912528992  \n","Epoch:36/50     Step:4|6   loss:0.5425388813018799  \n","Epoch:36/50     Step:5|6   loss:0.5323876738548279  \n","Epoch:36/50     Step:6|6   loss:0.5622909069061279  \n","Epoch:36/50     Step:7|6   loss:0.5432381629943848  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:37/50     Step:1|6   loss:0.5479750037193298  \n","Epoch:37/50     Step:2|6   loss:0.5373636484146118  \n","Epoch:37/50     Step:3|6   loss:0.5550278425216675  \n","Epoch:37/50     Step:4|6   loss:0.5431926250457764  \n","Epoch:37/50     Step:5|6   loss:0.53066086769104  \n","Epoch:37/50     Step:6|6   loss:0.5324655771255493  \n","Epoch:37/50     Step:7|6   loss:0.5331777930259705  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:38/50     Step:1|6   loss:0.5441575050354004  \n","Epoch:38/50     Step:2|6   loss:0.5376293659210205  \n","Epoch:38/50     Step:3|6   loss:0.5350867509841919  \n","Epoch:38/50     Step:4|6   loss:0.5396848917007446  \n","Epoch:38/50     Step:5|6   loss:0.545279860496521  \n","Epoch:38/50     Step:6|6   loss:0.5307265520095825  \n","Epoch:38/50     Step:7|6   loss:0.5346843004226685  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:39/50     Step:1|6   loss:0.5334828495979309  \n","Epoch:39/50     Step:2|6   loss:0.5327380895614624  \n","Epoch:39/50     Step:3|6   loss:0.5441957712173462  \n","Epoch:39/50     Step:4|6   loss:0.5333794951438904  \n","Epoch:39/50     Step:5|6   loss:0.5313796997070312  \n","Epoch:39/50     Step:6|6   loss:0.5352463722229004  \n","Epoch:39/50     Step:7|6   loss:0.5396973490715027  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:40/50     Step:1|6   loss:0.544994592666626  \n","Epoch:40/50     Step:2|6   loss:0.5399551391601562  \n","Epoch:40/50     Step:3|6   loss:0.5279054641723633  \n","Epoch:40/50     Step:4|6   loss:0.5300391316413879  \n","Epoch:40/50     Step:5|6   loss:0.5500326156616211  \n","Epoch:40/50     Step:6|6   loss:0.5427611470222473  \n","Epoch:40/50     Step:7|6   loss:0.5316019058227539  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:41/50     Step:1|6   loss:0.5357192158699036  \n","Epoch:41/50     Step:2|6   loss:0.5336542129516602  \n","Epoch:41/50     Step:3|6   loss:0.5349147319793701  \n","Epoch:41/50     Step:4|6   loss:0.5362426042556763  \n","Epoch:41/50     Step:5|6   loss:0.5426205396652222  \n","Epoch:41/50     Step:6|6   loss:0.5320004820823669  \n","Epoch:41/50     Step:7|6   loss:0.5394224524497986  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:42/50     Step:1|6   loss:0.5355292558670044  \n","Epoch:42/50     Step:2|6   loss:0.5175896286964417  \n","Epoch:42/50     Step:3|6   loss:0.5324414968490601  \n","Epoch:42/50     Step:4|6   loss:0.5353999137878418  \n","Epoch:42/50     Step:5|6   loss:0.5421106219291687  \n","Epoch:42/50     Step:6|6   loss:0.5358165502548218  \n","Epoch:42/50     Step:7|6   loss:0.5317030549049377  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:43/50     Step:1|6   loss:0.5349790453910828  \n","Epoch:43/50     Step:2|6   loss:0.537043035030365  \n","Epoch:43/50     Step:3|6   loss:0.5322743654251099  \n","Epoch:43/50     Step:4|6   loss:0.5272674560546875  \n","Epoch:43/50     Step:5|6   loss:0.5270193815231323  \n","Epoch:43/50     Step:6|6   loss:0.5570583343505859  \n","Epoch:43/50     Step:7|6   loss:0.553061842918396  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.5279571413993835  \n","Epoch:44/50     Step:2|6   loss:0.5542555451393127  \n","Epoch:44/50     Step:3|6   loss:0.5268106460571289  \n","Epoch:44/50     Step:4|6   loss:0.5601015686988831  \n","Epoch:44/50     Step:5|6   loss:0.5179980993270874  \n","Epoch:44/50     Step:6|6   loss:0.5359975099563599  \n","Epoch:44/50     Step:7|6   loss:0.5403274893760681  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5348066687583923  \n","Epoch:45/50     Step:2|6   loss:0.5221515893936157  \n","Epoch:45/50     Step:3|6   loss:0.5256261229515076  \n","Epoch:45/50     Step:4|6   loss:0.5435464978218079  \n","Epoch:45/50     Step:5|6   loss:0.5382062792778015  \n","Epoch:45/50     Step:6|6   loss:0.5242589712142944  \n","Epoch:45/50     Step:7|6   loss:0.5326796770095825  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5506962537765503  \n","Epoch:46/50     Step:2|6   loss:0.5273276567459106  \n","Epoch:46/50     Step:3|6   loss:0.5426250100135803  \n","Epoch:46/50     Step:4|6   loss:0.5344781875610352  \n","Epoch:46/50     Step:5|6   loss:0.5419976711273193  \n","Epoch:46/50     Step:6|6   loss:0.5315207839012146  \n","Epoch:46/50     Step:7|6   loss:0.5391428470611572  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5406574010848999  \n","Epoch:47/50     Step:2|6   loss:0.5289990305900574  \n","Epoch:47/50     Step:3|6   loss:0.5413808822631836  \n","Epoch:47/50     Step:4|6   loss:0.5636594891548157  \n","Epoch:47/50     Step:5|6   loss:0.5529487133026123  \n","Epoch:47/50     Step:6|6   loss:0.5529848337173462  \n","Epoch:47/50     Step:7|6   loss:0.5297377109527588  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.5746263265609741  \n","Epoch:48/50     Step:2|6   loss:0.529633641242981  \n","Epoch:48/50     Step:3|6   loss:0.5683190226554871  \n","Epoch:48/50     Step:4|6   loss:0.5362305045127869  \n","Epoch:48/50     Step:5|6   loss:0.542570173740387  \n","Epoch:48/50     Step:6|6   loss:0.5434939861297607  \n","Epoch:48/50     Step:7|6   loss:0.5222433805465698  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5332293510437012  \n","Epoch:49/50     Step:2|6   loss:0.5392749309539795  \n","Epoch:49/50     Step:3|6   loss:0.5354031920433044  \n","Epoch:49/50     Step:4|6   loss:0.5202431678771973  \n","Epoch:49/50     Step:5|6   loss:0.5185642242431641  \n","Epoch:49/50     Step:6|6   loss:0.5276719927787781  \n","Epoch:49/50     Step:7|6   loss:0.5176709294319153  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5139507055282593  \n","Epoch:50/50     Step:2|6   loss:0.5382049679756165  \n","Epoch:50/50     Step:3|6   loss:0.5170918703079224  \n","Epoch:50/50     Step:4|6   loss:0.5367993116378784  \n","Epoch:50/50     Step:5|6   loss:0.523017168045044  \n","Epoch:50/50     Step:6|6   loss:0.545590877532959  \n","Epoch:50/50     Step:7|6   loss:0.532481849193573  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Accuracy on test_set: 90.65 %\n","1\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1143773794174194  \n","Epoch:1/50     Step:2|6   loss:4.996971130371094  \n","Epoch:1/50     Step:3|6   loss:9.536195755004883  \n","Epoch:1/50     Step:4|6   loss:5.912901878356934  \n","Epoch:1/50     Step:5|6   loss:2.5878543853759766  \n","Epoch:1/50     Step:6|6   loss:5.8990864753723145  \n","Epoch:1/50     Step:7|6   loss:4.17844295501709  \n","Accuracy on test_set: 35.51 %\n","Accuracy on train_set: 40.05 %\n","current max accuracy\t test set:35.51%\t train set:40.05%\n","Epoch:2/50     Step:1|6   loss:2.819769859313965  \n","Epoch:2/50     Step:2|6   loss:1.3026535511016846  \n","Epoch:2/50     Step:3|6   loss:3.377639055252075  \n","Epoch:2/50     Step:4|6   loss:3.5944769382476807  \n","Epoch:2/50     Step:5|6   loss:3.5056631565093994  \n","Epoch:2/50     Step:6|6   loss:1.1342498064041138  \n","Epoch:2/50     Step:7|6   loss:1.842176914215088  \n","Accuracy on test_set: 40.19 %\n","Accuracy on train_set: 42.86 %\n","current max accuracy\t test set:40.19%\t train set:42.86%\n","Epoch:3/50     Step:1|6   loss:2.8136582374572754  \n","Epoch:3/50     Step:2|6   loss:3.306736707687378  \n","Epoch:3/50     Step:3|6   loss:1.649768352508545  \n","Epoch:3/50     Step:4|6   loss:0.8380128145217896  \n","Epoch:3/50     Step:5|6   loss:1.9281656742095947  \n","Epoch:3/50     Step:6|6   loss:2.0633490085601807  \n","Epoch:3/50     Step:7|6   loss:1.3651381731033325  \n","Accuracy on test_set: 67.29 %\n","Accuracy on train_set: 73.54 %\n","current max accuracy\t test set:67.29%\t train set:73.54%\n","Epoch:4/50     Step:1|6   loss:0.847650408744812  \n","Epoch:4/50     Step:2|6   loss:1.3391096591949463  \n","Epoch:4/50     Step:3|6   loss:1.6047037839889526  \n","Epoch:4/50     Step:4|6   loss:1.0859415531158447  \n","Epoch:4/50     Step:5|6   loss:0.7707937359809875  \n","Epoch:4/50     Step:6|6   loss:1.2895036935806274  \n","Epoch:4/50     Step:7|6   loss:1.4967098236083984  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 75.18 %\n","current max accuracy\t test set:71.96%\t train set:75.18%\n","Epoch:5/50     Step:1|6   loss:0.8465924263000488  \n","Epoch:5/50     Step:2|6   loss:1.0412870645523071  \n","Epoch:5/50     Step:3|6   loss:1.2328307628631592  \n","Epoch:5/50     Step:4|6   loss:0.8788462281227112  \n","Epoch:5/50     Step:5|6   loss:0.818236768245697  \n","Epoch:5/50     Step:6|6   loss:1.0308666229248047  \n","Epoch:5/50     Step:7|6   loss:0.9009015560150146  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:82.24%\t train set:87.82%\n","Epoch:6/50     Step:1|6   loss:0.7006840705871582  \n","Epoch:6/50     Step:2|6   loss:0.7871825695037842  \n","Epoch:6/50     Step:3|6   loss:0.8480088114738464  \n","Epoch:6/50     Step:4|6   loss:0.6958826780319214  \n","Epoch:6/50     Step:5|6   loss:0.7858991622924805  \n","Epoch:6/50     Step:6|6   loss:0.7571872472763062  \n","Epoch:6/50     Step:7|6   loss:0.8333286046981812  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:82.24%\t train set:87.82%\n","Epoch:7/50     Step:1|6   loss:0.6984259486198425  \n","Epoch:7/50     Step:2|6   loss:0.7504726648330688  \n","Epoch:7/50     Step:3|6   loss:0.7404799461364746  \n","Epoch:7/50     Step:4|6   loss:0.704549252986908  \n","Epoch:7/50     Step:5|6   loss:0.6756001710891724  \n","Epoch:7/50     Step:6|6   loss:0.7399483323097229  \n","Epoch:7/50     Step:7|6   loss:0.7475588321685791  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:82.24%\t train set:87.82%\n","Epoch:8/50     Step:1|6   loss:0.7189452648162842  \n","Epoch:8/50     Step:2|6   loss:0.7593604922294617  \n","Epoch:8/50     Step:3|6   loss:0.6427080631256104  \n","Epoch:8/50     Step:4|6   loss:0.6962447166442871  \n","Epoch:8/50     Step:5|6   loss:0.7193900346755981  \n","Epoch:8/50     Step:6|6   loss:0.6695702075958252  \n","Epoch:8/50     Step:7|6   loss:0.6999351978302002  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:82.24%\t train set:87.82%\n","Epoch:9/50     Step:1|6   loss:0.7067930102348328  \n","Epoch:9/50     Step:2|6   loss:0.6314020156860352  \n","Epoch:9/50     Step:3|6   loss:0.6421565413475037  \n","Epoch:9/50     Step:4|6   loss:0.678958535194397  \n","Epoch:9/50     Step:5|6   loss:0.7097855806350708  \n","Epoch:9/50     Step:6|6   loss:0.6451900005340576  \n","Epoch:9/50     Step:7|6   loss:0.7365429401397705  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:84.11%\t train set:90.87%\n","Epoch:10/50     Step:1|6   loss:0.6489188075065613  \n","Epoch:10/50     Step:2|6   loss:0.6713050007820129  \n","Epoch:10/50     Step:3|6   loss:0.667132556438446  \n","Epoch:10/50     Step:4|6   loss:0.657067060470581  \n","Epoch:10/50     Step:5|6   loss:0.6095642447471619  \n","Epoch:10/50     Step:6|6   loss:0.647919774055481  \n","Epoch:10/50     Step:7|6   loss:0.6365520358085632  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:84.11%\t train set:91.1%\n","Epoch:11/50     Step:1|6   loss:0.6705979108810425  \n","Epoch:11/50     Step:2|6   loss:0.6207118034362793  \n","Epoch:11/50     Step:3|6   loss:0.6316788196563721  \n","Epoch:11/50     Step:4|6   loss:0.5997501611709595  \n","Epoch:11/50     Step:5|6   loss:0.6565292477607727  \n","Epoch:11/50     Step:6|6   loss:0.628855288028717  \n","Epoch:11/50     Step:7|6   loss:0.6607555747032166  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:86.92%\t train set:92.97%\n","Epoch:12/50     Step:1|6   loss:0.6848222017288208  \n","Epoch:12/50     Step:2|6   loss:0.619577944278717  \n","Epoch:12/50     Step:3|6   loss:0.6072515249252319  \n","Epoch:12/50     Step:4|6   loss:0.6400516033172607  \n","Epoch:12/50     Step:5|6   loss:0.614412784576416  \n","Epoch:12/50     Step:6|6   loss:0.6032226085662842  \n","Epoch:12/50     Step:7|6   loss:0.6172925233840942  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:86.92%\t train set:93.44%\n","Epoch:13/50     Step:1|6   loss:0.6351134181022644  \n","Epoch:13/50     Step:2|6   loss:0.6661874651908875  \n","Epoch:13/50     Step:3|6   loss:0.611621618270874  \n","Epoch:13/50     Step:4|6   loss:0.6069574952125549  \n","Epoch:13/50     Step:5|6   loss:0.6217597723007202  \n","Epoch:13/50     Step:6|6   loss:0.611693263053894  \n","Epoch:13/50     Step:7|6   loss:0.6326009035110474  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:86.92%\t train set:95.78%\n","Epoch:14/50     Step:1|6   loss:0.5888128876686096  \n","Epoch:14/50     Step:2|6   loss:0.6255534887313843  \n","Epoch:14/50     Step:3|6   loss:0.6304944753646851  \n","Epoch:14/50     Step:4|6   loss:0.5879224538803101  \n","Epoch:14/50     Step:5|6   loss:0.6310672163963318  \n","Epoch:14/50     Step:6|6   loss:0.6810173988342285  \n","Epoch:14/50     Step:7|6   loss:0.6588857769966125  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:86.92%\t train set:95.78%\n","Epoch:15/50     Step:1|6   loss:0.6291992664337158  \n","Epoch:15/50     Step:2|6   loss:0.6381667256355286  \n","Epoch:15/50     Step:3|6   loss:0.6319615840911865  \n","Epoch:15/50     Step:4|6   loss:0.6431479454040527  \n","Epoch:15/50     Step:5|6   loss:0.6620283722877502  \n","Epoch:15/50     Step:6|6   loss:0.584307074546814  \n","Epoch:15/50     Step:7|6   loss:0.7280502319335938  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:87.85%\t train set:96.72%\n","Epoch:16/50     Step:1|6   loss:0.5843292474746704  \n","Epoch:16/50     Step:2|6   loss:0.6739047169685364  \n","Epoch:16/50     Step:3|6   loss:0.6100588440895081  \n","Epoch:16/50     Step:4|6   loss:0.6115404367446899  \n","Epoch:16/50     Step:5|6   loss:0.6300153136253357  \n","Epoch:16/50     Step:6|6   loss:0.6647416949272156  \n","Epoch:16/50     Step:7|6   loss:0.6105080246925354  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:87.85%\t train set:96.72%\n","Epoch:17/50     Step:1|6   loss:0.7013638019561768  \n","Epoch:17/50     Step:2|6   loss:0.5809242725372314  \n","Epoch:17/50     Step:3|6   loss:0.6365431547164917  \n","Epoch:17/50     Step:4|6   loss:0.5746753215789795  \n","Epoch:17/50     Step:5|6   loss:0.6366925239562988  \n","Epoch:17/50     Step:6|6   loss:0.591141402721405  \n","Epoch:17/50     Step:7|6   loss:0.5819858312606812  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:87.85%\t train set:96.72%\n","Epoch:18/50     Step:1|6   loss:0.5788761377334595  \n","Epoch:18/50     Step:2|6   loss:0.6525373458862305  \n","Epoch:18/50     Step:3|6   loss:0.6052751541137695  \n","Epoch:18/50     Step:4|6   loss:0.5795472860336304  \n","Epoch:18/50     Step:5|6   loss:0.5856449604034424  \n","Epoch:18/50     Step:6|6   loss:0.5989733934402466  \n","Epoch:18/50     Step:7|6   loss:0.6050131320953369  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:89.72%\t train set:96.96%\n","Epoch:19/50     Step:1|6   loss:0.5993839502334595  \n","Epoch:19/50     Step:2|6   loss:0.6116816401481628  \n","Epoch:19/50     Step:3|6   loss:0.5802209377288818  \n","Epoch:19/50     Step:4|6   loss:0.587357223033905  \n","Epoch:19/50     Step:5|6   loss:0.5673951506614685  \n","Epoch:19/50     Step:6|6   loss:0.5964576005935669  \n","Epoch:19/50     Step:7|6   loss:0.5800305008888245  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:89.72%\t train set:97.19%\n","Epoch:20/50     Step:1|6   loss:0.5865248441696167  \n","Epoch:20/50     Step:2|6   loss:0.5879564881324768  \n","Epoch:20/50     Step:3|6   loss:0.567489504814148  \n","Epoch:20/50     Step:4|6   loss:0.5962553024291992  \n","Epoch:20/50     Step:5|6   loss:0.6089677214622498  \n","Epoch:20/50     Step:6|6   loss:0.5925137400627136  \n","Epoch:20/50     Step:7|6   loss:0.559057891368866  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:89.72%\t train set:97.19%\n","Epoch:21/50     Step:1|6   loss:0.5958170890808105  \n","Epoch:21/50     Step:2|6   loss:0.5819211006164551  \n","Epoch:21/50     Step:3|6   loss:0.6030077934265137  \n","Epoch:21/50     Step:4|6   loss:0.543504536151886  \n","Epoch:21/50     Step:5|6   loss:0.5681319832801819  \n","Epoch:21/50     Step:6|6   loss:0.5484985709190369  \n","Epoch:21/50     Step:7|6   loss:0.5817800164222717  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:89.72%\t train set:97.66%\n","Epoch:22/50     Step:1|6   loss:0.561755895614624  \n","Epoch:22/50     Step:2|6   loss:0.5914661884307861  \n","Epoch:22/50     Step:3|6   loss:0.5689801573753357  \n","Epoch:22/50     Step:4|6   loss:0.5724241137504578  \n","Epoch:22/50     Step:5|6   loss:0.5467727184295654  \n","Epoch:22/50     Step:6|6   loss:0.5918675661087036  \n","Epoch:22/50     Step:7|6   loss:0.5585865378379822  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:89.72%\t train set:97.66%\n","Epoch:23/50     Step:1|6   loss:0.5766313076019287  \n","Epoch:23/50     Step:2|6   loss:0.541947603225708  \n","Epoch:23/50     Step:3|6   loss:0.5727358460426331  \n","Epoch:23/50     Step:4|6   loss:0.5747658014297485  \n","Epoch:23/50     Step:5|6   loss:0.5924541354179382  \n","Epoch:23/50     Step:6|6   loss:0.5741828680038452  \n","Epoch:23/50     Step:7|6   loss:0.5864576697349548  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:89.72%\t train set:97.66%\n","Epoch:24/50     Step:1|6   loss:0.5459827184677124  \n","Epoch:24/50     Step:2|6   loss:0.6182671189308167  \n","Epoch:24/50     Step:3|6   loss:0.6092020273208618  \n","Epoch:24/50     Step:4|6   loss:0.5840713381767273  \n","Epoch:24/50     Step:5|6   loss:0.65016108751297  \n","Epoch:24/50     Step:6|6   loss:0.5782099962234497  \n","Epoch:24/50     Step:7|6   loss:0.6214398145675659  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:90.65%\t train set:98.36%\n","Epoch:25/50     Step:1|6   loss:0.5763513445854187  \n","Epoch:25/50     Step:2|6   loss:0.551414966583252  \n","Epoch:25/50     Step:3|6   loss:0.66009521484375  \n","Epoch:25/50     Step:4|6   loss:0.5590060949325562  \n","Epoch:25/50     Step:5|6   loss:0.6269845366477966  \n","Epoch:25/50     Step:6|6   loss:0.5912914276123047  \n","Epoch:25/50     Step:7|6   loss:0.6126711964607239  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:90.65%\t train set:98.36%\n","Epoch:26/50     Step:1|6   loss:0.6039143800735474  \n","Epoch:26/50     Step:2|6   loss:0.5841265916824341  \n","Epoch:26/50     Step:3|6   loss:0.5667818784713745  \n","Epoch:26/50     Step:4|6   loss:0.5788587927818298  \n","Epoch:26/50     Step:5|6   loss:0.5842099785804749  \n","Epoch:26/50     Step:6|6   loss:0.6189717054367065  \n","Epoch:26/50     Step:7|6   loss:0.5687222480773926  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:27/50     Step:1|6   loss:0.5550787448883057  \n","Epoch:27/50     Step:2|6   loss:0.578814685344696  \n","Epoch:27/50     Step:3|6   loss:0.5605705976486206  \n","Epoch:27/50     Step:4|6   loss:0.555391788482666  \n","Epoch:27/50     Step:5|6   loss:0.5627959966659546  \n","Epoch:27/50     Step:6|6   loss:0.5592156648635864  \n","Epoch:27/50     Step:7|6   loss:0.5853262543678284  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:28/50     Step:1|6   loss:0.5572870969772339  \n","Epoch:28/50     Step:2|6   loss:0.571819007396698  \n","Epoch:28/50     Step:3|6   loss:0.590307354927063  \n","Epoch:28/50     Step:4|6   loss:0.6063270568847656  \n","Epoch:28/50     Step:5|6   loss:0.5981414318084717  \n","Epoch:28/50     Step:6|6   loss:0.5812492966651917  \n","Epoch:28/50     Step:7|6   loss:0.6101451516151428  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:29/50     Step:1|6   loss:0.5470362305641174  \n","Epoch:29/50     Step:2|6   loss:0.610939085483551  \n","Epoch:29/50     Step:3|6   loss:0.554866373538971  \n","Epoch:29/50     Step:4|6   loss:0.5412772297859192  \n","Epoch:29/50     Step:5|6   loss:0.559590220451355  \n","Epoch:29/50     Step:6|6   loss:0.5461496114730835  \n","Epoch:29/50     Step:7|6   loss:0.5598989725112915  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:90.65%\t train set:98.83%\n","Epoch:30/50     Step:1|6   loss:0.5501466393470764  \n","Epoch:30/50     Step:2|6   loss:0.5843637585639954  \n","Epoch:30/50     Step:3|6   loss:0.541721761226654  \n","Epoch:30/50     Step:4|6   loss:0.610119104385376  \n","Epoch:30/50     Step:5|6   loss:0.5396029949188232  \n","Epoch:30/50     Step:6|6   loss:0.6215882897377014  \n","Epoch:30/50     Step:7|6   loss:0.5476319193840027  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:90.65%\t train set:98.83%\n","Epoch:31/50     Step:1|6   loss:0.5421196818351746  \n","Epoch:31/50     Step:2|6   loss:0.6092059016227722  \n","Epoch:31/50     Step:3|6   loss:0.5511986017227173  \n","Epoch:31/50     Step:4|6   loss:0.5431293845176697  \n","Epoch:31/50     Step:5|6   loss:0.5676571726799011  \n","Epoch:31/50     Step:6|6   loss:0.5575722455978394  \n","Epoch:31/50     Step:7|6   loss:0.5951272249221802  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:32/50     Step:1|6   loss:0.5729014873504639  \n","Epoch:32/50     Step:2|6   loss:0.5563018321990967  \n","Epoch:32/50     Step:3|6   loss:0.5791298747062683  \n","Epoch:32/50     Step:4|6   loss:0.5589337348937988  \n","Epoch:32/50     Step:5|6   loss:0.5464298129081726  \n","Epoch:32/50     Step:6|6   loss:0.5571005344390869  \n","Epoch:32/50     Step:7|6   loss:0.5254876613616943  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.42 %2\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:33/50     Step:1|6   loss:0.5444920063018799  \n","Epoch:33/50     Step:2|6   loss:0.5517053604125977  \n","Epoch:33/50     Step:3|6   loss:0.5605911016464233  \n","Epoch:33/50     Step:4|6   loss:0.5694999098777771  \n","Epoch:33/50     Step:5|6   loss:0.5869441628456116  \n","Epoch:33/50     Step:6|6   loss:0.5859798789024353  \n","Epoch:33/50     Step:7|6   loss:0.5931438207626343  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:34/50     Step:1|6   loss:0.5485012531280518  \n","Epoch:34/50     Step:2|6   loss:0.5753878355026245  \n","Epoch:34/50     Step:3|6   loss:0.5307580828666687  \n","Epoch:34/50     Step:4|6   loss:0.5670129656791687  \n","Epoch:34/50     Step:5|6   loss:0.5503504276275635  \n","Epoch:34/50     Step:6|6   loss:0.5500232577323914  \n","Epoch:34/50     Step:7|6   loss:0.5392135977745056  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.3%\n","Epoch:35/50     Step:1|6   loss:0.5566267371177673  \n","Epoch:35/50     Step:2|6   loss:0.5340055227279663  \n","Epoch:35/50     Step:3|6   loss:0.5567263960838318  \n","Epoch:35/50     Step:4|6   loss:0.5542188286781311  \n","Epoch:35/50     Step:5|6   loss:0.5429768562316895  \n","Epoch:35/50     Step:6|6   loss:0.5461699366569519  \n","Epoch:35/50     Step:7|6   loss:0.5294630527496338  \n","Accuracy on test_set: 89.72 %\n","\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:90.65%\t train set:99.3%\n","Epoch:36/50     Step:1|6   loss:0.5780178904533386  \n","Epoch:36/50     Step:2|6   loss:0.5355954170227051  \n","Epoch:36/50     Step:3|6   loss:0.5419226884841919  \n","Epoch:36/50     Step:4|6   loss:0.5433023571968079  \n","Epoch:36/50     Step:5|6   loss:0.5455369353294373  \n","Epoch:36/50     Step:6|6   loss:0.5585196018218994  \n","Epoch:36/50     Step:7|6   loss:0.529367208480835  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.3%\n","Epoch:37/50     Step:1|6   loss:0.5598942041397095  \n","Epoch:37/50     Step:2|6   loss:0.5717304944992065  \n","Epoch:37/50     Step:3|6   loss:0.555167555809021  \n","Epoch:37/50     Step:4|6   loss:0.5358455777168274  \n","Epoch:37/50     Step:5|6   loss:0.5507596731185913  \n","Epoch:37/50     Step:6|6   loss:0.52518230676651  \n","Epoch:37/50     Step:7|6   loss:0.5416796803474426  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:38/50     Step:1|6   loss:0.5575767755508423  \n","Epoch:38/50     Step:2|6   loss:0.5657779574394226  \n","Epoch:38/50     Step:3|6   loss:0.5383338332176208  \n","Epoch:38/50     Step:4|6   loss:0.5489012598991394  \n","Epoch:38/50     Step:5|6   loss:0.5440698862075806  \n","Epoch:38/50     Step:6|6   loss:0.5399953722953796  \n","Epoch:38/50     Step:7|6   loss:0.5365502238273621  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:39/50     Step:1|6   loss:0.5699441432952881  \n","Epoch:39/50     Step:2|6   loss:0.554547131061554  \n","Epoch:39/50     Step:3|6   loss:0.5456068515777588  \n","Epoch:39/50     Step:4|6   loss:0.5641230344772339  \n","Epoch:39/50     Step:5|6   loss:0.5394930243492126  \n","Epoch:39/50     Step:6|6   loss:0.5673284530639648  \n","Epoch:39/50     Step:7|6   loss:0.5537797212600708  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:40/50     Step:1|6   loss:0.5698501467704773  \n","Epoch:40/50     Step:2|6   loss:0.5475457310676575  \n","Epoch:40/50     Step:3|6   loss:0.5283558368682861  \n","Epoch:40/50     Step:4|6   loss:0.5833010077476501  \n","Epoch:40/50     Step:5|6   loss:0.532819390296936  \n","Epoch:40/50     Step:6|6   loss:0.579852283000946  \n","Epoch:40/50     Step:7|6   loss:0.5498236417770386  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:41/50     Step:1|6   loss:0.5412194728851318  \n","Epoch:41/50     Step:2|6   loss:0.552276074886322  \n","Epoch:41/50     Step:3|6   loss:0.5366056561470032  \n","Epoch:41/50     Step:4|6   loss:0.5409752726554871  \n","Epoch:41/50     Step:5|6   loss:0.5489103198051453  \n","Epoch:41/50     Step:6|6   loss:0.5468644499778748  \n","Epoch:41/50     Step:7|6   loss:0.5206689834594727  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:42/50     Step:1|6   loss:0.5697454214096069  \n","Epoch:42/50     Step:2|6   loss:0.5149497985839844  \n","Epoch:42/50     Step:3|6   loss:0.5389431715011597  \n","Epoch:42/50     Step:4|6   loss:0.5544745922088623  \n","Epoch:42/50     Step:5|6   loss:0.5247182250022888  \n","Epoch:42/50     Step:6|6   loss:0.5540998578071594  \n","Epoch:42/50     Step:7|6   loss:0.5408627986907959  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:43/50     Step:1|6   loss:0.5444584488868713  \n","Epoch:43/50     Step:2|6   loss:0.5326658487319946  \n","Epoch:43/50     Step:3|6   loss:0.5159199833869934  \n","Epoch:43/50     Step:4|6   loss:0.5660973191261292  \n","Epoch:43/50     Step:5|6   loss:0.5262084007263184  \n","Epoch:43/50     Step:6|6   loss:0.5419219732284546  \n","Epoch:43/50     Step:7|6   loss:0.517665445804596  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:44/50     Step:1|6   loss:0.5356907844543457  \n","Epoch:44/50     Step:2|6   loss:0.5421966314315796  \n","Epoch:44/50     Step:3|6   loss:0.530086100101471  \n","Epoch:44/50     Step:4|6   loss:0.5362463593482971  \n","Epoch:44/50     Step:5|6   loss:0.5233349800109863  \n","Epoch:44/50     Step:6|6   loss:0.5307146906852722  \n","Epoch:44/50     Step:7|6   loss:0.54549640417099  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:45/50     Step:1|6   loss:0.5194571614265442  \n","Epoch:45/50     Step:2|6   loss:0.5322055816650391  \n","Epoch:45/50     Step:3|6   loss:0.5182235240936279  \n","Epoch:45/50     Step:4|6   loss:0.5232138633728027  \n","Epoch:45/50     Step:5|6   loss:0.52366042137146  \n","Epoch:45/50     Step:6|6   loss:0.5260132551193237  \n","Epoch:45/50     Step:7|6   loss:0.5286950469017029  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:46/50     Step:1|6   loss:0.5408932566642761  \n","Epoch:46/50     Step:2|6   loss:0.5342327952384949  \n","Epoch:46/50     Step:3|6   loss:0.5206509828567505  \n","Epoch:46/50     Step:4|6   loss:0.5518657565116882  \n","Epoch:46/50     Step:5|6   loss:0.5198668241500854  \n","Epoch:46/50     Step:6|6   loss:0.5586771368980408  \n","Epoch:46/50     Step:7|6   loss:0.5201998949050903  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:47/50     Step:1|6   loss:0.5348612666130066  \n","Epoch:47/50     Step:2|6   loss:0.5297496318817139  \n","Epoch:47/50     Step:3|6   loss:0.5145442485809326  \n","Epoch:47/50     Step:4|6   loss:0.5435189008712769  \n","Epoch:47/50     Step:5|6   loss:0.5241507291793823  \n","Epoch:47/50     Step:6|6   loss:0.5440536737442017  \n","Epoch:47/50     Step:7|6   loss:0.5185478925704956  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:48/50     Step:1|6   loss:0.5245280861854553  \n","Epoch:48/50     Step:2|6   loss:0.5318876504898071  \n","Epoch:48/50     Step:3|6   loss:0.5154880881309509  \n","Epoch:48/50     Step:4|6   loss:0.5287989377975464  \n","Epoch:48/50     Step:5|6   loss:0.5278527140617371  \n","Epoch:48/50     Step:6|6   loss:0.5217376351356506  \n","Epoch:48/50     Step:7|6   loss:0.5121634006500244  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5200543403625488  \n","Epoch:49/50     Step:2|6   loss:0.5278018712997437  \n","Epoch:49/50     Step:3|6   loss:0.514110267162323  \n","Epoch:49/50     Step:4|6   loss:0.5293183326721191  \n","Epoch:49/50     Step:5|6   loss:0.5176572799682617  \n","Epoch:49/50     Step:6|6   loss:0.5254780650138855  \n","Epoch:49/50     Step:7|6   loss:0.5273460149765015  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.531765341758728  \n","Epoch:50/50     Step:2|6   loss:0.5191342234611511  \n","Epoch:50/50     Step:3|6   loss:0.5286443829536438  \n","Epoch:50/50     Step:4|6   loss:0.5138146877288818  \n","Epoch:50/50     Step:5|6   loss:0.5425509810447693  \n","Epoch:50/50     Step:6|6   loss:0.5446743369102478  \n","Epoch:50/50     Step:7|6   loss:0.5132748484611511  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Accuracy on test_set: 89.72 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1354689598083496  \n","Epoch:1/50     Step:2|6   loss:5.496783256530762  \n","Epoch:1/50     Step:3|6   loss:6.568032264709473  \n","Epoch:1/50     Step:4|6   loss:4.25602912902832  \n","Epoch:1/50     Step:5|6   loss:2.691864013671875  \n","Epoch:1/50     Step:6|6   loss:6.985945701599121  \n","Epoch:1/50     Step:7|6   loss:8.535400390625  \n","Accuracy on test_set: 24.30 %\n","Accuracy on train_set: 29.04 %\n","current max accuracy\t test set:24.3%\t train set:29.04%\n","Epoch:2/50     Step:1|6   loss:4.277951240539551  \n","Epoch:2/50     Step:2|6   loss:1.4272273778915405  \n","Epoch:2/50     Step:3|6   loss:2.610910415649414  \n","Epoch:2/50     Step:4|6   loss:4.340487480163574  \n","Epoch:2/50     Step:5|6   loss:4.88625431060791  \n","Epoch:2/50     Step:6|6   loss:6.315380096435547  \n","Epoch:2/50     Step:7|6   loss:4.267199516296387  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 57.61 %\n","current max accuracy\t test set:64.49%\t train set:57.61%\n","Epoch:3/50     Step:1|6   loss:3.633340835571289  \n","Epoch:3/50     Step:2|6   loss:2.437934637069702  \n","Epoch:3/50     Step:3|6   loss:1.2600646018981934  \n","Epoch:3/50     Step:4|6   loss:1.6186492443084717  \n","Epoch:3/50     Step:5|6   loss:2.758650541305542  \n","Epoch:3/50     Step:6|6   loss:2.337233781814575  \n","Epoch:3/50     Step:7|6   loss:1.0263370275497437  \n","Accuracy on test_set: 66.36 %\n","Accuracy on train_set: 56.21 %\n","current max accuracy\t test set:66.36%\t train set:57.61%\n","Epoch:4/50     Step:1|6   loss:1.2566165924072266  \n","Epoch:4/50     Step:2|6   loss:1.663865566253662  \n","Epoch:4/50     Step:3|6   loss:2.0737569332122803  \n","Epoch:4/50     Step:4|6   loss:1.9690849781036377  \n","Epoch:4/50     Step:5|6   loss:1.6527646780014038  \n","Epoch:4/50     Step:6|6   loss:1.0966477394104004  \n","Epoch:4/50     Step:7|6   loss:1.2247116565704346  \n","Accuracy on test_set: 41.12 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:66.36%\t train set:57.61%\n","Epoch:5/50     Step:1|6   loss:1.6843464374542236  \n","Epoch:5/50     Step:2|6   loss:1.51458740234375  \n","Epoch:5/50     Step:3|6   loss:1.1164469718933105  \n","Epoch:5/50     Step:4|6   loss:1.0984089374542236  \n","Epoch:5/50     Step:5|6   loss:1.1479086875915527  \n","Epoch:5/50     Step:6|6   loss:1.6599918603897095  \n","Epoch:5/50     Step:7|6   loss:1.070288896560669  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 76.58 %\n","current max accuracy\t test set:81.31%\t train set:76.58%\n","Epoch:6/50     Step:1|6   loss:0.8925571441650391  \n","Epoch:6/50     Step:2|6   loss:0.9756389856338501  \n","Epoch:6/50     Step:3|6   loss:1.3210172653198242  \n","Epoch:6/50     Step:4|6   loss:0.9282565116882324  \n","Epoch:6/50     Step:5|6   loss:0.9122682809829712  \n","Epoch:6/50     Step:6|6   loss:0.8976298570632935  \n","Epoch:6/50     Step:7|6   loss:0.8265283703804016  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:85.98%\t train set:83.37%\n","Epoch:7/50     Step:1|6   loss:0.8233370780944824  \n","Epoch:7/50     Step:2|6   loss:0.7704311609268188  \n","Epoch:7/50     Step:3|6   loss:0.7623982429504395  \n","Epoch:7/50     Step:4|6   loss:0.7939728498458862  \n","Epoch:7/50     Step:5|6   loss:0.6883671879768372  \n","Epoch:7/50     Step:6|6   loss:0.7486779093742371  \n","Epoch:7/50     Step:7|6   loss:0.7823259830474854  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:85.98%\t train set:89.23%\n","Epoch:8/50     Step:1|6   loss:0.7162205576896667  \n","Epoch:8/50     Step:2|6   loss:0.6626236438751221  \n","Epoch:8/50     Step:3|6   loss:0.6990342736244202  \n","Epoch:8/50     Step:4|6   loss:0.6549955606460571  \n","Epoch:8/50     Step:5|6   loss:0.6528691053390503  \n","Epoch:8/50     Step:6|6   loss:0.7477772235870361  \n","Epoch:8/50     Step:7|6   loss:0.6948446035385132  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:85.98%\t train set:91.33%\n","Epoch:9/50     Step:1|6   loss:0.6407315731048584  \n","Epoch:9/50     Step:2|6   loss:0.6405796408653259  \n","Epoch:9/50     Step:3|6   loss:0.717025876045227  \n","Epoch:9/50     Step:4|6   loss:0.6853317022323608  \n","Epoch:9/50     Step:5|6   loss:0.626737117767334  \n","Epoch:9/50     Step:6|6   loss:0.6596141457557678  \n","Epoch:9/50     Step:7|6   loss:0.6412949562072754  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:87.85%\t train set:91.57%\n","Epoch:10/50     Step:1|6   loss:0.6849427223205566  \n","Epoch:10/50     Step:2|6   loss:0.6309740543365479  \n","Epoch:10/50     Step:3|6   loss:0.6735310554504395  \n","Epoch:10/50     Step:4|6   loss:0.6550488471984863  \n","Epoch:10/50     Step:5|6   loss:0.6641347408294678  \n","Epoch:10/50     Step:6|6   loss:0.5963387489318848  \n","Epoch:10/50     Step:7|6   loss:0.6882274150848389  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:87.85%\t train set:91.57%\n","Epoch:11/50     Step:1|6   loss:0.6763587594032288  \n","Epoch:11/50     Step:2|6   loss:0.7100473642349243  \n","Epoch:11/50     Step:3|6   loss:0.6251958012580872  \n","Epoch:11/50     Step:4|6   loss:0.6264902353286743  \n","Epoch:11/50     Step:5|6   loss:0.6234056949615479  \n","Epoch:11/50     Step:6|6   loss:0.6630094647407532  \n","Epoch:11/50     Step:7|6   loss:0.6931053996086121  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:87.85%\t train set:91.57%\n","Epoch:12/50     Step:1|6   loss:0.6478754281997681  \n","Epoch:12/50     Step:2|6   loss:0.7021325826644897  \n","Epoch:12/50     Step:3|6   loss:0.6091620922088623  \n","Epoch:12/50     Step:4|6   loss:0.6626436710357666  \n","Epoch:12/50     Step:5|6   loss:0.6522215604782104  \n","Epoch:12/50     Step:6|6   loss:0.6204158067703247  \n","Epoch:12/50     Step:7|6   loss:0.6402232646942139  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:87.85%\t train set:91.57%\n","Epoch:13/50     Step:1|6   loss:0.6766138076782227  \n","Epoch:13/50     Step:2|6   loss:0.6265898942947388  \n","Epoch:13/50     Step:3|6   loss:0.6297553777694702  \n","Epoch:13/50     Step:4|6   loss:0.5859461426734924  \n","Epoch:13/50     Step:5|6   loss:0.6152998208999634  \n","Epoch:13/50     Step:6|6   loss:0.6148618459701538  \n","Epoch:13/50     Step:7|6   loss:0.6579288840293884  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:87.85%\t train set:93.44%\n","Epoch:14/50     Step:1|6   loss:0.5891401767730713  \n","Epoch:14/50     Step:2|6   loss:0.6127547025680542  \n","Epoch:14/50     Step:3|6   loss:0.6135061383247375  \n","Epoch:14/50     Step:4|6   loss:0.6614820957183838  \n","Epoch:14/50     Step:5|6   loss:0.6910122036933899  \n","Epoch:14/50     Step:6|6   loss:0.6962364315986633  \n","Epoch:14/50     Step:7|6   loss:0.5649634599685669  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 87.82 %\n","3\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:87.85%\t train set:93.44%\n","Epoch:15/50     Step:1|6   loss:0.6938918828964233  \n","Epoch:15/50     Step:2|6   loss:0.59926837682724  \n","Epoch:15/50     Step:3|6   loss:0.6211406588554382  \n","Epoch:15/50     Step:4|6   loss:0.6365813612937927  \n","Epoch:15/50     Step:5|6   loss:0.6682778596878052  \n","Epoch:15/50     Step:6|6   loss:0.6164410710334778  \n","Epoch:15/50     Step:7|6   loss:0.5758209824562073  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:87.85%\t train set:93.44%\n","Epoch:16/50     Step:1|6   loss:0.6247636675834656  \n","Epoch:16/50     Step:2|6   loss:0.6176198720932007  \n","Epoch:16/50     Step:3|6   loss:0.6253758668899536  \n","Epoch:16/50     Step:4|6   loss:0.6192798018455505  \n","Epoch:16/50     Step:5|6   loss:0.5574676990509033  \n","Epoch:16/50     Step:6|6   loss:0.6251863837242126  \n","Epoch:16/50     Step:7|6   loss:0.5772619247436523  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:90.65%\t train set:97.66%\n","Epoch:17/50     Step:1|6   loss:0.5842843651771545  \n","Epoch:17/50     Step:2|6   loss:0.5665620565414429  \n","Epoch:17/50     Step:3|6   loss:0.59581458568573  \n","Epoch:17/50     Step:4|6   loss:0.5905284881591797  \n","Epoch:17/50     Step:5|6   loss:0.6157811880111694  \n","Epoch:17/50     Step:6|6   loss:0.5649622678756714  \n","Epoch:17/50     Step:7|6   loss:0.6128255128860474  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:91.59%\t train set:97.66%\n","Epoch:18/50     Step:1|6   loss:0.5859447717666626  \n","Epoch:18/50     Step:2|6   loss:0.5859599113464355  \n","Epoch:18/50     Step:3|6   loss:0.5763158202171326  \n","Epoch:18/50     Step:4|6   loss:0.5861221551895142  \n","Epoch:18/50     Step:5|6   loss:0.5745729804039001  \n","Epoch:18/50     Step:6|6   loss:0.6077785491943359  \n","Epoch:18/50     Step:7|6   loss:0.6372199058532715  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:91.59%\t train set:97.89%\n","Epoch:19/50     Step:1|6   loss:0.5785191655158997  \n","Epoch:19/50     Step:2|6   loss:0.5822531580924988  \n","Epoch:19/50     Step:3|6   loss:0.5464642643928528  \n","Epoch:19/50     Step:4|6   loss:0.5919881463050842  \n","Epoch:19/50     Step:5|6   loss:0.5885177850723267  \n","Epoch:19/50     Step:6|6   loss:0.5938888788223267  \n","Epoch:19/50     Step:7|6   loss:0.6359865665435791  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:91.59%\t train set:97.89%\n","Epoch:20/50     Step:1|6   loss:0.5856873989105225  \n","Epoch:20/50     Step:2|6   loss:0.5759885907173157  \n","Epoch:20/50     Step:3|6   loss:0.5855028629302979  \n","Epoch:20/50     Step:4|6   loss:0.59172123670578  \n","Epoch:20/50     Step:5|6   loss:0.5854447484016418  \n","Epoch:20/50     Step:6|6   loss:0.6058210134506226  \n","Epoch:20/50     Step:7|6   loss:0.573569118976593  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:91.59%\t train set:97.89%\n","Epoch:21/50     Step:1|6   loss:0.6454260945320129  \n","Epoch:21/50     Step:2|6   loss:0.5699303150177002  \n","Epoch:21/50     Step:3|6   loss:0.6179465651512146  \n","Epoch:21/50     Step:4|6   loss:0.5912534594535828  \n","Epoch:21/50     Step:5|6   loss:0.5656498074531555  \n","Epoch:21/50     Step:6|6   loss:0.6119853258132935  \n","Epoch:21/50     Step:7|6   loss:0.5665011405944824  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:91.59%\t train set:98.59%\n","Epoch:22/50     Step:1|6   loss:0.5413863658905029  \n","Epoch:22/50     Step:2|6   loss:0.5947827100753784  \n","Epoch:22/50     Step:3|6   loss:0.6098902225494385  \n","Epoch:22/50     Step:4|6   loss:0.5680981874465942  \n","Epoch:22/50     Step:5|6   loss:0.5759379267692566  \n","Epoch:22/50     Step:6|6   loss:0.5903950929641724  \n","Epoch:22/50     Step:7|6   loss:0.5795373916625977  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:91.59%\t train set:98.59%\n","Epoch:23/50     Step:1|6   loss:0.5645246505737305  \n","Epoch:23/50     Step:2|6   loss:0.5932453870773315  \n","Epoch:23/50     Step:3|6   loss:0.5873405337333679  \n","Epoch:23/50     Step:4|6   loss:0.609241247177124  \n","Epoch:23/50     Step:5|6   loss:0.5949341058731079  \n","Epoch:23/50     Step:6|6   loss:0.564281165599823  \n","Epoch:23/50     Step:7|6   loss:0.6119920015335083  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:91.59%\t train set:98.59%\n","Epoch:24/50     Step:1|6   loss:0.5805162787437439  \n","Epoch:24/50     Step:2|6   loss:0.5676825642585754  \n","Epoch:24/50     Step:3|6   loss:0.5928159952163696  \n","Epoch:24/50     Step:4|6   loss:0.5689441561698914  \n","Epoch:24/50     Step:5|6   loss:0.5524014234542847  \n","Epoch:24/50     Step:6|6   loss:0.5610693097114563  \n","Epoch:24/50     Step:7|6   loss:0.5779712200164795  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:91.59%\t train set:98.83%\n","Epoch:25/50     Step:1|6   loss:0.5794360041618347  \n","Epoch:25/50     Step:2|6   loss:0.5870923399925232  \n","Epoch:25/50     Step:3|6   loss:0.5752685070037842  \n","Epoch:25/50     Step:4|6   loss:0.5580201148986816  \n","Epoch:25/50     Step:5|6   loss:0.6270995140075684  \n","Epoch:25/50     Step:6|6   loss:0.5427223443984985  \n","Epoch:25/50     Step:7|6   loss:0.5972208976745605  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:91.59%\t train set:98.83%\n","Epoch:26/50     Step:1|6   loss:0.5691470503807068  \n","Epoch:26/50     Step:2|6   loss:0.5710146427154541  \n","Epoch:26/50     Step:3|6   loss:0.6074982285499573  \n","Epoch:26/50     Step:4|6   loss:0.5437924265861511  \n","Epoch:26/50     Step:5|6   loss:0.6233309507369995  \n","Epoch:26/50     Step:6|6   loss:0.5601011514663696  \n","Epoch:26/50     Step:7|6   loss:0.5803214907646179  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:91.59%\t train set:98.83%\n","Epoch:27/50     Step:1|6   loss:0.5663054585456848  \n","Epoch:27/50     Step:2|6   loss:0.5666572451591492  \n","Epoch:27/50     Step:3|6   loss:0.5630728006362915  \n","Epoch:27/50     Step:4|6   loss:0.5699913501739502  \n","Epoch:27/50     Step:5|6   loss:0.5584545135498047  \n","Epoch:27/50     Step:6|6   loss:0.5914793014526367  \n","Epoch:27/50     Step:7|6   loss:0.539313554763794  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:28/50     Step:1|6   loss:0.5750746726989746  \n","Epoch:28/50     Step:2|6   loss:0.5709234476089478  \n","Epoch:28/50     Step:3|6   loss:0.5439659357070923  \n","Epoch:28/50     Step:4|6   loss:0.5616070032119751  \n","Epoch:28/50     Step:5|6   loss:0.5682612061500549  \n","Epoch:28/50     Step:6|6   loss:0.5484933853149414  \n","Epoch:28/50     Step:7|6   loss:0.5700719356536865  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:29/50     Step:1|6   loss:0.5483793616294861  \n","Epoch:29/50     Step:2|6   loss:0.5488953590393066  \n","Epoch:29/50     Step:3|6   loss:0.5581437349319458  \n","Epoch:29/50     Step:4|6   loss:0.5654382705688477  \n","Epoch:29/50     Step:5|6   loss:0.5582631826400757  \n","Epoch:29/50     Step:6|6   loss:0.5499565005302429  \n","Epoch:29/50     Step:7|6   loss:0.5781923532485962  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:99.3%\n","Epoch:30/50     Step:1|6   loss:0.5480897426605225  \n","Epoch:30/50     Step:2|6   loss:0.5728280544281006  \n","Epoch:30/50     Step:3|6   loss:0.5749881863594055  \n","Epoch:30/50     Step:4|6   loss:0.5732045769691467  \n","Epoch:30/50     Step:5|6   loss:0.5482409596443176  \n","Epoch:30/50     Step:6|6   loss:0.5410998463630676  \n","Epoch:30/50     Step:7|6   loss:0.5684001445770264  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:31/50     Step:1|6   loss:0.543941855430603  \n","Epoch:31/50     Step:2|6   loss:0.618678092956543  \n","Epoch:31/50     Step:3|6   loss:0.5359351634979248  \n","Epoch:31/50     Step:4|6   loss:0.6026949882507324  \n","Epoch:31/50     Step:5|6   loss:0.5582162141799927  \n","Epoch:31/50     Step:6|6   loss:0.5529888868331909  \n","Epoch:31/50     Step:7|6   loss:0.5494667291641235  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:32/50     Step:1|6   loss:0.5384140610694885  \n","Epoch:32/50     Step:2|6   loss:0.5542196035385132  \n","Epoch:32/50     Step:3|6   loss:0.5291492342948914  \n","Epoch:32/50     Step:4|6   loss:0.5604579448699951  \n","Epoch:32/50     Step:5|6   loss:0.555260181427002  \n","Epoch:32/50     Step:6|6   loss:0.5688279867172241  \n","Epoch:32/50     Step:7|6   loss:0.5484263896942139  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:33/50     Step:1|6   loss:0.5487386584281921  \n","Epoch:33/50     Step:2|6   loss:0.5327516794204712  \n","Epoch:33/50     Step:3|6   loss:0.5483582019805908  \n","Epoch:33/50     Step:4|6   loss:0.5753522515296936  \n","Epoch:33/50     Step:5|6   loss:0.5497031807899475  \n","Epoch:33/50     Step:6|6   loss:0.570431113243103  \n","Epoch:33/50     Step:7|6   loss:0.5844266414642334  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:34/50     Step:1|6   loss:0.5814857482910156  \n","Epoch:34/50     Step:2|6   loss:0.5443931221961975  \n","Epoch:34/50     Step:3|6   loss:0.5571836233139038  \n","Epoch:34/50     Step:4|6   loss:0.5280603170394897  \n","Epoch:34/50     Step:5|6   loss:0.5728204846382141  \n","Epoch:34/50     Step:6|6   loss:0.5473095774650574  \n","Epoch:34/50     Step:7|6   loss:0.5448463559150696  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:35/50     Step:1|6   loss:0.5247988700866699  \n","Epoch:35/50     Step:2|6   loss:0.5683070421218872  \n","Epoch:35/50     Step:3|6   loss:0.5327673554420471  \n","Epoch:35/50     Step:4|6   loss:0.5532543659210205  \n","Epoch:35/50     Step:5|6   loss:0.5396068096160889  \n","Epoch:35/50     Step:6|6   loss:0.5705311298370361  \n","Epoch:35/50     Step:7|6   loss:0.5488694310188293  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.5468280911445618  \n","Epoch:36/50     Step:2|6   loss:0.5512145161628723  \n","Epoch:36/50     Step:3|6   loss:0.5466728806495667  \n","Epoch:36/50     Step:4|6   loss:0.5481843948364258  \n","Epoch:36/50     Step:5|6   loss:0.5358232259750366  \n","Epoch:36/50     Step:6|6   loss:0.5357645153999329  \n","Epoch:36/50     Step:7|6   loss:0.5665080547332764  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:99.77%\n","Epoch:37/50     Step:1|6   loss:0.5326364636421204  \n","Epoch:37/50     Step:2|6   loss:0.5513505935668945  \n","Epoch:37/50     Step:3|6   loss:0.5497504472732544  \n","Epoch:37/50     Step:4|6   loss:0.525513768196106  \n","Epoch:37/50     Step:5|6   loss:0.5802649855613708  \n","Epoch:37/50     Step:6|6   loss:0.5303431749343872  \n","Epoch:37/50     Step:7|6   loss:0.5362503528594971  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:92.52%\t train set:99.77%\n","Epoch:38/50     Step:1|6   loss:0.5452144145965576  \n","Epoch:38/50     Step:2|6   loss:0.5415648818016052  \n","Epoch:38/50     Step:3|6   loss:0.5480569005012512  \n","Epoch:38/50     Step:4|6   loss:0.5397064089775085  \n","Epoch:38/50     Step:5|6   loss:0.5522410869598389  \n","Epoch:38/50     Step:6|6   loss:0.5279825925827026  \n","Epoch:38/50     Step:7|6   loss:0.536554753780365  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.5238804817199707  \n","Epoch:39/50     Step:2|6   loss:0.5391106009483337  \n","Epoch:39/50     Step:3|6   loss:0.5380818843841553  \n","Epoch:39/50     Step:4|6   loss:0.5695237517356873  \n","Epoch:39/50     Step:5|6   loss:0.5212164521217346  \n","Epoch:39/50     Step:6|6   loss:0.5359410047531128  \n","Epoch:39/50     Step:7|6   loss:0.5469255447387695  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.5270923376083374  \n","Epoch:40/50     Step:2|6   loss:0.5312159061431885  \n","Epoch:40/50     Step:3|6   loss:0.5526610612869263  \n","Epoch:40/50     Step:4|6   loss:0.5526332259178162  \n","Epoch:40/50     Step:5|6   loss:0.5347616672515869  \n","Epoch:40/50     Step:6|6   loss:0.5598286390304565  \n","Epoch:40/50     Step:7|6   loss:0.5364199280738831  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.5444619655609131  \n","Epoch:41/50     Step:2|6   loss:0.5268955826759338  \n","Epoch:41/50     Step:3|6   loss:0.5224936008453369  \n","Epoch:41/50     Step:4|6   loss:0.5528391599655151  \n","Epoch:41/50     Step:5|6   loss:0.5366530418395996  \n","Epoch:41/50     Step:6|6   loss:0.5491616725921631  \n","Epoch:41/50     Step:7|6   loss:0.5222753882408142  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.5296423435211182  \n","Epoch:42/50     Step:2|6   loss:0.53803551197052  \n","Epoch:42/50     Step:3|6   loss:0.5404185056686401  \n","Epoch:42/50     Step:4|6   loss:0.5472663044929504  \n","Epoch:42/50     Step:5|6   loss:0.530351996421814  \n","Epoch:42/50     Step:6|6   loss:0.5354863405227661  \n","Epoch:42/50     Step:7|6   loss:0.5227597951889038  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.528103232383728  \n","Epoch:43/50     Step:2|6   loss:0.5572755932807922  \n","Epoch:43/50     Step:3|6   loss:0.5287944078445435  \n","Epoch:43/50     Step:4|6   loss:0.5522035360336304  \n","Epoch:43/50     Step:5|6   loss:0.5270586013793945  \n","Epoch:43/50     Step:6|6   loss:0.5671979784965515  \n","Epoch:43/50     Step:7|6   loss:0.529679536819458  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.526689887046814  \n","Epoch:44/50     Step:2|6   loss:0.5352997183799744  \n","Epoch:44/50     Step:3|6   loss:0.5329763293266296  \n","Epoch:44/50     Step:4|6   loss:0.5494566559791565  \n","Epoch:44/50     Step:5|6   loss:0.520649254322052  \n","Epoch:44/50     Step:6|6   loss:0.5658155679702759  \n","Epoch:44/50     Step:7|6   loss:0.528664231300354  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5475377440452576  \n","Epoch:45/50     Step:2|6   loss:0.5266295671463013  \n","Epoch:45/50     Step:3|6   loss:0.541411280632019  \n","Epoch:45/50     Step:4|6   loss:0.5188243985176086  \n","Epoch:45/50     Step:5|6   loss:0.5343105792999268  \n","Epoch:45/50     Step:6|6   loss:0.5370082855224609  \n","Epoch:45/50     Step:7|6   loss:0.5156876444816589  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5234503746032715  \n","Epoch:46/50     Step:2|6   loss:0.5399731397628784  \n","Epoch:46/50     Step:3|6   loss:0.5344665050506592  \n","Epoch:46/50     Step:4|6   loss:0.5297911763191223  \n","Epoch:46/50     Step:5|6   loss:0.5451954007148743  \n","Epoch:46/50     Step:6|6   loss:0.5311824679374695  \n","Epoch:46/50     Step:7|6   loss:0.5333144068717957  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5310167074203491  \n","Epoch:47/50     Step:2|6   loss:0.5251003503799438  \n","Epoch:47/50     Step:3|6   loss:0.5436776876449585  \n","Epoch:47/50     Step:4|6   loss:0.5221061706542969  \n","Epoch:47/50     Step:5|6   loss:0.5778399705886841  \n","Epoch:47/50     Step:6|6   loss:0.5254666805267334  \n","Epoch:47/50     Step:7|6   loss:0.5627046227455139  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.5173998475074768  \n","Epoch:48/50     Step:2|6   loss:0.5243433117866516  \n","Epoch:48/50     Step:3|6   loss:0.5268667340278625  \n","Epoch:48/50     Step:4|6   loss:0.5499556064605713  \n","Epoch:48/50     Step:5|6   loss:0.5279517769813538  \n","Epoch:48/50     Step:6|6   loss:0.5450373888015747  \n","Epoch:48/50     Step:7|6   loss:0.5297232866287231  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5366096496582031  \n","Epoch:49/50     Step:2|6   loss:0.5264068841934204  \n","Epoch:49/50     Step:3|6   loss:0.5523189306259155  \n","Epoch:49/50     Step:4|6   loss:0.5285094976425171  \n","Epoch:49/50     Step:5|6   loss:0.5639395713806152  \n","Epoch:49/50     Step:6|6   loss:0.5328208208084106  \n","Epoch:49/50     Step:7|6   loss:0.5506068468093872  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5422358512878418  \n","Epoch:50/50     Step:2|6   loss:0.5357915759086609  \n","Epoch:50/50     Step:3|6   loss:0.5476560592651367  \n","Epoch:50/50     Step:4|6   loss:0.5172616243362427  \n","Epoch:50/50     Step:5|6   loss:0.5327730774879456  \n","Epoch:50/50     Step:6|6   loss:0.5309770703315735  \n","Epoch:50/50     Step:7|6   loss:0.5248551368713379  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Accuracy on test_set: 88.79 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.2442479133605957  \n","Epoch:1/50     Step:2|6   loss:11.176267623901367  \n","Epoch:1/50     Step:3|6   loss:7.668262481689453  \n","Epoch:1/50     Step:4|6   loss:1.4599767923355103  \n","Epoch:1/50     Step:5|6   loss:4.67238187789917  \n","Epoch:1/50     Step:6|6   loss:6.469487190246582  \n","Epoch:1/50     Step:7|6   loss:3.691527843475342  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 25.29 %\n","current max accuracy\t test set:28.04%\t train set:25.29%\n","Epoch:2/50     Step:1|6   loss:1.6774351596832275  \n","Epoch:2/50     Step:2|6   loss:2.598259925842285  \n","Epoch:2/50     Step:3|6   loss:3.449174404144287  \n","Epoch:2/50     Step:4|6   loss:4.324101448059082  \n","Epoch:2/50     Step:5|6   loss:2.214878559112549  \n","Epoch:2/50     Step:6|6   loss:1.5860404968261719  \n","Epoch:2/50     Step:7|6   loss:1.6677780151367188  \n","Accuracy on test_set: 32.71 %\n","Accuracy on train_set: 28.10 %\n","current max accuracy\t test set:32.71%\t train set:28.1%\n","Epoch:3/50     Step:1|6   loss:2.495762586593628  \n","Epoch:3/50     Step:2|6   loss:2.11954927444458  \n","Epoch:3/50     Step:3|6   loss:0.8157463073730469  \n","Epoch:3/50     Step:4|6   loss:1.9345672130584717  \n","Epoch:3/50     Step:5|6   loss:2.3545186519622803  \n","Epoch:3/50     Step:6|6   loss:1.4092419147491455  \n","Epoch:3/50     Step:7|6   loss:1.4822673797607422  \n","Accuracy on test_set: 40.19 %\n","Accuracy on train_set: 41.92 %\n","current max accuracy\t test set:40.19%\t train set:41.92%\n","Epoch:4/50     Step:1|6   loss:1.0832616090774536  \n","Epoch:4/50     Step:2|6   loss:1.2679601907730103  \n","Epoch:4/50     Step:3|6   loss:1.3339616060256958  \n","Epoch:4/50     Step:4|6   loss:1.176323413848877  \n","Epoch:4/50     Step:5|6   loss:1.2488385438919067  \n","Epoch:4/50     Step:6|6   loss:1.0428415536880493  \n","Epoch:4/50     Step:7|6   loss:1.1762094497680664  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 68.62 %\n","current max accuracy\t test set:65.42%\t train set:68.62%\n","Epoch:5/50     Step:1|6   loss:1.0044649839401245  \n","Epoch:5/50     Step:2|6   loss:0.8539342284202576  \n","Epoch:5/50     Step:3|6   loss:1.1287792921066284  \n","Epoch:5/50     Step:4|6   loss:0.8001545071601868  \n","Epoch:5/50     Step:5|6   loss:0.7503011226654053  \n","Epoch:5/50     Step:6|6   loss:0.7877189517021179  \n","Epoch:5/50     Step:7|6   loss:0.7320489287376404  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 76.81 %\n","current max accuracy\t test set:74.77%\t train set:76.81%\n","Epoch:6/50     Step:1|6   loss:0.8529609441757202  \n","Epoch:6/50     Step:2|6   loss:0.7750191688537598  \n","Epoch:6/50     Step:3|6   loss:0.7639895677566528  \n","Epoch:6/50     Step:4|6   loss:0.7611329555511475  \n","Epoch:6/50     Step:5|6   loss:0.7272710800170898  \n","Epoch:6/50     Step:6|6   loss:0.6677327156066895  \n","Epoch:6/50     Step:7|6   loss:0.7345081567764282  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 82.44 %\n","current max accuracy\t test set:82.24%\t train set:82.44%\n","Epoch:7/50     Step:1|6   loss:0.768722653388977  \n","Epoch:7/50     Step:2|6   loss:0.7021532654762268  \n","Epoch:7/50     Step:3|6   loss:0.6461536288261414  \n","Epoch:7/50     Step:4|6   loss:0.7198270559310913  \n","Epoch:7/50     Step:5|6   loss:0.699927568435669  \n","Epoch:7/50     Step:6|6   loss:0.7201476097106934  \n","Epoch:7/50     Step:7|6   loss:0.6731380224227905  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 82.67 %\n","current max accuracy\t test set:82.24%\t train set:82.67%\n","Epoch:8/50     Step:1|6   loss:0.6986479163169861  \n","Epoch:8/50     Step:2|6   loss:0.7129355669021606  \n","Epoch:8/50     Step:3|6   loss:0.641076385974884  \n","Epoch:8/50     Step:4|6   loss:0.7515877485275269  \n","Epoch:8/50     Step:5|6   loss:0.7405554056167603  \n","Epoch:8/50     Step:6|6   loss:0.6874424815177917  \n","Epoch:8/50     Step:7|6   loss:0.7438571453094482  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:85.05%\t train set:86.65%\n","Epoch:9/50     Step:1|6   loss:0.7331154346466064  \n","Epoch:9/50     Step:2|6   loss:0.635939359664917  \n","Epoch:9/50     Step:3|6   loss:0.7424139976501465  \n","Epoch:9/50     Step:4|6   loss:0.7384161949157715  \n","Epoch:9/50     Step:5|6   loss:0.6205447316169739  \n","Epoch:9/50     Step:6|6   loss:0.6389240622520447  \n","Epoch:9/50     Step:7|6   loss:0.6449544429779053  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:90.65%\t train set:93.68%\n","Epoch:10/50     Step:1|6   loss:0.7021129131317139  \n","Epoch:10/50     Step:2|6   loss:0.6444032192230225  \n","Epoch:10/50     Step:3|6   loss:0.6490676403045654  \n","Epoch:10/50     Step:4|6   loss:0.6983903646469116  \n","Epoch:10/50     Step:5|6   loss:0.6332345008850098  \n","Epoch:10/50     Step:6|6   loss:0.6136364340782166  \n","Epoch:10/50     Step:7|6   loss:0.6443226337432861  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:90.65%\t train set:93.68%\n","Epoch:11/50     Step:1|6   loss:0.6086273789405823  \n","Epoch:11/50     Step:2|6   loss:0.6346009969711304  \n","Epoch:11/50     Step:3|6   loss:0.6741992831230164  \n","Epoch:11/50     Step:4|6   loss:0.6873666048049927  \n","Epoch:11/50     Step:5|6   loss:0.6369924545288086  \n","Epoch:11/50     Step:6|6   loss:0.6022237539291382  \n","Epoch:11/50     Step:7|6   loss:0.710335373878479  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:90.65%\t train set:93.68%\n","Epoch:12/50     Step:1|6   loss:0.7036796808242798  \n","Epoch:12/50     Step:2|6   loss:0.6386781334877014  \n","Epoch:12/50     Step:3|6   loss:0.686245322227478  \n","Epoch:12/50     Step:4|6   loss:0.5971739292144775  \n","Epoch:12/50     Step:5|6   loss:0.613547682762146  \n","Epoch:12/50     Step:6|6   loss:0.6443201303482056  \n","Epoch:12/50     Step:7|6   loss:0.6020209789276123  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:90.65%\t train set:94.15%\n","Epoch:13/50     Step:1|6   loss:0.592647910118103  \n","Epoch:13/50     Step:2|6   loss:0.6750181913375854  \n","Epoch:13/50     Step:3|6   loss:0.6195749044418335  \n","Epoch:13/50     Step:4|6   loss:0.6131348609924316  \n","Epoch:13/50     Step:5|6   loss:0.6077567338943481  \n","Epoch:13/50     Step:6|6   loss:0.6254366636276245  \n","Epoch:13/50     Step:7|6   loss:0.6099433898925781  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:90.65%\t train set:94.15%\n","Epoch:14/50     Step:1|6   loss:0.6063904166221619  \n","Epoch:14/50     Step:2|6   loss:0.658912181854248  \n","Epoch:14/50     Step:3|6   loss:0.6150119304656982  \n","Epoch:14/50     Step:4|6   loss:0.6705244779586792  \n","Epoch:14/50     Step:5|6   loss:0.6204688549041748  \n","Epoch:14/50     Step:6|6   loss:0.6193015575408936  \n","Epoch:14/50     Step:7|6   loss:0.574871301651001  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:90.65%\t train set:94.15%\n","Epoch:15/50     Step:1|6   loss:0.6058875322341919  \n","Epoch:15/50     Step:2|6   loss:0.6233218312263489  \n","Epoch:15/50     Step:3|6   loss:0.6244364976882935  \n","Epoch:15/50     Step:4|6   loss:0.6217614412307739  \n","Epoch:15/50     Step:5|6   loss:0.5984606146812439  \n","Epoch:15/50     Step:6|6   loss:0.6206273436546326  \n","Epoch:15/50     Step:7|6   loss:0.5738304853439331  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:90.65%\t train set:95.32%\n","Epoch:16/50     Step:1|6   loss:0.6663239002227783  \n","Epoch:16/50     Step:2|6   loss:0.5931175351142883  \n","Epoch:16/50     Step:3|6   loss:0.5934779047966003  \n","Epoch:16/50     Step:4|6   loss:0.6096892356872559  \n","Epoch:16/50     Step:5|6   loss:0.6132301092147827  \n","Epoch:16/50     Step:6|6   loss:0.60128253698349  \n","Epoch:16/50     Step:7|6   loss:0.5560973286628723  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:92.52%\t train set:96.49%\n","Epoch:17/50     Step:1|6   loss:0.6106336712837219  \n","Epoch:17/50     Step:2|6   loss:0.5980606079101562  \n","Epoch:17/50     Step:3|6   loss:0.5937609076499939  \n","Epoch:17/50     Step:4|6   loss:0.6202241778373718  \n","Epoch:17/50     Step:5|6   loss:0.586857259273529  \n","Epoch:17/50     Step:6|6   loss:0.5825904607772827  \n","Epoch:17/50     Step:7|6   loss:0.5951210260391235  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:92.52%\t train set:97.42%\n","Epoch:18/50     Step:1|6   loss:0.6087406873703003  \n","Epoch:18/50     Step:2|6   loss:0.5992722511291504  \n","Epoch:18/50     Step:3|6   loss:0.6015748977661133  \n","Epoch:18/50     Step:4|6   loss:0.5660157203674316  \n","Epoch:18/50     Step:5|6   loss:0.6484757661819458  \n","Epoch:18/50     Step:6|6   loss:0.6326347589492798  \n","Epoch:18/50     Step:7|6   loss:0.574482798576355  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:92.52%\t train set:97.42%\n","Epoch:19/50     Step:1|6   loss:0.6690405011177063  \n","Epoch:19/50     Step:2|6   loss:0.585640013217926  \n","Epoch:19/50     Step:3|6   loss:0.6504149436950684  \n","Epoch:19/50     Step:4|6   loss:0.652894139289856  \n","Epoch:19/50     Step:5|6   loss:0.5706322193145752  \n","Epoch:19/50     Step:6|6   loss:0.7006258964538574  \n","Epoch:19/50     Step:7|6   loss:0.6123138666152954  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:92.52%\t train set:97.42%\n","Epoch:20/50     Step:1|6   loss:0.588654100894928  \n","Epoch:20/50     Step:2|6   loss:0.6219487190246582  \n","Epoch:20/50     Step:3|6   loss:0.5808861255645752  \n","Epoch:20/50     Step:4|6   loss:0.601879894733429  \n","Epoch:20/50     Step:5|6   loss:0.6229673624038696  \n","Epoch:20/50     Step:6|6   loss:0.5892964601516724  \n","Epoch:20/50     Step:7|6   loss:0.5741221308708191  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:92.52%\t train set:97.42%\n","Epoch:21/50     Step:1|6   loss:0.5872462391853333  \n","Epoch:21/50     Step:2|6   loss:0.5756651163101196  \n","Epoch:21/50     Step:3|6   loss:0.5724631547927856  \n","Epoch:21/50     Step:4|6   loss:0.590169370174408  \n","Epoch:21/50     Step:5|6   loss:0.5866113305091858  \n","Epoch:21/50     Step:6|6   loss:0.5894607305526733  \n","Epoch:21/50     Step:7|6   loss:0.563806414604187  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:92.52%\t train set:97.42%\n","Epoch:22/50     Step:1|6   loss:0.6091416478157043  \n","Epoch:22/50     Step:2|6   loss:0.5811172723770142  \n","Epoch:22/50     Step:3|6   loss:0.5894591808319092  \n","Epoch:22/50     Step:4|6   loss:0.5694258213043213  \n","Epoch:22/50     Step:5|6   loss:0.5636771321296692  \n","Epoch:22/50     Step:6|6   loss:0.5666366219520569  \n","Epoch:22/50     Step:7|6   loss:0.5406444072723389  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:92.52%\t train set:97.89%\n","Epoch:23/50     Step:1|6   loss:0.5694653391838074  \n","Epoch:23/50     Step:2|6   loss:0.5658150911331177  \n","Epoch:23/50     Step:3|6   loss:0.5744127035140991  \n","Epoch:23/50     Step:4|6   loss:0.5703936219215393  \n","Epoch:23/50     Step:5|6   loss:0.5659885406494141  \n","Epoch:23/50     Step:6|6   loss:0.5648735761642456  \n","Epoch:23/50     Step:7|6   loss:0.6014835834503174  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:92.52%\t train set:97.89%\n","Epoch:24/50     Step:1|6   loss:0.5616122484207153  \n","Epoch:24/50     Step:2|6   loss:0.5618091821670532  \n","Epoch:24/50     Step:3|6   loss:0.5950855016708374  \n","Epoch:24/50     Step:4|6   loss:0.577538251876831  \n","Epoch:24/50     Step:5|6   loss:0.5691422820091248  \n","Epoch:24/50     Step:6|6   loss:0.5687101483345032  \n","Epoch:24/50     Step:7|6   loss:0.5521392226219177  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:25/50     Step:1|6   loss:0.5537534356117249  \n","Epoch:25/50     Step:2|6   loss:0.56282639503479  \n","Epoch:25/50     Step:3|6   loss:0.5560121536254883  \n","Epoch:25/50     Step:4|6   loss:0.5601623058319092  \n","Epoch:25/50     Step:5|6   loss:0.5544193983078003  \n","Epoch:25/50     Step:6|6   loss:0.5726324915885925  \n","Epoch:25/50     Step:7|6   loss:0.5908951759338379  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:26/50     Step:1|6   loss:0.589016318321228  \n","Epoch:26/50     Step:2|6   loss:0.5581761598587036  \n","Epoch:26/50     Step:3|6   loss:0.5457473397254944  \n","Epoch:26/50     Step:4|6   loss:0.5811262130737305  \n","Epoch:26/50     Step:5|6   loss:0.5509070158004761  \n","Epoch:26/50     Step:6|6   loss:0.5820622444152832  \n","Epoch:26/50     Step:7|6   loss:0.5649448037147522  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:27/50     Step:1|6   loss:0.5415239930152893  \n","Epoch:27/50     Step:2|6   loss:0.5575435757637024  \n","Epoch:27/50     Step:3|6   loss:0.5571433901786804  \n","Epoch:27/50     Step:4|6   loss:0.5964617133140564  \n","Epoch:27/50     Step:5|6   loss:0.572775661945343  \n","Epoch:27/50     Step:6|6   loss:0.611631453037262  \n","Epoch:27/50     Step:7|6   loss:0.5682430863380432  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:28/50     Step:1|6   loss:0.591669499874115  \n","Epoch:28/50     Step:2|6   loss:0.561090886592865  \n","Epoch:28/50     Step:3|6   loss:0.5932674407958984  \n","Epoch:28/50     Step:4|6   loss:0.5991560816764832  \n","Epoch:28/50     Step:5|6   loss:0.5615631341934204  \n","Epoch:28/50     Step:6|6   loss:0.6018635630607605  \n","Epoch:28/50     Step:7|6   loss:0.5634604096412659  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:29/50     Step:1|6   loss:0.5628097057342529  \n","Epoch:29/50     Step:2|6   loss:0.5612853765487671  \n","Epoch:29/50     Step:3|6   loss:0.5650979280471802  \n","Epoch:29/50     Step:4|6   loss:0.5580503940582275  \n","Epoch:29/50     Step:5|6   loss:0.5844866037368774  \n","Epoch:29/50     Step:6|6   loss:0.53835529088974  \n","Epoch:29/50     Step:7|6   loss:0.5543746948242188  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:99.3%\n","Epoch:30/50     Step:1|6   loss:0.5597674250602722  \n","Epoch:30/50     Step:2|6   loss:0.5551917552947998  \n","Epoch:30/50     Step:3|6   loss:0.5670298933982849  \n","Epoch:30/50     Step:4|6   loss:0.584228515625  \n","Epoch:30/50     Step:5|6   loss:0.5811330676078796  \n","Epoch:30/50     Step:6|6   loss:0.5516954064369202  \n","Epoch:30/50     Step:7|6   loss:0.5514068007469177  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:99.77%\n","Epoch:31/50     Step:1|6   loss:0.5331071615219116  \n","Epoch:31/50     Step:2|6   loss:0.5541874170303345  \n","Epoch:31/50     Step:3|6   loss:0.5643672347068787  \n","Epoch:31/50     Step:4|6   loss:0.5387084484100342  \n","Epoch:31/50     Step:5|6   loss:0.5505778193473816  \n","Epoch:31/50     Step:6|6   loss:0.5495278835296631  \n","Epoch:31/50     Step:7|6   loss:0.5640401840209961  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.5455745458602905  \n","Epoch:32/50     Step:2|6   loss:0.5463210344314575  \n","Epoch:32/50     Step:3|6   loss:0.5576984286308289  \n","Epoch:32/50     Step:4|6   loss:0.5474709272384644  \n","Epoch:32/50     Step:5|6   loss:0.5532252788543701  \n","Epoch:32/50     Step:6|6   loss:0.5550443530082703  \n","Epoch:32/50     Step:7|6   loss:0.5351069569587708  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.5385429263114929  \n","Epoch:33/50     Step:2|6   loss:0.5539194345474243  \n","Epoch:33/50     Step:3|6   loss:0.544341504573822  \n","Epoch:33/50     Step:4|6   loss:0.5453200936317444  \n","Epoch:33/50     Step:5|6   loss:0.5549030900001526  \n","Epoch:33/50     Step:6|6   loss:0.5349013805389404  \n","Epoch:33/50     Step:7|6   loss:0.5342346429824829  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.5414994955062866  \n","Epoch:34/50     Step:2|6   loss:0.5351029634475708  \n","Epoch:34/50     Step:3|6   loss:0.5404974818229675  \n","Epoch:34/50     Step:4|6   loss:0.5476990342140198  \n","Epoch:34/50     Step:5|6   loss:0.5444656610488892  \n","Epoch:34/50     Step:6|6   loss:0.5273868441581726  \n","Epoch:34/50     Step:7|6   loss:0.5490263104438782  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.5676065683364868  \n","Epoch:35/50     Step:2|6   loss:0.5421333909034729  \n","Epoch:35/50     Step:3|6   loss:0.5796502232551575  \n","Epoch:35/50     Step:4|6   loss:0.5353671908378601  \n","Epoch:35/50     Step:5|6   loss:0.5309891104698181  \n","Epoch:35/50     Step:6|6   loss:0.5627466440200806  \n","Epoch:35/50     Step:7|6   loss:0.5455606579780579  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.554203450679779  \n","Epoch:36/50     Step:2|6   loss:0.5349363088607788  \n","Epoch:36/50     Step:3|6   loss:0.5280967354774475  \n","Epoch:36/50     Step:4|6   loss:0.5473055839538574  \n","Epoch:36/50     Step:5|6   loss:0.5471690893173218  \n","Epoch:36/50     Step:6|6   loss:0.5362691879272461  \n","Epoch:36/50     Step:7|6   loss:0.5361364483833313  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.5376725792884827  \n","Epoch:37/50     Step:2|6   loss:0.539491593837738  \n","Epoch:37/50     Step:3|6   loss:0.5486018657684326  \n","Epoch:37/50     Step:4|6   loss:0.5696194171905518  \n","Epoch:37/50     Step:5|6   loss:0.5276803970336914  \n","Epoch:37/50     Step:6|6   loss:0.5408767461776733  \n","Epoch:37/50     Step:7|6   loss:0.5379558801651001  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.5371381044387817  \n","Epoch:38/50     Step:2|6   loss:0.524820864200592  \n","Epoch:38/50     Step:3|6   loss:0.5434505939483643  \n","Epoch:38/50     Step:4|6   loss:0.5398057699203491  \n","Epoch:38/50     Step:5|6   loss:0.5535422563552856  \n","Epoch:38/50     Step:6|6   loss:0.535805881023407  \n","Epoch:38/50     Step:7|6   loss:0.5299711227416992  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.5440261363983154  \n","Epoch:39/50     Step:2|6   loss:0.5262443423271179  \n","Epoch:39/50     Step:3|6   loss:0.5485202670097351  \n","Epoch:39/50     Step:4|6   loss:0.531384289264679  \n","Epoch:39/50     Step:5|6   loss:0.544952392578125  \n","Epoch:39/50     Step:6|6   loss:0.5230456590652466  \n","Epoch:39/50     Step:7|6   loss:0.5280052423477173  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.5334253311157227  \n","Epoch:40/50     Step:2|6   loss:0.5344854593276978  \n","Epoch:40/50     Step:3|6   loss:0.5252689719200134  \n","Epoch:40/50     Step:4|6   loss:0.5332807302474976  \n","Epoch:40/50     Step:5|6   loss:0.5283613204956055  \n","Epoch:40/50     Step:6|6   loss:0.544506311416626  \n","Epoch:40/50     Step:7|6   loss:0.5265931487083435  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.5277165770530701  \n","Epoch:41/50     Step:2|6   loss:0.5280134677886963  \n","Epoch:41/50     Step:3|6   loss:0.5337557196617126  \n","Epoch:41/50     Step:4|6   loss:0.5380737781524658  \n","Epoch:41/50     Step:5|6   loss:0.5294798612594604  \n","Epoch:41/50     Step:6|6   loss:0.528221607208252  \n","Epoch:41/50     Step:7|6   loss:0.5465471148490906  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.5352630615234375  \n","Epoch:42/50     Step:2|6   loss:0.5616346597671509  \n","Epoch:42/50     Step:3|6   loss:0.5523648262023926  \n","Epoch:42/50     Step:4|6   loss:0.5613776445388794  \n","Epoch:42/50     Step:5|6   loss:0.5265631675720215  \n","Epoch:42/50     Step:6|6   loss:0.5559585690498352  \n","Epoch:42/50     Step:7|6   loss:0.5194235444068909  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.5612722039222717  \n","Epoch:43/50     Step:2|6   loss:0.5307275652885437  \n","Epoch:43/50     Step:3|6   loss:0.5631357431411743  \n","Epoch:43/50     Step:4|6   loss:0.5263369679450989  \n","Epoch:43/50     Step:5|6   loss:0.5368656516075134  \n","Epoch:43/50     Step:6|6   loss:0.5409443378448486  \n","Epoch:43/50     Step:7|6   loss:0.5271276235580444  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.5407455563545227  \n","Epoch:44/50     Step:2|6   loss:0.5233056545257568  \n","Epoch:44/50     Step:3|6   loss:0.5390247106552124  \n","Epoch:44/50     Step:4|6   loss:0.5312526226043701  \n","Epoch:44/50     Step:5|6   loss:0.5413714051246643  \n","Epoch:44/50     Step:6|6   loss:0.5340202450752258  \n","Epoch:44/50     Step:7|6   loss:0.5391099452972412  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5398190021514893  \n","Epoch:45/50     Step:2|6   loss:0.5470840930938721  \n","Epoch:45/50     Step:3|6   loss:0.5340992212295532  \n","Epoch:45/50     Step:4|6   loss:0.5574458241462708  \n","Epoch:45/50     Step:5|6   loss:0.519548773765564  \n","Epoch:45/50     Step:6|6   loss:0.5369899868965149  \n","Epoch:45/50     Step:7|6   loss:0.5348935723304749  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5248863697052002  \n","Epoch:46/50     Step:2|6   loss:0.5342901945114136  \n","Epoch:46/50     Step:3|6   loss:0.5218012928962708  \n","Epoch:46/50     Step:4|6   loss:0.5224989652633667  \n","Epoch:46/50     Step:5|6   loss:0.5160461664199829  \n","Epoch:46/50     Step:6|6   loss:0.5388350486755371  \n","Epoch:46/50     Step:7|6   loss:0.518212080001831  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5516688227653503  \n","4\n","Epoch:47/50     Step:2|6   loss:0.5187731981277466  \n","Epoch:47/50     Step:3|6   loss:0.5270262956619263  \n","Epoch:47/50     Step:4|6   loss:0.5197352170944214  \n","Epoch:47/50     Step:5|6   loss:0.531389594078064  \n","Epoch:47/50     Step:6|6   loss:0.5164939165115356  \n","Epoch:47/50     Step:7|6   loss:0.5206822752952576  \n","Accuracy on test_set: 90.65 %\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.5211595296859741  \n","Epoch:48/50     Step:2|6   loss:0.5230005979537964  \n","Epoch:48/50     Step:3|6   loss:0.5247032642364502  \n","Epoch:48/50     Step:4|6   loss:0.5317850708961487  \n","Epoch:48/50     Step:5|6   loss:0.5427441000938416  \n","Epoch:48/50     Step:6|6   loss:0.5181692242622375  \n","Epoch:48/50     Step:7|6   loss:0.5425117015838623  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5200255513191223  \n","Epoch:49/50     Step:2|6   loss:0.5292396545410156  \n","Epoch:49/50     Step:3|6   loss:0.5175278186798096  \n","Epoch:49/50     Step:4|6   loss:0.523931086063385  \n","Epoch:49/50     Step:5|6   loss:0.5266525149345398  \n","Epoch:49/50     Step:6|6   loss:0.5388497710227966  \n","Epoch:49/50     Step:7|6   loss:0.5155823230743408  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5183643698692322  \n","Epoch:50/50     Step:2|6   loss:0.5204644799232483  \n","Epoch:50/50     Step:3|6   loss:0.5192831158638  \n","Epoch:50/50     Step:4|6   loss:0.5181503891944885  \n","Epoch:50/50     Step:5|6   loss:0.5183669924736023  \n","Epoch:50/50     Step:6|6   loss:0.5228129625320435  \n","Epoch:50/50     Step:7|6   loss:0.522168755531311  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Accuracy on test_set: 90.65 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.098102331161499  \n","Epoch:1/50     Step:2|6   loss:3.2336950302124023  \n","Epoch:1/50     Step:3|6   loss:2.389111280441284  \n","Epoch:1/50     Step:4|6   loss:1.2304472923278809  \n","Epoch:1/50     Step:5|6   loss:1.5313891172409058  \n","Epoch:1/50     Step:6|6   loss:1.33301842212677  \n","Epoch:1/50     Step:7|6   loss:1.2999486923217773  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 36.77 %\n","current max accuracy\t test set:28.04%\t train set:36.77%\n","Epoch:2/50     Step:1|6   loss:1.4991756677627563  \n","Epoch:2/50     Step:2|6   loss:0.9235478639602661  \n","Epoch:2/50     Step:3|6   loss:1.2721316814422607  \n","Epoch:2/50     Step:4|6   loss:1.6713980436325073  \n","Epoch:2/50     Step:5|6   loss:1.4231289625167847  \n","Epoch:2/50     Step:6|6   loss:0.9287919998168945  \n","Epoch:2/50     Step:7|6   loss:1.3062305450439453  \n","Accuracy on test_set: 47.66 %\n","Accuracy on train_set: 58.78 %\n","current max accuracy\t test set:47.66%\t train set:58.78%\n","Epoch:3/50     Step:1|6   loss:1.1247613430023193  \n","Epoch:3/50     Step:2|6   loss:0.9998672604560852  \n","Epoch:3/50     Step:3|6   loss:1.2410963773727417  \n","Epoch:3/50     Step:4|6   loss:1.4197301864624023  \n","Epoch:3/50     Step:5|6   loss:1.1220388412475586  \n","Epoch:3/50     Step:6|6   loss:0.7692495584487915  \n","Epoch:3/50     Step:7|6   loss:1.0334439277648926  \n","Accuracy on test_set: 56.07 %\n","Accuracy on train_set: 63.23 %\n","current max accuracy\t test set:56.07%\t train set:63.23%\n","Epoch:4/50     Step:1|6   loss:0.9397312998771667  \n","Epoch:4/50     Step:2|6   loss:0.8259390592575073  \n","Epoch:4/50     Step:3|6   loss:0.8417063355445862  \n","Epoch:4/50     Step:4|6   loss:1.1421520709991455  \n","Epoch:4/50     Step:5|6   loss:0.8836047649383545  \n","Epoch:4/50     Step:6|6   loss:0.975316047668457  \n","Epoch:4/50     Step:7|6   loss:1.021586537361145  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 76.35 %\n","current max accuracy\t test set:64.49%\t train set:76.35%\n","Epoch:5/50     Step:1|6   loss:0.7567664384841919  \n","Epoch:5/50     Step:2|6   loss:0.759932279586792  \n","Epoch:5/50     Step:3|6   loss:1.1120349168777466  \n","Epoch:5/50     Step:4|6   loss:0.9395968914031982  \n","Epoch:5/50     Step:5|6   loss:0.7003580331802368  \n","Epoch:5/50     Step:6|6   loss:1.011305570602417  \n","Epoch:5/50     Step:7|6   loss:0.8113728761672974  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:78.5%\t train set:84.78%\n","Epoch:6/50     Step:1|6   loss:0.7254109978675842  \n","Epoch:6/50     Step:2|6   loss:0.8292776346206665  \n","Epoch:6/50     Step:3|6   loss:0.7601067423820496  \n","Epoch:6/50     Step:4|6   loss:0.6380654573440552  \n","Epoch:6/50     Step:5|6   loss:0.8524864315986633  \n","Epoch:6/50     Step:6|6   loss:0.8423386812210083  \n","Epoch:6/50     Step:7|6   loss:0.7134373784065247  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 82.67 %\n","current max accuracy\t test set:78.5%\t train set:84.78%\n","Epoch:7/50     Step:1|6   loss:0.7107350826263428  \n","Epoch:7/50     Step:2|6   loss:0.7244282960891724  \n","Epoch:7/50     Step:3|6   loss:0.6099201440811157  \n","Epoch:7/50     Step:4|6   loss:0.7563204765319824  \n","Epoch:7/50     Step:5|6   loss:0.6459628939628601  \n","Epoch:7/50     Step:6|6   loss:0.746280312538147  \n","Epoch:7/50     Step:7|6   loss:0.7991358041763306  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:86.92%\t train set:92.04%\n","Epoch:8/50     Step:1|6   loss:0.6529589891433716  \n","Epoch:8/50     Step:2|6   loss:0.6369718313217163  \n","Epoch:8/50     Step:3|6   loss:0.6654795408248901  \n","Epoch:8/50     Step:4|6   loss:0.6306103467941284  \n","Epoch:8/50     Step:5|6   loss:0.7206213474273682  \n","Epoch:8/50     Step:6|6   loss:0.5800228118896484  \n","Epoch:8/50     Step:7|6   loss:0.6211825609207153  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:86.92%\t train set:92.04%\n","Epoch:9/50     Step:1|6   loss:0.6871528625488281  \n","Epoch:9/50     Step:2|6   loss:0.6224340200424194  \n","Epoch:9/50     Step:3|6   loss:0.6385067701339722  \n","Epoch:9/50     Step:4|6   loss:0.6420094966888428  \n","Epoch:9/50     Step:5|6   loss:0.5951287150382996  \n","Epoch:9/50     Step:6|6   loss:0.6427677273750305  \n","Epoch:9/50     Step:7|6   loss:0.5873876214027405  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:90.65%\t train set:95.32%\n","Epoch:10/50     Step:1|6   loss:0.5950759649276733  \n","Epoch:10/50     Step:2|6   loss:0.6125392317771912  \n","Epoch:10/50     Step:3|6   loss:0.6248749494552612  \n","Epoch:10/50     Step:4|6   loss:0.5946643352508545  \n","Epoch:10/50     Step:5|6   loss:0.6406235694885254  \n","Epoch:10/50     Step:6|6   loss:0.5972778797149658  \n","Epoch:10/50     Step:7|6   loss:0.5878577828407288  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:90.65%\t train set:95.55%\n","Epoch:11/50     Step:1|6   loss:0.5837249159812927  \n","Epoch:11/50     Step:2|6   loss:0.5916980504989624  \n","Epoch:11/50     Step:3|6   loss:0.61263507604599  \n","Epoch:11/50     Step:4|6   loss:0.5951454639434814  \n","Epoch:11/50     Step:5|6   loss:0.5757003426551819  \n","Epoch:11/50     Step:6|6   loss:0.6026889085769653  \n","Epoch:11/50     Step:7|6   loss:0.6119936108589172  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:12/50     Step:1|6   loss:0.6016692519187927  \n","Epoch:12/50     Step:2|6   loss:0.6095253229141235  \n","Epoch:12/50     Step:3|6   loss:0.5728334188461304  \n","Epoch:12/50     Step:4|6   loss:0.567823052406311  \n","Epoch:12/50     Step:5|6   loss:0.674543023109436  \n","Epoch:12/50     Step:6|6   loss:0.6099791526794434  \n","Epoch:12/50     Step:7|6   loss:0.6746618747711182  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:13/50     Step:1|6   loss:0.6235692501068115  \n","Epoch:13/50     Step:2|6   loss:0.5701945424079895  \n","Epoch:13/50     Step:3|6   loss:0.6463901400566101  \n","Epoch:13/50     Step:4|6   loss:0.6217923164367676  \n","Epoch:13/50     Step:5|6   loss:0.5758727192878723  \n","Epoch:13/50     Step:6|6   loss:0.6571813225746155  \n","Epoch:13/50     Step:7|6   loss:0.6178184747695923  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:14/50     Step:1|6   loss:0.606622040271759  \n","Epoch:14/50     Step:2|6   loss:0.6590332984924316  \n","Epoch:14/50     Step:3|6   loss:0.557983934879303  \n","Epoch:14/50     Step:4|6   loss:0.6370068788528442  \n","Epoch:14/50     Step:5|6   loss:0.5797752141952515  \n","Epoch:14/50     Step:6|6   loss:0.5737830996513367  \n","Epoch:14/50     Step:7|6   loss:0.5774503946304321  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:15/50     Step:1|6   loss:0.6184321641921997  \n","Epoch:15/50     Step:2|6   loss:0.60123610496521  \n","Epoch:15/50     Step:3|6   loss:0.6234678626060486  \n","Epoch:15/50     Step:4|6   loss:0.553978681564331  \n","Epoch:15/50     Step:5|6   loss:0.6029178500175476  \n","Epoch:15/50     Step:6|6   loss:0.5684468746185303  \n","Epoch:15/50     Step:7|6   loss:0.5494614839553833  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:16/50     Step:1|6   loss:0.5677178502082825  \n","Epoch:16/50     Step:2|6   loss:0.5784893035888672  \n","Epoch:16/50     Step:3|6   loss:0.5687394738197327  \n","Epoch:16/50     Step:4|6   loss:0.5702230930328369  \n","Epoch:16/50     Step:5|6   loss:0.568681001663208  \n","Epoch:16/50     Step:6|6   loss:0.5689854621887207  \n","Epoch:16/50     Step:7|6   loss:0.6086089611053467  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:17/50     Step:1|6   loss:0.5652011036872864  \n","Epoch:17/50     Step:2|6   loss:0.5831973552703857  \n","Epoch:17/50     Step:3|6   loss:0.5655571222305298  \n","Epoch:17/50     Step:4|6   loss:0.5763301849365234  \n","Epoch:17/50     Step:5|6   loss:0.5451669096946716  \n","Epoch:17/50     Step:6|6   loss:0.6151089072227478  \n","Epoch:17/50     Step:7|6   loss:0.5942184329032898  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:18/50     Step:1|6   loss:0.5603554248809814  \n","Epoch:18/50     Step:2|6   loss:0.5697273015975952  \n","Epoch:18/50     Step:3|6   loss:0.5470700263977051  \n","Epoch:18/50     Step:4|6   loss:0.5486742854118347  \n","Epoch:18/50     Step:5|6   loss:0.5511870980262756  \n","Epoch:18/50     Step:6|6   loss:0.5615394115447998  \n","Epoch:18/50     Step:7|6   loss:0.5991334915161133  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:19/50     Step:1|6   loss:0.61430823802948  \n","Epoch:19/50     Step:2|6   loss:0.5832061171531677  \n","Epoch:19/50     Step:3|6   loss:0.6212059259414673  \n","Epoch:19/50     Step:4|6   loss:0.5781399011611938  \n","Epoch:19/50     Step:5|6   loss:0.6443483829498291  \n","Epoch:19/50     Step:6|6   loss:0.5741355419158936  \n","Epoch:19/50     Step:7|6   loss:0.6987879276275635  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:20/50     Step:1|6   loss:0.5980760455131531  \n","Epoch:20/50     Step:2|6   loss:0.6477936506271362  \n","Epoch:20/50     Step:3|6   loss:0.5671453475952148  \n","Epoch:20/50     Step:4|6   loss:0.6838473081588745  \n","Epoch:20/50     Step:5|6   loss:0.5596719980239868  \n","Epoch:20/50     Step:6|6   loss:0.6182568669319153  \n","Epoch:20/50     Step:7|6   loss:0.5532525777816772  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:21/50     Step:1|6   loss:0.5808594822883606  \n","Epoch:21/50     Step:2|6   loss:0.5517717003822327  \n","Epoch:21/50     Step:3|6   loss:0.5465428829193115  \n","Epoch:21/50     Step:4|6   loss:0.5687858462333679  \n","Epoch:21/50     Step:5|6   loss:0.5494762063026428  \n","Epoch:21/50     Step:6|6   loss:0.5439327955245972  \n","Epoch:21/50     Step:7|6   loss:0.5495131015777588  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:96.26%\t train set:98.83%\n","Epoch:22/50     Step:1|6   loss:0.5483198165893555  \n","Epoch:22/50     Step:2|6   loss:0.5244715213775635  \n","Epoch:22/50     Step:3|6   loss:0.5328369140625  \n","Epoch:22/50     Step:4|6   loss:0.5638817548751831  \n","Epoch:22/50     Step:5|6   loss:0.5591188669204712  \n","Epoch:22/50     Step:6|6   loss:0.5990116596221924  \n","Epoch:22/50     Step:7|6   loss:0.5808409452438354  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:96.26%\t train set:98.83%\n","Epoch:23/50     Step:1|6   loss:0.5345265865325928  \n","Epoch:23/50     Step:2|6   loss:0.5347973704338074  \n","Epoch:23/50     Step:3|6   loss:0.5554677844047546  \n","Epoch:23/50     Step:4|6   loss:0.5595645308494568  \n","Epoch:23/50     Step:5|6   loss:0.5948761105537415  \n","Epoch:23/50     Step:6|6   loss:0.5510077476501465  \n","Epoch:23/50     Step:7|6   loss:0.5613534450531006  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:96.26%\t train set:99.06%\n","Epoch:24/50     Step:1|6   loss:0.53400057554245  \n","Epoch:24/50     Step:2|6   loss:0.5830087065696716  \n","Epoch:24/50     Step:3|6   loss:0.5405757427215576  \n","Epoch:24/50     Step:4|6   loss:0.5896549820899963  \n","Epoch:24/50     Step:5|6   loss:0.5765902996063232  \n","Epoch:24/50     Step:6|6   loss:0.5619031190872192  \n","Epoch:24/50     Step:7|6   loss:0.5391128063201904  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:96.26%\t train set:99.06%\n","Epoch:25/50     Step:1|6   loss:0.5497573018074036  \n","Epoch:25/50     Step:2|6   loss:0.5461899042129517  \n","Epoch:25/50     Step:3|6   loss:0.5402407646179199  \n","Epoch:25/50     Step:4|6   loss:0.5636480450630188  \n","Epoch:25/50     Step:5|6   loss:0.5579720735549927  \n","Epoch:25/50     Step:6|6   loss:0.5463292002677917  \n","Epoch:25/50     Step:7|6   loss:0.5386645197868347  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:96.26%\t train set:99.06%\n","Epoch:26/50     Step:1|6   loss:0.5739790201187134  \n","Epoch:26/50     Step:2|6   loss:0.5515192747116089  \n","Epoch:26/50     Step:3|6   loss:0.5544712543487549  \n","Epoch:26/50     Step:4|6   loss:0.5376249551773071  \n","Epoch:26/50     Step:5|6   loss:0.5587873458862305  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch:26/50     Step:6|6   loss:0.5455507636070251  \n","Epoch:26/50     Step:7|6   loss:0.5514813661575317  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:96.26%\t train set:99.53%\n","Epoch:27/50     Step:1|6   loss:0.5515408515930176  \n","Epoch:27/50     Step:2|6   loss:0.5307774543762207  \n","Epoch:27/50     Step:3|6   loss:0.5628350973129272  \n","Epoch:27/50     Step:4|6   loss:0.555129885673523  \n","Epoch:27/50     Step:5|6   loss:0.5589340925216675  \n","Epoch:27/50     Step:6|6   loss:0.5600252151489258  \n","Epoch:27/50     Step:7|6   loss:0.5396578907966614  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:96.26%\t train set:99.53%\n","Epoch:28/50     Step:1|6   loss:0.5719992518424988  \n","Epoch:28/50     Step:2|6   loss:0.541300892829895  \n","Epoch:28/50     Step:3|6   loss:0.5728519558906555  \n","Epoch:28/50     Step:4|6   loss:0.5257726311683655  \n","Epoch:28/50     Step:5|6   loss:0.5590204000473022  \n","Epoch:28/50     Step:6|6   loss:0.5339059233665466  \n","Epoch:28/50     Step:7|6   loss:0.573210597038269  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.5490874648094177  \n","Epoch:29/50     Step:2|6   loss:0.5769761800765991  \n","Epoch:29/50     Step:3|6   loss:0.5295124053955078  \n","Epoch:29/50     Step:4|6   loss:0.5745218992233276  \n","Epoch:29/50     Step:5|6   loss:0.5423672199249268  \n","Epoch:29/50     Step:6|6   loss:0.5671117305755615  \n","Epoch:29/50     Step:7|6   loss:0.5183110237121582  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.5314723253250122  \n","Epoch:30/50     Step:2|6   loss:0.5395904779434204  \n","Epoch:30/50     Step:3|6   loss:0.5394884347915649  \n","Epoch:30/50     Step:4|6   loss:0.5500742197036743  \n","Epoch:30/50     Step:5|6   loss:0.5260387659072876  \n","Epoch:30/50     Step:6|6   loss:0.546527087688446  \n","Epoch:30/50     Step:7|6   loss:0.5367115139961243  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.5321859121322632  \n","Epoch:31/50     Step:2|6   loss:0.5219748020172119  \n","Epoch:31/50     Step:3|6   loss:0.5550286173820496  \n","Epoch:31/50     Step:4|6   loss:0.5434619784355164  \n","Epoch:31/50     Step:5|6   loss:0.5623862147331238  \n","Epoch:31/50     Step:6|6   loss:0.5340036153793335  \n","Epoch:31/50     Step:7|6   loss:0.5937889218330383  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.5629281401634216  \n","Epoch:32/50     Step:2|6   loss:0.5801558494567871  \n","Epoch:32/50     Step:3|6   loss:0.5419877767562866  \n","Epoch:32/50     Step:4|6   loss:0.5970934629440308  \n","Epoch:32/50     Step:5|6   loss:0.5614482760429382  \n","Epoch:32/50     Step:6|6   loss:0.609967052936554  \n","Epoch:32/50     Step:7|6   loss:0.5395195484161377  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.6130401492118835  \n","Epoch:33/50     Step:2|6   loss:0.5698392391204834  \n","Epoch:33/50     Step:3|6   loss:0.5773136615753174  \n","Epoch:33/50     Step:4|6   loss:0.5766475796699524  \n","Epoch:33/50     Step:5|6   loss:0.5885563492774963  \n","Epoch:33/50     Step:6|6   loss:0.5547572374343872  \n","Epoch:33/50     Step:7|6   loss:0.5470994710922241  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.5364333391189575  \n","Epoch:34/50     Step:2|6   loss:0.5441418290138245  \n","Epoch:34/50     Step:3|6   loss:0.5492619276046753  \n","Epoch:34/50     Step:4|6   loss:0.5239840745925903  \n","Epoch:34/50     Step:5|6   loss:0.5281388759613037  \n","Epoch:34/50     Step:6|6   loss:0.5608766078948975  \n","Epoch:34/50     Step:7|6   loss:0.516241729259491  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.5575955510139465  \n","Epoch:35/50     Step:2|6   loss:0.5241225957870483  \n","Epoch:35/50     Step:3|6   loss:0.5855788588523865  \n","Epoch:35/50     Step:4|6   loss:0.5269376635551453  \n","Epoch:35/50     Step:5|6   loss:0.5600254535675049  \n","Epoch:35/50     Step:6|6   loss:0.531322181224823  \n","Epoch:35/50     Step:7|6   loss:0.5621057152748108  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.5244395136833191  \n","Epoch:36/50     Step:2|6   loss:0.5509066581726074  \n","Epoch:36/50     Step:3|6   loss:0.5274636745452881  \n","Epoch:36/50     Step:4|6   loss:0.517406165599823  \n","Epoch:36/50     Step:5|6   loss:0.5437362790107727  \n","Epoch:36/50     Step:6|6   loss:0.5418905019760132  \n","Epoch:36/50     Step:7|6   loss:0.5371876955032349  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.5323890447616577  \n","Epoch:37/50     Step:2|6   loss:0.5178443789482117  \n","Epoch:37/50     Step:3|6   loss:0.5222129225730896  \n","Epoch:37/50     Step:4|6   loss:0.5178759098052979  \n","Epoch:37/50     Step:5|6   loss:0.5310735702514648  \n","Epoch:37/50     Step:6|6   loss:0.5229947566986084  \n","Epoch:37/50     Step:7|6   loss:0.5239403247833252  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.520915150642395  \n","Epoch:38/50     Step:2|6   loss:0.5284673571586609  \n","Epoch:38/50     Step:3|6   loss:0.538780927658081  \n","Epoch:38/50     Step:4|6   loss:0.5268614292144775  \n","Epoch:38/50     Step:5|6   loss:0.553208589553833  \n","Epoch:38/50     Step:6|6   loss:0.5243189334869385  \n","Epoch:38/50     Step:7|6   loss:0.5538312196731567  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.5257321000099182  \n","Epoch:39/50     Step:2|6   loss:0.559599757194519  \n","Epoch:39/50     Step:3|6   loss:0.5130051374435425  \n","Epoch:39/50     Step:4|6   loss:0.5532260537147522  \n","Epoch:39/50     Step:5|6   loss:0.5154239535331726  \n","Epoch:39/50     Step:6|6   loss:0.5340692400932312  \n","Epoch:39/50     Step:7|6   loss:0.543505072593689  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.528974175453186  \n","Epoch:40/50     Step:2|6   loss:0.5230120420455933  \n","Epoch:40/50     Step:3|6   loss:0.5223017930984497  \n","Epoch:40/50     Step:4|6   loss:0.5277007818222046  \n","Epoch:40/50     Step:5|6   loss:0.5202460885047913  \n","Epoch:40/50     Step:6|6   loss:0.5250074863433838  \n","Epoch:40/50     Step:7|6   loss:0.5180457830429077  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.5297016501426697  \n","Epoch:41/50     Step:2|6   loss:0.5363139510154724  \n","Epoch:41/50     Step:3|6   loss:0.5130977034568787  \n","Epoch:41/50     Step:4|6   loss:0.5334670543670654  \n","Epoch:41/50     Step:5|6   loss:0.5211024284362793  \n","Epoch:41/50     Step:6|6   loss:0.5599773526191711  \n","Epoch:41/50     Step:7|6   loss:0.5210486650466919  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.573465883731842  \n","Epoch:42/50     Step:2|6   loss:0.5312317609786987  \n","Epoch:42/50     Step:3|6   loss:0.5696442127227783  \n","Epoch:42/50     Step:4|6   loss:0.5351004600524902  \n","Epoch:42/50     Step:5|6   loss:0.5708965063095093  \n","Epoch:42/50     Step:6|6   loss:0.5543743968009949  \n","Epoch:42/50     Step:7|6   loss:0.5979156494140625  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.5741935968399048  \n","Epoch:43/50     Step:2|6   loss:0.5950510501861572  \n","Epoch:43/50     Step:3|6   loss:0.628720760345459  \n","Epoch:43/50     Step:4|6   loss:0.6333328485488892  \n","Epoch:43/50     Step:5|6   loss:0.6907898783683777  \n","Epoch:43/50     Step:6|6   loss:0.5900794267654419  \n","Epoch:43/50     Step:7|6   loss:0.701431393623352  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.5415900349617004  \n","Epoch:44/50     Step:2|6   loss:0.6296547651290894  \n","Epoch:44/50     Step:3|6   loss:0.5200175642967224  \n","Epoch:44/50     Step:4|6   loss:0.5906805396080017  \n","Epoch:44/50     Step:5|6   loss:0.5220063328742981  \n","Epoch:44/50     Step:6|6   loss:0.5310292840003967  \n","Epoch:44/50     Step:7|6   loss:0.5173956751823425  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5302588939666748  \n","Epoch:45/50     Step:2|6   loss:0.5275774598121643  \n","Epoch:45/50     Step:3|6   loss:0.5305370092391968  \n","Epoch:45/50     Step:4|6   loss:0.5256611704826355  \n","Epoch:45/50     Step:5|6   loss:0.538733959197998  \n","Epoch:45/50     Step:6|6   loss:0.5302718281745911  \n","Epoch:45/50     Step:7|6   loss:0.5269185304641724  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5270902514457703  \n","Epoch:46/50     Step:2|6   loss:0.5118330717086792  \n","Epoch:46/50     Step:3|6   loss:0.5388268828392029  \n","Epoch:46/50     Step:4|6   loss:0.5146872997283936  \n","Epoch:46/50     Step:5|6   loss:0.5264572501182556  \n","Epoch:46/50     Step:6|6   loss:0.5240492224693298  \n","Epoch:46/50     Step:7|6   loss:0.5304721593856812  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5176159143447876  \n","Epoch:47/50     Step:2|6   loss:0.5273664593696594  \n","Epoch:47/50     Step:3|6   loss:0.5255448222160339  \n","Epoch:47/50     Step:4|6   loss:0.5269308090209961  \n","Epoch:47/50     Step:5|6   loss:0.5220111012458801  \n","Epoch:47/50     Step:6|6   loss:0.5159062147140503  \n","Epoch:47/50     Step:7|6   loss:0.5132998824119568  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.5236817002296448  \n","Epoch:48/50     Step:2|6   loss:0.5100469589233398  \n","Epoch:48/50     Step:3|6   loss:0.5140639543533325  \n","Epoch:48/50     Step:4|6   loss:0.5183143019676208  \n","Epoch:48/50     Step:5|6   loss:0.5203133821487427  \n","Epoch:48/50     Step:6|6   loss:0.5481395125389099  \n","Epoch:48/50     Step:7|6   loss:0.5209312438964844  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5511395931243896  \n","Epoch:49/50     Step:2|6   loss:0.5220549702644348  \n","Epoch:49/50     Step:3|6   loss:0.5234408974647522  \n","Epoch:49/50     Step:4|6   loss:0.5412980318069458  \n","Epoch:49/50     Step:5|6   loss:0.5241904854774475  \n","Epoch:49/50     Step:6|6   loss:0.5916796922683716  \n","Epoch:49/50     Step:7|6   loss:0.5081533789634705  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5592136383056641  \n","Epoch:50/50     Step:2|6   loss:0.512113094329834  \n","Epoch:50/50     Step:3|6   loss:0.5587270855903625  \n","Epoch:50/50     Step:4|6   loss:0.5168102979660034  \n","Epoch:50/50     Step:5|6   loss:0.5298305153846741  \n","Epoch:50/50     Step:6|6   loss:0.5267607569694519  \n","Epoch:50/50     Step:7|6   loss:0.5144960880279541  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Accuracy on test_set: 92.52 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4   --model Logistic_two_stream --mode rgb --index {i}"},{"cell_type":"code","execution_count":4,"id":"93c2b700","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1203633546829224  \n","Epoch:1/50     Step:2|6   loss:2.530146837234497  \n","Epoch:1/50     Step:3|6   loss:1.2690508365631104  \n","Epoch:1/50     Step:4|6   loss:1.8297321796417236  \n","Epoch:1/50     Step:5|6   loss:1.0061185359954834  \n","Epoch:1/50     Step:6|6   loss:1.6020067930221558  \n","Epoch:1/50     Step:7|6   loss:1.0678753852844238  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:84.11%\t train set:85.25%\n","Epoch:2/50     Step:1|6   loss:0.891861081123352  \n","Epoch:2/50     Step:2|6   loss:0.8436769843101501  \n","Epoch:2/50     Step:3|6   loss:0.9903229475021362  \n","Epoch:2/50     Step:4|6   loss:1.220890998840332  \n","Epoch:2/50     Step:5|6   loss:0.9378847479820251  \n","Epoch:2/50     Step:6|6   loss:0.8265118598937988  \n","Epoch:2/50     Step:7|6   loss:1.2060821056365967  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 81.73 %\n","current max accuracy\t test set:84.11%\t train set:85.25%\n","Epoch:3/50     Step:1|6   loss:0.8906846046447754  \n","Epoch:3/50     Step:2|6   loss:0.733539342880249  \n","Epoch:3/50     Step:3|6   loss:0.7763769626617432  \n","Epoch:3/50     Step:4|6   loss:0.7994164228439331  \n","Epoch:3/50     Step:5|6   loss:0.6994628310203552  \n","Epoch:3/50     Step:6|6   loss:0.6386744976043701  \n","Epoch:3/50     Step:7|6   loss:0.7425559759140015  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:84.11%\t train set:88.29%\n","Epoch:4/50     Step:1|6   loss:0.7060837745666504  \n","Epoch:4/50     Step:2|6   loss:0.7166345119476318  \n","Epoch:4/50     Step:3|6   loss:0.6420316100120544  \n","Epoch:4/50     Step:4|6   loss:0.6424532532691956  \n","Epoch:4/50     Step:5|6   loss:0.7025986909866333  \n","Epoch:4/50     Step:6|6   loss:0.6427538394927979  \n","Epoch:4/50     Step:7|6   loss:0.6280670762062073  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:84.11%\t train set:90.63%\n","Epoch:5/50     Step:1|6   loss:0.7829679846763611  \n","Epoch:5/50     Step:2|6   loss:0.5886390209197998  \n","Epoch:5/50     Step:3|6   loss:0.6000018119812012  \n","Epoch:5/50     Step:4|6   loss:0.6319965124130249  \n","Epoch:5/50     Step:5|6   loss:0.6100817918777466  \n","Epoch:5/50     Step:6|6   loss:0.5566303730010986  \n","Epoch:5/50     Step:7|6   loss:0.5968031883239746  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 89.46 %\n","current max accuracy\t test set:84.11%\t train set:90.63%\n","Epoch:6/50     Step:1|6   loss:0.6399503946304321  \n","Epoch:6/50     Step:2|6   loss:0.5737824440002441  \n","Epoch:6/50     Step:3|6   loss:0.5985245704650879  \n","Epoch:6/50     Step:4|6   loss:0.6186869144439697  \n","Epoch:6/50     Step:5|6   loss:0.6350457668304443  \n","Epoch:6/50     Step:6|6   loss:0.5693997144699097  \n","Epoch:6/50     Step:7|6   loss:0.599285364151001  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:89.72%\t train set:97.66%\n","Epoch:7/50     Step:1|6   loss:0.5986077785491943  \n","Epoch:7/50     Step:2|6   loss:0.580220639705658  \n","Epoch:7/50     Step:3|6   loss:0.5802657008171082  \n","Epoch:7/50     Step:4|6   loss:0.5456956624984741  \n","Epoch:7/50     Step:5|6   loss:0.5700379014015198  \n","Epoch:7/50     Step:6|6   loss:0.5619338750839233  \n","Epoch:7/50     Step:7|6   loss:0.5625928640365601  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:97.66%\n","Epoch:8/50     Step:1|6   loss:0.5818231701850891  \n","Epoch:8/50     Step:2|6   loss:0.5410854816436768  \n","Epoch:8/50     Step:3|6   loss:0.5738095641136169  \n","Epoch:8/50     Step:4|6   loss:0.5447923541069031  \n","Epoch:8/50     Step:5|6   loss:0.540940523147583  \n","Epoch:8/50     Step:6|6   loss:0.5304626822471619  \n","Epoch:8/50     Step:7|6   loss:0.531970202922821  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:9/50     Step:1|6   loss:0.5190672278404236  \n","Epoch:9/50     Step:2|6   loss:0.5425812602043152  \n","Epoch:9/50     Step:3|6   loss:0.5360056161880493  \n","Epoch:9/50     Step:4|6   loss:0.5343335866928101  \n","Epoch:9/50     Step:5|6   loss:0.5374950170516968  \n","Epoch:9/50     Step:6|6   loss:0.5260626077651978  \n","Epoch:9/50     Step:7|6   loss:0.5128461122512817  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:10/50     Step:1|6   loss:0.5164743661880493  \n","Epoch:10/50     Step:2|6   loss:0.5311800241470337  \n","Epoch:10/50     Step:3|6   loss:0.524551272392273  \n","Epoch:10/50     Step:4|6   loss:0.5292414426803589  \n","Epoch:10/50     Step:5|6   loss:0.5077948570251465  \n","Epoch:10/50     Step:6|6   loss:0.510400652885437  \n","Epoch:10/50     Step:7|6   loss:0.5298566818237305  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:11/50     Step:1|6   loss:0.5137718915939331  \n","Epoch:11/50     Step:2|6   loss:0.5154052972793579  \n","Epoch:11/50     Step:3|6   loss:0.5134518146514893  \n","Epoch:11/50     Step:4|6   loss:0.5141987800598145  \n","Epoch:11/50     Step:5|6   loss:0.5031512975692749  \n","Epoch:11/50     Step:6|6   loss:0.5114814639091492  \n","Epoch:11/50     Step:7|6   loss:0.5255911350250244  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:12/50     Step:1|6   loss:0.5082666873931885  \n","Epoch:12/50     Step:2|6   loss:0.516033411026001  \n","Epoch:12/50     Step:3|6   loss:0.5069608092308044  \n","Epoch:12/50     Step:4|6   loss:0.5073583126068115  \n","Epoch:12/50     Step:5|6   loss:0.5224643349647522  \n","Epoch:12/50     Step:6|6   loss:0.5060610175132751  \n","Epoch:12/50     Step:7|6   loss:0.5185105800628662  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5033706426620483  \n","Epoch:13/50     Step:2|6   loss:0.506136953830719  \n","Epoch:13/50     Step:3|6   loss:0.49876272678375244  \n","Epoch:13/50     Step:4|6   loss:0.5065792798995972  \n","Epoch:13/50     Step:5|6   loss:0.5086057186126709  \n","Epoch:13/50     Step:6|6   loss:0.503319263458252  \n","Epoch:13/50     Step:7|6   loss:0.5078585147857666  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5003958344459534  \n","Epoch:14/50     Step:2|6   loss:0.5061818957328796  \n","Epoch:14/50     Step:3|6   loss:0.5015175342559814  \n","Epoch:14/50     Step:4|6   loss:0.5021557807922363  \n","Epoch:14/50     Step:5|6   loss:0.49929720163345337  \n","Epoch:14/50     Step:6|6   loss:0.4997064471244812  \n","Epoch:14/50     Step:7|6   loss:0.501296877861023  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.4971984624862671  \n","Epoch:15/50     Step:2|6   loss:0.4980418086051941  \n","Epoch:15/50     Step:3|6   loss:0.5064530968666077  \n","Epoch:15/50     Step:4|6   loss:0.493900865316391  \n","Epoch:15/50     Step:5|6   loss:0.4958997070789337  \n","Epoch:15/50     Step:6|6   loss:0.4998313784599304  \n","Epoch:15/50     Step:7|6   loss:0.4981708526611328  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.49995723366737366  \n","Epoch:16/50     Step:2|6   loss:0.49581724405288696  \n","Epoch:16/50     Step:3|6   loss:0.4928978681564331  \n","Epoch:16/50     Step:4|6   loss:0.5008114576339722  \n","Epoch:16/50     Step:5|6   loss:0.49812573194503784  \n","Epoch:16/50     Step:6|6   loss:0.4921199083328247  \n","Epoch:16/50     Step:7|6   loss:0.49806636571884155  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.4965061545372009  \n","Epoch:17/50     Step:2|6   loss:0.4968971610069275  \n","Epoch:17/50     Step:3|6   loss:0.4995354413986206  \n","Epoch:17/50     Step:4|6   loss:0.494376003742218  \n","Epoch:17/50     Step:5|6   loss:0.49572786688804626  \n","Epoch:17/50     Step:6|6   loss:0.4947037696838379  \n","Epoch:17/50     Step:7|6   loss:0.5019826889038086  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.49216729402542114  \n","Epoch:18/50     Step:2|6   loss:0.4949394464492798  \n","Epoch:18/50     Step:3|6   loss:0.499208927154541  \n","Epoch:18/50     Step:4|6   loss:0.49451160430908203  \n","Epoch:18/50     Step:5|6   loss:0.49544739723205566  \n","Epoch:18/50     Step:6|6   loss:0.4955424666404724  \n","Epoch:18/50     Step:7|6   loss:0.4954385757446289  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4931594133377075  \n","Epoch:19/50     Step:2|6   loss:0.49523019790649414  \n","Epoch:19/50     Step:3|6   loss:0.494464635848999  \n","Epoch:19/50     Step:4|6   loss:0.49777138233184814  \n","Epoch:19/50     Step:5|6   loss:0.4912644624710083  \n","Epoch:19/50     Step:6|6   loss:0.4946698546409607  \n","Epoch:19/50     Step:7|6   loss:0.49433761835098267  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.48958447575569153  \n","Epoch:20/50     Step:2|6   loss:0.492001473903656  \n","Epoch:20/50     Step:3|6   loss:0.4921157956123352  \n","Epoch:20/50     Step:4|6   loss:0.490303635597229  \n","Epoch:20/50     Step:5|6   loss:0.4932636618614197  \n","Epoch:20/50     Step:6|6   loss:0.49181246757507324  \n","Epoch:20/50     Step:7|6   loss:0.4947148859500885  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.49359485507011414  \n","Epoch:21/50     Step:2|6   loss:0.48938965797424316  \n","Epoch:21/50     Step:3|6   loss:0.49313199520111084  \n","Epoch:21/50     Step:4|6   loss:0.4898965060710907  \n","Epoch:21/50     Step:5|6   loss:0.49201875925064087  \n","Epoch:21/50     Step:6|6   loss:0.49200281500816345  \n","Epoch:21/50     Step:7|6   loss:0.4881616234779358  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.49011579155921936  \n","Epoch:22/50     Step:2|6   loss:0.4917009472846985  \n","Epoch:22/50     Step:3|6   loss:0.4888749122619629  \n","Epoch:22/50     Step:4|6   loss:0.49016648530960083  \n","Epoch:22/50     Step:5|6   loss:0.4896342158317566  \n","Epoch:22/50     Step:6|6   loss:0.49110448360443115  \n","Epoch:22/50     Step:7|6   loss:0.48871928453445435  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.48947370052337646  \n","Epoch:23/50     Step:2|6   loss:0.4906842112541199  \n","Epoch:23/50     Step:3|6   loss:0.4893748164176941  \n","Epoch:23/50     Step:4|6   loss:0.4886464476585388  \n","Epoch:23/50     Step:5|6   loss:0.48988962173461914  \n","Epoch:23/50     Step:6|6   loss:0.4886120855808258  \n","Epoch:23/50     Step:7|6   loss:0.48923155665397644  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4898175001144409  \n","Epoch:24/50     Step:2|6   loss:0.4905731678009033  \n","Epoch:24/50     Step:3|6   loss:0.489641398191452  \n","Epoch:24/50     Step:4|6   loss:0.48988568782806396  \n","Epoch:24/50     Step:5|6   loss:0.48792991042137146  \n","Epoch:24/50     Step:6|6   loss:0.48886507749557495  \n","Epoch:24/50     Step:7|6   loss:0.4887247085571289  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.48887139558792114  \n","Epoch:25/50     Step:2|6   loss:0.4883354902267456  \n","Epoch:25/50     Step:3|6   loss:0.4887808859348297  \n","Epoch:25/50     Step:4|6   loss:0.48835107684135437  \n","Epoch:25/50     Step:5|6   loss:0.4879641830921173  \n","Epoch:25/50     Step:6|6   loss:0.48915648460388184  \n","Epoch:25/50     Step:7|6   loss:0.4884170889854431  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48758456110954285  \n","Epoch:26/50     Step:2|6   loss:0.48818379640579224  \n","Epoch:26/50     Step:3|6   loss:0.48861005902290344  \n","Epoch:26/50     Step:4|6   loss:0.48888149857521057  \n","Epoch:26/50     Step:5|6   loss:0.48925551772117615  \n","Epoch:26/50     Step:6|6   loss:0.4881862998008728  \n","Epoch:26/50     Step:7|6   loss:0.4868277311325073  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.48882099986076355  \n","Epoch:27/50     Step:2|6   loss:0.4871227741241455  \n","Epoch:27/50     Step:3|6   loss:0.48854947090148926  \n","Epoch:27/50     Step:4|6   loss:0.4889903664588928  \n","Epoch:27/50     Step:5|6   loss:0.48793402314186096  \n","Epoch:27/50     Step:6|6   loss:0.4895368814468384  \n","Epoch:27/50     Step:7|6   loss:0.49003589153289795  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.4877956807613373  \n","Epoch:28/50     Step:2|6   loss:0.48951423168182373  \n","Epoch:28/50     Step:3|6   loss:0.4875640571117401  \n","Epoch:28/50     Step:4|6   loss:0.4900996685028076  \n","Epoch:28/50     Step:5|6   loss:0.48801836371421814  \n","Epoch:28/50     Step:6|6   loss:0.4880274832248688  \n","Epoch:28/50     Step:7|6   loss:0.488192081451416  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.48779022693634033  \n","Epoch:29/50     Step:2|6   loss:0.4877893328666687  \n","Epoch:29/50     Step:3|6   loss:0.4879201054573059  \n","Epoch:29/50     Step:4|6   loss:0.48702502250671387  \n","Epoch:29/50     Step:5|6   loss:0.48728084564208984  \n","Epoch:29/50     Step:6|6   loss:0.48730605840682983  \n","Epoch:29/50     Step:7|6   loss:0.48641031980514526  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.48771095275878906  \n","Epoch:30/50     Step:2|6   loss:0.488098680973053  \n","Epoch:30/50     Step:3|6   loss:0.48760899901390076  \n","Epoch:30/50     Step:4|6   loss:0.48667141795158386  \n","Epoch:30/50     Step:5|6   loss:0.4872923493385315  \n","Epoch:30/50     Step:6|6   loss:0.48699289560317993  \n","Epoch:30/50     Step:7|6   loss:0.4877238869667053  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.4874810576438904  \n","Epoch:31/50     Step:2|6   loss:0.48734140396118164  \n","Epoch:31/50     Step:3|6   loss:0.4873504042625427  \n","Epoch:31/50     Step:4|6   loss:0.48691171407699585  \n","Epoch:31/50     Step:5|6   loss:0.4863821864128113  \n","Epoch:31/50     Step:6|6   loss:0.48855629563331604  \n","Epoch:31/50     Step:7|6   loss:0.4867296814918518  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4863767623901367  \n","Epoch:32/50     Step:2|6   loss:0.48666447401046753  \n","Epoch:32/50     Step:3|6   loss:0.4864932894706726  \n","Epoch:32/50     Step:4|6   loss:0.48666706681251526  \n","Epoch:32/50     Step:5|6   loss:0.48747000098228455  \n","Epoch:32/50     Step:6|6   loss:0.4869639277458191  \n","Epoch:32/50     Step:7|6   loss:0.4865242838859558  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4867248833179474  \n","Epoch:33/50     Step:2|6   loss:0.48662686347961426  \n","Epoch:33/50     Step:3|6   loss:0.4863024353981018  \n","Epoch:33/50     Step:4|6   loss:0.48625802993774414  \n","Epoch:33/50     Step:5|6   loss:0.4866088032722473  \n","Epoch:33/50     Step:6|6   loss:0.4865474998950958  \n","Epoch:33/50     Step:7|6   loss:0.4870000183582306  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.48681584000587463  \n","Epoch:34/50     Step:2|6   loss:0.4865766167640686  \n","Epoch:34/50     Step:3|6   loss:0.4869212210178375  \n","Epoch:34/50     Step:4|6   loss:0.4867408573627472  \n","Epoch:34/50     Step:5|6   loss:0.4864796996116638  \n","Epoch:34/50     Step:6|6   loss:0.48678916692733765  \n","Epoch:34/50     Step:7|6   loss:0.48572200536727905  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.48684802651405334  \n","Epoch:35/50     Step:2|6   loss:0.4863521456718445  \n","Epoch:35/50     Step:3|6   loss:0.4869908094406128  \n","Epoch:35/50     Step:4|6   loss:0.486712783575058  \n","Epoch:35/50     Step:5|6   loss:0.4861786365509033  \n","Epoch:35/50     Step:6|6   loss:0.48655077815055847  \n","Epoch:35/50     Step:7|6   loss:0.4861803650856018  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.48628681898117065  \n","Epoch:36/50     Step:2|6   loss:0.486950159072876  \n","Epoch:36/50     Step:3|6   loss:0.48645851016044617  \n","Epoch:36/50     Step:4|6   loss:0.4864150583744049  \n","Epoch:36/50     Step:5|6   loss:0.48665422201156616  \n","Epoch:36/50     Step:6|6   loss:0.48686692118644714  \n","Epoch:36/50     Step:7|6   loss:0.4860759377479553  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4862726330757141  \n","Epoch:37/50     Step:2|6   loss:0.4867110848426819  \n","Epoch:37/50     Step:3|6   loss:0.48632824420928955  \n","Epoch:37/50     Step:4|6   loss:0.4866912364959717  \n","Epoch:37/50     Step:5|6   loss:0.485992968082428  \n","Epoch:37/50     Step:6|6   loss:0.48702365159988403  \n","Epoch:37/50     Step:7|6   loss:0.4859602451324463  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4862833321094513  \n","Epoch:38/50     Step:2|6   loss:0.48654910922050476  \n","Epoch:38/50     Step:3|6   loss:0.48629677295684814  \n","Epoch:38/50     Step:4|6   loss:0.48662853240966797  \n","Epoch:38/50     Step:5|6   loss:0.48609787225723267  \n","Epoch:38/50     Step:6|6   loss:0.4867139160633087  \n","Epoch:38/50     Step:7|6   loss:0.4859282076358795  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.48662933707237244  \n","Epoch:39/50     Step:2|6   loss:0.4861694276332855  \n","Epoch:39/50     Step:3|6   loss:0.4859924912452698  \n","Epoch:39/50     Step:4|6   loss:0.4861029386520386  \n","Epoch:39/50     Step:5|6   loss:0.48616230487823486  \n","Epoch:39/50     Step:6|6   loss:0.4858240783214569  \n","Epoch:39/50     Step:7|6   loss:0.4858799874782562  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48572826385498047  \n","Epoch:40/50     Step:2|6   loss:0.4858660399913788  \n","Epoch:40/50     Step:3|6   loss:0.48598697781562805  \n","Epoch:40/50     Step:4|6   loss:0.486193984746933  \n","Epoch:40/50     Step:5|6   loss:0.4860396385192871  \n","Epoch:40/50     Step:6|6   loss:0.4858810603618622  \n","Epoch:40/50     Step:7|6   loss:0.48623126745224  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.48621025681495667  \n","Epoch:41/50     Step:2|6   loss:0.486055850982666  \n","Epoch:41/50     Step:3|6   loss:0.4858916103839874  \n","Epoch:41/50     Step:4|6   loss:0.4860057234764099  \n","Epoch:41/50     Step:5|6   loss:0.48561638593673706  \n","Epoch:41/50     Step:6|6   loss:0.4859583377838135  \n","Epoch:41/50     Step:7|6   loss:0.48553088307380676  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48576048016548157  \n","Epoch:42/50     Step:2|6   loss:0.48597291111946106  \n","Epoch:42/50     Step:3|6   loss:0.48590147495269775  \n","Epoch:42/50     Step:4|6   loss:0.4858129024505615  \n","Epoch:42/50     Step:5|6   loss:0.4858975410461426  \n","Epoch:42/50     Step:6|6   loss:0.48589029908180237  \n","Epoch:42/50     Step:7|6   loss:0.4859660863876343  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.48615139722824097  \n","Epoch:43/50     Step:2|6   loss:0.4854738414287567  \n","Epoch:43/50     Step:3|6   loss:0.4855598211288452  \n","Epoch:43/50     Step:4|6   loss:0.48569852113723755  \n","Epoch:43/50     Step:5|6   loss:0.4860597848892212  \n","Epoch:43/50     Step:6|6   loss:0.48629066348075867  \n","Epoch:43/50     Step:7|6   loss:0.48601728677749634  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.485617458820343  \n","Epoch:44/50     Step:2|6   loss:0.4855167269706726  \n","Epoch:44/50     Step:3|6   loss:0.48554450273513794  \n","Epoch:44/50     Step:4|6   loss:0.48542243242263794  \n","Epoch:44/50     Step:5|6   loss:0.4858451187610626  \n","Epoch:44/50     Step:6|6   loss:0.485748827457428  \n","Epoch:44/50     Step:7|6   loss:0.48580825328826904  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.48541203141212463  \n","Epoch:45/50     Step:2|6   loss:0.4855467975139618  \n","Epoch:45/50     Step:3|6   loss:0.48555198311805725  \n","Epoch:45/50     Step:4|6   loss:0.48579874634742737  \n","Epoch:45/50     Step:5|6   loss:0.48562532663345337  \n","Epoch:45/50     Step:6|6   loss:0.48570606112480164  \n","Epoch:45/50     Step:7|6   loss:0.48580580949783325  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.48565733432769775  \n","Epoch:46/50     Step:2|6   loss:0.4857133626937866  \n","Epoch:46/50     Step:3|6   loss:0.4855441153049469  \n","Epoch:46/50     Step:4|6   loss:0.48580482602119446  \n","Epoch:46/50     Step:5|6   loss:0.4856805205345154  \n","Epoch:46/50     Step:6|6   loss:0.48548001050949097  \n","Epoch:46/50     Step:7|6   loss:0.48555827140808105  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48542481660842896  \n","Epoch:47/50     Step:2|6   loss:0.4855954051017761  \n","Epoch:47/50     Step:3|6   loss:0.48548823595046997  \n","Epoch:47/50     Step:4|6   loss:0.4857890009880066  \n","Epoch:47/50     Step:5|6   loss:0.4855133593082428  \n","Epoch:47/50     Step:6|6   loss:0.4854127764701843  \n","Epoch:47/50     Step:7|6   loss:0.48563361167907715  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4855329692363739  \n","Epoch:48/50     Step:2|6   loss:0.4854753017425537  \n","Epoch:48/50     Step:3|6   loss:0.48571300506591797  \n","Epoch:48/50     Step:4|6   loss:0.4857519567012787  \n","Epoch:48/50     Step:5|6   loss:0.48587876558303833  \n","Epoch:48/50     Step:6|6   loss:0.48565077781677246  \n","Epoch:48/50     Step:7|6   loss:0.48600056767463684  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4857182502746582  \n","Epoch:49/50     Step:2|6   loss:0.48585987091064453  \n","Epoch:49/50     Step:3|6   loss:0.48552435636520386  \n","Epoch:49/50     Step:4|6   loss:0.48562899231910706  \n","Epoch:49/50     Step:5|6   loss:0.4857896566390991  \n","Epoch:49/50     Step:6|6   loss:0.4861592650413513  \n","Epoch:49/50     Step:7|6   loss:0.4856654703617096  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4855450391769409  \n","Epoch:50/50     Step:2|6   loss:0.48626041412353516  \n","Epoch:50/50     Step:3|6   loss:0.48553550243377686  \n","Epoch:50/50     Step:4|6   loss:0.48570799827575684  \n","Epoch:50/50     Step:5|6   loss:0.48539382219314575  \n","Epoch:50/50     Step:6|6   loss:0.48568642139434814  \n","Epoch:50/50     Step:7|6   loss:0.485379695892334  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Accuracy on test_set: 92.52 %\n","1\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1104991436004639  \n","Epoch:1/50     Step:2|6   loss:5.425106525421143  \n","Epoch:1/50     Step:3|6   loss:0.9584481120109558  \n","Epoch:1/50     Step:4|6   loss:2.8695404529571533  \n","Epoch:1/50     Step:5|6   loss:3.0988776683807373  \n","Epoch:1/50     Step:6|6   loss:2.2920596599578857  \n","Epoch:1/50     Step:7|6   loss:1.0965149402618408  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 77.28 %\n","current max accuracy\t test set:85.98%\t train set:77.28%\n","Epoch:2/50     Step:1|6   loss:1.6141669750213623  \n","Epoch:2/50     Step:2|6   loss:1.7544043064117432  \n","Epoch:2/50     Step:3|6   loss:1.57796311378479  \n","Epoch:2/50     Step:4|6   loss:1.1330711841583252  \n","Epoch:2/50     Step:5|6   loss:1.2400951385498047  \n","Epoch:2/50     Step:6|6   loss:1.595365285873413  \n","Epoch:2/50     Step:7|6   loss:1.2850191593170166  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:85.98%\t train set:85.01%\n","Epoch:3/50     Step:1|6   loss:1.0790671110153198  \n","Epoch:3/50     Step:2|6   loss:0.8982769250869751  \n","Epoch:3/50     Step:3|6   loss:1.0854181051254272  \n","Epoch:3/50     Step:4|6   loss:1.0222121477127075  \n","Epoch:3/50     Step:5|6   loss:0.9099966287612915  \n","Epoch:3/50     Step:6|6   loss:0.8862212896347046  \n","Epoch:3/50     Step:7|6   loss:0.877197265625  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:85.98%\t train set:85.01%\n","Epoch:4/50     Step:1|6   loss:0.7979830503463745  \n","Epoch:4/50     Step:2|6   loss:1.0175650119781494  \n","Epoch:4/50     Step:3|6   loss:0.8624899387359619  \n","Epoch:4/50     Step:4|6   loss:0.774925172328949  \n","Epoch:4/50     Step:5|6   loss:0.6572892665863037  \n","Epoch:4/50     Step:6|6   loss:0.8574216365814209  \n","Epoch:4/50     Step:7|6   loss:0.7339149117469788  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:85.98%\t train set:94.15%\n","Epoch:5/50     Step:1|6   loss:0.6025118231773376  \n","Epoch:5/50     Step:2|6   loss:0.6415321826934814  \n","Epoch:5/50     Step:3|6   loss:0.6880991458892822  \n","Epoch:5/50     Step:4|6   loss:0.655116081237793  \n","Epoch:5/50     Step:5|6   loss:0.616123378276825  \n","Epoch:5/50     Step:6|6   loss:0.5830947160720825  \n","Epoch:5/50     Step:7|6   loss:0.6200284957885742  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:88.79%\t train set:94.15%\n","Epoch:6/50     Step:1|6   loss:0.6256742477416992  \n","Epoch:6/50     Step:2|6   loss:0.6240936517715454  \n","Epoch:6/50     Step:3|6   loss:0.5815797448158264  \n","Epoch:6/50     Step:4|6   loss:0.5979127883911133  \n","Epoch:6/50     Step:5|6   loss:0.60981285572052  \n","Epoch:6/50     Step:6|6   loss:0.5983385443687439  \n","Epoch:6/50     Step:7|6   loss:0.5371764302253723  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:88.79%\t train set:95.08%\n","Epoch:7/50     Step:1|6   loss:0.5753822326660156  \n","Epoch:7/50     Step:2|6   loss:0.5709435939788818  \n","Epoch:7/50     Step:3|6   loss:0.5593041777610779  \n","Epoch:7/50     Step:4|6   loss:0.5567562580108643  \n","Epoch:7/50     Step:5|6   loss:0.5819534063339233  \n","Epoch:7/50     Step:6|6   loss:0.5815224647521973  \n","Epoch:7/50     Step:7|6   loss:0.5747995376586914  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:88.79%\t train set:99.3%\n","Epoch:8/50     Step:1|6   loss:0.5511706471443176  \n","Epoch:8/50     Step:2|6   loss:0.5707564353942871  \n","Epoch:8/50     Step:3|6   loss:0.5535491704940796  \n","Epoch:8/50     Step:4|6   loss:0.533318281173706  \n","Epoch:8/50     Step:5|6   loss:0.5450241565704346  \n","Epoch:8/50     Step:6|6   loss:0.5515204071998596  \n","Epoch:8/50     Step:7|6   loss:0.5484659671783447  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:88.79%\t train set:99.53%\n","Epoch:9/50     Step:1|6   loss:0.5289487838745117  \n","Epoch:9/50     Step:2|6   loss:0.5377881526947021  \n","Epoch:9/50     Step:3|6   loss:0.5288175344467163  \n","Epoch:9/50     Step:4|6   loss:0.5168927907943726  \n","Epoch:9/50     Step:5|6   loss:0.5214977264404297  \n","Epoch:9/50     Step:6|6   loss:0.5466557741165161  \n","Epoch:9/50     Step:7|6   loss:0.540509045124054  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:88.79%\t train set:99.53%\n","Epoch:10/50     Step:1|6   loss:0.5233817100524902  \n","Epoch:10/50     Step:2|6   loss:0.5394155383110046  \n","Epoch:10/50     Step:3|6   loss:0.5223166942596436  \n","Epoch:10/50     Step:4|6   loss:0.5239663124084473  \n","Epoch:10/50     Step:5|6   loss:0.5100315809249878  \n","Epoch:10/50     Step:6|6   loss:0.5228348970413208  \n","Epoch:10/50     Step:7|6   loss:0.5220146775245667  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:88.79%\t train set:99.77%\n","Epoch:11/50     Step:1|6   loss:0.5126396417617798  \n","Epoch:11/50     Step:2|6   loss:0.5236420035362244  \n","Epoch:11/50     Step:3|6   loss:0.5351898670196533  \n","Epoch:11/50     Step:4|6   loss:0.5119155049324036  \n","Epoch:11/50     Step:5|6   loss:0.5291643738746643  \n","Epoch:11/50     Step:6|6   loss:0.5263655185699463  \n","Epoch:11/50     Step:7|6   loss:0.49940842390060425  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:12/50     Step:1|6   loss:0.5094581842422485  \n","Epoch:12/50     Step:2|6   loss:0.5153948068618774  \n","Epoch:12/50     Step:3|6   loss:0.5019631385803223  \n","Epoch:12/50     Step:4|6   loss:0.5105810165405273  \n","Epoch:12/50     Step:5|6   loss:0.535236120223999  \n","Epoch:12/50     Step:6|6   loss:0.5045032501220703  2\n","\n","Epoch:12/50     Step:7|6   loss:0.5078141093254089  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5014824867248535  \n","Epoch:13/50     Step:2|6   loss:0.5083696246147156  \n","Epoch:13/50     Step:3|6   loss:0.5271005034446716  \n","Epoch:13/50     Step:4|6   loss:0.5028800368309021  \n","Epoch:13/50     Step:5|6   loss:0.5043137073516846  \n","Epoch:13/50     Step:6|6   loss:0.5027909278869629  \n","Epoch:13/50     Step:7|6   loss:0.5039139986038208  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5070125460624695  \n","Epoch:14/50     Step:2|6   loss:0.49607613682746887  \n","Epoch:14/50     Step:3|6   loss:0.499948650598526  \n","Epoch:14/50     Step:4|6   loss:0.5070616602897644  \n","Epoch:14/50     Step:5|6   loss:0.498110294342041  \n","Epoch:14/50     Step:6|6   loss:0.5033619999885559  \n","Epoch:14/50     Step:7|6   loss:0.502050518989563  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.5010314583778381  \n","Epoch:15/50     Step:2|6   loss:0.5065025091171265  \n","Epoch:15/50     Step:3|6   loss:0.5070006251335144  \n","Epoch:15/50     Step:4|6   loss:0.4939996600151062  \n","Epoch:15/50     Step:5|6   loss:0.49430620670318604  \n","Epoch:15/50     Step:6|6   loss:0.4982038736343384  \n","Epoch:15/50     Step:7|6   loss:0.4989266097545624  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.4995574951171875  \n","Epoch:16/50     Step:2|6   loss:0.5030307769775391  \n","Epoch:16/50     Step:3|6   loss:0.49443894624710083  \n","Epoch:16/50     Step:4|6   loss:0.49591028690338135  \n","Epoch:16/50     Step:5|6   loss:0.4995978772640228  \n","Epoch:16/50     Step:6|6   loss:0.49439537525177  \n","Epoch:16/50     Step:7|6   loss:0.5006790161132812  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.5041337013244629  \n","Epoch:17/50     Step:2|6   loss:0.4934267997741699  \n","Epoch:17/50     Step:3|6   loss:0.4972916841506958  \n","Epoch:17/50     Step:4|6   loss:0.5001124143600464  \n","Epoch:17/50     Step:5|6   loss:0.49396058917045593  \n","Epoch:17/50     Step:6|6   loss:0.4943908452987671  \n","Epoch:17/50     Step:7|6   loss:0.4925200343132019  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.4933249354362488  \n","Epoch:18/50     Step:2|6   loss:0.49562251567840576  \n","Epoch:18/50     Step:3|6   loss:0.495574027299881  \n","Epoch:18/50     Step:4|6   loss:0.49495717883110046  \n","Epoch:18/50     Step:5|6   loss:0.4984406530857086  \n","Epoch:18/50     Step:6|6   loss:0.492636501789093  \n","Epoch:18/50     Step:7|6   loss:0.49248993396759033  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.49773508310317993  \n","Epoch:19/50     Step:2|6   loss:0.4920008182525635  \n","Epoch:19/50     Step:3|6   loss:0.49329543113708496  \n","Epoch:19/50     Step:4|6   loss:0.491968035697937  \n","Epoch:19/50     Step:5|6   loss:0.49521082639694214  \n","Epoch:19/50     Step:6|6   loss:0.49271801114082336  \n","Epoch:19/50     Step:7|6   loss:0.4971582889556885  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49209344387054443  \n","Epoch:20/50     Step:2|6   loss:0.49374499917030334  \n","Epoch:20/50     Step:3|6   loss:0.4933319389820099  \n","Epoch:20/50     Step:4|6   loss:0.49514222145080566  \n","Epoch:20/50     Step:5|6   loss:0.4911092519760132  \n","Epoch:20/50     Step:6|6   loss:0.491444855928421  \n","Epoch:20/50     Step:7|6   loss:0.4928930997848511  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4937870502471924  \n","Epoch:21/50     Step:2|6   loss:0.49207931756973267  \n","Epoch:21/50     Step:3|6   loss:0.495233416557312  \n","Epoch:21/50     Step:4|6   loss:0.49396586418151855  \n","Epoch:21/50     Step:5|6   loss:0.48880085349082947  \n","Epoch:21/50     Step:6|6   loss:0.4893624484539032  \n","Epoch:21/50     Step:7|6   loss:0.49170342087745667  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.492729514837265  \n","Epoch:22/50     Step:2|6   loss:0.4914220869541168  \n","Epoch:22/50     Step:3|6   loss:0.4935839772224426  \n","Epoch:22/50     Step:4|6   loss:0.4903916120529175  \n","Epoch:22/50     Step:5|6   loss:0.4902411699295044  \n","Epoch:22/50     Step:6|6   loss:0.4910012185573578  \n","Epoch:22/50     Step:7|6   loss:0.4925956130027771  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.49101102352142334  \n","Epoch:23/50     Step:2|6   loss:0.4936761260032654  \n","Epoch:23/50     Step:3|6   loss:0.4925285577774048  \n","Epoch:23/50     Step:4|6   loss:0.4879692792892456  \n","Epoch:23/50     Step:5|6   loss:0.49103015661239624  \n","Epoch:23/50     Step:6|6   loss:0.4883745014667511  \n","Epoch:23/50     Step:7|6   loss:0.491721510887146  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.48920315504074097  \n","Epoch:24/50     Step:2|6   loss:0.48909902572631836  \n","Epoch:24/50     Step:3|6   loss:0.4920576214790344  \n","Epoch:24/50     Step:4|6   loss:0.48986342549324036  \n","Epoch:24/50     Step:5|6   loss:0.4922281503677368  \n","Epoch:24/50     Step:6|6   loss:0.4884459972381592  \n","Epoch:24/50     Step:7|6   loss:0.48991966247558594  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.48832595348358154  \n","Epoch:25/50     Step:2|6   loss:0.48831242322921753  \n","Epoch:25/50     Step:3|6   loss:0.49321287870407104  \n","Epoch:25/50     Step:4|6   loss:0.4880622327327728  \n","Epoch:25/50     Step:5|6   loss:0.48951226472854614  \n","Epoch:25/50     Step:6|6   loss:0.4893382489681244  \n","Epoch:25/50     Step:7|6   loss:0.4920564591884613  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48976483941078186  \n","Epoch:26/50     Step:2|6   loss:0.4910363256931305  \n","Epoch:26/50     Step:3|6   loss:0.4904896020889282  \n","Epoch:26/50     Step:4|6   loss:0.4882630705833435  \n","Epoch:26/50     Step:5|6   loss:0.4891144037246704  \n","Epoch:26/50     Step:6|6   loss:0.48776841163635254  \n","Epoch:26/50     Step:7|6   loss:0.4879170358181  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.48974281549453735  \n","Epoch:27/50     Step:2|6   loss:0.48814961314201355  \n","Epoch:27/50     Step:3|6   loss:0.4871131479740143  \n","Epoch:27/50     Step:4|6   loss:0.48950570821762085  \n","Epoch:27/50     Step:5|6   loss:0.4884780943393707  \n","Epoch:27/50     Step:6|6   loss:0.4876008629798889  \n","Epoch:27/50     Step:7|6   loss:0.48899850249290466  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.4909780025482178  \n","Epoch:28/50     Step:2|6   loss:0.48959338665008545  \n","Epoch:28/50     Step:3|6   loss:0.4887899160385132  \n","Epoch:28/50     Step:4|6   loss:0.4872206449508667  \n","Epoch:28/50     Step:5|6   loss:0.4876163899898529  \n","Epoch:28/50     Step:6|6   loss:0.48751571774482727  \n","Epoch:28/50     Step:7|6   loss:0.4872245192527771  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4873851537704468  \n","Epoch:29/50     Step:2|6   loss:0.4880194067955017  \n","Epoch:29/50     Step:3|6   loss:0.4872697591781616  \n","Epoch:29/50     Step:4|6   loss:0.4878333806991577  \n","Epoch:29/50     Step:5|6   loss:0.48710793256759644  \n","Epoch:29/50     Step:6|6   loss:0.4920167326927185  \n","Epoch:29/50     Step:7|6   loss:0.4871498942375183  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.488191694021225  \n","Epoch:30/50     Step:2|6   loss:0.4879314601421356  \n","Epoch:30/50     Step:3|6   loss:0.4873173236846924  \n","Epoch:30/50     Step:4|6   loss:0.48808255791664124  \n","Epoch:30/50     Step:5|6   loss:0.48748937249183655  \n","Epoch:30/50     Step:6|6   loss:0.487829327583313  \n","Epoch:30/50     Step:7|6   loss:0.4897223711013794  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48831772804260254  \n","Epoch:31/50     Step:2|6   loss:0.48632243275642395  \n","Epoch:31/50     Step:3|6   loss:0.48866182565689087  \n","Epoch:31/50     Step:4|6   loss:0.487596333026886  \n","Epoch:31/50     Step:5|6   loss:0.48703646659851074  \n","Epoch:31/50     Step:6|6   loss:0.4882541298866272  \n","Epoch:31/50     Step:7|6   loss:0.48737919330596924  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4875989556312561  \n","Epoch:32/50     Step:2|6   loss:0.4872880280017853  \n","Epoch:32/50     Step:3|6   loss:0.48761847615242004  \n","Epoch:32/50     Step:4|6   loss:0.4872186779975891  \n","Epoch:32/50     Step:5|6   loss:0.4864881932735443  \n","Epoch:32/50     Step:6|6   loss:0.48767876625061035  \n","Epoch:32/50     Step:7|6   loss:0.4888620972633362  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48821884393692017  \n","Epoch:33/50     Step:2|6   loss:0.4866889715194702  \n","Epoch:33/50     Step:3|6   loss:0.4886202812194824  \n","Epoch:33/50     Step:4|6   loss:0.4864785075187683  \n","Epoch:33/50     Step:5|6   loss:0.48742854595184326  \n","Epoch:33/50     Step:6|6   loss:0.48715639114379883  \n","Epoch:33/50     Step:7|6   loss:0.48670828342437744  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.48679354786872864  \n","Epoch:34/50     Step:2|6   loss:0.48707371950149536  \n","Epoch:34/50     Step:3|6   loss:0.48713260889053345  \n","Epoch:34/50     Step:4|6   loss:0.48837214708328247  \n","Epoch:34/50     Step:5|6   loss:0.4876129925251007  \n","Epoch:34/50     Step:6|6   loss:0.4870796203613281  \n","Epoch:34/50     Step:7|6   loss:0.4860263168811798  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4879705011844635  \n","Epoch:35/50     Step:2|6   loss:0.486663281917572  \n","Epoch:35/50     Step:3|6   loss:0.487248957157135  \n","Epoch:35/50     Step:4|6   loss:0.48666054010391235  \n","Epoch:35/50     Step:5|6   loss:0.4864959120750427  \n","Epoch:35/50     Step:6|6   loss:0.4869159162044525  \n","Epoch:35/50     Step:7|6   loss:0.48684972524642944  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4866032600402832  \n","Epoch:36/50     Step:2|6   loss:0.48689940571784973  \n","Epoch:36/50     Step:3|6   loss:0.4873703122138977  \n","Epoch:36/50     Step:4|6   loss:0.4861975312232971  \n","Epoch:36/50     Step:5|6   loss:0.4861321747303009  \n","Epoch:36/50     Step:6|6   loss:0.48665308952331543  \n","Epoch:36/50     Step:7|6   loss:0.48700135946273804  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48720961809158325  \n","Epoch:37/50     Step:2|6   loss:0.486616849899292  \n","Epoch:37/50     Step:3|6   loss:0.4860959053039551  \n","Epoch:37/50     Step:4|6   loss:0.4861048758029938  \n","Epoch:37/50     Step:5|6   loss:0.48662304878234863  \n","Epoch:37/50     Step:6|6   loss:0.4863690435886383  \n","Epoch:37/50     Step:7|6   loss:0.4876869022846222  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.48616108298301697  \n","Epoch:38/50     Step:2|6   loss:0.4861542582511902  \n","Epoch:38/50     Step:3|6   loss:0.4865584373474121  \n","Epoch:38/50     Step:4|6   loss:0.48779726028442383  \n","Epoch:38/50     Step:5|6   loss:0.48642754554748535  \n","Epoch:38/50     Step:6|6   loss:0.4860391616821289  \n","Epoch:38/50     Step:7|6   loss:0.4877275228500366  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4857439398765564  \n","Epoch:39/50     Step:2|6   loss:0.4869014024734497  \n","Epoch:39/50     Step:3|6   loss:0.4878233075141907  \n","Epoch:39/50     Step:4|6   loss:0.4859042167663574  \n","Epoch:39/50     Step:5|6   loss:0.48765718936920166  \n","Epoch:39/50     Step:6|6   loss:0.48697030544281006  \n","Epoch:39/50     Step:7|6   loss:0.48686546087265015  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48769840598106384  \n","Epoch:40/50     Step:2|6   loss:0.48677703738212585  \n","Epoch:40/50     Step:3|6   loss:0.4867746829986572  \n","Epoch:40/50     Step:4|6   loss:0.4874676465988159  \n","Epoch:40/50     Step:5|6   loss:0.4858383536338806  \n","Epoch:40/50     Step:6|6   loss:0.4872441291809082  \n","Epoch:40/50     Step:7|6   loss:0.48599135875701904  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.48779088258743286  \n","Epoch:41/50     Step:2|6   loss:0.48620033264160156  \n","Epoch:41/50     Step:3|6   loss:0.4866458773612976  \n","Epoch:41/50     Step:4|6   loss:0.48600196838378906  \n","Epoch:41/50     Step:5|6   loss:0.4859667420387268  \n","Epoch:41/50     Step:6|6   loss:0.48585742712020874  \n","Epoch:41/50     Step:7|6   loss:0.48582136631011963  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4870873987674713  \n","Epoch:42/50     Step:2|6   loss:0.4861115515232086  \n","Epoch:42/50     Step:3|6   loss:0.48610594868659973  \n","Epoch:42/50     Step:4|6   loss:0.4865058660507202  \n","Epoch:42/50     Step:5|6   loss:0.48615163564682007  \n","Epoch:42/50     Step:6|6   loss:0.4861236810684204  \n","Epoch:42/50     Step:7|6   loss:0.4860093891620636  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.48639005422592163  \n","Epoch:43/50     Step:2|6   loss:0.48798081278800964  \n","Epoch:43/50     Step:3|6   loss:0.4860953390598297  \n","Epoch:43/50     Step:4|6   loss:0.4862292408943176  \n","Epoch:43/50     Step:5|6   loss:0.485919713973999  \n","Epoch:43/50     Step:6|6   loss:0.4861775040626526  \n","Epoch:43/50     Step:7|6   loss:0.4860554337501526  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4862270951271057  \n","Epoch:44/50     Step:2|6   loss:0.4856852889060974  \n","Epoch:44/50     Step:3|6   loss:0.4866296648979187  \n","Epoch:44/50     Step:4|6   loss:0.48680752515792847  \n","Epoch:44/50     Step:5|6   loss:0.4862119257450104  \n","Epoch:44/50     Step:6|6   loss:0.4857614040374756  \n","Epoch:44/50     Step:7|6   loss:0.48569390177726746  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4861663281917572  \n","Epoch:45/50     Step:2|6   loss:0.48645779490470886  \n","Epoch:45/50     Step:3|6   loss:0.48572760820388794  \n","Epoch:45/50     Step:4|6   loss:0.485777884721756  \n","Epoch:45/50     Step:5|6   loss:0.4857068955898285  \n","Epoch:45/50     Step:6|6   loss:0.48581111431121826  \n","Epoch:45/50     Step:7|6   loss:0.4863344430923462  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4863673448562622  \n","Epoch:46/50     Step:2|6   loss:0.48550668358802795  \n","Epoch:46/50     Step:3|6   loss:0.48588597774505615  \n","Epoch:46/50     Step:4|6   loss:0.4865969717502594  \n","Epoch:46/50     Step:5|6   loss:0.48630720376968384  \n","Epoch:46/50     Step:6|6   loss:0.486115962266922  \n","Epoch:46/50     Step:7|6   loss:0.4863113462924957  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4856153130531311  \n","Epoch:47/50     Step:2|6   loss:0.48760390281677246  \n","Epoch:47/50     Step:3|6   loss:0.48577064275741577  \n","Epoch:47/50     Step:4|6   loss:0.4862756133079529  \n","Epoch:47/50     Step:5|6   loss:0.48596280813217163  \n","Epoch:47/50     Step:6|6   loss:0.4858691394329071  \n","Epoch:47/50     Step:7|6   loss:0.485427588224411  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.48615872859954834  \n","Epoch:48/50     Step:2|6   loss:0.4859798550605774  \n","Epoch:48/50     Step:3|6   loss:0.4861639738082886  \n","Epoch:48/50     Step:4|6   loss:0.4859679639339447  \n","Epoch:48/50     Step:5|6   loss:0.4857127070426941  \n","Epoch:48/50     Step:6|6   loss:0.4864436984062195  \n","Epoch:48/50     Step:7|6   loss:0.4856971204280853  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48564413189888  \n","Epoch:49/50     Step:2|6   loss:0.48559802770614624  \n","Epoch:49/50     Step:3|6   loss:0.4858545660972595  \n","Epoch:49/50     Step:4|6   loss:0.4857085347175598  \n","Epoch:49/50     Step:5|6   loss:0.48577508330345154  \n","Epoch:49/50     Step:6|6   loss:0.48567336797714233  \n","Epoch:49/50     Step:7|6   loss:0.4865402281284332  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4855499863624573  \n","Epoch:50/50     Step:2|6   loss:0.48559319972991943  \n","Epoch:50/50     Step:3|6   loss:0.48556509613990784  \n","Epoch:50/50     Step:4|6   loss:0.4862556457519531  \n","Epoch:50/50     Step:5|6   loss:0.4855566918849945  \n","Epoch:50/50     Step:6|6   loss:0.4855901896953583  \n","Epoch:50/50     Step:7|6   loss:0.4858696162700653  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Accuracy on test_set: 89.72 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.0641118288040161  \n","Epoch:1/50     Step:2|6   loss:1.7340607643127441  \n","Epoch:1/50     Step:3|6   loss:2.1353507041931152  \n","Epoch:1/50     Step:4|6   loss:2.7846550941467285  \n","Epoch:1/50     Step:5|6   loss:2.322014331817627  \n","Epoch:1/50     Step:6|6   loss:1.055328369140625  \n","Epoch:1/50     Step:7|6   loss:1.250817894935608  \n","Accuracy on test_set: 62.62 %\n","Accuracy on train_set: 68.38 %\n","current max accuracy\t test set:62.62%\t train set:68.38%\n","Epoch:2/50     Step:1|6   loss:1.6807835102081299  \n","Epoch:2/50     Step:2|6   loss:1.9670350551605225  \n","Epoch:2/50     Step:3|6   loss:1.507509469985962  \n","Epoch:2/50     Step:4|6   loss:1.8526015281677246  \n","Epoch:2/50     Step:5|6   loss:1.3305710554122925  \n","Epoch:2/50     Step:6|6   loss:1.0911598205566406  \n","Epoch:2/50     Step:7|6   loss:1.232072353363037  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:81.31%\t train set:84.78%\n","Epoch:3/50     Step:1|6   loss:1.139433741569519  \n","Epoch:3/50     Step:2|6   loss:1.4420607089996338  \n","Epoch:3/50     Step:3|6   loss:1.4722867012023926  \n","Epoch:3/50     Step:4|6   loss:1.2597966194152832  \n","Epoch:3/50     Step:5|6   loss:1.1868395805358887  \n","Epoch:3/50     Step:6|6   loss:1.0293461084365845  \n","Epoch:3/50     Step:7|6   loss:1.1459290981292725  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 81.26 %\n","current max accuracy\t test set:81.31%\t train set:84.78%\n","Epoch:4/50     Step:1|6   loss:1.1932957172393799  \n","Epoch:4/50     Step:2|6   loss:0.9810788631439209  \n","Epoch:4/50     Step:3|6   loss:1.0132886171340942  \n","Epoch:4/50     Step:4|6   loss:0.9900665879249573  \n","Epoch:4/50     Step:5|6   loss:1.0241137742996216  \n","Epoch:4/50     Step:6|6   loss:0.9247605800628662  \n","Epoch:4/50     Step:7|6   loss:0.897040605545044  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:87.85%\t train set:95.08%\n","Epoch:5/50     Step:1|6   loss:0.7524764537811279  \n","Epoch:5/50     Step:2|6   loss:0.6881506443023682  \n","Epoch:5/50     Step:3|6   loss:0.8022235631942749  \n","Epoch:5/50     Step:4|6   loss:0.8803181052207947  \n","Epoch:5/50     Step:5|6   loss:0.6849398612976074  \n","Epoch:5/50     Step:6|6   loss:0.6143949627876282  \n","Epoch:5/50     Step:7|6   loss:0.7080084085464478  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 90.40 %\n","current max accuracy\t test set:87.85%\t train set:95.08%\n","Epoch:6/50     Step:1|6   loss:0.6880953311920166  \n","Epoch:6/50     Step:2|6   loss:0.6163905262947083  \n","Epoch:6/50     Step:3|6   loss:0.5670380592346191  \n","Epoch:6/50     Step:4|6   loss:0.5835329294204712  \n","Epoch:6/50     Step:5|6   loss:0.6070785522460938  \n","Epoch:6/50     Step:6|6   loss:0.577935516834259  \n","Epoch:6/50     Step:7|6   loss:0.5785176157951355  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:88.79%\t train set:96.72%\n","Epoch:7/50     Step:1|6   loss:0.5952151417732239  \n","Epoch:7/50     Step:2|6   loss:0.5803881883621216  \n","Epoch:7/50     Step:3|6   loss:0.5546148419380188  \n","Epoch:7/50     Step:4|6   loss:0.5944352746009827  \n","Epoch:7/50     Step:5|6   loss:0.5644806623458862  \n","Epoch:7/50     Step:6|6   loss:0.5583648085594177  \n","Epoch:7/50     Step:7|6   loss:0.5636724233627319  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:89.72%\t train set:97.66%\n","Epoch:8/50     Step:1|6   loss:0.5664768815040588  \n","Epoch:8/50     Step:2|6   loss:0.5384873747825623  \n","Epoch:8/50     Step:3|6   loss:0.5395547747612  \n","Epoch:8/50     Step:4|6   loss:0.5385935306549072  \n","Epoch:8/50     Step:5|6   loss:0.5416162014007568  \n","Epoch:8/50     Step:6|6   loss:0.535161554813385  \n","Epoch:8/50     Step:7|6   loss:0.5453171133995056  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:92.52%\t train set:99.77%\n","Epoch:9/50     Step:1|6   loss:0.5329076647758484  \n","Epoch:9/50     Step:2|6   loss:0.5288266539573669  \n","Epoch:9/50     Step:3|6   loss:0.5253648161888123  \n","Epoch:9/50     Step:4|6   loss:0.515006959438324  \n","Epoch:9/50     Step:5|6   loss:0.537761926651001  \n","Epoch:9/50     Step:6|6   loss:0.5206903219223022  \n","Epoch:9/50     Step:7|6   loss:0.5200678706169128  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:99.77%\n","Epoch:10/50     Step:1|6   loss:0.5154085159301758  \n","Epoch:10/50     Step:2|6   loss:0.5297510027885437  \n","Epoch:10/50     Step:3|6   loss:0.5155118703842163  \n","Epoch:10/50     Step:4|6   loss:0.51694655418396  \n","Epoch:10/50     Step:5|6   loss:0.5239382982254028  \n","Epoch:10/50     Step:6|6   loss:0.5213196277618408  \n","Epoch:10/50     Step:7|6   loss:0.5176955461502075  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:99.77%\n","Epoch:11/50     Step:1|6   loss:0.5175253748893738  \n","Epoch:11/50     Step:2|6   loss:0.5132012963294983  \n","Epoch:11/50     Step:3|6   loss:0.5105884075164795  \n","Epoch:11/50     Step:4|6   loss:0.5196993947029114  \n","Epoch:11/50     Step:5|6   loss:0.5154455900192261  \n","Epoch:11/50     Step:6|6   loss:0.5176557898521423  \n","Epoch:11/50     Step:7|6   loss:0.5194400548934937  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:12/50     Step:1|6   loss:0.5081315040588379  \n","Epoch:12/50     Step:2|6   loss:0.5086463093757629  3\n","\n","Epoch:12/50     Step:3|6   loss:0.518898069858551  \n","Epoch:12/50     Step:4|6   loss:0.5053003430366516  \n","Epoch:12/50     Step:5|6   loss:0.5122909545898438  \n","Epoch:12/50     Step:6|6   loss:0.5104895234107971  \n","Epoch:12/50     Step:7|6   loss:0.5035452246665955  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5123544931411743  \n","Epoch:13/50     Step:2|6   loss:0.49786376953125  \n","Epoch:13/50     Step:3|6   loss:0.4979129433631897  \n","Epoch:13/50     Step:4|6   loss:0.5070404410362244  \n","Epoch:13/50     Step:5|6   loss:0.5023781061172485  \n","Epoch:13/50     Step:6|6   loss:0.5047473907470703  \n","Epoch:13/50     Step:7|6   loss:0.49670010805130005  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5010266900062561  \n","Epoch:14/50     Step:2|6   loss:0.506889283657074  \n","Epoch:14/50     Step:3|6   loss:0.497143030166626  \n","Epoch:14/50     Step:4|6   loss:0.5037547945976257  \n","Epoch:14/50     Step:5|6   loss:0.501689076423645  \n","Epoch:14/50     Step:6|6   loss:0.5018155574798584  \n","Epoch:14/50     Step:7|6   loss:0.5032793879508972  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.49906522035598755  \n","Epoch:15/50     Step:2|6   loss:0.49619776010513306  \n","Epoch:15/50     Step:3|6   loss:0.49411216378211975  \n","Epoch:15/50     Step:4|6   loss:0.5099886059761047  \n","Epoch:15/50     Step:5|6   loss:0.4988819360733032  \n","Epoch:15/50     Step:6|6   loss:0.5011622905731201  \n","Epoch:15/50     Step:7|6   loss:0.4960007071495056  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.49701258540153503  \n","Epoch:16/50     Step:2|6   loss:0.5023396015167236  \n","Epoch:16/50     Step:3|6   loss:0.4953458309173584  \n","Epoch:16/50     Step:4|6   loss:0.4985266923904419  \n","Epoch:16/50     Step:5|6   loss:0.5005773901939392  \n","Epoch:16/50     Step:6|6   loss:0.4925277829170227  \n","Epoch:16/50     Step:7|6   loss:0.5012828707695007  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.4945991635322571  \n","Epoch:17/50     Step:2|6   loss:0.49430763721466064  \n","Epoch:17/50     Step:3|6   loss:0.4939451217651367  \n","Epoch:17/50     Step:4|6   loss:0.4946523904800415  \n","Epoch:17/50     Step:5|6   loss:0.4960709810256958  \n","Epoch:17/50     Step:6|6   loss:0.5010316371917725  \n","Epoch:17/50     Step:7|6   loss:0.49479520320892334  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.4937857985496521  \n","Epoch:18/50     Step:2|6   loss:0.4921724200248718  \n","Epoch:18/50     Step:3|6   loss:0.4923039972782135  \n","Epoch:18/50     Step:4|6   loss:0.49361830949783325  \n","Epoch:18/50     Step:5|6   loss:0.49861425161361694  \n","Epoch:18/50     Step:6|6   loss:0.49039536714553833  \n","Epoch:18/50     Step:7|6   loss:0.4937957525253296  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4921109080314636  \n","Epoch:19/50     Step:2|6   loss:0.49127358198165894  \n","Epoch:19/50     Step:3|6   loss:0.495951771736145  \n","Epoch:19/50     Step:4|6   loss:0.4920274019241333  \n","Epoch:19/50     Step:5|6   loss:0.48959845304489136  \n","Epoch:19/50     Step:6|6   loss:0.49293583631515503  \n","Epoch:19/50     Step:7|6   loss:0.4911864399909973  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49132704734802246  \n","Epoch:20/50     Step:2|6   loss:0.493405818939209  \n","Epoch:20/50     Step:3|6   loss:0.490901380777359  \n","Epoch:20/50     Step:4|6   loss:0.49160754680633545  \n","Epoch:20/50     Step:5|6   loss:0.4902641177177429  \n","Epoch:20/50     Step:6|6   loss:0.4898228645324707  \n","Epoch:20/50     Step:7|6   loss:0.4908633828163147  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.491813600063324  \n","Epoch:21/50     Step:2|6   loss:0.49017947912216187  \n","Epoch:21/50     Step:3|6   loss:0.49109241366386414  \n","Epoch:21/50     Step:4|6   loss:0.4907236695289612  \n","Epoch:21/50     Step:5|6   loss:0.4888384938240051  \n","Epoch:21/50     Step:6|6   loss:0.48969602584838867  \n","Epoch:21/50     Step:7|6   loss:0.489957332611084  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.4898083209991455  \n","Epoch:22/50     Step:2|6   loss:0.4912664294242859  \n","Epoch:22/50     Step:3|6   loss:0.4883646070957184  \n","Epoch:22/50     Step:4|6   loss:0.4924042224884033  \n","Epoch:22/50     Step:5|6   loss:0.48914825916290283  \n","Epoch:22/50     Step:6|6   loss:0.4887079894542694  \n","Epoch:22/50     Step:7|6   loss:0.4909772276878357  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.48891884088516235  \n","Epoch:23/50     Step:2|6   loss:0.4920138120651245  \n","Epoch:23/50     Step:3|6   loss:0.4909798204898834  \n","Epoch:23/50     Step:4|6   loss:0.4902718663215637  \n","Epoch:23/50     Step:5|6   loss:0.4904298484325409  \n","Epoch:23/50     Step:6|6   loss:0.4880463182926178  \n","Epoch:23/50     Step:7|6   loss:0.4886668920516968  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4910202622413635  \n","Epoch:24/50     Step:2|6   loss:0.4896228313446045  \n","Epoch:24/50     Step:3|6   loss:0.48990172147750854  \n","Epoch:24/50     Step:4|6   loss:0.48824936151504517  \n","Epoch:24/50     Step:5|6   loss:0.4874603748321533  \n","Epoch:24/50     Step:6|6   loss:0.4915897846221924  \n","Epoch:24/50     Step:7|6   loss:0.48945000767707825  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.4890512526035309  \n","Epoch:25/50     Step:2|6   loss:0.4902842044830322  \n","Epoch:25/50     Step:3|6   loss:0.4886862337589264  \n","Epoch:25/50     Step:4|6   loss:0.488722562789917  \n","Epoch:25/50     Step:5|6   loss:0.49037110805511475  \n","Epoch:25/50     Step:6|6   loss:0.48739898204803467  \n","Epoch:25/50     Step:7|6   loss:0.49191054701805115  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.4886213541030884  \n","Epoch:26/50     Step:2|6   loss:0.4892251789569855  \n","Epoch:26/50     Step:3|6   loss:0.4891566038131714  \n","Epoch:26/50     Step:4|6   loss:0.48871904611587524  \n","Epoch:26/50     Step:5|6   loss:0.48830023407936096  \n","Epoch:26/50     Step:6|6   loss:0.48882585763931274  \n","Epoch:26/50     Step:7|6   loss:0.4882139265537262  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4883847236633301  \n","Epoch:27/50     Step:2|6   loss:0.48881977796554565  \n","Epoch:27/50     Step:3|6   loss:0.489093542098999  \n","Epoch:27/50     Step:4|6   loss:0.48898419737815857  \n","Epoch:27/50     Step:5|6   loss:0.48830172419548035  \n","Epoch:27/50     Step:6|6   loss:0.48845916986465454  \n","Epoch:27/50     Step:7|6   loss:0.48973438143730164  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48972654342651367  \n","Epoch:28/50     Step:2|6   loss:0.4899245500564575  \n","Epoch:28/50     Step:3|6   loss:0.4894546568393707  \n","Epoch:28/50     Step:4|6   loss:0.48709434270858765  \n","Epoch:28/50     Step:5|6   loss:0.48878902196884155  \n","Epoch:28/50     Step:6|6   loss:0.48772144317626953  \n","Epoch:28/50     Step:7|6   loss:0.48695892095565796  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.48817044496536255  \n","Epoch:29/50     Step:2|6   loss:0.48726898431777954  \n","Epoch:29/50     Step:3|6   loss:0.48911523818969727  \n","Epoch:29/50     Step:4|6   loss:0.48816800117492676  \n","Epoch:29/50     Step:5|6   loss:0.4877908229827881  \n","Epoch:29/50     Step:6|6   loss:0.488491028547287  \n","Epoch:29/50     Step:7|6   loss:0.48712506890296936  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4868658185005188  \n","Epoch:30/50     Step:2|6   loss:0.4878280758857727  \n","Epoch:30/50     Step:3|6   loss:0.48759371042251587  \n","Epoch:30/50     Step:4|6   loss:0.4886317253112793  \n","Epoch:30/50     Step:5|6   loss:0.48808586597442627  \n","Epoch:30/50     Step:6|6   loss:0.48673567175865173  \n","Epoch:30/50     Step:7|6   loss:0.487549364566803  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48742637038230896  \n","Epoch:31/50     Step:2|6   loss:0.4867907762527466  \n","Epoch:31/50     Step:3|6   loss:0.4889479875564575  \n","Epoch:31/50     Step:4|6   loss:0.48680469393730164  \n","Epoch:31/50     Step:5|6   loss:0.4881734251976013  \n","Epoch:31/50     Step:6|6   loss:0.48739099502563477  \n","Epoch:31/50     Step:7|6   loss:0.48775678873062134  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.488519549369812  \n","Epoch:32/50     Step:2|6   loss:0.48618340492248535  \n","Epoch:32/50     Step:3|6   loss:0.48906728625297546  \n","Epoch:32/50     Step:4|6   loss:0.48829537630081177  \n","Epoch:32/50     Step:5|6   loss:0.48713237047195435  \n","Epoch:32/50     Step:6|6   loss:0.4888297915458679  \n","Epoch:32/50     Step:7|6   loss:0.4860517382621765  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4868914484977722  \n","Epoch:33/50     Step:2|6   loss:0.4876404106616974  \n","Epoch:33/50     Step:3|6   loss:0.48630595207214355  \n","Epoch:33/50     Step:4|6   loss:0.4881972074508667  \n","Epoch:33/50     Step:5|6   loss:0.48645058274269104  \n","Epoch:33/50     Step:6|6   loss:0.487388551235199  \n","Epoch:33/50     Step:7|6   loss:0.4873250126838684  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4869559705257416  \n","Epoch:34/50     Step:2|6   loss:0.4878798723220825  \n","Epoch:34/50     Step:3|6   loss:0.486142635345459  \n","Epoch:34/50     Step:4|6   loss:0.4881961941719055  \n","Epoch:34/50     Step:5|6   loss:0.4868953824043274  \n","Epoch:34/50     Step:6|6   loss:0.487446129322052  \n","Epoch:34/50     Step:7|6   loss:0.4882892966270447  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4869176745414734  \n","Epoch:35/50     Step:2|6   loss:0.48847970366477966  \n","Epoch:35/50     Step:3|6   loss:0.4855647385120392  \n","Epoch:35/50     Step:4|6   loss:0.4882758855819702  \n","Epoch:35/50     Step:5|6   loss:0.48618465662002563  \n","Epoch:35/50     Step:6|6   loss:0.4873386025428772  \n","Epoch:35/50     Step:7|6   loss:0.48700958490371704  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.48614075779914856  \n","Epoch:36/50     Step:2|6   loss:0.4862489700317383  \n","Epoch:36/50     Step:3|6   loss:0.48610883951187134  \n","Epoch:36/50     Step:4|6   loss:0.4863216280937195  \n","Epoch:36/50     Step:5|6   loss:0.4865038990974426  \n","Epoch:36/50     Step:6|6   loss:0.486496239900589  \n","Epoch:36/50     Step:7|6   loss:0.485731840133667  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48599973320961  \n","Epoch:37/50     Step:2|6   loss:0.4863203465938568  \n","Epoch:37/50     Step:3|6   loss:0.4859783947467804  \n","Epoch:37/50     Step:4|6   loss:0.4863351881504059  \n","Epoch:37/50     Step:5|6   loss:0.48617199063301086  \n","Epoch:37/50     Step:6|6   loss:0.4859732687473297  \n","Epoch:37/50     Step:7|6   loss:0.48620128631591797  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.48586034774780273  \n","Epoch:38/50     Step:2|6   loss:0.48666805028915405  \n","Epoch:38/50     Step:3|6   loss:0.48602813482284546  \n","Epoch:38/50     Step:4|6   loss:0.48613131046295166  \n","Epoch:38/50     Step:5|6   loss:0.48642751574516296  \n","Epoch:38/50     Step:6|6   loss:0.48640406131744385  \n","Epoch:38/50     Step:7|6   loss:0.48685991764068604  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.48591941595077515  \n","Epoch:39/50     Step:2|6   loss:0.4861295521259308  \n","Epoch:39/50     Step:3|6   loss:0.48611271381378174  \n","Epoch:39/50     Step:4|6   loss:0.485910028219223  \n","Epoch:39/50     Step:5|6   loss:0.486272394657135  \n","Epoch:39/50     Step:6|6   loss:0.4861270785331726  \n","Epoch:39/50     Step:7|6   loss:0.48562169075012207  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48598402738571167  \n","Epoch:40/50     Step:2|6   loss:0.4860256314277649  \n","Epoch:40/50     Step:3|6   loss:0.48587173223495483  \n","Epoch:40/50     Step:4|6   loss:0.48560604453086853  \n","Epoch:40/50     Step:5|6   loss:0.4858819842338562  \n","Epoch:40/50     Step:6|6   loss:0.48609721660614014  \n","Epoch:40/50     Step:7|6   loss:0.4860874116420746  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.48583725094795227  \n","Epoch:41/50     Step:2|6   loss:0.48615071177482605  \n","Epoch:41/50     Step:3|6   loss:0.48584434390068054  \n","Epoch:41/50     Step:4|6   loss:0.48574888706207275  \n","Epoch:41/50     Step:5|6   loss:0.48577865958213806  \n","Epoch:41/50     Step:6|6   loss:0.4861711263656616  \n","Epoch:41/50     Step:7|6   loss:0.4859298765659332  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4858390986919403  \n","Epoch:42/50     Step:2|6   loss:0.48562026023864746  \n","Epoch:42/50     Step:3|6   loss:0.48604243993759155  \n","Epoch:42/50     Step:4|6   loss:0.4857495427131653  \n","Epoch:42/50     Step:5|6   loss:0.4857407212257385  \n","Epoch:42/50     Step:6|6   loss:0.4854751229286194  \n","Epoch:42/50     Step:7|6   loss:0.4858526587486267  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.48579177260398865  \n","Epoch:43/50     Step:2|6   loss:0.48588961362838745  \n","Epoch:43/50     Step:3|6   loss:0.4855777323246002  \n","Epoch:43/50     Step:4|6   loss:0.4857052266597748  \n","Epoch:43/50     Step:5|6   loss:0.485800564289093  \n","Epoch:43/50     Step:6|6   loss:0.48563456535339355  \n","Epoch:43/50     Step:7|6   loss:0.4857402443885803  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48582524061203003  \n","Epoch:44/50     Step:2|6   loss:0.48552006483078003  \n","Epoch:44/50     Step:3|6   loss:0.4855670630931854  \n","Epoch:44/50     Step:4|6   loss:0.4854254722595215  \n","Epoch:44/50     Step:5|6   loss:0.4856250286102295  \n","Epoch:44/50     Step:6|6   loss:0.48579972982406616  \n","Epoch:44/50     Step:7|6   loss:0.48579373955726624  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.48559245467185974  \n","Epoch:45/50     Step:2|6   loss:0.48545193672180176  \n","Epoch:45/50     Step:3|6   loss:0.48572635650634766  \n","Epoch:45/50     Step:4|6   loss:0.48543351888656616  \n","Epoch:45/50     Step:5|6   loss:0.4856939911842346  \n","Epoch:45/50     Step:6|6   loss:0.4859538674354553  \n","Epoch:45/50     Step:7|6   loss:0.48545947670936584  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.485476553440094  \n","Epoch:46/50     Step:2|6   loss:0.48557573556900024  \n","Epoch:46/50     Step:3|6   loss:0.4858025312423706  \n","Epoch:46/50     Step:4|6   loss:0.48556724190711975  \n","Epoch:46/50     Step:5|6   loss:0.4856853485107422  \n","Epoch:46/50     Step:6|6   loss:0.4854971468448639  \n","Epoch:46/50     Step:7|6   loss:0.48538318276405334  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48543646931648254  \n","Epoch:47/50     Step:2|6   loss:0.4855402708053589  \n","Epoch:47/50     Step:3|6   loss:0.48565465211868286  \n","Epoch:47/50     Step:4|6   loss:0.4859604239463806  \n","Epoch:47/50     Step:5|6   loss:0.4855498671531677  \n","Epoch:47/50     Step:6|6   loss:0.4857099950313568  \n","Epoch:47/50     Step:7|6   loss:0.48567214608192444  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4854608178138733  \n","Epoch:48/50     Step:2|6   loss:0.48574647307395935  \n","Epoch:48/50     Step:3|6   loss:0.4854034185409546  \n","Epoch:48/50     Step:4|6   loss:0.4859304428100586  \n","Epoch:48/50     Step:5|6   loss:0.4855242669582367  \n","Epoch:48/50     Step:6|6   loss:0.48570680618286133  \n","Epoch:48/50     Step:7|6   loss:0.4859428107738495  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48578864336013794  \n","Epoch:49/50     Step:2|6   loss:0.48538824915885925  \n","Epoch:49/50     Step:3|6   loss:0.4855864644050598  \n","Epoch:49/50     Step:4|6   loss:0.48553943634033203  \n","Epoch:49/50     Step:5|6   loss:0.48570266366004944  \n","Epoch:49/50     Step:6|6   loss:0.48546817898750305  \n","Epoch:49/50     Step:7|6   loss:0.48554930090904236  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48545318841934204  \n","Epoch:50/50     Step:2|6   loss:0.4854050874710083  \n","Epoch:50/50     Step:3|6   loss:0.48536691069602966  \n","Epoch:50/50     Step:4|6   loss:0.4854377210140228  \n","Epoch:50/50     Step:5|6   loss:0.4858325123786926  \n","Epoch:50/50     Step:6|6   loss:0.48544979095458984  \n","Epoch:50/50     Step:7|6   loss:0.4857329726219177  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Accuracy on test_set: 94.39 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.166027307510376  \n","Epoch:1/50     Step:2|6   loss:3.616741895675659  \n","Epoch:1/50     Step:3|6   loss:2.182382822036743  \n","Epoch:1/50     Step:4|6   loss:1.176943302154541  \n","Epoch:1/50     Step:5|6   loss:1.2641665935516357  \n","Epoch:1/50     Step:6|6   loss:1.5558907985687256  \n","Epoch:1/50     Step:7|6   loss:1.0324171781539917  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:83.18%\t train set:84.78%\n","Epoch:2/50     Step:1|6   loss:1.156836748123169  \n","Epoch:2/50     Step:2|6   loss:1.1431902647018433  \n","Epoch:2/50     Step:3|6   loss:1.244901418685913  \n","Epoch:2/50     Step:4|6   loss:1.2345037460327148  \n","Epoch:2/50     Step:5|6   loss:1.2068543434143066  \n","Epoch:2/50     Step:6|6   loss:1.3764623403549194  \n","Epoch:2/50     Step:7|6   loss:1.3053596019744873  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:87.85%\t train set:86.65%\n","Epoch:3/50     Step:1|6   loss:1.1532737016677856  \n","Epoch:3/50     Step:2|6   loss:1.0540995597839355  \n","Epoch:3/50     Step:3|6   loss:1.0291465520858765  \n","Epoch:3/50     Step:4|6   loss:0.9732797145843506  \n","Epoch:3/50     Step:5|6   loss:0.8904557824134827  \n","Epoch:3/50     Step:6|6   loss:1.1415594816207886  \n","Epoch:3/50     Step:7|6   loss:0.9056738615036011  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:87.85%\t train set:90.63%\n","Epoch:4/50     Step:1|6   loss:0.9066746234893799  \n","Epoch:4/50     Step:2|6   loss:0.7932795286178589  \n","Epoch:4/50     Step:3|6   loss:0.8465011715888977  \n","Epoch:4/50     Step:4|6   loss:0.7122396230697632  \n","Epoch:4/50     Step:5|6   loss:0.6582156419754028  \n","Epoch:4/50     Step:6|6   loss:0.7757582664489746  \n","Epoch:4/50     Step:7|6   loss:0.6861122846603394  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:89.72%\t train set:94.15%\n","Epoch:5/50     Step:1|6   loss:0.5665209293365479  \n","Epoch:5/50     Step:2|6   loss:0.6922372579574585  \n","Epoch:5/50     Step:3|6   loss:0.795613169670105  \n","Epoch:5/50     Step:4|6   loss:0.605379581451416  \n","Epoch:5/50     Step:5|6   loss:0.7143300771713257  \n","Epoch:5/50     Step:6|6   loss:0.6695483326911926  \n","Epoch:5/50     Step:7|6   loss:0.6054443120956421  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:89.72%\t train set:94.15%\n","Epoch:6/50     Step:1|6   loss:0.5815062522888184  \n","Epoch:6/50     Step:2|6   loss:0.6837191581726074  \n","Epoch:6/50     Step:3|6   loss:0.6844409108161926  \n","Epoch:6/50     Step:4|6   loss:0.6584205627441406  \n","Epoch:6/50     Step:5|6   loss:0.6305527687072754  \n","Epoch:6/50     Step:6|6   loss:0.6154563426971436  \n","Epoch:6/50     Step:7|6   loss:0.6123886704444885  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:89.72%\t train set:94.15%\n","Epoch:7/50     Step:1|6   loss:0.6520203351974487  \n","Epoch:7/50     Step:2|6   loss:0.6142836809158325  \n","Epoch:7/50     Step:3|6   loss:0.5760355591773987  \n","Epoch:7/50     Step:4|6   loss:0.5952080488204956  \n","Epoch:7/50     Step:5|6   loss:0.6182320713996887  \n","Epoch:7/50     Step:6|6   loss:0.5413069128990173  \n","Epoch:7/50     Step:7|6   loss:0.5835102796554565  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:90.65%\t train set:94.85%\n","Epoch:8/50     Step:1|6   loss:0.5719115138053894  \n","Epoch:8/50     Step:2|6   loss:0.5659860372543335  \n","Epoch:8/50     Step:3|6   loss:0.5842045545578003  \n","Epoch:8/50     Step:4|6   loss:0.6079154014587402  \n","Epoch:8/50     Step:5|6   loss:0.5260984897613525  \n","Epoch:8/50     Step:6|6   loss:0.5602480173110962  \n","Epoch:8/50     Step:7|6   loss:0.563981294631958  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:94.39%\t train set:99.06%\n","Epoch:9/50     Step:1|6   loss:0.5158793926239014  \n","Epoch:9/50     Step:2|6   loss:0.5506918430328369  \n","Epoch:9/50     Step:3|6   loss:0.5789633989334106  \n","Epoch:9/50     Step:4|6   loss:0.5247268676757812  \n","Epoch:9/50     Step:5|6   loss:0.5292791128158569  \n","Epoch:9/50     Step:6|6   loss:0.5416105389595032  \n","Epoch:9/50     Step:7|6   loss:0.5287189483642578  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:10/50     Step:1|6   loss:0.5276721119880676  \n","Epoch:10/50     Step:2|6   loss:0.5291471481323242  \n","Epoch:10/50     Step:3|6   loss:0.5295131802558899  \n","Epoch:10/50     Step:4|6   loss:0.5123332738876343  \n","Epoch:10/50     Step:5|6   loss:0.5337686538696289  \n","Epoch:10/50     Step:6|6   loss:0.5431051850318909  \n","Epoch:10/50     Step:7|6   loss:0.5131087899208069  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:11/50     Step:1|6   loss:0.5211002826690674  \n","Epoch:11/50     Step:2|6   loss:0.5439715385437012  \n","Epoch:11/50     Step:3|6   loss:0.5003366470336914  \n","Epoch:11/50     Step:4|6   loss:0.5009680986404419  \n","Epoch:11/50     Step:5|6   loss:0.527452826499939  \n","Epoch:11/50     Step:6|6   loss:0.5119924545288086  \n","Epoch:11/50     Step:7|6   loss:0.5076595544815063  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:12/50     Step:1|6   loss:0.5164445638656616  \n","Epoch:12/50     Step:2|6   loss:0.5186041593551636  \n","Epoch:12/50     Step:3|6   loss:0.497318834066391  \n","Epoch:12/50     Step:4|6   loss:0.5383282899856567  \n","Epoch:12/50     Step:5|6   loss:0.5056124329566956  \n","Epoch:12/50     Step:6|6   loss:0.5141352415084839  \n","Epoch:12/50     Step:7|6   loss:0.5101828575134277  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5135364532470703  \n","Epoch:13/50     Step:2|6   loss:0.5038297772407532  \n","Epoch:13/50     Step:3|6   loss:0.502536416053772  \n","Epoch:13/50     Step:4|6   loss:0.5077399015426636  \n","Epoch:13/50     Step:5|6   loss:0.49499958753585815  \n","Epoch:13/50     Step:6|6   loss:0.5006095767021179  \n","Epoch:13/50     Step:7|6   loss:0.49719375371932983  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.49608707427978516  \n","Epoch:14/50     Step:2|6   loss:0.5006306171417236  \n","Epoch:14/50     Step:3|6   loss:0.4945369362831116  \n","Epoch:14/50     Step:4|6   loss:0.4975968599319458  \n","Epoch:14/50     Step:5|6   loss:0.5074368715286255  \n","Epoch:14/50     Step:6|6   loss:0.5013529062271118  \n","Epoch:14/50     Step:7|6   loss:0.4979475736618042  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.4916501045227051  \n","Epoch:15/50     Step:2|6   loss:0.49705272912979126  \n","Epoch:15/50     Step:3|6   loss:0.49998438358306885  \n","Epoch:15/50     Step:4|6   loss:0.4938020706176758  \n","Epoch:15/50     Step:5|6   loss:0.5021464824676514  \n","Epoch:15/50     Step:6|6   loss:0.5013633966445923  \n","Epoch:15/50     Step:7|6   loss:0.4996326267719269  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.49422892928123474  \n","Epoch:16/50     Step:2|6   loss:0.5015696287155151  \n","Epoch:16/50     Step:3|6   loss:0.49620962142944336  \n","Epoch:16/50     Step:4|6   loss:0.4954446852207184  \n","Epoch:16/50     Step:5|6   loss:0.49515122175216675  \n","Epoch:16/50     Step:6|6   loss:0.4949900507926941  \n","Epoch:16/50     Step:7|6   loss:0.49510088562965393  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.4943119287490845  \n","Epoch:17/50     Step:2|6   loss:0.4961317777633667  \n","Epoch:17/50     Step:3|6   loss:0.49457329511642456  \n","Epoch:17/50     Step:4|6   loss:0.49264582991600037  \n","Epoch:17/50     Step:5|6   loss:0.49958741664886475  \n","Epoch:17/50     Step:6|6   loss:0.49767255783081055  \n","Epoch:17/50     Step:7|6   loss:0.49124062061309814  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.5018745064735413  \n","Epoch:18/50     Step:2|6   loss:0.4907693862915039  \n","Epoch:18/50     Step:3|6   loss:0.4962575435638428  \n","Epoch:18/50     Step:4|6   loss:0.49381694197654724  \n","Epoch:18/50     Step:5|6   loss:0.4916430711746216  \n","Epoch:18/50     Step:6|6   loss:0.4969446063041687  \n","Epoch:18/50     Step:7|6   loss:0.4968326687812805  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4925627112388611  \n","Epoch:19/50     Step:2|6   loss:0.4943124055862427  \n","Epoch:19/50     Step:3|6   loss:0.49202340841293335  \n","Epoch:19/50     Step:4|6   loss:0.49134746193885803  \n","Epoch:19/50     Step:5|6   loss:0.49386849999427795  \n","Epoch:19/50     Step:6|6   loss:0.49262070655822754  \n","Epoch:19/50     Step:7|6   loss:0.4903258681297302  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.4923541247844696  \n","Epoch:20/50     Step:2|6   loss:0.49360328912734985  \n","Epoch:20/50     Step:3|6   loss:0.4904296100139618  \n","Epoch:20/50     Step:4|6   loss:0.49031540751457214  \n","Epoch:20/50     Step:5|6   loss:0.49070513248443604  \n","Epoch:20/50     Step:6|6   loss:0.4891640841960907  \n","Epoch:20/50     Step:7|6   loss:0.48942190408706665  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.48985281586647034  \n","Epoch:21/50     Step:2|6   loss:0.4909902811050415  \n","Epoch:21/50     Step:3|6   loss:0.48917466402053833  \n","Epoch:21/50     Step:4|6   loss:0.49031662940979004  \n","Epoch:21/50     Step:5|6   loss:0.4910511076450348  \n","Epoch:21/50     Step:6|6   loss:0.48893916606903076  \n","Epoch:21/50     Step:7|6   loss:0.4899486303329468  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.488887757062912  \n","Epoch:22/50     Step:2|6   loss:0.48945459723472595  \n","Epoch:22/50     Step:3|6   loss:0.48923781514167786  \n","Epoch:22/50     Step:4|6   loss:0.48793554306030273  \n","Epoch:22/50     Step:5|6   loss:0.490728497505188  \n","Epoch:22/50     Step:6|6   loss:0.49026238918304443  \n","Epoch:22/50     Step:7|6   loss:0.4898873567581177  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.48905080556869507  \n","Epoch:23/50     Step:2|6   loss:0.4894460141658783  \n","Epoch:23/50     Step:3|6   loss:0.4897901117801666  \n","Epoch:23/50     Step:4|6   loss:0.4878007769584656  \n","Epoch:23/50     Step:5|6   loss:0.48907503485679626  \n","Epoch:23/50     Step:6|6   loss:0.48863890767097473  \n","Epoch:23/50     Step:7|6   loss:0.4892410635948181  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.48930296301841736  \n","Epoch:24/50     Step:2|6   loss:0.4886537194252014  \n","Epoch:24/50     Step:3|6   loss:0.489261269569397  \n","Epoch:24/50     Step:4|6   loss:0.4877861440181732  \n","Epoch:24/50     Step:5|6   loss:0.4898798167705536  \n","Epoch:24/50     Step:6|6   loss:0.48742926120758057  \n","Epoch:24/50     Step:7|6   loss:0.4902037978172302  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.48761481046676636  \n","Epoch:25/50     Step:2|6   loss:0.4889340400695801  \n","Epoch:25/50     Step:3|6   loss:0.48727571964263916  \n","Epoch:25/50     Step:4|6   loss:0.48707595467567444  \n","Epoch:25/50     Step:5|6   loss:0.48900920152664185  \n","Epoch:25/50     Step:6|6   loss:0.48968082666397095  \n","Epoch:25/50     Step:7|6   loss:0.4890313148498535  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48898372054100037  \n","Epoch:26/50     Step:2|6   loss:0.4875775873661041  \n","Epoch:26/50     Step:3|6   loss:0.48752251267433167  \n","Epoch:26/50     Step:4|6   loss:0.48645567893981934  \n","Epoch:26/50     Step:5|6   loss:0.4882734417915344  \n","Epoch:26/50     Step:6|6   loss:0.48923957347869873  \n","Epoch:26/50     Step:7|6   loss:0.4871641993522644  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4879482388496399  \n","Epoch:27/50     Step:2|6   loss:0.4878677427768707  \n","Epoch:27/50     Step:3|6   loss:0.4871704876422882  \n","Epoch:27/50     Step:4|6   loss:0.489043265581131  \n","Epoch:27/50     Step:5|6   loss:0.48689714074134827  \n","Epoch:27/50     Step:6|6   loss:0.4874948263168335  \n","Epoch:27/50     Step:7|6   loss:0.48743656277656555  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48812413215637207  \n","Epoch:28/50     Step:2|6   loss:0.48713064193725586  \n","Epoch:28/50     Step:3|6   loss:0.4870014190673828  \n","Epoch:28/50     Step:4|6   loss:0.48669344186782837  \n","Epoch:28/50     Step:5|6   loss:0.48957541584968567  \n","Epoch:28/50     Step:6|6   loss:0.48717427253723145  \n","Epoch:28/50     Step:7|6   loss:0.48745405673980713  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4867832362651825  \n","Epoch:29/50     Step:2|6   loss:0.48726600408554077  \n","Epoch:29/50     Step:3|6   loss:0.4872346520423889  \n","Epoch:29/50     Step:4|6   loss:0.48664775490760803  \n","Epoch:29/50     Step:5|6   loss:0.48904168605804443  \n","Epoch:29/50     Step:6|6   loss:0.48710042238235474  \n","Epoch:29/50     Step:7|6   loss:0.4865027070045471  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.48716986179351807  \n","Epoch:30/50     Step:2|6   loss:0.4879152476787567  \n","Epoch:30/50     Step:3|6   loss:0.4865284264087677  \n","Epoch:30/50     Step:4|6   loss:0.48649850487709045  \n","Epoch:30/50     Step:5|6   loss:0.486721396446228  \n","Epoch:30/50     Step:6|6   loss:0.48810112476348877  \n","Epoch:30/50     Step:7|6   loss:0.48590317368507385  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.4870063066482544  \n","Epoch:31/50     Step:2|6   loss:0.48657622933387756  \n","Epoch:31/50     Step:3|6   loss:0.4869176745414734  \n","Epoch:31/50     Step:4|6   loss:0.4865884780883789  \n","Epoch:31/50     Step:5|6   loss:0.48819902539253235  \n","Epoch:31/50     Step:6|6   loss:0.4872806966304779  \n","Epoch:31/50     Step:7|6   loss:0.486324280500412  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4870927333831787  \n","Epoch:32/50     Step:2|6   loss:0.4863367974758148  \n","Epoch:32/50     Step:3|6   loss:0.48690685629844666  \n","Epoch:32/50     Step:4|6   loss:0.48659461736679077  \n","Epoch:32/50     Step:5|6   loss:0.4866161346435547  \n","Epoch:32/50     Step:6|6   loss:0.4870786964893341  \n","Epoch:32/50     Step:7|6   loss:0.4863235354423523  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48656123876571655  \n","Epoch:33/50     Step:2|6   loss:0.48626410961151123  \n","Epoch:33/50     Step:3|6   loss:0.48624753952026367  \n","Epoch:33/50     Step:4|6   loss:0.48603639006614685  \n","Epoch:33/50     Step:5|6   loss:0.4864671230316162  \n","Epoch:33/50     Step:6|6   loss:0.48654597997665405  \n","Epoch:33/50     Step:7|6   loss:0.4884687662124634  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.48654136061668396  \n","Epoch:34/50     Step:2|6   loss:0.4866372346878052  \n","Epoch:34/50     Step:3|6   loss:0.48620474338531494  \n","Epoch:34/50     Step:4|6   loss:0.4861351251602173  \n","Epoch:34/50     Step:5|6   loss:0.48616141080856323  \n","Epoch:34/50     Step:6|6   loss:0.48710185289382935  \n","Epoch:34/50     Step:7|6   loss:0.486494243144989  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.48624715209007263  \n","Epoch:35/50     Step:2|6   loss:0.48615363240242004  \n","Epoch:35/50     Step:3|6   loss:0.48727431893348694  \n","Epoch:35/50     Step:4|6   loss:0.48654621839523315  \n","Epoch:35/50     Step:5|6   loss:0.48614341020584106  \n","Epoch:35/50     Step:6|6   loss:0.48588019609451294  \n","Epoch:35/50     Step:7|6   loss:0.4864223599433899  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4865477383136749  \n","Epoch:36/50     Step:2|6   loss:0.48617517948150635  \n","Epoch:36/50     Step:3|6   loss:0.48650795221328735  \n","Epoch:36/50     Step:4|6   loss:0.48603665828704834  \n","Epoch:36/50     Step:5|6   loss:0.4858354330062866  \n","Epoch:36/50     Step:6|6   loss:0.4860231876373291  \n","Epoch:36/50     Step:7|6   loss:0.4860658645629883  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48687538504600525  \n","Epoch:37/50     Step:2|6   loss:0.48559167981147766  \n","Epoch:37/50     Step:3|6   loss:0.48592400550842285  \n","Epoch:37/50     Step:4|6   loss:0.4862397015094757  \n","Epoch:37/50     Step:5|6   loss:0.48587512969970703  \n","Epoch:37/50     Step:6|6   loss:0.48616623878479004  \n","Epoch:37/50     Step:7|6   loss:0.48572927713394165  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4861931800842285  \n","Epoch:38/50     Step:2|6   loss:0.485808789730072  \n","Epoch:38/50     Step:3|6   loss:0.4866555333137512  \n","Epoch:38/50     Step:4|6   loss:0.48620519042015076  \n","Epoch:38/50     Step:5|6   loss:0.4858192205429077  \n","Epoch:38/50     Step:6|6   loss:0.4859365224838257  \n","Epoch:38/50     Step:7|6   loss:0.48562270402908325  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.48601004481315613  \n","Epoch:39/50     Step:2|6   loss:0.4859010577201843  \n","Epoch:39/50     Step:3|6   loss:0.48593610525131226  \n","Epoch:39/50     Step:4|6   loss:0.486158162355423  \n","Epoch:39/50     Step:5|6   loss:0.4856531322002411  \n","Epoch:39/50     Step:6|6   loss:0.4863177537918091  \n","Epoch:39/50     Step:7|6   loss:0.48631200194358826  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48560065031051636  \n","Epoch:40/50     Step:2|6   loss:0.4867976903915405  \n","Epoch:40/50     Step:3|6   loss:0.48586398363113403  \n","Epoch:40/50     Step:4|6   loss:0.48609164357185364  \n","Epoch:40/50     Step:5|6   loss:0.4855435788631439  \n","Epoch:40/50     Step:6|6   loss:0.48642799258232117  \n","Epoch:40/50     Step:7|6   loss:0.4857460856437683  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4857916533946991  \n","Epoch:41/50     Step:2|6   loss:0.48600849509239197  \n","Epoch:41/50     Step:3|6   loss:0.4856879711151123  \n","Epoch:41/50     Step:4|6   loss:0.48576128482818604  \n","Epoch:41/50     Step:5|6   loss:0.48561134934425354  \n","Epoch:41/50     Step:6|6   loss:0.4861021637916565  \n","Epoch:41/50     Step:7|6   loss:0.4856373369693756  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4857260584831238  \n","Epoch:42/50     Step:2|6   loss:0.48563918471336365  \n","Epoch:42/50     Step:3|6   loss:0.48595696687698364  \n","Epoch:42/50     Step:4|6   loss:0.48549532890319824  \n","Epoch:42/50     Step:5|6   loss:0.48564693331718445  \n","Epoch:42/50     Step:6|6   loss:0.48558101058006287  \n","Epoch:42/50     Step:7|6   loss:0.4854724109172821  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4855167269706726  \n","Epoch:43/50     Step:2|6   loss:0.4855811893939972  \n","Epoch:43/50     Step:3|6   loss:0.48568111658096313  \n","Epoch:43/50     Step:4|6   loss:0.48579782247543335  \n","Epoch:43/50     Step:5|6   loss:0.4856818616390228  \n","Epoch:43/50     Step:6|6   loss:0.4856736660003662  \n","Epoch:43/50     Step:7|6   loss:0.4857846796512604  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4857289493083954  \n","Epoch:44/50     Step:2|6   loss:0.4855451285839081  \n","Epoch:44/50     Step:3|6   loss:0.4854573607444763  \n","Epoch:44/50     Step:4|6   loss:0.4857390522956848  \n","Epoch:44/50     Step:5|6   loss:0.4855831563472748  \n","Epoch:44/50     Step:6|6   loss:0.4855507016181946  \n","Epoch:44/50     Step:7|6   loss:0.4857453405857086  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4857981204986572  \n","Epoch:45/50     Step:2|6   loss:0.48540937900543213  \n","Epoch:45/50     Step:3|6   loss:0.48570671677589417  \n","Epoch:45/50     Step:4|6   loss:0.4857598543167114  \n","Epoch:45/50     Step:5|6   loss:0.48595279455184937  \n","Epoch:45/50     Step:6|6   loss:0.4855145514011383  \n","Epoch:45/50     Step:7|6   loss:0.48576265573501587  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.48576244711875916  \n","Epoch:46/50     Step:2|6   loss:0.48564741015434265  \n","Epoch:46/50     Step:3|6   loss:0.4861326813697815  \n","Epoch:46/50     Step:4|6   loss:0.4854171872138977  \n","Epoch:46/50     Step:5|6   loss:0.48611363768577576  \n","Epoch:46/50     Step:6|6   loss:0.4858006536960602  \n","Epoch:46/50     Step:7|6   loss:0.48567402362823486  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4856583774089813  \n","Epoch:47/50     Step:2|6   loss:0.4857734739780426  \n","Epoch:47/50     Step:3|6   loss:0.4859619140625  \n","Epoch:47/50     Step:4|6   loss:0.48566317558288574  \n","Epoch:47/50     Step:5|6   loss:0.48572424054145813  \n","Epoch:47/50     Step:6|6   loss:0.4855699837207794  \n","Epoch:47/50     Step:7|6   loss:0.4854632616043091  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4856341481208801  \n","Epoch:48/50     Step:2|6   loss:0.48545414209365845  \n","Epoch:48/50     Step:3|6   loss:0.48577117919921875  \n","Epoch:48/50     Step:4|6   loss:0.48547059297561646  \n","Epoch:48/50     Step:5|6   loss:0.4858928918838501  \n","Epoch:48/50     Step:6|6   loss:0.4854169487953186  \n","Epoch:48/50     Step:7|6   loss:0.4857688546180725  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.485482394695282  \n","Epoch:49/50     Step:2|6   loss:0.485518217086792  \n","Epoch:49/50     Step:3|6   loss:0.48550787568092346  \n","Epoch:49/50     Step:4|6   loss:0.48539382219314575  \n","Epoch:49/50     Step:5|6   loss:0.48530831933021545  \n","Epoch:49/50     Step:6|6   loss:0.4854261577129364  \n","Epoch:49/50     Step:7|6   loss:0.485359251499176  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48552680015563965  \n","Epoch:50/50     Step:2|6   loss:0.4854382276535034  \n","Epoch:50/50     Step:3|6   loss:0.4854074716567993  \n","Epoch:50/50     Step:4|6   loss:0.4852822721004486  \n","Epoch:50/50     Step:5|6   loss:0.4854072630405426  \n","Epoch:50/50     Step:6|6   loss:0.48534664511680603  \n","Epoch:50/50     Step:7|6   loss:0.48550713062286377  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Accuracy on test_set: 95.33 %\n","4\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1785036325454712  \n","Epoch:1/50     Step:2|6   loss:5.435739994049072  \n","Epoch:1/50     Step:3|6   loss:2.1230175495147705  \n","Epoch:1/50     Step:4|6   loss:1.588615894317627  \n","Epoch:1/50     Step:5|6   loss:2.8552873134613037  \n","Epoch:1/50     Step:6|6   loss:2.8843746185302734  \n","Epoch:1/50     Step:7|6   loss:2.0109033584594727  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 80.80 %\n","current max accuracy\t test set:75.7%\t train set:80.8%\n","Epoch:2/50     Step:1|6   loss:1.3585201501846313  \n","Epoch:2/50     Step:2|6   loss:1.4705123901367188  \n","Epoch:2/50     Step:3|6   loss:1.638425350189209  \n","Epoch:2/50     Step:4|6   loss:1.1289927959442139  \n","Epoch:2/50     Step:5|6   loss:1.1857402324676514  \n","Epoch:2/50     Step:6|6   loss:1.4090774059295654  \n","Epoch:2/50     Step:7|6   loss:1.2343577146530151  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:77.57%\t train set:84.78%\n","Epoch:3/50     Step:1|6   loss:1.2596429586410522  \n","Epoch:3/50     Step:2|6   loss:1.0689737796783447  \n","Epoch:3/50     Step:3|6   loss:1.1884671449661255  \n","Epoch:3/50     Step:4|6   loss:1.2167848348617554  \n","Epoch:3/50     Step:5|6   loss:1.0536999702453613  \n","Epoch:3/50     Step:6|6   loss:1.0119081735610962  \n","Epoch:3/50     Step:7|6   loss:1.1671321392059326  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:80.37%\t train set:84.78%\n","Epoch:4/50     Step:1|6   loss:1.2092350721359253  \n","Epoch:4/50     Step:2|6   loss:0.9367932677268982  \n","Epoch:4/50     Step:3|6   loss:0.7936311364173889  \n","Epoch:4/50     Step:4|6   loss:0.7891697883605957  \n","Epoch:4/50     Step:5|6   loss:0.7676397562026978  \n","Epoch:4/50     Step:6|6   loss:0.774208664894104  \n","Epoch:4/50     Step:7|6   loss:0.6649690270423889  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:80.37%\t train set:90.87%\n","Epoch:5/50     Step:1|6   loss:0.7322946786880493  \n","Epoch:5/50     Step:2|6   loss:0.6273009777069092  \n","Epoch:5/50     Step:3|6   loss:0.7113257646560669  \n","Epoch:5/50     Step:4|6   loss:0.6222926378250122  \n","Epoch:5/50     Step:5|6   loss:0.5976259112358093  \n","Epoch:5/50     Step:6|6   loss:0.6126796007156372  \n","Epoch:5/50     Step:7|6   loss:0.5963343381881714  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:88.79%\t train set:96.49%\n","Epoch:6/50     Step:1|6   loss:0.5649370551109314  \n","Epoch:6/50     Step:2|6   loss:0.5540385246276855  \n","Epoch:6/50     Step:3|6   loss:0.5581185221672058  \n","Epoch:6/50     Step:4|6   loss:0.5857709050178528  \n","Epoch:6/50     Step:5|6   loss:0.5675403475761414  \n","Epoch:6/50     Step:6|6   loss:0.5577864646911621  \n","Epoch:6/50     Step:7|6   loss:0.5346413850784302  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:88.79%\t train set:97.89%\n","Epoch:7/50     Step:1|6   loss:0.5664578676223755  \n","Epoch:7/50     Step:2|6   loss:0.5507224202156067  \n","Epoch:7/50     Step:3|6   loss:0.5447648763656616  \n","Epoch:7/50     Step:4|6   loss:0.5394952297210693  \n","Epoch:7/50     Step:5|6   loss:0.5499253273010254  \n","Epoch:7/50     Step:6|6   loss:0.5491942167282104  \n","Epoch:7/50     Step:7|6   loss:0.5427997708320618  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:88.79%\t train set:97.89%\n","Epoch:8/50     Step:1|6   loss:0.5367668271064758  \n","Epoch:8/50     Step:2|6   loss:0.5959526300430298  \n","Epoch:8/50     Step:3|6   loss:0.5161839127540588  \n","Epoch:8/50     Step:4|6   loss:0.5366778373718262  \n","Epoch:8/50     Step:5|6   loss:0.5588088035583496  \n","Epoch:8/50     Step:6|6   loss:0.5451915264129639  \n","Epoch:8/50     Step:7|6   loss:0.5518838763237  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:88.79%\t train set:98.83%\n","Epoch:9/50     Step:1|6   loss:0.5472120046615601  \n","Epoch:9/50     Step:2|6   loss:0.5301879644393921  \n","Epoch:9/50     Step:3|6   loss:0.5133075714111328  \n","Epoch:9/50     Step:4|6   loss:0.5195043087005615  \n","Epoch:9/50     Step:5|6   loss:0.5224055051803589  \n","Epoch:9/50     Step:6|6   loss:0.516644299030304  \n","Epoch:9/50     Step:7|6   loss:0.5147316455841064  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:88.79%\t train set:99.77%\n","Epoch:10/50     Step:1|6   loss:0.5202049612998962  \n","Epoch:10/50     Step:2|6   loss:0.5272094011306763  \n","Epoch:10/50     Step:3|6   loss:0.5091555714607239  \n","Epoch:10/50     Step:4|6   loss:0.5165122747421265  \n","Epoch:10/50     Step:5|6   loss:0.5213311910629272  \n","Epoch:10/50     Step:6|6   loss:0.5162034630775452  \n","Epoch:10/50     Step:7|6   loss:0.5111022591590881  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:88.79%\t train set:99.77%\n","Epoch:11/50     Step:1|6   loss:0.5189107656478882  \n","Epoch:11/50     Step:2|6   loss:0.5173084735870361  \n","Epoch:11/50     Step:3|6   loss:0.5229853987693787  \n","Epoch:11/50     Step:4|6   loss:0.5120726227760315  \n","Epoch:11/50     Step:5|6   loss:0.5139437913894653  \n","Epoch:11/50     Step:6|6   loss:0.5124586820602417  \n","Epoch:11/50     Step:7|6   loss:0.5141816139221191  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:12/50     Step:1|6   loss:0.5041036605834961  \n","Epoch:12/50     Step:2|6   loss:0.5092728137969971  \n","Epoch:12/50     Step:3|6   loss:0.5029110312461853  \n","Epoch:12/50     Step:4|6   loss:0.5062834024429321  \n","Epoch:12/50     Step:5|6   loss:0.511029839515686  \n","Epoch:12/50     Step:6|6   loss:0.5004538893699646  \n","Epoch:12/50     Step:7|6   loss:0.508232831954956  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5034970045089722  \n","Epoch:13/50     Step:2|6   loss:0.5062741637229919  \n","Epoch:13/50     Step:3|6   loss:0.5024250745773315  \n","Epoch:13/50     Step:4|6   loss:0.5010190010070801  \n","Epoch:13/50     Step:5|6   loss:0.49777889251708984  \n","Epoch:13/50     Step:6|6   loss:0.4978855550289154  \n","Epoch:13/50     Step:7|6   loss:0.5098400115966797  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5041413903236389  \n","Epoch:14/50     Step:2|6   loss:0.5017423629760742  \n","Epoch:14/50     Step:3|6   loss:0.49922657012939453  \n","Epoch:14/50     Step:4|6   loss:0.4999696612358093  \n","Epoch:14/50     Step:5|6   loss:0.4990866184234619  \n","Epoch:14/50     Step:6|6   loss:0.49976176023483276  \n","Epoch:14/50     Step:7|6   loss:0.4973566234111786  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:89.72%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.49638932943344116  \n","Epoch:15/50     Step:2|6   loss:0.4967588186264038  \n","Epoch:15/50     Step:3|6   loss:0.5026779770851135  \n","Epoch:15/50     Step:4|6   loss:0.5021146535873413  \n","Epoch:15/50     Step:5|6   loss:0.5001299381256104  \n","Epoch:15/50     Step:6|6   loss:0.4968041777610779  \n","Epoch:15/50     Step:7|6   loss:0.4975491166114807  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.49673402309417725  \n","Epoch:16/50     Step:2|6   loss:0.49607813358306885  \n","Epoch:16/50     Step:3|6   loss:0.49701714515686035  \n","Epoch:16/50     Step:4|6   loss:0.5011090636253357  \n","Epoch:16/50     Step:5|6   loss:0.49338603019714355  \n","Epoch:16/50     Step:6|6   loss:0.4939766526222229  \n","Epoch:16/50     Step:7|6   loss:0.4951345920562744  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.49356991052627563  \n","Epoch:17/50     Step:2|6   loss:0.5005494952201843  \n","Epoch:17/50     Step:3|6   loss:0.49246251583099365  \n","Epoch:17/50     Step:4|6   loss:0.4940073490142822  \n","Epoch:17/50     Step:5|6   loss:0.4961020350456238  \n","Epoch:17/50     Step:6|6   loss:0.49401557445526123  \n","Epoch:17/50     Step:7|6   loss:0.4924317002296448  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.49143466353416443  \n","Epoch:18/50     Step:2|6   loss:0.49157798290252686  \n","Epoch:18/50     Step:3|6   loss:0.4942212998867035  \n","Epoch:18/50     Step:4|6   loss:0.49479833245277405  \n","Epoch:18/50     Step:5|6   loss:0.4936019480228424  \n","Epoch:18/50     Step:6|6   loss:0.4927992820739746  \n","Epoch:18/50     Step:7|6   loss:0.4915236830711365  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4931352734565735  \n","Epoch:19/50     Step:2|6   loss:0.4892153739929199  \n","Epoch:19/50     Step:3|6   loss:0.48989933729171753  \n","Epoch:19/50     Step:4|6   loss:0.49029815196990967  \n","Epoch:19/50     Step:5|6   loss:0.4926190674304962  \n","Epoch:19/50     Step:6|6   loss:0.49576324224472046  \n","Epoch:19/50     Step:7|6   loss:0.4957156181335449  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49084603786468506  \n","Epoch:20/50     Step:2|6   loss:0.49123913049697876  \n","Epoch:20/50     Step:3|6   loss:0.4944149851799011  \n","Epoch:20/50     Step:4|6   loss:0.49052268266677856  \n","Epoch:20/50     Step:5|6   loss:0.491253137588501  \n","Epoch:20/50     Step:6|6   loss:0.4925733804702759  \n","Epoch:20/50     Step:7|6   loss:0.492208868265152  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4906570613384247  \n","Epoch:21/50     Step:2|6   loss:0.4910433888435364  \n","Epoch:21/50     Step:3|6   loss:0.48821699619293213  \n","Epoch:21/50     Step:4|6   loss:0.49246951937675476  \n","Epoch:21/50     Step:5|6   loss:0.49270665645599365  \n","Epoch:21/50     Step:6|6   loss:0.492031455039978  \n","Epoch:21/50     Step:7|6   loss:0.4904736280441284  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.4879080057144165  \n","Epoch:22/50     Step:2|6   loss:0.49133267998695374  \n","Epoch:22/50     Step:3|6   loss:0.49131494760513306  \n","Epoch:22/50     Step:4|6   loss:0.4895963668823242  \n","Epoch:22/50     Step:5|6   loss:0.49273502826690674  \n","Epoch:22/50     Step:6|6   loss:0.4912402033805847  \n","Epoch:22/50     Step:7|6   loss:0.49951890110969543  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.490531861782074  \n","Epoch:23/50     Step:2|6   loss:0.4917939305305481  \n","Epoch:23/50     Step:3|6   loss:0.49132251739501953  \n","Epoch:23/50     Step:4|6   loss:0.4909750521183014  \n","Epoch:23/50     Step:5|6   loss:0.48980164527893066  \n","Epoch:23/50     Step:6|6   loss:0.4902232587337494  \n","Epoch:23/50     Step:7|6   loss:0.48894399404525757  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4896841049194336  \n","Epoch:24/50     Step:2|6   loss:0.4906277656555176  \n","Epoch:24/50     Step:3|6   loss:0.4901747703552246  \n","Epoch:24/50     Step:4|6   loss:0.49008697271347046  \n","Epoch:24/50     Step:5|6   loss:0.4924837052822113  \n","Epoch:24/50     Step:6|6   loss:0.4882708787918091  \n","Epoch:24/50     Step:7|6   loss:0.4889812767505646  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.4892128109931946  \n","Epoch:25/50     Step:2|6   loss:0.48944729566574097  \n","Epoch:25/50     Step:3|6   loss:0.4903378486633301  \n","Epoch:25/50     Step:4|6   loss:0.48964715003967285  \n","Epoch:25/50     Step:5|6   loss:0.4868766665458679  \n","Epoch:25/50     Step:6|6   loss:0.4887106120586395  \n","Epoch:25/50     Step:7|6   loss:0.49017027020454407  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48921090364456177  \n","Epoch:26/50     Step:2|6   loss:0.4874315559864044  \n","Epoch:26/50     Step:3|6   loss:0.4886322021484375  \n","Epoch:26/50     Step:4|6   loss:0.488545686006546  \n","Epoch:26/50     Step:5|6   loss:0.4874895513057709  \n","Epoch:26/50     Step:6|6   loss:0.48828333616256714  \n","Epoch:26/50     Step:7|6   loss:0.4879348576068878  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4876669943332672  \n","Epoch:27/50     Step:2|6   loss:0.4880560636520386  \n","Epoch:27/50     Step:3|6   loss:0.48768001794815063  \n","Epoch:27/50     Step:4|6   loss:0.48767632246017456  \n","Epoch:27/50     Step:5|6   loss:0.4901731610298157  \n","Epoch:27/50     Step:6|6   loss:0.48719221353530884  \n","Epoch:27/50     Step:7|6   loss:0.49067360162734985  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48823025822639465  \n","Epoch:28/50     Step:2|6   loss:0.4868387281894684  \n","Epoch:28/50     Step:3|6   loss:0.4891275465488434  \n","Epoch:28/50     Step:4|6   loss:0.4878312349319458  \n","Epoch:28/50     Step:5|6   loss:0.4877402186393738  \n","Epoch:28/50     Step:6|6   loss:0.4875839650630951  \n","Epoch:28/50     Step:7|6   loss:0.48939523100852966  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.48831331729888916  \n","Epoch:29/50     Step:2|6   loss:0.4878484606742859  \n","Epoch:29/50     Step:3|6   loss:0.4874316453933716  \n","Epoch:29/50     Step:4|6   loss:0.48836588859558105  \n","Epoch:29/50     Step:5|6   loss:0.48764750361442566  \n","Epoch:29/50     Step:6|6   loss:0.4871823489665985  \n","Epoch:29/50     Step:7|6   loss:0.4870849847793579  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.48676884174346924  \n","Epoch:30/50     Step:2|6   loss:0.48776793479919434  \n","Epoch:30/50     Step:3|6   loss:0.48726561665534973  \n","Epoch:30/50     Step:4|6   loss:0.48745235800743103  \n","Epoch:30/50     Step:5|6   loss:0.48743993043899536  \n","Epoch:30/50     Step:6|6   loss:0.48734045028686523  \n","Epoch:30/50     Step:7|6   loss:0.48706257343292236  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48688021302223206  \n","Epoch:31/50     Step:2|6   loss:0.48782649636268616  \n","Epoch:31/50     Step:3|6   loss:0.4867492616176605  \n","Epoch:31/50     Step:4|6   loss:0.48801088333129883  \n","Epoch:31/50     Step:5|6   loss:0.4867641031742096  \n","Epoch:31/50     Step:6|6   loss:0.48743581771850586  \n","Epoch:31/50     Step:7|6   loss:0.4879232943058014  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4873000681400299  \n","Epoch:32/50     Step:2|6   loss:0.48678329586982727  \n","Epoch:32/50     Step:3|6   loss:0.48640143871307373  \n","Epoch:32/50     Step:4|6   loss:0.48620301485061646  \n","Epoch:32/50     Step:5|6   loss:0.4868481755256653  \n","Epoch:32/50     Step:6|6   loss:0.4867536127567291  \n","Epoch:32/50     Step:7|6   loss:0.4872914254665375  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48693573474884033  \n","Epoch:33/50     Step:2|6   loss:0.48641544580459595  \n","Epoch:33/50     Step:3|6   loss:0.4868139624595642  \n","Epoch:33/50     Step:4|6   loss:0.48683130741119385  \n","Epoch:33/50     Step:5|6   loss:0.48634105920791626  \n","Epoch:33/50     Step:6|6   loss:0.48631197214126587  \n","Epoch:33/50     Step:7|6   loss:0.48698145151138306  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4866129755973816  \n","Epoch:34/50     Step:2|6   loss:0.48762068152427673  \n","Epoch:34/50     Step:3|6   loss:0.4861854910850525  \n","Epoch:34/50     Step:4|6   loss:0.4869175851345062  \n","Epoch:34/50     Step:5|6   loss:0.4863855540752411  \n","Epoch:34/50     Step:6|6   loss:0.48621097207069397  \n","Epoch:34/50     Step:7|6   loss:0.4862593412399292  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4867318868637085  \n","Epoch:35/50     Step:2|6   loss:0.48629775643348694  \n","Epoch:35/50     Step:3|6   loss:0.4860638380050659  \n","Epoch:35/50     Step:4|6   loss:0.4866444170475006  \n","Epoch:35/50     Step:5|6   loss:0.48660561442375183  \n","Epoch:35/50     Step:6|6   loss:0.48597654700279236  \n","Epoch:35/50     Step:7|6   loss:0.48641544580459595  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.48589155077934265  \n","Epoch:36/50     Step:2|6   loss:0.48633602261543274  \n","Epoch:36/50     Step:3|6   loss:0.4859941899776459  \n","Epoch:36/50     Step:4|6   loss:0.4863734841346741  \n","Epoch:36/50     Step:5|6   loss:0.4862223267555237  \n","Epoch:36/50     Step:6|6   loss:0.4863124191761017  \n","Epoch:36/50     Step:7|6   loss:0.48633313179016113  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4865124523639679  \n","Epoch:37/50     Step:2|6   loss:0.4857386648654938  \n","Epoch:37/50     Step:3|6   loss:0.48611190915107727  \n","Epoch:37/50     Step:4|6   loss:0.48623308539390564  \n","Epoch:37/50     Step:5|6   loss:0.4861498177051544  \n","Epoch:37/50     Step:6|6   loss:0.48618578910827637  \n","Epoch:37/50     Step:7|6   loss:0.48565059900283813  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.48628953099250793  \n","Epoch:38/50     Step:2|6   loss:0.4858156442642212  \n","Epoch:38/50     Step:3|6   loss:0.4859916865825653  \n","Epoch:38/50     Step:4|6   loss:0.4860106408596039  \n","Epoch:38/50     Step:5|6   loss:0.4859054982662201  \n","Epoch:38/50     Step:6|6   loss:0.4859481751918793  \n","Epoch:38/50     Step:7|6   loss:0.48565298318862915  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.48551538586616516  \n","Epoch:39/50     Step:2|6   loss:0.48600926995277405  \n","Epoch:39/50     Step:3|6   loss:0.48587605357170105  \n","Epoch:39/50     Step:4|6   loss:0.4859766364097595  \n","Epoch:39/50     Step:5|6   loss:0.4860706925392151  \n","Epoch:39/50     Step:6|6   loss:0.4858108460903168  \n","Epoch:39/50     Step:7|6   loss:0.4858255684375763  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48618486523628235  \n","Epoch:40/50     Step:2|6   loss:0.48600873351097107  \n","Epoch:40/50     Step:3|6   loss:0.48563849925994873  \n","Epoch:40/50     Step:4|6   loss:0.48566490411758423  \n","Epoch:40/50     Step:5|6   loss:0.4857736825942993  \n","Epoch:40/50     Step:6|6   loss:0.48583051562309265  \n","Epoch:40/50     Step:7|6   loss:0.4858560264110565  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4860009253025055  \n","Epoch:41/50     Step:2|6   loss:0.48572689294815063  \n","Epoch:41/50     Step:3|6   loss:0.485797643661499  \n","Epoch:41/50     Step:4|6   loss:0.485992431640625  \n","Epoch:41/50     Step:5|6   loss:0.48583438992500305  \n","Epoch:41/50     Step:6|6   loss:0.48551368713378906  \n","Epoch:41/50     Step:7|6   loss:0.4857257008552551  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4857085347175598  \n","Epoch:42/50     Step:2|6   loss:0.4857058823108673  \n","Epoch:42/50     Step:3|6   loss:0.48572033643722534  \n","Epoch:42/50     Step:4|6   loss:0.4858502149581909  \n","Epoch:42/50     Step:5|6   loss:0.48569566011428833  \n","Epoch:42/50     Step:6|6   loss:0.48572421073913574  \n","Epoch:42/50     Step:7|6   loss:0.48573651909828186  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4856220781803131  \n","Epoch:43/50     Step:2|6   loss:0.48574233055114746  \n","Epoch:43/50     Step:3|6   loss:0.48580673336982727  \n","Epoch:43/50     Step:4|6   loss:0.48537927865982056  \n","Epoch:43/50     Step:5|6   loss:0.48562368750572205  \n","Epoch:43/50     Step:6|6   loss:0.48588597774505615  \n","Epoch:43/50     Step:7|6   loss:0.4859875440597534  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4856943190097809  \n","Epoch:44/50     Step:2|6   loss:0.4854738116264343  \n","Epoch:44/50     Step:3|6   loss:0.4854644238948822  \n","Epoch:44/50     Step:4|6   loss:0.4858199954032898  \n","Epoch:44/50     Step:5|6   loss:0.4857027232646942  \n","Epoch:44/50     Step:6|6   loss:0.4855216145515442  \n","Epoch:44/50     Step:7|6   loss:0.486047625541687  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4857103228569031  \n","Epoch:45/50     Step:2|6   loss:0.4858071804046631  \n","Epoch:45/50     Step:3|6   loss:0.4856293499469757  \n","Epoch:45/50     Step:4|6   loss:0.4855332374572754  \n","Epoch:45/50     Step:5|6   loss:0.4855077862739563  \n","Epoch:45/50     Step:6|6   loss:0.4858642816543579  \n","Epoch:45/50     Step:7|6   loss:0.48549726605415344  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4855915307998657  \n","Epoch:46/50     Step:2|6   loss:0.48548823595046997  \n","Epoch:46/50     Step:3|6   loss:0.4855465292930603  \n","Epoch:46/50     Step:4|6   loss:0.48569121956825256  \n","Epoch:46/50     Step:5|6   loss:0.48600372672080994  \n","Epoch:46/50     Step:6|6   loss:0.48562151193618774  \n","Epoch:46/50     Step:7|6   loss:0.48537570238113403  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4854460656642914  \n","Epoch:47/50     Step:2|6   loss:0.48538219928741455  \n","Epoch:47/50     Step:3|6   loss:0.48568806052207947  \n","Epoch:47/50     Step:4|6   loss:0.4857478737831116  \n","Epoch:47/50     Step:5|6   loss:0.4857940077781677  \n","Epoch:47/50     Step:6|6   loss:0.48552316427230835  \n","Epoch:47/50     Step:7|6   loss:0.4855254590511322  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.48549121618270874  \n","Epoch:48/50     Step:2|6   loss:0.4854748845100403  \n","Epoch:48/50     Step:3|6   loss:0.48563751578330994  \n","Epoch:48/50     Step:4|6   loss:0.4855974316596985  \n","Epoch:48/50     Step:5|6   loss:0.48550817370414734  \n","Epoch:48/50     Step:6|6   loss:0.48565492033958435  \n","Epoch:48/50     Step:7|6   loss:0.48543858528137207  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48583361506462097  \n","Epoch:49/50     Step:2|6   loss:0.48563140630722046  \n","Epoch:49/50     Step:3|6   loss:0.48555633425712585  \n","Epoch:49/50     Step:4|6   loss:0.4855051636695862  \n","Epoch:49/50     Step:5|6   loss:0.4853462874889374  \n","Epoch:49/50     Step:6|6   loss:0.48544758558273315  \n","Epoch:49/50     Step:7|6   loss:0.4855140745639801  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48537322878837585  \n","Epoch:50/50     Step:2|6   loss:0.48532602190971375  \n","Epoch:50/50     Step:3|6   loss:0.48534438014030457  \n","Epoch:50/50     Step:4|6   loss:0.48553910851478577  \n","Epoch:50/50     Step:5|6   loss:0.48540374636650085  \n","Epoch:50/50     Step:6|6   loss:0.48550689220428467  \n","Epoch:50/50     Step:7|6   loss:0.48590371012687683  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Accuracy on test_set: 92.52 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4  --model Logistic_two_stream --mode ir --index {i}"},{"cell_type":"code","execution_count":5,"id":"e2f15ff9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.133400559425354  \n","Epoch:1/50     Step:2|6   loss:9.966906547546387  \n","Epoch:1/50     Step:3|6   loss:15.421146392822266  \n","Epoch:1/50     Step:4|6   loss:7.030516624450684  \n","Epoch:1/50     Step:5|6   loss:1.765881061553955  \n","Epoch:1/50     Step:6|6   loss:7.58043098449707  \n","Epoch:1/50     Step:7|6   loss:4.835222244262695  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 47.54 %\n","current max accuracy\t test set:42.99%\t train set:47.54%\n","Epoch:2/50     Step:1|6   loss:6.134134769439697  \n","Epoch:2/50     Step:2|6   loss:3.3137779235839844  \n","Epoch:2/50     Step:3|6   loss:1.9012079238891602  \n","Epoch:2/50     Step:4|6   loss:3.464426040649414  \n","Epoch:2/50     Step:5|6   loss:4.347634315490723  \n","Epoch:2/50     Step:6|6   loss:4.0122175216674805  \n","Epoch:2/50     Step:7|6   loss:2.167936325073242  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:76.64%\t train set:88.06%\n","Epoch:3/50     Step:1|6   loss:2.2187986373901367  \n","Epoch:3/50     Step:2|6   loss:2.461118698120117  \n","Epoch:3/50     Step:3|6   loss:3.3762762546539307  \n","Epoch:3/50     Step:4|6   loss:3.2165637016296387  \n","Epoch:3/50     Step:5|6   loss:2.29923677444458  \n","Epoch:3/50     Step:6|6   loss:1.8077725172042847  \n","Epoch:3/50     Step:7|6   loss:2.0483620166778564  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:76.64%\t train set:88.06%\n","Epoch:4/50     Step:1|6   loss:2.5917158126831055  \n","Epoch:4/50     Step:2|6   loss:2.727518320083618  \n","Epoch:4/50     Step:3|6   loss:2.235591411590576  \n","Epoch:4/50     Step:4|6   loss:2.354909658432007  \n","Epoch:4/50     Step:5|6   loss:1.6477447748184204  \n","Epoch:4/50     Step:6|6   loss:2.281005382537842  \n","Epoch:4/50     Step:7|6   loss:1.6228740215301514  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 79.63 %\n","current max accuracy\t test set:76.64%\t train set:88.06%\n","Epoch:5/50     Step:1|6   loss:2.3407506942749023  \n","Epoch:5/50     Step:2|6   loss:1.8994982242584229  \n","Epoch:5/50     Step:3|6   loss:1.1617048978805542  \n","Epoch:5/50     Step:4|6   loss:1.4541226625442505  \n","Epoch:5/50     Step:5|6   loss:1.515554666519165  \n","Epoch:5/50     Step:6|6   loss:1.9089839458465576  \n","Epoch:5/50     Step:7|6   loss:1.7910397052764893  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:79.44%\t train set:88.99%\n","Epoch:6/50     Step:1|6   loss:1.4527106285095215  \n","Epoch:6/50     Step:2|6   loss:1.119644284248352  \n","Epoch:6/50     Step:3|6   loss:0.8723032474517822  \n","Epoch:6/50     Step:4|6   loss:1.5731561183929443  \n","Epoch:6/50     Step:5|6   loss:1.1211460828781128  \n","Epoch:6/50     Step:6|6   loss:0.9394756555557251  \n","Epoch:6/50     Step:7|6   loss:0.9752272367477417  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 74.94 %\n","current max accuracy\t test set:79.44%\t train set:88.99%\n","Epoch:7/50     Step:1|6   loss:1.154795527458191  \n","Epoch:7/50     Step:2|6   loss:1.0777242183685303  \n","Epoch:7/50     Step:3|6   loss:1.0797481536865234  \n","Epoch:7/50     Step:4|6   loss:0.8261613845825195  \n","Epoch:7/50     Step:5|6   loss:0.9998977184295654  \n","Epoch:7/50     Step:6|6   loss:0.9749897718429565  \n","Epoch:7/50     Step:7|6   loss:0.9968013763427734  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:81.31%\t train set:92.97%\n","Epoch:8/50     Step:1|6   loss:0.8465808033943176  \n","Epoch:8/50     Step:2|6   loss:0.9271036386489868  \n","Epoch:8/50     Step:3|6   loss:1.0926849842071533  \n","Epoch:8/50     Step:4|6   loss:0.9238962531089783  \n","Epoch:8/50     Step:5|6   loss:0.7669938802719116  \n","Epoch:8/50     Step:6|6   loss:1.0902360677719116  \n","Epoch:8/50     Step:7|6   loss:1.051174283027649  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:84.11%\t train set:97.66%\n","Epoch:9/50     Step:1|6   loss:0.7920413017272949  \n","Epoch:9/50     Step:2|6   loss:0.7937449216842651  \n","Epoch:9/50     Step:3|6   loss:0.9104260206222534  \n","Epoch:9/50     Step:4|6   loss:0.800294041633606  \n","Epoch:9/50     Step:5|6   loss:0.7199423313140869  \n","Epoch:9/50     Step:6|6   loss:0.6957060694694519  \n","Epoch:9/50     Step:7|6   loss:0.6578875780105591  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:84.11%\t train set:97.66%\n","Epoch:10/50     Step:1|6   loss:0.6663803458213806  \n","Epoch:10/50     Step:2|6   loss:0.5982965230941772  \n","Epoch:10/50     Step:3|6   loss:0.7450272440910339  \n","Epoch:10/50     Step:4|6   loss:0.5743880271911621  \n","Epoch:10/50     Step:5|6   loss:0.6230930685997009  \n","Epoch:10/50     Step:6|6   loss:0.6279492378234863  \n","Epoch:10/50     Step:7|6   loss:0.5512974858283997  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:88.79%\t train set:97.89%\n","Epoch:11/50     Step:1|6   loss:0.623424768447876  \n","Epoch:11/50     Step:2|6   loss:0.6028121709823608  \n","Epoch:11/50     Step:3|6   loss:0.5512316226959229  \n","Epoch:11/50     Step:4|6   loss:0.5614607334136963  \n","Epoch:11/50     Step:5|6   loss:0.602575957775116  \n","Epoch:11/50     Step:6|6   loss:0.5497957468032837  \n","Epoch:11/50     Step:7|6   loss:0.5754439830780029  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:12/50     Step:1|6   loss:0.6083027124404907  \n","Epoch:12/50     Step:2|6   loss:0.5540658235549927  \n","Epoch:12/50     Step:3|6   loss:0.5410621166229248  \n","Epoch:12/50     Step:4|6   loss:0.5843585729598999  \n","Epoch:12/50     Step:5|6   loss:0.5543497800827026  \n","Epoch:12/50     Step:6|6   loss:0.5381838083267212  \n","Epoch:12/50     Step:7|6   loss:0.6083550453186035  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5344198942184448  \n","Epoch:13/50     Step:2|6   loss:0.5654624700546265  \n","Epoch:13/50     Step:3|6   loss:0.5685157179832458  \n","Epoch:13/50     Step:4|6   loss:0.5211907029151917  \n","Epoch:13/50     Step:5|6   loss:0.5678816437721252  \n","Epoch:13/50     Step:6|6   loss:0.5287507176399231  \n","Epoch:13/50     Step:7|6   loss:0.5193392634391785  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5377517938613892  \n","Epoch:14/50     Step:2|6   loss:0.5154697895050049  \n","Epoch:14/50     Step:3|6   loss:0.5159493684768677  \n","Epoch:14/50     Step:4|6   loss:0.5352639555931091  \n","Epoch:14/50     Step:5|6   loss:0.5136200189590454  \n","Epoch:14/50     Step:6|6   loss:0.5299389958381653  \n","Epoch:14/50     Step:7|6   loss:0.5099976658821106  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.5152555704116821  \n","Epoch:15/50     Step:2|6   loss:0.5186396837234497  \n","Epoch:15/50     Step:3|6   loss:0.5086432695388794  \n","Epoch:15/50     Step:4|6   loss:0.5122807025909424  \n","Epoch:15/50     Step:5|6   loss:0.5122033357620239  \n","Epoch:15/50     Step:6|6   loss:0.5059618353843689  \n","Epoch:15/50     Step:7|6   loss:0.5265882015228271  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.5011091232299805  \n","Epoch:16/50     Step:2|6   loss:0.5128953456878662  \n","Epoch:16/50     Step:3|6   loss:0.5013877749443054  \n","Epoch:16/50     Step:4|6   loss:0.512204647064209  \n","Epoch:16/50     Step:5|6   loss:0.5035560131072998  \n","Epoch:16/50     Step:6|6   loss:0.5032132267951965  \n","Epoch:16/50     Step:7|6   loss:0.4969687759876251  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.4948793649673462  \n","Epoch:17/50     Step:2|6   loss:0.4979691505432129  \n","Epoch:17/50     Step:3|6   loss:0.49838879704475403  \n","Epoch:17/50     Step:4|6   loss:0.49737483263015747  \n","Epoch:17/50     Step:5|6   loss:0.4955295920372009  \n","Epoch:17/50     Step:6|6   loss:0.501360297203064  \n","Epoch:17/50     Step:7|6   loss:0.49782589077949524  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.49681830406188965  \n","Epoch:18/50     Step:2|6   loss:0.49569645524024963  \n","Epoch:18/50     Step:3|6   loss:0.496901273727417  \n","Epoch:18/50     Step:4|6   loss:0.4963769316673279  \n","Epoch:18/50     Step:5|6   loss:0.4942057728767395  \n","Epoch:18/50     Step:6|6   loss:0.49776971340179443  \n","Epoch:18/50     Step:7|6   loss:0.4908011555671692  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.494260311126709  \n","Epoch:19/50     Step:2|6   loss:0.4930235743522644  \n","Epoch:19/50     Step:3|6   loss:0.4931289851665497  \n","Epoch:19/50     Step:4|6   loss:0.4959709048271179  \n","Epoch:19/50     Step:5|6   loss:0.49301207065582275  \n","Epoch:19/50     Step:6|6   loss:0.49682968854904175  \n","Epoch:19/50     Step:7|6   loss:0.49337038397789  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.4955407977104187  \n","Epoch:20/50     Step:2|6   loss:0.4963648319244385  \n","Epoch:20/50     Step:3|6   loss:0.4931383430957794  \n","Epoch:20/50     Step:4|6   loss:0.49583664536476135  \n","Epoch:20/50     Step:5|6   loss:0.49192410707473755  \n","Epoch:20/50     Step:6|6   loss:0.49565473198890686  \n","Epoch:20/50     Step:7|6   loss:0.49138107895851135  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4919406771659851  \n","Epoch:21/50     Step:2|6   loss:0.49117976427078247  \n","Epoch:21/50     Step:3|6   loss:0.4918106198310852  \n","Epoch:21/50     Step:4|6   loss:0.492190420627594  \n","Epoch:21/50     Step:5|6   loss:0.4931008815765381  \n","Epoch:21/50     Step:6|6   loss:0.49078893661499023  \n","Epoch:21/50     Step:7|6   loss:0.49161380529403687  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.4898419976234436  \n","Epoch:22/50     Step:2|6   loss:0.489108145236969  \n","Epoch:22/50     Step:3|6   loss:0.4920492470264435  \n","Epoch:22/50     Step:4|6   loss:0.48966842889785767  \n","Epoch:22/50     Step:5|6   loss:0.48973315954208374  \n","Epoch:22/50     Step:6|6   loss:0.4906767010688782  \n","Epoch:22/50     Step:7|6   loss:0.49189361929893494  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.49078428745269775  \n","Epoch:23/50     Step:2|6   loss:0.4901249408721924  \n","Epoch:23/50     Step:3|6   loss:0.4898102879524231  \n","Epoch:23/50     Step:4|6   loss:0.4900343418121338  \n","Epoch:23/50     Step:5|6   loss:0.4902123212814331  \n","Epoch:23/50     Step:6|6   loss:0.4906938374042511  \n","Epoch:23/50     Step:7|6   loss:0.4903707206249237  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4907993674278259  \n","Epoch:24/50     Step:2|6   loss:0.4892648458480835  \n","Epoch:24/50     Step:3|6   loss:0.49076324701309204  \n","Epoch:24/50     Step:4|6   loss:0.48923903703689575  \n","Epoch:24/50     Step:5|6   loss:0.4899243116378784  \n","Epoch:24/50     Step:6|6   loss:0.4894446134567261  \n","Epoch:24/50     Step:7|6   loss:0.4891988933086395  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.4880182147026062  \n","Epoch:25/50     Step:2|6   loss:0.4891245663166046  \n","Epoch:25/50     Step:3|6   loss:0.49043285846710205  \n","Epoch:25/50     Step:4|6   loss:0.48988500237464905  \n","Epoch:25/50     Step:5|6   loss:0.48839208483695984  \n","Epoch:25/50     Step:6|6   loss:0.48826462030410767  \n","Epoch:25/50     Step:7|6   loss:0.4891812801361084  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48832494020462036  \n","Epoch:26/50     Step:2|6   loss:0.488578200340271  \n","Epoch:26/50     Step:3|6   loss:0.4887312054634094  \n","Epoch:26/50     Step:4|6   loss:0.48798730969429016  \n","Epoch:26/50     Step:5|6   loss:0.48890167474746704  \n","Epoch:26/50     Step:6|6   loss:0.487991601228714  \n","Epoch:26/50     Step:7|6   loss:0.4880746901035309  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4883887469768524  \n","Epoch:27/50     Step:2|6   loss:0.48823827505111694  \n","Epoch:27/50     Step:3|6   loss:0.48801013827323914  \n","Epoch:27/50     Step:4|6   loss:0.4873253405094147  \n","Epoch:27/50     Step:5|6   loss:0.48882201313972473  \n","Epoch:27/50     Step:6|6   loss:0.4884747564792633  \n","Epoch:27/50     Step:7|6   loss:0.4874429702758789  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.4883654713630676  \n","Epoch:28/50     Step:2|6   loss:0.4870966672897339  \n","Epoch:28/50     Step:3|6   loss:0.488251656293869  \n","Epoch:28/50     Step:4|6   loss:0.48834481835365295  \n","Epoch:28/50     Step:5|6   loss:0.4872947931289673  \n","Epoch:28/50     Step:6|6   loss:0.4881305694580078  \n","Epoch:28/50     Step:7|6   loss:0.4883832335472107  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4873902201652527  \n","1\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:29/50     Step:2|6   loss:0.48761042952537537  \n","Epoch:29/50     Step:3|6   loss:0.48816922307014465  \n","Epoch:29/50     Step:4|6   loss:0.48816922307014465  \n","Epoch:29/50     Step:5|6   loss:0.4877268373966217  \n","Epoch:29/50     Step:6|6   loss:0.4874109923839569  \n","Epoch:29/50     Step:7|6   loss:0.48878973722457886  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4873278737068176  \n","Epoch:30/50     Step:2|6   loss:0.4884110987186432  \n","Epoch:30/50     Step:3|6   loss:0.48754438757896423  \n","Epoch:30/50     Step:4|6   loss:0.488241046667099  \n","Epoch:30/50     Step:5|6   loss:0.4872140884399414  \n","Epoch:30/50     Step:6|6   loss:0.48902302980422974  \n","Epoch:30/50     Step:7|6   loss:0.48696058988571167  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48956161737442017  \n","Epoch:31/50     Step:2|6   loss:0.4885452389717102  \n","Epoch:31/50     Step:3|6   loss:0.48854559659957886  \n","Epoch:31/50     Step:4|6   loss:0.4876353442668915  \n","Epoch:31/50     Step:5|6   loss:0.48752719163894653  \n","Epoch:31/50     Step:6|6   loss:0.4874373972415924  \n","Epoch:31/50     Step:7|6   loss:0.4897952079772949  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.490795761346817  \n","Epoch:32/50     Step:2|6   loss:0.48711666464805603  \n","Epoch:32/50     Step:3|6   loss:0.48937541246414185  \n","Epoch:32/50     Step:4|6   loss:0.48686593770980835  \n","Epoch:32/50     Step:5|6   loss:0.4886491894721985  \n","Epoch:32/50     Step:6|6   loss:0.487505167722702  \n","Epoch:32/50     Step:7|6   loss:0.4877680838108063  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48676514625549316  \n","Epoch:33/50     Step:2|6   loss:0.488153874874115  \n","Epoch:33/50     Step:3|6   loss:0.4874289929866791  \n","Epoch:33/50     Step:4|6   loss:0.4872896373271942  \n","Epoch:33/50     Step:5|6   loss:0.48734956979751587  \n","Epoch:33/50     Step:6|6   loss:0.4880974590778351  \n","Epoch:33/50     Step:7|6   loss:0.4879536032676697  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4880216419696808  \n","Epoch:34/50     Step:2|6   loss:0.4870505630970001  \n","Epoch:34/50     Step:3|6   loss:0.48836851119995117  \n","Epoch:34/50     Step:4|6   loss:0.48827680945396423  \n","Epoch:34/50     Step:5|6   loss:0.4877395033836365  \n","Epoch:34/50     Step:6|6   loss:0.4875558018684387  \n","Epoch:34/50     Step:7|6   loss:0.4863888621330261  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.487707257270813  \n","Epoch:35/50     Step:2|6   loss:0.4865790605545044  \n","Epoch:35/50     Step:3|6   loss:0.4887734651565552  \n","Epoch:35/50     Step:4|6   loss:0.48712676763534546  \n","Epoch:35/50     Step:5|6   loss:0.48808786273002625  \n","Epoch:35/50     Step:6|6   loss:0.488046258687973  \n","Epoch:35/50     Step:7|6   loss:0.48799020051956177  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.48737823963165283  \n","Epoch:36/50     Step:2|6   loss:0.48669523000717163  \n","Epoch:36/50     Step:3|6   loss:0.48654916882514954  \n","Epoch:36/50     Step:4|6   loss:0.486480712890625  \n","Epoch:36/50     Step:5|6   loss:0.487580806016922  \n","Epoch:36/50     Step:6|6   loss:0.48664379119873047  \n","Epoch:36/50     Step:7|6   loss:0.4862957000732422  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4865220785140991  \n","Epoch:37/50     Step:2|6   loss:0.48665183782577515  \n","Epoch:37/50     Step:3|6   loss:0.48606809973716736  \n","Epoch:37/50     Step:4|6   loss:0.48636412620544434  \n","Epoch:37/50     Step:5|6   loss:0.4862250089645386  \n","Epoch:37/50     Step:6|6   loss:0.4866712689399719  \n","Epoch:37/50     Step:7|6   loss:0.4871973693370819  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4867776334285736  \n","Epoch:38/50     Step:2|6   loss:0.486246258020401  \n","Epoch:38/50     Step:3|6   loss:0.48691704869270325  \n","Epoch:38/50     Step:4|6   loss:0.48650267720222473  \n","Epoch:38/50     Step:5|6   loss:0.4861489534378052  \n","Epoch:38/50     Step:6|6   loss:0.4865071773529053  \n","Epoch:38/50     Step:7|6   loss:0.48626190423965454  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.48634663224220276  \n","Epoch:39/50     Step:2|6   loss:0.4858943819999695  \n","Epoch:39/50     Step:3|6   loss:0.48689985275268555  \n","Epoch:39/50     Step:4|6   loss:0.48654311895370483  \n","Epoch:39/50     Step:5|6   loss:0.48652997612953186  \n","Epoch:39/50     Step:6|6   loss:0.48605823516845703  \n","Epoch:39/50     Step:7|6   loss:0.48646172881126404  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48653024435043335  \n","Epoch:40/50     Step:2|6   loss:0.4861379861831665  \n","Epoch:40/50     Step:3|6   loss:0.4865579307079315  \n","Epoch:40/50     Step:4|6   loss:0.4866224229335785  \n","Epoch:40/50     Step:5|6   loss:0.48601168394088745  \n","Epoch:40/50     Step:6|6   loss:0.48618683218955994  \n","Epoch:40/50     Step:7|6   loss:0.48583972454071045  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4860389828681946  \n","Epoch:41/50     Step:2|6   loss:0.4864395260810852  \n","Epoch:41/50     Step:3|6   loss:0.48601508140563965  \n","Epoch:41/50     Step:4|6   loss:0.48623839020729065  \n","Epoch:41/50     Step:5|6   loss:0.4870568513870239  \n","Epoch:41/50     Step:6|6   loss:0.4860488772392273  \n","Epoch:41/50     Step:7|6   loss:0.4860721230506897  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48626697063446045  \n","Epoch:42/50     Step:2|6   loss:0.485956072807312  \n","Epoch:42/50     Step:3|6   loss:0.48620593547821045  \n","Epoch:42/50     Step:4|6   loss:0.4863479733467102  \n","Epoch:42/50     Step:5|6   loss:0.4865097999572754  \n","Epoch:42/50     Step:6|6   loss:0.4864620566368103  \n","Epoch:42/50     Step:7|6   loss:0.48613354563713074  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4858454167842865  \n","Epoch:43/50     Step:2|6   loss:0.48581987619400024  \n","Epoch:43/50     Step:3|6   loss:0.4865102171897888  \n","Epoch:43/50     Step:4|6   loss:0.485775351524353  \n","Epoch:43/50     Step:5|6   loss:0.48638713359832764  \n","Epoch:43/50     Step:6|6   loss:0.486347496509552  \n","Epoch:43/50     Step:7|6   loss:0.48614031076431274  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48660290241241455  \n","Epoch:44/50     Step:2|6   loss:0.4859503507614136  \n","Epoch:44/50     Step:3|6   loss:0.486782431602478  \n","Epoch:44/50     Step:4|6   loss:0.48640990257263184  \n","Epoch:44/50     Step:5|6   loss:0.48614439368247986  \n","Epoch:44/50     Step:6|6   loss:0.48665255308151245  \n","Epoch:44/50     Step:7|6   loss:0.48591580986976624  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4864671528339386  \n","Epoch:45/50     Step:2|6   loss:0.48609647154808044  \n","Epoch:45/50     Step:3|6   loss:0.48581430315971375  \n","Epoch:45/50     Step:4|6   loss:0.4858314096927643  \n","Epoch:45/50     Step:5|6   loss:0.4856446385383606  \n","Epoch:45/50     Step:6|6   loss:0.48567676544189453  \n","Epoch:45/50     Step:7|6   loss:0.4856153130531311  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.485818088054657  \n","Epoch:46/50     Step:2|6   loss:0.4856966733932495  \n","Epoch:46/50     Step:3|6   loss:0.4858197271823883  \n","Epoch:46/50     Step:4|6   loss:0.4856146574020386  \n","Epoch:46/50     Step:5|6   loss:0.48580098152160645  \n","Epoch:46/50     Step:6|6   loss:0.48578426241874695  \n","Epoch:46/50     Step:7|6   loss:0.48577824234962463  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4857475757598877  \n","Epoch:47/50     Step:2|6   loss:0.4863255023956299  \n","Epoch:47/50     Step:3|6   loss:0.48614799976348877  \n","Epoch:47/50     Step:4|6   loss:0.48570331931114197  \n","Epoch:47/50     Step:5|6   loss:0.4857787489891052  \n","Epoch:47/50     Step:6|6   loss:0.4860793650150299  \n","Epoch:47/50     Step:7|6   loss:0.4857475161552429  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4856935441493988  \n","Epoch:48/50     Step:2|6   loss:0.4861157536506653  \n","Epoch:48/50     Step:3|6   loss:0.4857807159423828  \n","Epoch:48/50     Step:4|6   loss:0.4858415126800537  \n","Epoch:48/50     Step:5|6   loss:0.48576486110687256  \n","Epoch:48/50     Step:6|6   loss:0.4858974814414978  \n","Epoch:48/50     Step:7|6   loss:0.4857724606990814  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.485653817653656  \n","Epoch:49/50     Step:2|6   loss:0.4857545495033264  \n","Epoch:49/50     Step:3|6   loss:0.48589974641799927  \n","Epoch:49/50     Step:4|6   loss:0.485891193151474  \n","Epoch:49/50     Step:5|6   loss:0.48573216795921326  \n","Epoch:49/50     Step:6|6   loss:0.4856947660446167  \n","Epoch:49/50     Step:7|6   loss:0.4857974946498871  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48574331402778625  \n","Epoch:50/50     Step:2|6   loss:0.48574405908584595  \n","Epoch:50/50     Step:3|6   loss:0.485676109790802  \n","Epoch:50/50     Step:4|6   loss:0.48578792810440063  \n","Epoch:50/50     Step:5|6   loss:0.4856075048446655  \n","Epoch:50/50     Step:6|6   loss:0.4861736595630646  \n","Epoch:50/50     Step:7|6   loss:0.4861234128475189  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Accuracy on test_set: 90.65 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.2672748565673828  \n","Epoch:1/50     Step:2|6   loss:8.017406463623047  \n","Epoch:1/50     Step:3|6   loss:17.79593849182129  \n","Epoch:1/50     Step:4|6   loss:7.986302375793457  \n","Epoch:1/50     Step:5|6   loss:9.380435943603516  \n","Epoch:1/50     Step:6|6   loss:8.684015274047852  \n","Epoch:1/50     Step:7|6   loss:3.6529927253723145  \n","Accuracy on test_set: 27.10 %\n","Accuracy on train_set: 21.55 %\n","current max accuracy\t test set:27.1%\t train set:21.55%\n","Epoch:2/50     Step:1|6   loss:8.884056091308594  \n","Epoch:2/50     Step:2|6   loss:8.710445404052734  \n","Epoch:2/50     Step:3|6   loss:2.6313424110412598  \n","Epoch:2/50     Step:4|6   loss:1.9509061574935913  \n","Epoch:2/50     Step:5|6   loss:3.5301904678344727  \n","Epoch:2/50     Step:6|6   loss:3.9269907474517822  \n","Epoch:2/50     Step:7|6   loss:3.9410881996154785  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 49.88 %\n","current max accuracy\t test set:43.93%\t train set:49.88%\n","Epoch:3/50     Step:1|6   loss:3.500741481781006  \n","Epoch:3/50     Step:2|6   loss:3.9583804607391357  \n","Epoch:3/50     Step:3|6   loss:2.5858983993530273  \n","Epoch:3/50     Step:4|6   loss:2.190004587173462  \n","Epoch:3/50     Step:5|6   loss:2.1386260986328125  \n","Epoch:3/50     Step:6|6   loss:2.298434257507324  \n","Epoch:3/50     Step:7|6   loss:2.1007823944091797  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:84.11%\t train set:84.07%\n","Epoch:4/50     Step:1|6   loss:2.6809325218200684  \n","Epoch:4/50     Step:2|6   loss:2.783048629760742  \n","Epoch:4/50     Step:3|6   loss:2.981618642807007  \n","Epoch:4/50     Step:4|6   loss:3.0682544708251953  \n","Epoch:4/50     Step:5|6   loss:3.0007832050323486  \n","Epoch:4/50     Step:6|6   loss:2.4661829471588135  \n","Epoch:4/50     Step:7|6   loss:2.548424243927002  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:85.98%\t train set:87.82%\n","Epoch:5/50     Step:1|6   loss:2.1022276878356934  \n","Epoch:5/50     Step:2|6   loss:2.0647201538085938  \n","Epoch:5/50     Step:3|6   loss:2.0794034004211426  \n","Epoch:5/50     Step:4|6   loss:2.2295339107513428  \n","Epoch:5/50     Step:5|6   loss:1.8119562864303589  \n","Epoch:5/50     Step:6|6   loss:2.014634370803833  \n","Epoch:5/50     Step:7|6   loss:1.8294042348861694  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 80.09 %\n","current max accuracy\t test set:85.98%\t train set:87.82%\n","Epoch:6/50     Step:1|6   loss:1.7313549518585205  \n","Epoch:6/50     Step:2|6   loss:1.8597667217254639  \n","Epoch:6/50     Step:3|6   loss:1.7252411842346191  \n","Epoch:6/50     Step:4|6   loss:2.0265846252441406  \n","Epoch:6/50     Step:5|6   loss:1.5644268989562988  \n","Epoch:6/50     Step:6|6   loss:1.4053146839141846  \n","Epoch:6/50     Step:7|6   loss:1.520573377609253  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:93.46%\t train set:93.21%\n","Epoch:7/50     Step:1|6   loss:1.4676235914230347  \n","Epoch:7/50     Step:2|6   loss:1.4498369693756104  \n","Epoch:7/50     Step:3|6   loss:1.4727082252502441  \n","Epoch:7/50     Step:4|6   loss:1.4720791578292847  \n","Epoch:7/50     Step:5|6   loss:1.3370355367660522  \n","Epoch:7/50     Step:6|6   loss:1.2430742979049683  \n","Epoch:7/50     Step:7|6   loss:1.0629050731658936  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:96.26%\t train set:96.02%\n","Epoch:8/50     Step:1|6   loss:0.9929351210594177  \n","Epoch:8/50     Step:2|6   loss:1.102678894996643  \n","Epoch:8/50     Step:3|6   loss:1.0383830070495605  \n","Epoch:8/50     Step:4|6   loss:0.9193774461746216  \n","Epoch:8/50     Step:5|6   loss:0.8958103656768799  \n","Epoch:8/50     Step:6|6   loss:0.9567883014678955  \n","Epoch:8/50     Step:7|6   loss:0.771558403968811  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:9/50     Step:1|6   loss:0.804993748664856  \n","Epoch:9/50     Step:2|6   loss:0.7216978073120117  \n","Epoch:9/50     Step:3|6   loss:0.7515482306480408  \n","Epoch:9/50     Step:4|6   loss:0.7464792728424072  \n","Epoch:9/50     Step:5|6   loss:0.7378934621810913  \n","Epoch:9/50     Step:6|6   loss:0.644485354423523  \n","Epoch:9/50     Step:7|6   loss:0.6666475534439087  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:10/50     Step:1|6   loss:0.6875772476196289  \n","Epoch:10/50     Step:2|6   loss:0.5866566896438599  \n","Epoch:10/50     Step:3|6   loss:0.64244145154953  \n","Epoch:10/50     Step:4|6   loss:0.6165148615837097  \n","Epoch:10/50     Step:5|6   loss:0.5703603625297546  \n","Epoch:10/50     Step:6|6   loss:0.6639525294303894  \n","Epoch:10/50     Step:7|6   loss:0.5553662776947021  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:11/50     Step:1|6   loss:0.5509671568870544  \n","Epoch:11/50     Step:2|6   loss:0.5864819288253784  \n","Epoch:11/50     Step:3|6   loss:0.5479514598846436  \n","Epoch:11/50     Step:4|6   loss:0.555508017539978  \n","Epoch:11/50     Step:5|6   loss:0.5567620992660522  \n","Epoch:11/50     Step:6|6   loss:0.5278723239898682  \n","Epoch:11/50     Step:7|6   loss:0.5331431031227112  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:12/50     Step:1|6   loss:0.5350094437599182  \n","Epoch:12/50     Step:2|6   loss:0.5161165595054626  \n","Epoch:12/50     Step:3|6   loss:0.5455003380775452  \n","Epoch:12/50     Step:4|6   loss:0.5509293079376221  \n","Epoch:12/50     Step:5|6   loss:0.5378856062889099  \n","Epoch:12/50     Step:6|6   loss:0.5194075703620911  \n","Epoch:12/50     Step:7|6   loss:0.5160475969314575  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:13/50     Step:1|6   loss:0.5262610912322998  \n","Epoch:13/50     Step:2|6   loss:0.5468393564224243  \n","Epoch:13/50     Step:3|6   loss:0.5081630945205688  \n","Epoch:13/50     Step:4|6   loss:0.5175818800926208  \n","Epoch:13/50     Step:5|6   loss:0.5165584087371826  \n","Epoch:13/50     Step:6|6   loss:0.5094816088676453  \n","Epoch:13/50     Step:7|6   loss:0.5158360600471497  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5133470296859741  \n","Epoch:14/50     Step:2|6   loss:0.5073952674865723  \n","Epoch:14/50     Step:3|6   loss:0.5209746956825256  \n","Epoch:14/50     Step:4|6   loss:0.5047078132629395  \n","Epoch:14/50     Step:5|6   loss:0.5165013074874878  \n","Epoch:14/50     Step:6|6   loss:0.512052595615387  \n","Epoch:14/50     Step:7|6   loss:0.4979175925254822  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.5157373547554016  \n","Epoch:15/50     Step:2|6   loss:0.5006045699119568  \n","Epoch:15/50     Step:3|6   loss:0.5096705555915833  \n","Epoch:15/50     Step:4|6   loss:0.5088496208190918  \n","Epoch:15/50     Step:5|6   loss:0.5046380162239075  \n","Epoch:15/50     Step:6|6   loss:0.5127488970756531  \n","Epoch:15/50     Step:7|6   loss:0.49763423204421997  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.49959662556648254  \n","Epoch:16/50     Step:2|6   loss:0.5047034621238708  \n","Epoch:16/50     Step:3|6   loss:0.4984511137008667  \n","Epoch:16/50     Step:4|6   loss:0.5093929171562195  \n","Epoch:16/50     Step:5|6   loss:0.5010954141616821  \n","Epoch:16/50     Step:6|6   loss:0.5012118816375732  \n","Epoch:16/50     Step:7|6   loss:0.5077966451644897  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.49266576766967773  \n","Epoch:17/50     Step:2|6   loss:0.5072636604309082  \n","Epoch:17/50     Step:3|6   loss:0.4952227473258972  \n","Epoch:17/50     Step:4|6   loss:0.5013003349304199  \n","Epoch:17/50     Step:5|6   loss:0.5002879500389099  \n","Epoch:17/50     Step:6|6   loss:0.4952196478843689  \n","Epoch:17/50     Step:7|6   loss:0.5087645053863525  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.49407076835632324  \n","Epoch:18/50     Step:2|6   loss:0.4951990246772766  \n","Epoch:18/50     Step:3|6   loss:0.49748313426971436  \n","Epoch:18/50     Step:4|6   loss:0.4947638213634491  \n","Epoch:18/50     Step:5|6   loss:0.49704450368881226  \n","Epoch:18/50     Step:6|6   loss:0.5003366470336914  \n","Epoch:18/50     Step:7|6   loss:0.4956750273704529  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4955728352069855  \n","Epoch:19/50     Step:2|6   loss:0.4973706901073456  \n","Epoch:19/50     Step:3|6   loss:0.4942176640033722  \n","Epoch:19/50     Step:4|6   loss:0.49352800846099854  \n","Epoch:19/50     Step:5|6   loss:0.4928698241710663  \n","Epoch:19/50     Step:6|6   loss:0.4941326677799225  \n","Epoch:19/50     Step:7|6   loss:0.49177685379981995  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49557656049728394  \n","Epoch:20/50     Step:2|6   loss:0.49385231733322144  \n","Epoch:20/50     Step:3|6   loss:0.4933255910873413  \n","Epoch:20/50     Step:4|6   loss:0.4946369528770447  \n","Epoch:20/50     Step:5|6   loss:0.49539411067962646  \n","Epoch:20/50     Step:6|6   loss:0.4905744194984436  \n","Epoch:20/50     Step:7|6   loss:0.4904550313949585  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4918115735054016  \n","Epoch:21/50     Step:2|6   loss:0.493069052696228  \n","Epoch:21/50     Step:3|6   loss:0.4906434416770935  \n","Epoch:21/50     Step:4|6   loss:0.49432963132858276  \n","Epoch:21/50     Step:5|6   loss:0.49258914589881897  \n","Epoch:21/50     Step:6|6   loss:0.492429256439209  \n","Epoch:21/50     Step:7|6   loss:0.4909176826477051  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.49486005306243896  \n","Epoch:22/50     Step:2|6   loss:0.49097973108291626  \n","Epoch:22/50     Step:3|6   loss:0.4903547167778015  \n","Epoch:22/50     Step:4|6   loss:0.49121978878974915  \n","Epoch:22/50     Step:5|6   loss:0.49328121542930603  \n","Epoch:22/50     Step:6|6   loss:0.4911077618598938  \n","Epoch:22/50     Step:7|6   loss:0.4928509593009949  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.4920077919960022  \n","Epoch:23/50     Step:2|6   loss:0.49156033992767334  \n","Epoch:23/50     Step:3|6   loss:0.4918934106826782  \n","Epoch:23/50     Step:4|6   loss:0.49210458993911743  \n","Epoch:23/50     Step:5|6   loss:0.4910709857940674  \n","Epoch:23/50     Step:6|6   loss:0.4916905462741852  \n","Epoch:23/50     Step:7|6   loss:0.48911651968955994  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4924927353858948  \n","Epoch:24/50     Step:2|6   loss:0.48812171816825867  \n","Epoch:24/50     Step:3|6   loss:0.4906235933303833  \n","Epoch:24/50     Step:4|6   loss:0.48903366923332214  \n","Epoch:24/50     Step:5|6   loss:0.4901919662952423  \n","Epoch:24/50     Step:6|6   loss:0.49214446544647217  \n","Epoch:24/50     Step:7|6   loss:0.49043628573417664  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.4898488521575928  \n","Epoch:25/50     Step:2|6   loss:0.488613486289978  \n","Epoch:25/50     Step:3|6   loss:0.4887033700942993  \n","Epoch:25/50     Step:4|6   loss:0.4890800714492798  \n","Epoch:25/50     Step:5|6   loss:0.4936867952346802  \n","Epoch:25/50     Step:6|6   loss:0.4885534942150116  \n","Epoch:25/50     Step:7|6   loss:0.4893261790275574  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.4887697994709015  \n","Epoch:26/50     Step:2|6   loss:0.4889422655105591  \n","Epoch:26/50     Step:3|6   loss:0.4898524880409241  \n","Epoch:26/50     Step:4|6   loss:0.4899853467941284  \n","Epoch:26/50     Step:5|6   loss:0.4910427927970886  \n","Epoch:26/50     Step:6|6   loss:0.4894726872444153  \n","Epoch:26/50     Step:7|6   loss:0.4890066683292389  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4892471134662628  \n","Epoch:27/50     Step:2|6   loss:0.4895915687084198  \n","Epoch:27/50     Step:3|6   loss:0.4928426742553711  \n","Epoch:27/50     Step:4|6   loss:0.48774465918540955  \n","Epoch:27/50     Step:5|6   loss:0.48859596252441406  \n","Epoch:27/50     Step:6|6   loss:0.4891481101512909  \n","Epoch:27/50     Step:7|6   loss:0.4872111678123474  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48798811435699463  \n","Epoch:28/50     Step:2|6   loss:0.48801207542419434  \n","Epoch:28/50     Step:3|6   loss:0.4879942238330841  \n","Epoch:28/50     Step:4|6   loss:0.48760512471199036  \n","Epoch:28/50     Step:5|6   loss:0.4907780587673187  \n","Epoch:28/50     Step:6|6   loss:0.4878179728984833  \n","Epoch:28/50     Step:7|6   loss:0.4907715320587158  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4897735118865967  \n","Epoch:29/50     Step:2|6   loss:0.48837700486183167  \n","Epoch:29/50     Step:3|6   loss:0.4885932207107544  \n","Epoch:29/50     Step:4|6   loss:0.48853591084480286  \n","Epoch:29/50     Step:5|6   loss:0.4891260862350464  \n","Epoch:29/50     Step:6|6   loss:0.48867088556289673  \n","Epoch:29/50     Step:7|6   loss:0.48734134435653687  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.48958858847618103  \n","Epoch:30/50     Step:2|6   loss:0.4878145754337311  \n","Epoch:30/50     Step:3|6   loss:0.48827749490737915  \n","Epoch:30/50     Step:4|6   loss:0.489030659198761  \n","Epoch:30/50     Step:5|6   loss:0.48812419176101685  \n","Epoch:30/50     Step:6|6   loss:0.48990654945373535  \n","Epoch:30/50     Step:7|6   loss:0.48736563324928284  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.488840788602829  \n","Epoch:31/50     Step:2|6   loss:0.48727914690971375  \n","Epoch:31/50     Step:3|6   loss:0.48830294609069824  \n","Epoch:31/50     Step:4|6   loss:0.48736637830734253  \n","Epoch:31/50     Step:5|6   loss:0.48807695508003235  \n","Epoch:31/50     Step:6|6   loss:0.4875926673412323  \n","Epoch:31/50     Step:7|6   loss:0.48954981565475464  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4879895746707916  \n","Epoch:32/50     Step:2|6   loss:0.4869316816329956  \n","Epoch:32/50     Step:3|6   loss:0.4914771318435669  \n","Epoch:32/50     Step:4|6   loss:0.48788949847221375  \n","Epoch:32/50     Step:5|6   loss:0.4890819191932678  \n","Epoch:32/50     Step:6|6   loss:0.48747774958610535  2\n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:32/50     Step:7|6   loss:0.48955559730529785  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48786479234695435  \n","Epoch:33/50     Step:2|6   loss:0.4890521168708801  \n","Epoch:33/50     Step:3|6   loss:0.4874398410320282  \n","Epoch:33/50     Step:4|6   loss:0.4899898171424866  \n","Epoch:33/50     Step:5|6   loss:0.486592561006546  \n","Epoch:33/50     Step:6|6   loss:0.4897388815879822  \n","Epoch:33/50     Step:7|6   loss:0.4877936840057373  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.49076294898986816  \n","Epoch:34/50     Step:2|6   loss:0.4885694682598114  \n","Epoch:34/50     Step:3|6   loss:0.4888421297073364  \n","Epoch:34/50     Step:4|6   loss:0.48859700560569763  \n","Epoch:34/50     Step:5|6   loss:0.4900091290473938  \n","Epoch:34/50     Step:6|6   loss:0.487346351146698  \n","Epoch:34/50     Step:7|6   loss:0.48834028840065  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4887414574623108  \n","Epoch:35/50     Step:2|6   loss:0.48949486017227173  \n","Epoch:35/50     Step:3|6   loss:0.48737412691116333  \n","Epoch:35/50     Step:4|6   loss:0.4915565848350525  \n","Epoch:35/50     Step:5|6   loss:0.48674026131629944  \n","Epoch:35/50     Step:6|6   loss:0.49108317494392395  \n","Epoch:35/50     Step:7|6   loss:0.4869751036167145  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4911811947822571  \n","Epoch:36/50     Step:2|6   loss:0.48783499002456665  \n","Epoch:36/50     Step:3|6   loss:0.48988044261932373  \n","Epoch:36/50     Step:4|6   loss:0.48842573165893555  \n","Epoch:36/50     Step:5|6   loss:0.49159640073776245  \n","Epoch:36/50     Step:6|6   loss:0.4863702654838562  \n","Epoch:36/50     Step:7|6   loss:0.4879230260848999  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.488046258687973  \n","Epoch:37/50     Step:2|6   loss:0.48937129974365234  \n","Epoch:37/50     Step:3|6   loss:0.48728621006011963  \n","Epoch:37/50     Step:4|6   loss:0.48892804980278015  \n","Epoch:37/50     Step:5|6   loss:0.48967814445495605  \n","Epoch:37/50     Step:6|6   loss:0.4876357614994049  \n","Epoch:37/50     Step:7|6   loss:0.4888139069080353  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4904313087463379  \n","Epoch:38/50     Step:2|6   loss:0.48665401339530945  \n","Epoch:38/50     Step:3|6   loss:0.48893609642982483  \n","Epoch:38/50     Step:4|6   loss:0.4868027865886688  \n","Epoch:38/50     Step:5|6   loss:0.48807385563850403  \n","Epoch:38/50     Step:6|6   loss:0.48752355575561523  \n","Epoch:38/50     Step:7|6   loss:0.48840874433517456  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4885794222354889  \n","Epoch:39/50     Step:2|6   loss:0.4865134656429291  \n","Epoch:39/50     Step:3|6   loss:0.4887621998786926  \n","Epoch:39/50     Step:4|6   loss:0.48646119236946106  \n","Epoch:39/50     Step:5|6   loss:0.4881359338760376  \n","Epoch:39/50     Step:6|6   loss:0.4886070787906647  \n","Epoch:39/50     Step:7|6   loss:0.4884399175643921  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.4874557852745056  \n","Epoch:40/50     Step:2|6   loss:0.488760769367218  \n","Epoch:40/50     Step:3|6   loss:0.487648069858551  \n","Epoch:40/50     Step:4|6   loss:0.48751556873321533  \n","Epoch:40/50     Step:5|6   loss:0.4888119697570801  \n","Epoch:40/50     Step:6|6   loss:0.4868614375591278  \n","Epoch:40/50     Step:7|6   loss:0.48696866631507874  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.48664405941963196  \n","Epoch:41/50     Step:2|6   loss:0.4863996207714081  \n","Epoch:41/50     Step:3|6   loss:0.4867134690284729  \n","Epoch:41/50     Step:4|6   loss:0.488170862197876  \n","Epoch:41/50     Step:5|6   loss:0.48647934198379517  \n","Epoch:41/50     Step:6|6   loss:0.4864216446876526  \n","Epoch:41/50     Step:7|6   loss:0.48675355315208435  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48662176728248596  \n","Epoch:42/50     Step:2|6   loss:0.4860268235206604  \n","Epoch:42/50     Step:3|6   loss:0.4874400496482849  \n","Epoch:42/50     Step:4|6   loss:0.48782411217689514  \n","Epoch:42/50     Step:5|6   loss:0.48892179131507874  \n","Epoch:42/50     Step:6|6   loss:0.486873596906662  \n","Epoch:42/50     Step:7|6   loss:0.4886215031147003  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4892466068267822  \n","Epoch:43/50     Step:2|6   loss:0.4866614043712616  \n","Epoch:43/50     Step:3|6   loss:0.48866552114486694  \n","Epoch:43/50     Step:4|6   loss:0.4885041117668152  \n","Epoch:43/50     Step:5|6   loss:0.48970934748649597  \n","Epoch:43/50     Step:6|6   loss:0.49136286973953247  \n","Epoch:43/50     Step:7|6   loss:0.4866381287574768  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48820289969444275  \n","Epoch:44/50     Step:2|6   loss:0.48946499824523926  \n","Epoch:44/50     Step:3|6   loss:0.487081378698349  \n","Epoch:44/50     Step:4|6   loss:0.48981285095214844  \n","Epoch:44/50     Step:5|6   loss:0.4876343905925751  \n","Epoch:44/50     Step:6|6   loss:0.4888893961906433  \n","Epoch:44/50     Step:7|6   loss:0.4898473024368286  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.48607489466667175  \n","Epoch:45/50     Step:2|6   loss:0.4888489544391632  \n","Epoch:45/50     Step:3|6   loss:0.486753910779953  \n","Epoch:45/50     Step:4|6   loss:0.48657241463661194  \n","Epoch:45/50     Step:5|6   loss:0.48843955993652344  \n","Epoch:45/50     Step:6|6   loss:0.48752957582473755  \n","Epoch:45/50     Step:7|6   loss:0.4878961443901062  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.48778611421585083  \n","Epoch:46/50     Step:2|6   loss:0.4870474338531494  \n","Epoch:46/50     Step:3|6   loss:0.48900306224823  \n","Epoch:46/50     Step:4|6   loss:0.48734036087989807  \n","Epoch:46/50     Step:5|6   loss:0.4879905581474304  \n","Epoch:46/50     Step:6|6   loss:0.48866337537765503  \n","Epoch:46/50     Step:7|6   loss:0.4863406717777252  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4876885414123535  \n","Epoch:47/50     Step:2|6   loss:0.48782026767730713  \n","Epoch:47/50     Step:3|6   loss:0.4878789484500885  \n","Epoch:47/50     Step:4|6   loss:0.48719727993011475  \n","Epoch:47/50     Step:5|6   loss:0.486476331949234  \n","Epoch:47/50     Step:6|6   loss:0.48729127645492554  \n","Epoch:47/50     Step:7|6   loss:0.4860139489173889  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.48783665895462036  \n","Epoch:48/50     Step:2|6   loss:0.4870181679725647  \n","Epoch:48/50     Step:3|6   loss:0.4857797622680664  \n","Epoch:48/50     Step:4|6   loss:0.4881659150123596  \n","Epoch:48/50     Step:5|6   loss:0.4887237250804901  \n","Epoch:48/50     Step:6|6   loss:0.48617222905158997  \n","Epoch:48/50     Step:7|6   loss:0.48704540729522705  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48795002698898315  \n","Epoch:49/50     Step:2|6   loss:0.4860139489173889  \n","Epoch:49/50     Step:3|6   loss:0.4874826967716217  \n","Epoch:49/50     Step:4|6   loss:0.4874650537967682  \n","Epoch:49/50     Step:5|6   loss:0.4864696264266968  \n","Epoch:49/50     Step:6|6   loss:0.48783785104751587  \n","Epoch:49/50     Step:7|6   loss:0.4864359200000763  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4892008304595947  \n","Epoch:50/50     Step:2|6   loss:0.48734980821609497  \n","Epoch:50/50     Step:3|6   loss:0.48616576194763184  \n","Epoch:50/50     Step:4|6   loss:0.48893117904663086  \n","Epoch:50/50     Step:5|6   loss:0.4874747693538666  \n","Epoch:50/50     Step:6|6   loss:0.4859895408153534  \n","Epoch:50/50     Step:7|6   loss:0.48908114433288574  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Accuracy on test_set: 97.20 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.112810730934143  \n","Epoch:1/50     Step:2|6   loss:10.174617767333984  \n","Epoch:1/50     Step:3|6   loss:8.419188499450684  \n","Epoch:1/50     Step:4|6   loss:6.040824890136719  \n","Epoch:1/50     Step:5|6   loss:6.8139848709106445  \n","Epoch:1/50     Step:6|6   loss:5.014128684997559  \n","Epoch:1/50     Step:7|6   loss:1.2800811529159546  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 80.33 %\n","current max accuracy\t test set:72.9%\t train set:80.33%\n","Epoch:2/50     Step:1|6   loss:2.0150036811828613  \n","Epoch:2/50     Step:2|6   loss:2.4651007652282715  \n","Epoch:2/50     Step:3|6   loss:2.521110773086548  \n","Epoch:2/50     Step:4|6   loss:3.7592544555664062  \n","Epoch:2/50     Step:5|6   loss:3.6427536010742188  \n","Epoch:2/50     Step:6|6   loss:3.192934513092041  \n","Epoch:2/50     Step:7|6   loss:3.4582407474517822  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:72.9%\t train set:83.37%\n","Epoch:3/50     Step:1|6   loss:2.6852798461914062  \n","Epoch:3/50     Step:2|6   loss:1.940295934677124  \n","Epoch:3/50     Step:3|6   loss:1.6705259084701538  \n","Epoch:3/50     Step:4|6   loss:1.511634349822998  \n","Epoch:3/50     Step:5|6   loss:1.9054330587387085  \n","Epoch:3/50     Step:6|6   loss:2.6656124591827393  \n","Epoch:3/50     Step:7|6   loss:2.4652583599090576  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 66.74 %\n","current max accuracy\t test set:72.9%\t train set:83.37%\n","Epoch:4/50     Step:1|6   loss:2.0403554439544678  \n","Epoch:4/50     Step:2|6   loss:2.278860569000244  \n","Epoch:4/50     Step:3|6   loss:1.6398351192474365  \n","Epoch:4/50     Step:4|6   loss:2.2801594734191895  \n","Epoch:4/50     Step:5|6   loss:1.7063229084014893  \n","Epoch:4/50     Step:6|6   loss:1.9005446434020996  \n","Epoch:4/50     Step:7|6   loss:2.060420036315918  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:85.98%\t train set:91.33%\n","Epoch:5/50     Step:1|6   loss:1.7121466398239136  \n","Epoch:5/50     Step:2|6   loss:1.6697415113449097  \n","Epoch:5/50     Step:3|6   loss:1.8170077800750732  \n","Epoch:5/50     Step:4|6   loss:1.780880331993103  \n","Epoch:5/50     Step:5|6   loss:1.6480690240859985  \n","Epoch:5/50     Step:6|6   loss:1.6570818424224854  \n","Epoch:5/50     Step:7|6   loss:1.6519172191619873  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:85.98%\t train set:91.33%\n","Epoch:6/50     Step:1|6   loss:1.6252551078796387  \n","Epoch:6/50     Step:2|6   loss:1.4934940338134766  \n","Epoch:6/50     Step:3|6   loss:1.2046583890914917  \n","Epoch:6/50     Step:4|6   loss:1.2559294700622559  \n","Epoch:6/50     Step:5|6   loss:1.2343876361846924  \n","Epoch:6/50     Step:6|6   loss:1.0817943811416626  \n","Epoch:6/50     Step:7|6   loss:1.314731478691101  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:85.98%\t train set:94.61%\n","Epoch:7/50     Step:1|6   loss:1.067291021347046  \n","Epoch:7/50     Step:2|6   loss:0.9268592596054077  \n","Epoch:7/50     Step:3|6   loss:0.872236430644989  \n","Epoch:7/50     Step:4|6   loss:0.9411664009094238  \n","Epoch:7/50     Step:5|6   loss:0.8223150968551636  \n","Epoch:7/50     Step:6|6   loss:0.7921538949012756  \n","Epoch:7/50     Step:7|6   loss:0.7296065092086792  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:92.52%\t train set:98.13%\n","Epoch:8/50     Step:1|6   loss:0.7219208478927612  \n","Epoch:8/50     Step:2|6   loss:0.7156689167022705  \n","Epoch:8/50     Step:3|6   loss:0.7223182916641235  \n","Epoch:8/50     Step:4|6   loss:0.683506190776825  \n","Epoch:8/50     Step:5|6   loss:0.7390395402908325  \n","Epoch:8/50     Step:6|6   loss:0.650021493434906  \n","Epoch:8/50     Step:7|6   loss:0.7529412508010864  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:96.26%\t train set:99.53%\n","Epoch:9/50     Step:1|6   loss:0.5650882720947266  \n","Epoch:9/50     Step:2|6   loss:0.6614353656768799  \n","Epoch:9/50     Step:3|6   loss:0.6145073175430298  \n","Epoch:9/50     Step:4|6   loss:0.619820773601532  \n","Epoch:9/50     Step:5|6   loss:0.637432336807251  \n","Epoch:9/50     Step:6|6   loss:0.5958119630813599  \n","Epoch:9/50     Step:7|6   loss:0.6347858905792236  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:96.26%\t train set:99.53%\n","Epoch:10/50     Step:1|6   loss:0.6545854806900024  \n","Epoch:10/50     Step:2|6   loss:0.6095023155212402  \n","Epoch:10/50     Step:3|6   loss:0.6777291297912598  \n","Epoch:10/50     Step:4|6   loss:0.5748761296272278  \n","Epoch:10/50     Step:5|6   loss:0.6097749471664429  \n","Epoch:10/50     Step:6|6   loss:0.5651447176933289  \n","Epoch:10/50     Step:7|6   loss:0.5483102798461914  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:11/50     Step:1|6   loss:0.5806230902671814  \n","Epoch:11/50     Step:2|6   loss:0.6033958792686462  \n","Epoch:11/50     Step:3|6   loss:0.5644237399101257  \n","Epoch:11/50     Step:4|6   loss:0.5503652095794678  \n","Epoch:11/50     Step:5|6   loss:0.6409715414047241  \n","Epoch:11/50     Step:6|6   loss:0.5267648100852966  \n","Epoch:11/50     Step:7|6   loss:0.6275668740272522  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:12/50     Step:1|6   loss:0.5630955696105957  \n","Epoch:12/50     Step:2|6   loss:0.5399050712585449  \n","Epoch:12/50     Step:3|6   loss:0.564509391784668  \n","Epoch:12/50     Step:4|6   loss:0.5347124338150024  \n","Epoch:12/50     Step:5|6   loss:0.5279442071914673  \n","Epoch:12/50     Step:6|6   loss:0.567584753036499  \n","Epoch:12/50     Step:7|6   loss:0.5109636187553406  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.542461097240448  \n","Epoch:13/50     Step:2|6   loss:0.5359225869178772  \n","Epoch:13/50     Step:3|6   loss:0.5125082731246948  \n","Epoch:13/50     Step:4|6   loss:0.5256123542785645  \n","Epoch:13/50     Step:5|6   loss:0.518861711025238  \n","Epoch:13/50     Step:6|6   loss:0.5146639347076416  \n","Epoch:13/50     Step:7|6   loss:0.5286017656326294  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5012238025665283  \n","Epoch:14/50     Step:2|6   loss:0.5254660844802856  \n","Epoch:14/50     Step:3|6   loss:0.499744176864624  \n","Epoch:14/50     Step:4|6   loss:0.5092978477478027  \n","Epoch:14/50     Step:5|6   loss:0.5187069773674011  \n","Epoch:14/50     Step:6|6   loss:0.5116361379623413  \n","Epoch:14/50     Step:7|6   loss:0.512111246585846  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.5104917883872986  \n","Epoch:15/50     Step:2|6   loss:0.5024970173835754  \n","Epoch:15/50     Step:3|6   loss:0.5100550651550293  \n","Epoch:15/50     Step:4|6   loss:0.5042479038238525  \n","Epoch:15/50     Step:5|6   loss:0.5097740888595581  \n","Epoch:15/50     Step:6|6   loss:0.5057989358901978  \n","Epoch:15/50     Step:7|6   loss:0.5086503624916077  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.5023317933082581  \n","Epoch:16/50     Step:2|6   loss:0.5022045969963074  \n","Epoch:16/50     Step:3|6   loss:0.5039227604866028  \n","Epoch:16/50     Step:4|6   loss:0.49590396881103516  \n","Epoch:16/50     Step:5|6   loss:0.5041511058807373  \n","Epoch:16/50     Step:6|6   loss:0.4959426522254944  \n","Epoch:16/50     Step:7|6   loss:0.5032084584236145  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.4937657415866852  \n","Epoch:17/50     Step:2|6   loss:0.4970835745334625  \n","Epoch:17/50     Step:3|6   loss:0.4975993037223816  \n","Epoch:17/50     Step:4|6   loss:0.4941936135292053  \n","Epoch:17/50     Step:5|6   loss:0.5015690326690674  \n","Epoch:17/50     Step:6|6   loss:0.49591824412345886  \n","Epoch:17/50     Step:7|6   loss:0.495529443025589  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.4929881691932678  \n","Epoch:18/50     Step:2|6   loss:0.5011671781539917  \n","Epoch:18/50     Step:3|6   loss:0.4926638603210449  \n","Epoch:18/50     Step:4|6   loss:0.4923706352710724  \n","Epoch:18/50     Step:5|6   loss:0.4930725693702698  \n","Epoch:18/50     Step:6|6   loss:0.49453651905059814  \n","Epoch:18/50     Step:7|6   loss:0.49204176664352417  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.49467146396636963  \n","Epoch:19/50     Step:2|6   loss:0.49071550369262695  \n","Epoch:19/50     Step:3|6   loss:0.49387824535369873  \n","Epoch:19/50     Step:4|6   loss:0.49049344658851624  \n","Epoch:19/50     Step:5|6   loss:0.49096864461898804  \n","Epoch:19/50     Step:6|6   loss:0.4913058578968048  \n","Epoch:19/50     Step:7|6   loss:0.4904348850250244  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.4902385473251343  \n","Epoch:20/50     Step:2|6   loss:0.489626944065094  \n","Epoch:20/50     Step:3|6   loss:0.4912145733833313  \n","Epoch:20/50     Step:4|6   loss:0.4901729226112366  \n","Epoch:20/50     Step:5|6   loss:0.4905100166797638  \n","Epoch:20/50     Step:6|6   loss:0.4893566370010376  \n","Epoch:20/50     Step:7|6   loss:0.49106964468955994  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4921409487724304  \n","Epoch:21/50     Step:2|6   loss:0.4913039207458496  \n","Epoch:21/50     Step:3|6   loss:0.4893721342086792  \n","Epoch:21/50     Step:4|6   loss:0.48927316069602966  \n","Epoch:21/50     Step:5|6   loss:0.4905332326889038  \n","Epoch:21/50     Step:6|6   loss:0.49004361033439636  \n","Epoch:21/50     Step:7|6   loss:0.4894757866859436  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.4886472225189209  \n","Epoch:22/50     Step:2|6   loss:0.489358514547348  \n","Epoch:22/50     Step:3|6   loss:0.4891817271709442  \n","Epoch:22/50     Step:4|6   loss:0.49122488498687744  \n","Epoch:22/50     Step:5|6   loss:0.49124619364738464  \n","Epoch:22/50     Step:6|6   loss:0.49097251892089844  \n","Epoch:22/50     Step:7|6   loss:0.48894813656806946  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.4923248589038849  \n","Epoch:23/50     Step:2|6   loss:0.48931723833084106  \n","Epoch:23/50     Step:3|6   loss:0.49296873807907104  \n","Epoch:23/50     Step:4|6   loss:0.4895009398460388  \n","Epoch:23/50     Step:5|6   loss:0.4957646429538727  \n","Epoch:23/50     Step:6|6   loss:0.4897652566432953  \n","Epoch:23/50     Step:7|6   loss:0.4894295334815979  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4887433648109436  \n","Epoch:24/50     Step:2|6   loss:0.4906708896160126  \n","Epoch:24/50     Step:3|6   loss:0.49202972650527954  \n","Epoch:24/50     Step:4|6   loss:0.49060267210006714  \n","Epoch:24/50     Step:5|6   loss:0.4894780218601227  \n","Epoch:24/50     Step:6|6   loss:0.4897605776786804  \n","Epoch:24/50     Step:7|6   loss:0.4880175292491913  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.48967382311820984  \n","Epoch:25/50     Step:2|6   loss:0.4887281358242035  \n","Epoch:25/50     Step:3|6   loss:0.48931923508644104  \n","Epoch:25/50     Step:4|6   loss:0.4884495139122009  \n","Epoch:25/50     Step:5|6   loss:0.4882785379886627  \n","Epoch:25/50     Step:6|6   loss:0.48811790347099304  \n","Epoch:25/50     Step:7|6   loss:0.48847952485084534  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48795533180236816  \n","Epoch:26/50     Step:2|6   loss:0.4873742461204529  \n","Epoch:26/50     Step:3|6   loss:0.4880027770996094  \n","Epoch:26/50     Step:4|6   loss:0.4876992702484131  \n","Epoch:26/50     Step:5|6   loss:0.48841384053230286  \n","Epoch:26/50     Step:6|6   loss:0.4876049757003784  \n","Epoch:26/50     Step:7|6   loss:0.4874262809753418  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4873712658882141  \n","Epoch:27/50     Step:2|6   loss:0.4877944886684418  \n","Epoch:27/50     Step:3|6   loss:0.4873564839363098  \n","Epoch:27/50     Step:4|6   loss:0.4877653419971466  \n","Epoch:27/50     Step:5|6   loss:0.4874805212020874  \n","Epoch:27/50     Step:6|6   loss:0.48741504549980164  \n","Epoch:27/50     Step:7|6   loss:0.4887523651123047  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48762109875679016  \n","Epoch:28/50     Step:2|6   loss:0.48774293065071106  \n","Epoch:28/50     Step:3|6   loss:0.489231139421463  \n","Epoch:28/50     Step:4|6   loss:0.4873329699039459  \n","Epoch:28/50     Step:5|6   loss:0.4881279468536377  \n","Epoch:28/50     Step:6|6   loss:0.4869215786457062  \n","Epoch:28/50     Step:7|6   loss:0.48824378848075867  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4875757396221161  \n","Epoch:29/50     Step:2|6   loss:0.48778319358825684  \n","Epoch:29/50     Step:3|6   loss:0.4878401458263397  \n","Epoch:29/50     Step:4|6   loss:0.487414687871933  \n","Epoch:29/50     Step:5|6   loss:0.4882185459136963  \n","Epoch:29/50     Step:6|6   loss:0.48739781975746155  \n","Epoch:29/50     Step:7|6   loss:0.4867394268512726  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4873546063899994  \n","Epoch:30/50     Step:2|6   loss:0.4876476228237152  \n","Epoch:30/50     Step:3|6   loss:0.4872596561908722  \n","Epoch:30/50     Step:4|6   loss:0.48665651679039  \n","Epoch:30/50     Step:5|6   loss:0.48753613233566284  \n","Epoch:30/50     Step:6|6   loss:0.4874921143054962  \n","Epoch:30/50     Step:7|6   loss:0.48655590415000916  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48664283752441406  \n","Epoch:31/50     Step:2|6   loss:0.4876345694065094  \n","Epoch:31/50     Step:3|6   loss:0.4865086078643799  \n","Epoch:31/50     Step:4|6   loss:0.4882814884185791  \n","Epoch:31/50     Step:5|6   loss:0.48751726746559143  \n","Epoch:31/50     Step:6|6   loss:0.4863993525505066  \n","Epoch:31/50     Step:7|6   loss:0.4874188303947449  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4873996675014496  \n","Epoch:32/50     Step:2|6   loss:0.488443523645401  \n","Epoch:32/50     Step:3|6   loss:0.48648566007614136  \n","Epoch:32/50     Step:4|6   loss:0.4891378879547119  \n","Epoch:32/50     Step:5|6   loss:0.4864990711212158  \n","Epoch:32/50     Step:6|6   loss:0.48814478516578674  \n","Epoch:32/50     Step:7|6   loss:0.48648515343666077  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4875476658344269  \n","Epoch:33/50     Step:2|6   loss:0.4866405427455902  \n","Epoch:33/50     Step:3|6   loss:0.4877983331680298  \n","Epoch:33/50     Step:4|6   loss:0.4865206480026245  \n","Epoch:33/50     Step:5|6   loss:0.4873103201389313  \n","Epoch:33/50     Step:6|6   loss:0.48648250102996826  \n","Epoch:33/50     Step:7|6   loss:0.4869620203971863  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4868272542953491  \n","Epoch:34/50     Step:2|6   loss:0.48632699251174927  \n","Epoch:34/50     Step:3|6   loss:0.48692262172698975  \n","Epoch:34/50     Step:4|6   loss:0.4864409863948822  \n","Epoch:34/50     Step:5|6   loss:0.4864586293697357  \n","Epoch:34/50     Step:6|6   loss:0.48626264929771423  \n","Epoch:34/50     Step:7|6   loss:0.4870249629020691  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.48694899678230286  \n","Epoch:35/50     Step:2|6   loss:0.48680537939071655  \n","Epoch:35/50     Step:3|6   loss:0.48592981696128845  \n","Epoch:35/50     Step:4|6   loss:0.486259400844574  \n","Epoch:35/50     Step:5|6   loss:0.4862874150276184  \n","Epoch:35/50     Step:6|6   loss:0.4867296516895294  \n","Epoch:35/50     Step:7|6   loss:0.4868437945842743  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4860040545463562  \n","Epoch:36/50     Step:2|6   loss:0.48627156019210815  \n","Epoch:36/50     Step:3|6   loss:0.48627594113349915  \n","Epoch:36/50     Step:4|6   loss:0.4867227375507355  \n","Epoch:36/50     Step:5|6   loss:0.48656970262527466  \n","Epoch:36/50     Step:6|6   loss:0.48618608713150024  \n","Epoch:36/50     Step:7|6   loss:0.48714596033096313  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4862128794193268  \n","Epoch:37/50     Step:2|6   loss:0.48614561557769775  \n","Epoch:37/50     Step:3|6   loss:0.48640531301498413  \n","Epoch:37/50     Step:4|6   loss:0.4858541786670685  \n","Epoch:37/50     Step:5|6   loss:0.48626863956451416  \n","Epoch:37/50     Step:6|6   loss:0.48589733242988586  \n","Epoch:37/50     Step:7|6   loss:0.48597025871276855  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4863249957561493  \n","Epoch:38/50     Step:2|6   loss:0.48605862259864807  \n","Epoch:38/50     Step:3|6   loss:0.4862961769104004  \n","Epoch:38/50     Step:4|6   loss:0.48674875497817993  \n","Epoch:38/50     Step:5|6   loss:0.48598724603652954  \n","Epoch:38/50     Step:6|6   loss:0.4868459701538086  \n","Epoch:38/50     Step:7|6   loss:0.4870679974555969  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.486040860414505  \n","Epoch:39/50     Step:2|6   loss:0.4863983392715454  \n","Epoch:39/50     Step:3|6   loss:0.48722970485687256  \n","Epoch:39/50     Step:4|6   loss:0.48650670051574707  \n","Epoch:39/50     Step:5|6   loss:0.4867388606071472  \n","Epoch:39/50     Step:6|6   loss:0.48695865273475647  \n","Epoch:39/50     Step:7|6   loss:0.4859515428543091  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48691004514694214  \n","Epoch:40/50     Step:2|6   loss:0.4860520660877228  \n","Epoch:40/50     Step:3|6   loss:0.48609691858291626  \n","Epoch:40/50     Step:4|6   loss:0.4863473176956177  \n","Epoch:40/50     Step:5|6   loss:0.48587363958358765  \n","Epoch:40/50     Step:6|6   loss:0.4861906170845032  \n","Epoch:40/50     Step:7|6   loss:0.4857073128223419  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4859654903411865  \n","Epoch:41/50     Step:2|6   loss:0.4862118065357208  \n","Epoch:41/50     Step:3|6   loss:0.48623982071876526  \n","Epoch:41/50     Step:4|6   loss:0.48618486523628235  \n","Epoch:41/50     Step:5|6   loss:0.4856659770011902  \n","Epoch:41/50     Step:6|6   loss:0.486186683177948  \n","Epoch:41/50     Step:7|6   loss:0.4859413504600525  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4862770438194275  \n","Epoch:42/50     Step:2|6   loss:0.486524373292923  \n","Epoch:42/50     Step:3|6   loss:0.4860709011554718  \n","Epoch:42/50     Step:4|6   loss:0.4870592951774597  \n","Epoch:42/50     Step:5|6   loss:0.48599934577941895  \n","Epoch:42/50     Step:6|6   loss:0.4860512614250183  \n","Epoch:42/50     Step:7|6   loss:0.4868992269039154  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4856303632259369  \n","Epoch:43/50     Step:2|6   loss:0.4871971905231476  \n","Epoch:43/50     Step:3|6   loss:0.48677632212638855  \n","Epoch:43/50     Step:4|6   loss:0.4861159920692444  \n","Epoch:43/50     Step:5|6   loss:0.4866923391819  \n","Epoch:43/50     Step:6|6   loss:0.48565664887428284  \n","Epoch:43/50     Step:7|6   loss:0.488192617893219  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48763585090637207  \n","Epoch:44/50     Step:2|6   loss:0.48601004481315613  \n","Epoch:44/50     Step:3|6   loss:0.4882214367389679  \n","Epoch:44/50     Step:4|6   loss:0.48638883233070374  \n","Epoch:44/50     Step:5|6   loss:0.4871898889541626  \n","Epoch:44/50     Step:6|6   loss:0.4882547855377197  \n","Epoch:44/50     Step:7|6   loss:0.486042857170105  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.48814162611961365  \n","Epoch:45/50     Step:2|6   loss:0.4862865209579468  \n","Epoch:45/50     Step:3|6   loss:0.48714208602905273  \n","Epoch:45/50     Step:4|6   loss:0.4878905713558197  \n","Epoch:45/50     Step:5|6   loss:0.48583856225013733  \n","Epoch:45/50     Step:6|6   loss:0.4862319231033325  \n","Epoch:45/50     Step:7|6   loss:0.48679012060165405  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4864141345024109  \n","Epoch:46/50     Step:2|6   loss:0.4865542948246002  \n","Epoch:46/50     Step:3|6   loss:0.48569455742836  \n","Epoch:46/50     Step:4|6   loss:0.4860355854034424  \n","Epoch:46/50     Step:5|6   loss:0.48627573251724243  \n","Epoch:46/50     Step:6|6   loss:0.485592782497406  \n","Epoch:46/50     Step:7|6   loss:0.4860462546348572  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4859278202056885  \n","Epoch:47/50     Step:2|6   loss:0.48551833629608154  \n","Epoch:47/50     Step:3|6   loss:0.48612356185913086  \n","Epoch:47/50     Step:4|6   loss:0.4857591986656189  \n","Epoch:47/50     Step:5|6   loss:0.4861765503883362  \n","Epoch:47/50     Step:6|6   loss:0.48618364334106445  \n","Epoch:47/50     Step:7|6   loss:0.48565995693206787  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4856307804584503  \n","Epoch:48/50     Step:2|6   loss:0.4856938123703003  \n","Epoch:48/50     Step:3|6   loss:0.4855140745639801  \n","Epoch:48/50     Step:4|6   loss:0.4856221675872803  \n","Epoch:48/50     Step:5|6   loss:0.48574939370155334  \n","Epoch:48/50     Step:6|6   loss:0.48570552468299866  \n","Epoch:48/50     Step:7|6   loss:0.4855996370315552  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4859720468521118  \n","Epoch:49/50     Step:2|6   loss:0.4862299859523773  \n","Epoch:49/50     Step:3|6   loss:0.4857582449913025  \n","Epoch:49/50     Step:4|6   loss:0.48562318086624146  \n","Epoch:49/50     Step:5|6   loss:0.4864802658557892  \n","Epoch:49/50     Step:6|6   loss:0.4867075979709625  \n","Epoch:49/50     Step:7|6   loss:0.485791951417923  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4859476089477539  \n","Epoch:50/50     Step:2|6   loss:0.4872328042984009  \n","Epoch:50/50     Step:3|6   loss:0.4875982701778412  \n","Epoch:50/50     Step:4|6   loss:0.48649531602859497  \n","Epoch:50/50     Step:5|6   loss:0.4856972396373749  \n","Epoch:50/50     Step:6|6   loss:0.4867795705795288  \n","Epoch:50/50     Step:7|6   loss:0.4868614673614502  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Accuracy on test_set: 95.33 %\n","3\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1144987344741821  \n","Epoch:1/50     Step:2|6   loss:15.152494430541992  \n","Epoch:1/50     Step:3|6   loss:5.441650867462158  \n","Epoch:1/50     Step:4|6   loss:9.068412780761719  \n","Epoch:1/50     Step:5|6   loss:9.975942611694336  \n","Epoch:1/50     Step:6|6   loss:9.206160545349121  \n","Epoch:1/50     Step:7|6   loss:5.5101637840271  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 78.45 %\n","current max accuracy\t test set:73.83%\t train set:78.45%\n","Epoch:2/50     Step:1|6   loss:1.2119300365447998  \n","Epoch:2/50     Step:2|6   loss:2.844287633895874  \n","Epoch:2/50     Step:3|6   loss:5.167726516723633  \n","Epoch:2/50     Step:4|6   loss:5.091122627258301  \n","Epoch:2/50     Step:5|6   loss:3.185248851776123  \n","Epoch:2/50     Step:6|6   loss:2.6206274032592773  \n","Epoch:2/50     Step:7|6   loss:3.4480695724487305  \n","Accuracy on test_set: 67.29 %\n","Accuracy on train_set: 72.37 %\n","current max accuracy\t test set:73.83%\t train set:78.45%\n","Epoch:3/50     Step:1|6   loss:2.566905975341797  \n","Epoch:3/50     Step:2|6   loss:1.6022148132324219  \n","Epoch:3/50     Step:3|6   loss:1.7128015756607056  \n","Epoch:3/50     Step:4|6   loss:2.519646167755127  \n","Epoch:3/50     Step:5|6   loss:2.927647590637207  \n","Epoch:3/50     Step:6|6   loss:3.104099750518799  \n","Epoch:3/50     Step:7|6   loss:2.1174545288085938  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:85.98%\t train set:88.52%\n","Epoch:4/50     Step:1|6   loss:1.708143711090088  \n","Epoch:4/50     Step:2|6   loss:1.635438084602356  \n","Epoch:4/50     Step:3|6   loss:2.14196515083313  \n","Epoch:4/50     Step:4|6   loss:2.145954132080078  \n","Epoch:4/50     Step:5|6   loss:2.1454124450683594  \n","Epoch:4/50     Step:6|6   loss:1.794367790222168  \n","Epoch:4/50     Step:7|6   loss:2.3596689701080322  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 82.67 %\n","current max accuracy\t test set:85.98%\t train set:88.52%\n","Epoch:5/50     Step:1|6   loss:2.225566864013672  \n","Epoch:5/50     Step:2|6   loss:2.1071314811706543  \n","Epoch:5/50     Step:3|6   loss:1.5764172077178955  \n","Epoch:5/50     Step:4|6   loss:1.919677734375  \n","Epoch:5/50     Step:5|6   loss:1.6278215646743774  \n","Epoch:5/50     Step:6|6   loss:1.3763437271118164  \n","Epoch:5/50     Step:7|6   loss:1.4697424173355103  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:86.92%\t train set:92.27%\n","Epoch:6/50     Step:1|6   loss:1.3745157718658447  \n","Epoch:6/50     Step:2|6   loss:1.3824509382247925  \n","Epoch:6/50     Step:3|6   loss:1.107818603515625  \n","Epoch:6/50     Step:4|6   loss:1.1118829250335693  \n","Epoch:6/50     Step:5|6   loss:1.1411457061767578  \n","Epoch:6/50     Step:6|6   loss:0.9793685674667358  \n","Epoch:6/50     Step:7|6   loss:0.9447845220565796  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:86.92%\t train set:92.51%\n","Epoch:7/50     Step:1|6   loss:1.006209373474121  \n","Epoch:7/50     Step:2|6   loss:0.9540417790412903  \n","Epoch:7/50     Step:3|6   loss:0.8795605897903442  \n","Epoch:7/50     Step:4|6   loss:0.9909313321113586  \n","Epoch:7/50     Step:5|6   loss:0.8627063035964966  \n","Epoch:7/50     Step:6|6   loss:0.8136885166168213  \n","Epoch:7/50     Step:7|6   loss:0.9552624225616455  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:86.92%\t train set:93.44%\n","Epoch:8/50     Step:1|6   loss:0.8085147738456726  \n","Epoch:8/50     Step:2|6   loss:0.8144354820251465  \n","Epoch:8/50     Step:3|6   loss:0.6907745003700256  \n","Epoch:8/50     Step:4|6   loss:0.7467296123504639  \n","Epoch:8/50     Step:5|6   loss:0.7033323645591736  \n","Epoch:8/50     Step:6|6   loss:0.7177920937538147  \n","Epoch:8/50     Step:7|6   loss:0.6683875918388367  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:96.26%\t train set:99.3%\n","Epoch:9/50     Step:1|6   loss:0.7097170948982239  \n","Epoch:9/50     Step:2|6   loss:0.651100218296051  \n","Epoch:9/50     Step:3|6   loss:0.6582255959510803  \n","Epoch:9/50     Step:4|6   loss:0.6205786466598511  \n","Epoch:9/50     Step:5|6   loss:0.6361473202705383  \n","Epoch:9/50     Step:6|6   loss:0.6149970293045044  \n","Epoch:9/50     Step:7|6   loss:0.5886536836624146  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:10/50     Step:1|6   loss:0.5927717685699463  \n","Epoch:10/50     Step:2|6   loss:0.5724068284034729  \n","Epoch:10/50     Step:3|6   loss:0.5533936023712158  \n","Epoch:10/50     Step:4|6   loss:0.5724957585334778  \n","Epoch:10/50     Step:5|6   loss:0.5680661797523499  \n","Epoch:10/50     Step:6|6   loss:0.5304771661758423  \n","Epoch:10/50     Step:7|6   loss:0.559255063533783  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:11/50     Step:1|6   loss:0.5555441975593567  \n","Epoch:11/50     Step:2|6   loss:0.5398358702659607  \n","Epoch:11/50     Step:3|6   loss:0.5763086080551147  \n","Epoch:11/50     Step:4|6   loss:0.5290894508361816  \n","Epoch:11/50     Step:5|6   loss:0.5868865251541138  \n","Epoch:11/50     Step:6|6   loss:0.5268100500106812  \n","Epoch:11/50     Step:7|6   loss:0.557096540927887  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:12/50     Step:1|6   loss:0.5327094197273254  \n","Epoch:12/50     Step:2|6   loss:0.5342923998832703  \n","Epoch:12/50     Step:3|6   loss:0.5288920402526855  \n","Epoch:12/50     Step:4|6   loss:0.5324735045433044  \n","Epoch:12/50     Step:5|6   loss:0.5390400290489197  \n","Epoch:12/50     Step:6|6   loss:0.5257835984230042  \n","Epoch:12/50     Step:7|6   loss:0.508907675743103  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5383768677711487  \n","Epoch:13/50     Step:2|6   loss:0.5108233690261841  \n","Epoch:13/50     Step:3|6   loss:0.5218904614448547  \n","Epoch:13/50     Step:4|6   loss:0.5220057964324951  \n","Epoch:13/50     Step:5|6   loss:0.5165137052536011  \n","Epoch:13/50     Step:6|6   loss:0.5170423984527588  \n","Epoch:13/50     Step:7|6   loss:0.5023013353347778  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5116857290267944  \n","Epoch:14/50     Step:2|6   loss:0.505276620388031  \n","Epoch:14/50     Step:3|6   loss:0.505555272102356  \n","Epoch:14/50     Step:4|6   loss:0.5024903416633606  \n","Epoch:14/50     Step:5|6   loss:0.5016265511512756  \n","Epoch:14/50     Step:6|6   loss:0.5039440989494324  \n","Epoch:14/50     Step:7|6   loss:0.509831428527832  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.5080161690711975  \n","Epoch:15/50     Step:2|6   loss:0.5021754503250122  \n","Epoch:15/50     Step:3|6   loss:0.49910619854927063  \n","Epoch:15/50     Step:4|6   loss:0.5069692134857178  \n","Epoch:15/50     Step:5|6   loss:0.4961116313934326  \n","Epoch:15/50     Step:6|6   loss:0.5033155679702759  \n","Epoch:15/50     Step:7|6   loss:0.5047445297241211  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.4973739981651306  \n","Epoch:16/50     Step:2|6   loss:0.5013827681541443  \n","Epoch:16/50     Step:3|6   loss:0.49541541934013367  \n","Epoch:16/50     Step:4|6   loss:0.5008279085159302  \n","Epoch:16/50     Step:5|6   loss:0.4954688549041748  \n","Epoch:16/50     Step:6|6   loss:0.5012261271476746  \n","Epoch:16/50     Step:7|6   loss:0.49748411774635315  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.4964841306209564  \n","Epoch:17/50     Step:2|6   loss:0.49678993225097656  \n","Epoch:17/50     Step:3|6   loss:0.4996308982372284  \n","Epoch:17/50     Step:4|6   loss:0.4939938187599182  \n","Epoch:17/50     Step:5|6   loss:0.4955151379108429  \n","Epoch:17/50     Step:6|6   loss:0.496435284614563  \n","Epoch:17/50     Step:7|6   loss:0.49319973587989807  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.49680888652801514  \n","Epoch:18/50     Step:2|6   loss:0.49304133653640747  \n","Epoch:18/50     Step:3|6   loss:0.49287813901901245  \n","Epoch:18/50     Step:4|6   loss:0.4941779375076294  \n","Epoch:18/50     Step:5|6   loss:0.49480798840522766  \n","Epoch:18/50     Step:6|6   loss:0.5038386583328247  \n","Epoch:18/50     Step:7|6   loss:0.5009979605674744  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.49701887369155884  \n","Epoch:19/50     Step:2|6   loss:0.49346521496772766  \n","Epoch:19/50     Step:3|6   loss:0.4994472861289978  \n","Epoch:19/50     Step:4|6   loss:0.49398273229599  \n","Epoch:19/50     Step:5|6   loss:0.49672725796699524  \n","Epoch:19/50     Step:6|6   loss:0.4894617795944214  \n","Epoch:19/50     Step:7|6   loss:0.4933589696884155  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49285852909088135  \n","Epoch:20/50     Step:2|6   loss:0.49204856157302856  \n","Epoch:20/50     Step:3|6   loss:0.4916827380657196  \n","Epoch:20/50     Step:4|6   loss:0.4939321279525757  \n","Epoch:20/50     Step:5|6   loss:0.49185866117477417  \n","Epoch:20/50     Step:6|6   loss:0.49438852071762085  \n","Epoch:20/50     Step:7|6   loss:0.4924127459526062  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4914186894893646  \n","Epoch:21/50     Step:2|6   loss:0.4936874210834503  \n","Epoch:21/50     Step:3|6   loss:0.4889078736305237  \n","Epoch:21/50     Step:4|6   loss:0.4905397295951843  \n","Epoch:21/50     Step:5|6   loss:0.49320465326309204  \n","Epoch:21/50     Step:6|6   loss:0.4935835301876068  \n","Epoch:21/50     Step:7|6   loss:0.4932432174682617  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.4896368384361267  \n","Epoch:22/50     Step:2|6   loss:0.4935816824436188  \n","Epoch:22/50     Step:3|6   loss:0.4924171566963196  \n","Epoch:22/50     Step:4|6   loss:0.49388888478279114  \n","Epoch:22/50     Step:5|6   loss:0.49371272325515747  \n","Epoch:22/50     Step:6|6   loss:0.4965522885322571  \n","Epoch:22/50     Step:7|6   loss:0.4935818910598755  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.4916265308856964  \n","Epoch:23/50     Step:2|6   loss:0.4905017912387848  \n","Epoch:23/50     Step:3|6   loss:0.49329912662506104  \n","Epoch:23/50     Step:4|6   loss:0.4915478527545929  \n","Epoch:23/50     Step:5|6   loss:0.4907771944999695  \n","Epoch:23/50     Step:6|6   loss:0.4888727068901062  \n","Epoch:23/50     Step:7|6   loss:0.489190936088562  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.49117809534072876  \n","Epoch:24/50     Step:2|6   loss:0.4903436601161957  \n","Epoch:24/50     Step:3|6   loss:0.4899139404296875  \n","Epoch:24/50     Step:4|6   loss:0.4892573356628418  \n","Epoch:24/50     Step:5|6   loss:0.49128860235214233  \n","Epoch:24/50     Step:6|6   loss:0.4901575446128845  \n","Epoch:24/50     Step:7|6   loss:0.49236416816711426  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.49105387926101685  \n","Epoch:25/50     Step:2|6   loss:0.4915752410888672  \n","Epoch:25/50     Step:3|6   loss:0.48928290605545044  \n","Epoch:25/50     Step:4|6   loss:0.4908917248249054  \n","Epoch:25/50     Step:5|6   loss:0.48989319801330566  \n","Epoch:25/50     Step:6|6   loss:0.4878217577934265  \n","Epoch:25/50     Step:7|6   loss:0.4886825680732727  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.4877144992351532  \n","Epoch:26/50     Step:2|6   loss:0.48834002017974854  \n","Epoch:26/50     Step:3|6   loss:0.48781946301460266  \n","Epoch:26/50     Step:4|6   loss:0.48995378613471985  \n","Epoch:26/50     Step:5|6   loss:0.48773080110549927  \n","Epoch:26/50     Step:6|6   loss:0.4888068735599518  \n","Epoch:26/50     Step:7|6   loss:0.4894494414329529  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4902426600456238  \n","Epoch:27/50     Step:2|6   loss:0.48884057998657227  \n","Epoch:27/50     Step:3|6   loss:0.48754796385765076  \n","Epoch:27/50     Step:4|6   loss:0.48880159854888916  \n","Epoch:27/50     Step:5|6   loss:0.488284170627594  \n","Epoch:27/50     Step:6|6   loss:0.4880636930465698  \n","Epoch:27/50     Step:7|6   loss:0.4887827932834625  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.4896446764469147  \n","Epoch:28/50     Step:2|6   loss:0.4882599711418152  \n","Epoch:28/50     Step:3|6   loss:0.48872649669647217  \n","Epoch:28/50     Step:4|6   loss:0.4886234700679779  \n","Epoch:28/50     Step:5|6   loss:0.4894770085811615  \n","Epoch:28/50     Step:6|6   loss:0.48824387788772583  \n","Epoch:28/50     Step:7|6   loss:0.48969006538391113  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4890289306640625  \n","Epoch:29/50     Step:2|6   loss:0.4901909828186035  \n","Epoch:29/50     Step:3|6   loss:0.4889291524887085  \n","Epoch:29/50     Step:4|6   loss:0.4896399676799774  \n","Epoch:29/50     Step:5|6   loss:0.4874076843261719  \n","Epoch:29/50     Step:6|6   loss:0.4894879460334778  \n","Epoch:29/50     Step:7|6   loss:0.4882439970970154  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4900268316268921  \n","Epoch:30/50     Step:2|6   loss:0.4898192882537842  \n","Epoch:30/50     Step:3|6   loss:0.4879794120788574  \n","Epoch:30/50     Step:4|6   loss:0.49079078435897827  \n","Epoch:30/50     Step:5|6   loss:0.4871416389942169  \n","Epoch:30/50     Step:6|6   loss:0.48825228214263916  \n","Epoch:30/50     Step:7|6   loss:0.48902854323387146  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48860058188438416  \n","Epoch:31/50     Step:2|6   loss:0.48763206601142883  \n","Epoch:31/50     Step:3|6   loss:0.48982322216033936  \n","Epoch:31/50     Step:4|6   loss:0.4882364869117737  \n","Epoch:31/50     Step:5|6   loss:0.49062803387641907  \n","Epoch:31/50     Step:6|6   loss:0.4893435835838318  \n","Epoch:31/50     Step:7|6   loss:0.490225613117218  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.489105224609375  \n","Epoch:32/50     Step:2|6   loss:0.49017152190208435  \n","Epoch:32/50     Step:3|6   loss:0.48818981647491455  \n","Epoch:32/50     Step:4|6   loss:0.49203774333000183  \n","Epoch:32/50     Step:5|6   loss:0.4868837594985962  \n","Epoch:32/50     Step:6|6   loss:0.4944310486316681  \n","Epoch:32/50     Step:7|6   loss:0.48840802907943726  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4934929311275482  \n","Epoch:33/50     Step:2|6   loss:0.4901311993598938  \n","Epoch:33/50     Step:3|6   loss:0.4943660497665405  \n","Epoch:33/50     Step:4|6   loss:0.4944450855255127  \n","Epoch:33/50     Step:5|6   loss:0.4953348636627197  \n","Epoch:33/50     Step:6|6   loss:0.4951358437538147  \n","Epoch:33/50     Step:7|6   loss:0.49002593755722046  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4964461028575897  \n","Epoch:34/50     Step:2|6   loss:0.4896543622016907  \n","Epoch:34/50     Step:3|6   loss:0.4934954047203064  \n","Epoch:34/50     Step:4|6   loss:0.49060916900634766  \n","Epoch:34/50     Step:5|6   loss:0.4890560805797577  \n","Epoch:34/50     Step:6|6   loss:0.4886004626750946  \n","Epoch:34/50     Step:7|6   loss:0.49078020453453064  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.48908135294914246  \n","Epoch:35/50     Step:2|6   loss:0.4901224672794342  \n","Epoch:35/50     Step:3|6   loss:0.4881267547607422  \n","Epoch:35/50     Step:4|6   loss:0.49183598160743713  \n","Epoch:35/50     Step:5|6   loss:0.490217000246048  \n","Epoch:35/50     Step:6|6   loss:0.4910968840122223  \n","Epoch:35/50     Step:7|6   loss:0.49173182249069214  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.48923832178115845  \n","Epoch:36/50     Step:2|6   loss:0.49191388487815857  \n","Epoch:36/50     Step:3|6   loss:0.4865230917930603  \n","Epoch:36/50     Step:4|6   loss:0.4902942180633545  \n","Epoch:36/50     Step:5|6   loss:0.4866606593132019  \n","Epoch:36/50     Step:6|6   loss:0.4920133650302887  \n","Epoch:36/50     Step:7|6   loss:0.48784351348876953  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48798495531082153  \n","Epoch:37/50     Step:2|6   loss:0.4881950616836548  \n","Epoch:37/50     Step:3|6   loss:0.48850423097610474  \n","Epoch:37/50     Step:4|6   loss:0.4895384907722473  \n","Epoch:37/50     Step:5|6   loss:0.48782703280448914  \n","Epoch:37/50     Step:6|6   loss:0.4885278344154358  \n","Epoch:37/50     Step:7|6   loss:0.4869697093963623  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4866531789302826  \n","Epoch:38/50     Step:2|6   loss:0.4873117208480835  \n","Epoch:38/50     Step:3|6   loss:0.4868658483028412  \n","Epoch:38/50     Step:4|6   loss:0.48677635192871094  \n","Epoch:38/50     Step:5|6   loss:0.48735511302948  \n","Epoch:38/50     Step:6|6   loss:0.4867324233055115  \n","Epoch:38/50     Step:7|6   loss:0.48610833287239075  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4862792491912842  \n","Epoch:39/50     Step:2|6   loss:0.486806720495224  \n","Epoch:39/50     Step:3|6   loss:0.48690471053123474  \n","Epoch:39/50     Step:4|6   loss:0.4861770272254944  \n","Epoch:39/50     Step:5|6   loss:0.48611313104629517  \n","Epoch:39/50     Step:6|6   loss:0.4859887957572937  \n","Epoch:39/50     Step:7|6   loss:0.48632127046585083  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.4859943091869354  \n","Epoch:40/50     Step:2|6   loss:0.486128568649292  \n","Epoch:40/50     Step:3|6   loss:0.48689374327659607  \n","Epoch:40/50     Step:4|6   loss:0.4865526258945465  \n","Epoch:40/50     Step:5|6   loss:0.4868999123573303  \n","Epoch:40/50     Step:6|6   loss:0.4860078692436218  \n","Epoch:40/50     Step:7|6   loss:0.48679399490356445  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4861629605293274  \n","Epoch:41/50     Step:2|6   loss:0.48605433106422424  \n","Epoch:41/50     Step:3|6   loss:0.48627012968063354  \n","Epoch:41/50     Step:4|6   loss:0.48623886704444885  \n","Epoch:41/50     Step:5|6   loss:0.4866756200790405  \n","Epoch:41/50     Step:6|6   loss:0.48685967922210693  \n","Epoch:41/50     Step:7|6   loss:0.48578187823295593  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4869888722896576  \n","Epoch:42/50     Step:2|6   loss:0.48614275455474854  \n","Epoch:42/50     Step:3|6   loss:0.4866054654121399  \n","Epoch:42/50     Step:4|6   loss:0.48749515414237976  \n","Epoch:42/50     Step:5|6   loss:0.48595407605171204  \n","Epoch:42/50     Step:6|6   loss:0.48606428503990173  \n","Epoch:42/50     Step:7|6   loss:0.48650386929512024  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.48639750480651855  \n","Epoch:43/50     Step:2|6   loss:0.4865863621234894  \n","Epoch:43/50     Step:3|6   loss:0.486868292093277  \n","Epoch:43/50     Step:4|6   loss:0.4861290454864502  \n","Epoch:43/50     Step:5|6   loss:0.48624590039253235  \n","Epoch:43/50     Step:6|6   loss:0.48600906133651733  \n","Epoch:43/50     Step:7|6   loss:0.4869409203529358  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.486291766166687  \n","Epoch:44/50     Step:2|6   loss:0.4856850504875183  \n","Epoch:44/50     Step:3|6   loss:0.4870316684246063  \n","Epoch:44/50     Step:4|6   loss:0.48660808801651  \n","Epoch:44/50     Step:5|6   loss:0.4863892197608948  \n","Epoch:44/50     Step:6|6   loss:0.4868967831134796  \n","Epoch:44/50     Step:7|6   loss:0.4860756993293762  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4862181842327118  \n","Epoch:45/50     Step:2|6   loss:0.48614925146102905  \n","Epoch:45/50     Step:3|6   loss:0.4857490360736847  \n","Epoch:45/50     Step:4|6   loss:0.4859311878681183  \n","Epoch:45/50     Step:5|6   loss:0.48605915904045105  \n","Epoch:45/50     Step:6|6   loss:0.4861789345741272  \n","Epoch:45/50     Step:7|6   loss:0.48580634593963623  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4857518672943115  \n","Epoch:46/50     Step:2|6   loss:0.4856967329978943  \n","Epoch:46/50     Step:3|6   loss:0.4858819246292114  \n","Epoch:46/50     Step:4|6   loss:0.4858092963695526  \n","Epoch:46/50     Step:5|6   loss:0.48607107996940613  \n","Epoch:46/50     Step:6|6   loss:0.4859713912010193  \n","Epoch:46/50     Step:7|6   loss:0.48577550053596497  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4858570098876953  \n","Epoch:47/50     Step:2|6   loss:0.48581063747406006  \n","Epoch:47/50     Step:3|6   loss:0.4856092631816864  \n","Epoch:47/50     Step:4|6   loss:0.48572424054145813  \n","Epoch:47/50     Step:5|6   loss:0.4858977496623993  \n","Epoch:47/50     Step:6|6   loss:0.4861373007297516  \n","Epoch:47/50     Step:7|6   loss:0.48564016819000244  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4861069917678833  \n","Epoch:48/50     Step:2|6   loss:0.48567113280296326  \n","Epoch:48/50     Step:3|6   loss:0.486078143119812  \n","Epoch:48/50     Step:4|6   loss:0.4855274558067322  \n","Epoch:48/50     Step:5|6   loss:0.48613405227661133  \n","Epoch:48/50     Step:6|6   loss:0.48591992259025574  \n","Epoch:48/50     Step:7|6   loss:0.4856182932853699  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4860142469406128  \n","Epoch:49/50     Step:2|6   loss:0.48594602942466736  \n","Epoch:49/50     Step:3|6   loss:0.4864081144332886  \n","Epoch:49/50     Step:4|6   loss:0.4861082136631012  \n","Epoch:49/50     Step:5|6   loss:0.48584336042404175  \n","Epoch:49/50     Step:6|6   loss:0.48614364862442017  \n","Epoch:49/50     Step:7|6   loss:0.48578009009361267  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48589324951171875  \n","Epoch:50/50     Step:2|6   loss:0.48563241958618164  \n","Epoch:50/50     Step:3|6   loss:0.4855138659477234  \n","Epoch:50/50     Step:4|6   loss:0.4859209954738617  \n","Epoch:50/50     Step:5|6   loss:0.48616141080856323  \n","Epoch:50/50     Step:6|6   loss:0.48721104860305786  \n","Epoch:50/50     Step:7|6   loss:0.48588067293167114  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n","4\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Logistic_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Logistic_two_stream(\n","  (IN): Sequential(\n","    (0): Linear(in_features=193548, out_features=3, bias=True)\n","  )\n","  (IN_both): Sequential(\n","    (0): Linear(in_features=387096, out_features=3, bias=True)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")\n","Epoch:1/50     Step:1|6   loss:1.1262750625610352  \n","Epoch:1/50     Step:2|6   loss:5.555239677429199  \n","Epoch:1/50     Step:3|6   loss:8.14096736907959  \n","Epoch:1/50     Step:4|6   loss:7.0525126457214355  \n","Epoch:1/50     Step:5|6   loss:7.67643928527832  \n","Epoch:1/50     Step:6|6   loss:2.988163471221924  \n","Epoch:1/50     Step:7|6   loss:5.041937828063965  \n","Accuracy on test_set: 48.60 %\n","Accuracy on train_set: 59.72 %\n","current max accuracy\t test set:48.6%\t train set:59.72%\n","Epoch:2/50     Step:1|6   loss:5.96778678894043  \n","Epoch:2/50     Step:2|6   loss:3.909475803375244  \n","Epoch:2/50     Step:3|6   loss:1.9912104606628418  \n","Epoch:2/50     Step:4|6   loss:2.4687328338623047  \n","Epoch:2/50     Step:5|6   loss:4.382593631744385  \n","Epoch:2/50     Step:6|6   loss:4.836300849914551  \n","Epoch:2/50     Step:7|6   loss:2.290881633758545  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:82.24%\t train set:88.29%\n","Epoch:3/50     Step:1|6   loss:2.0288851261138916  \n","Epoch:3/50     Step:2|6   loss:2.3170697689056396  \n","Epoch:3/50     Step:3|6   loss:2.8107495307922363  \n","Epoch:3/50     Step:4|6   loss:4.531630992889404  \n","Epoch:3/50     Step:5|6   loss:2.8291759490966797  \n","Epoch:3/50     Step:6|6   loss:2.9665935039520264  \n","Epoch:3/50     Step:7|6   loss:2.086817502975464  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:84.11%\t train set:92.27%\n","Epoch:4/50     Step:1|6   loss:1.7440056800842285  \n","Epoch:4/50     Step:2|6   loss:2.292728900909424  \n","Epoch:4/50     Step:3|6   loss:2.148207902908325  \n","Epoch:4/50     Step:4|6   loss:2.233292579650879  \n","Epoch:4/50     Step:5|6   loss:2.17758846282959  \n","Epoch:4/50     Step:6|6   loss:2.1489858627319336  \n","Epoch:4/50     Step:7|6   loss:2.096116542816162  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:87.85%\t train set:92.27%\n","Epoch:5/50     Step:1|6   loss:1.7793264389038086  \n","Epoch:5/50     Step:2|6   loss:2.9815657138824463  \n","Epoch:5/50     Step:3|6   loss:2.3612053394317627  \n","Epoch:5/50     Step:4|6   loss:1.8396979570388794  \n","Epoch:5/50     Step:5|6   loss:1.3459172248840332  \n","Epoch:5/50     Step:6|6   loss:1.8421156406402588  \n","Epoch:5/50     Step:7|6   loss:1.212727665901184  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:87.85%\t train set:92.27%\n","Epoch:6/50     Step:1|6   loss:1.3493202924728394  \n","Epoch:6/50     Step:2|6   loss:1.816077709197998  \n","Epoch:6/50     Step:3|6   loss:1.4529600143432617  \n","Epoch:6/50     Step:4|6   loss:1.8793226480484009  \n","Epoch:6/50     Step:5|6   loss:1.5821127891540527  \n","Epoch:6/50     Step:6|6   loss:1.2628194093704224  \n","Epoch:6/50     Step:7|6   loss:0.9980577230453491  \n","Accuracy on test_set: 57.01 %\n","Accuracy on train_set: 55.97 %\n","current max accuracy\t test set:87.85%\t train set:92.27%\n","Epoch:7/50     Step:1|6   loss:1.6970255374908447  \n","Epoch:7/50     Step:2|6   loss:1.0608618259429932  \n","Epoch:7/50     Step:3|6   loss:0.971919059753418  \n","Epoch:7/50     Step:4|6   loss:1.0032862424850464  \n","Epoch:7/50     Step:5|6   loss:1.3366878032684326  \n","Epoch:7/50     Step:6|6   loss:1.1955922842025757  \n","Epoch:7/50     Step:7|6   loss:1.0346641540527344  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:90.65%\t train set:97.19%\n","Epoch:8/50     Step:1|6   loss:0.8354701995849609  \n","Epoch:8/50     Step:2|6   loss:0.7176417708396912  \n","Epoch:8/50     Step:3|6   loss:1.0064780712127686  \n","Epoch:8/50     Step:4|6   loss:0.8890101909637451  \n","Epoch:8/50     Step:5|6   loss:0.8103687763214111  \n","Epoch:8/50     Step:6|6   loss:0.812291145324707  \n","Epoch:8/50     Step:7|6   loss:0.9057028293609619  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:90.65%\t train set:97.19%\n","Epoch:9/50     Step:1|6   loss:0.925696611404419  \n","Epoch:9/50     Step:2|6   loss:0.8579175472259521  \n","Epoch:9/50     Step:3|6   loss:0.6751044392585754  \n","Epoch:9/50     Step:4|6   loss:0.8639059066772461  \n","Epoch:9/50     Step:5|6   loss:0.8878202438354492  \n","Epoch:9/50     Step:6|6   loss:0.6638486385345459  \n","Epoch:9/50     Step:7|6   loss:0.6803697943687439  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:91.59%\t train set:97.89%\n","Epoch:10/50     Step:1|6   loss:0.7443581819534302  \n","Epoch:10/50     Step:2|6   loss:0.7631912231445312  \n","Epoch:10/50     Step:3|6   loss:0.7579306364059448  \n","Epoch:10/50     Step:4|6   loss:0.7249785661697388  \n","Epoch:10/50     Step:5|6   loss:0.6412757039070129  \n","Epoch:10/50     Step:6|6   loss:0.6463727355003357  \n","Epoch:10/50     Step:7|6   loss:0.7479912042617798  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:91.59%\t train set:97.89%\n","Epoch:11/50     Step:1|6   loss:0.6314246654510498  \n","Epoch:11/50     Step:2|6   loss:0.584443986415863  \n","Epoch:11/50     Step:3|6   loss:0.6197003126144409  \n","Epoch:11/50     Step:4|6   loss:0.637620210647583  \n","Epoch:11/50     Step:5|6   loss:0.578286349773407  \n","Epoch:11/50     Step:6|6   loss:0.5969647169113159  \n","Epoch:11/50     Step:7|6   loss:0.6535708904266357  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:12/50     Step:1|6   loss:0.5515949726104736  \n","Epoch:12/50     Step:2|6   loss:0.618535578250885  \n","Epoch:12/50     Step:3|6   loss:0.6236250400543213  \n","Epoch:12/50     Step:4|6   loss:0.549992561340332  \n","Epoch:12/50     Step:5|6   loss:0.5877087116241455  \n","Epoch:12/50     Step:6|6   loss:0.5736307501792908  \n","Epoch:12/50     Step:7|6   loss:0.5658105611801147  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:13/50     Step:1|6   loss:0.5597686171531677  \n","Epoch:13/50     Step:2|6   loss:0.5655540227890015  \n","Epoch:13/50     Step:3|6   loss:0.5300745964050293  \n","Epoch:13/50     Step:4|6   loss:0.5261402726173401  \n","Epoch:13/50     Step:5|6   loss:0.5464968681335449  \n","Epoch:13/50     Step:6|6   loss:0.5256286859512329  \n","Epoch:13/50     Step:7|6   loss:0.5154997706413269  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5378700494766235  \n","Epoch:14/50     Step:2|6   loss:0.5178489089012146  \n","Epoch:14/50     Step:3|6   loss:0.5380085706710815  \n","Epoch:14/50     Step:4|6   loss:0.5132749080657959  \n","Epoch:14/50     Step:5|6   loss:0.5172467231750488  \n","Epoch:14/50     Step:6|6   loss:0.5156736969947815  \n","Epoch:14/50     Step:7|6   loss:0.5027568340301514  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.5080040693283081  \n","Epoch:15/50     Step:2|6   loss:0.5065152645111084  \n","Epoch:15/50     Step:3|6   loss:0.5069444179534912  \n","Epoch:15/50     Step:4|6   loss:0.5239768028259277  \n","Epoch:15/50     Step:5|6   loss:0.5018747448921204  \n","Epoch:15/50     Step:6|6   loss:0.5203859210014343  \n","Epoch:15/50     Step:7|6   loss:0.5055931806564331  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.5089549422264099  \n","Epoch:16/50     Step:2|6   loss:0.5012292265892029  \n","Epoch:16/50     Step:3|6   loss:0.4992840886116028  \n","Epoch:16/50     Step:4|6   loss:0.5049572587013245  \n","Epoch:16/50     Step:5|6   loss:0.5015285015106201  \n","Epoch:16/50     Step:6|6   loss:0.5104464292526245  \n","Epoch:16/50     Step:7|6   loss:0.5002630949020386  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.502363383769989  \n","Epoch:17/50     Step:2|6   loss:0.4994145333766937  \n","Epoch:17/50     Step:3|6   loss:0.4972493648529053  \n","Epoch:17/50     Step:4|6   loss:0.49890878796577454  \n","Epoch:17/50     Step:5|6   loss:0.4970646798610687  \n","Epoch:17/50     Step:6|6   loss:0.4978613257408142  \n","Epoch:17/50     Step:7|6   loss:0.4997327923774719  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.4935304522514343  \n","Epoch:18/50     Step:2|6   loss:0.5005123615264893  \n","Epoch:18/50     Step:3|6   loss:0.49916499853134155  \n","Epoch:18/50     Step:4|6   loss:0.49810510873794556  \n","Epoch:18/50     Step:5|6   loss:0.4974339008331299  \n","Epoch:18/50     Step:6|6   loss:0.49744686484336853  \n","Epoch:18/50     Step:7|6   loss:0.49626290798187256  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4976685047149658  \n","Epoch:19/50     Step:2|6   loss:0.5008688569068909  \n","Epoch:19/50     Step:3|6   loss:0.49609607458114624  \n","Epoch:19/50     Step:4|6   loss:0.500369668006897  \n","Epoch:19/50     Step:5|6   loss:0.4928503930568695  \n","Epoch:19/50     Step:6|6   loss:0.4968909025192261  \n","Epoch:19/50     Step:7|6   loss:0.49334707856178284  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49578428268432617  \n","Epoch:20/50     Step:2|6   loss:0.4942564368247986  \n","Epoch:20/50     Step:3|6   loss:0.4920107126235962  \n","Epoch:20/50     Step:4|6   loss:0.49504202604293823  \n","Epoch:20/50     Step:5|6   loss:0.49308907985687256  \n","Epoch:20/50     Step:6|6   loss:0.49244940280914307  \n","Epoch:20/50     Step:7|6   loss:0.49516674876213074  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.49426212906837463  \n","Epoch:21/50     Step:2|6   loss:0.4931286573410034  \n","Epoch:21/50     Step:3|6   loss:0.49209970235824585  \n","Epoch:21/50     Step:4|6   loss:0.4932021498680115  \n","Epoch:21/50     Step:5|6   loss:0.4920901656150818  \n","Epoch:21/50     Step:6|6   loss:0.49471062421798706  \n","Epoch:21/50     Step:7|6   loss:0.4904176890850067  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.4942321181297302  \n","Epoch:22/50     Step:2|6   loss:0.4912920892238617  \n","Epoch:22/50     Step:3|6   loss:0.4926224946975708  \n","Epoch:22/50     Step:4|6   loss:0.4918762743473053  \n","Epoch:22/50     Step:5|6   loss:0.49219781160354614  \n","Epoch:22/50     Step:6|6   loss:0.49365824460983276  \n","Epoch:22/50     Step:7|6   loss:0.4929769039154053  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.4908127784729004  \n","Epoch:23/50     Step:2|6   loss:0.4920005798339844  \n","Epoch:23/50     Step:3|6   loss:0.4927241802215576  \n","Epoch:23/50     Step:4|6   loss:0.49153631925582886  \n","Epoch:23/50     Step:5|6   loss:0.4969613254070282  \n","Epoch:23/50     Step:6|6   loss:0.4903711676597595  \n","Epoch:23/50     Step:7|6   loss:0.49394723773002625  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4912051856517792  \n","Epoch:24/50     Step:2|6   loss:0.49140429496765137  \n","Epoch:24/50     Step:3|6   loss:0.4916435480117798  \n","Epoch:24/50     Step:4|6   loss:0.49058830738067627  \n","Epoch:24/50     Step:5|6   loss:0.4910873770713806  \n","Epoch:24/50     Step:6|6   loss:0.489413321018219  \n","Epoch:24/50     Step:7|6   loss:0.49066993594169617  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.49051421880722046  \n","Epoch:25/50     Step:2|6   loss:0.49120572209358215  \n","Epoch:25/50     Step:3|6   loss:0.49024027585983276  \n","Epoch:25/50     Step:4|6   loss:0.4903687536716461  \n","Epoch:25/50     Step:5|6   loss:0.48798730969429016  \n","Epoch:25/50     Step:6|6   loss:0.48998966813087463  \n","Epoch:25/50     Step:7|6   loss:0.4897441267967224  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.4918646812438965  \n","Epoch:26/50     Step:2|6   loss:0.4908407926559448  \n","Epoch:26/50     Step:3|6   loss:0.4903949499130249  \n","Epoch:26/50     Step:4|6   loss:0.4900839328765869  \n","Epoch:26/50     Step:5|6   loss:0.493291437625885  \n","Epoch:26/50     Step:6|6   loss:0.49090951681137085  \n","Epoch:26/50     Step:7|6   loss:0.4925346374511719  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.49041807651519775  \n","Epoch:27/50     Step:2|6   loss:0.4902435541152954  \n","Epoch:27/50     Step:3|6   loss:0.48831695318222046  \n","Epoch:27/50     Step:4|6   loss:0.4936565160751343  \n","Epoch:27/50     Step:5|6   loss:0.48966091871261597  \n","Epoch:27/50     Step:6|6   loss:0.49494168162345886  \n","Epoch:27/50     Step:7|6   loss:0.4917886257171631  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48992201685905457  \n","Epoch:28/50     Step:2|6   loss:0.49023962020874023  \n","Epoch:28/50     Step:3|6   loss:0.48908817768096924  \n","Epoch:28/50     Step:4|6   loss:0.4913598895072937  \n","Epoch:28/50     Step:5|6   loss:0.488831102848053  \n","Epoch:28/50     Step:6|6   loss:0.49307286739349365  \n","Epoch:28/50     Step:7|6   loss:0.4882158041000366  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4909586012363434  \n","Epoch:29/50     Step:2|6   loss:0.4892781376838684  \n","Epoch:29/50     Step:3|6   loss:0.4913986325263977  \n","Epoch:29/50     Step:4|6   loss:0.4892530143260956  \n","Epoch:29/50     Step:5|6   loss:0.48938873410224915  \n","Epoch:29/50     Step:6|6   loss:0.48874974250793457  \n","Epoch:29/50     Step:7|6   loss:0.4887405037879944  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4879514276981354  \n","Epoch:30/50     Step:2|6   loss:0.4884765148162842  \n","Epoch:30/50     Step:3|6   loss:0.4892616868019104  \n","Epoch:30/50     Step:4|6   loss:0.4876939356327057  \n","Epoch:30/50     Step:5|6   loss:0.48812153935432434  \n","Epoch:30/50     Step:6|6   loss:0.4875166118144989  \n","Epoch:30/50     Step:7|6   loss:0.48781853914260864  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48785290122032166  \n","Epoch:31/50     Step:2|6   loss:0.49000781774520874  \n","Epoch:31/50     Step:3|6   loss:0.48766666650772095  \n","Epoch:31/50     Step:4|6   loss:0.48829957842826843  \n","Epoch:31/50     Step:5|6   loss:0.487252414226532  \n","Epoch:31/50     Step:6|6   loss:0.48802450299263  \n","Epoch:31/50     Step:7|6   loss:0.48737862706184387  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4872931241989136  \n","Epoch:32/50     Step:2|6   loss:0.4871736466884613  \n","Epoch:32/50     Step:3|6   loss:0.4877467751502991  \n","Epoch:32/50     Step:4|6   loss:0.48720380663871765  \n","Epoch:32/50     Step:5|6   loss:0.4881025552749634  \n","Epoch:32/50     Step:6|6   loss:0.4869809150695801  \n","Epoch:32/50     Step:7|6   loss:0.48822417855262756  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48737654089927673  \n","Epoch:33/50     Step:2|6   loss:0.48841020464897156  \n","Epoch:33/50     Step:3|6   loss:0.4874887764453888  \n","Epoch:33/50     Step:4|6   loss:0.4867703318595886  \n","Epoch:33/50     Step:5|6   loss:0.4880509078502655  \n","Epoch:33/50     Step:6|6   loss:0.4870772063732147  \n","Epoch:33/50     Step:7|6   loss:0.48793280124664307  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4875450134277344  \n","Epoch:34/50     Step:2|6   loss:0.4889718294143677  \n","Epoch:34/50     Step:3|6   loss:0.4875115156173706  \n","Epoch:34/50     Step:4|6   loss:0.4889267086982727  \n","Epoch:34/50     Step:5|6   loss:0.48767757415771484  \n","Epoch:34/50     Step:6|6   loss:0.4883991479873657  \n","Epoch:34/50     Step:7|6   loss:0.48700612783432007  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.48859599232673645  \n","Epoch:35/50     Step:2|6   loss:0.4870070219039917  \n","Epoch:35/50     Step:3|6   loss:0.48764482140541077  \n","Epoch:35/50     Step:4|6   loss:0.48693180084228516  \n","Epoch:35/50     Step:5|6   loss:0.4872381091117859  \n","Epoch:35/50     Step:6|6   loss:0.4869880974292755  \n","Epoch:35/50     Step:7|6   loss:0.48743346333503723  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4870283901691437  \n","Epoch:36/50     Step:2|6   loss:0.48658931255340576  \n","Epoch:36/50     Step:3|6   loss:0.48649823665618896  \n","Epoch:36/50     Step:4|6   loss:0.4866683781147003  \n","Epoch:36/50     Step:5|6   loss:0.48639848828315735  \n","Epoch:36/50     Step:6|6   loss:0.4867551922798157  \n","Epoch:36/50     Step:7|6   loss:0.48704564571380615  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48644983768463135  \n","Epoch:37/50     Step:2|6   loss:0.4869263768196106  \n","Epoch:37/50     Step:3|6   loss:0.4873638153076172  \n","Epoch:37/50     Step:4|6   loss:0.4872141480445862  \n","Epoch:37/50     Step:5|6   loss:0.4867311120033264  \n","Epoch:37/50     Step:6|6   loss:0.48807817697525024  \n","Epoch:37/50     Step:7|6   loss:0.4867401719093323  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.48642075061798096  \n","Epoch:38/50     Step:2|6   loss:0.4863933324813843  \n","Epoch:38/50     Step:3|6   loss:0.48670899868011475  \n","Epoch:38/50     Step:4|6   loss:0.4870399832725525  \n","Epoch:38/50     Step:5|6   loss:0.4866124987602234  \n","Epoch:38/50     Step:6|6   loss:0.4865058958530426  \n","Epoch:38/50     Step:7|6   loss:0.48693957924842834  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.48698028922080994  \n","Epoch:39/50     Step:2|6   loss:0.4873373210430145  \n","Epoch:39/50     Step:3|6   loss:0.4862343370914459  \n","Epoch:39/50     Step:4|6   loss:0.4861462414264679  \n","Epoch:39/50     Step:5|6   loss:0.4862065613269806  \n","Epoch:39/50     Step:6|6   loss:0.48601430654525757  \n","Epoch:39/50     Step:7|6   loss:0.48669570684432983  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48637697100639343  \n","Epoch:40/50     Step:2|6   loss:0.4874380826950073  \n","Epoch:40/50     Step:3|6   loss:0.4880119562149048  \n","Epoch:40/50     Step:4|6   loss:0.48641079664230347  \n","Epoch:40/50     Step:5|6   loss:0.48756125569343567  \n","Epoch:40/50     Step:6|6   loss:0.48778513073921204  \n","Epoch:40/50     Step:7|6   loss:0.48635002970695496  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4884863495826721  \n","Epoch:41/50     Step:2|6   loss:0.48696115612983704  \n","Epoch:41/50     Step:3|6   loss:0.48749664425849915  \n","Epoch:41/50     Step:4|6   loss:0.48847848176956177  \n","Epoch:41/50     Step:5|6   loss:0.48610788583755493  \n","Epoch:41/50     Step:6|6   loss:0.48786404728889465  \n","Epoch:41/50     Step:7|6   loss:0.4879230260848999  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48626771569252014  \n","Epoch:42/50     Step:2|6   loss:0.48749348521232605  \n","Epoch:42/50     Step:3|6   loss:0.4858778119087219  \n","Epoch:42/50     Step:4|6   loss:0.48722943663597107  \n","Epoch:42/50     Step:5|6   loss:0.4865545928478241  \n","Epoch:42/50     Step:6|6   loss:0.4869263172149658  \n","Epoch:42/50     Step:7|6   loss:0.4871799051761627  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4863617718219757  \n","Epoch:43/50     Step:2|6   loss:0.4868730902671814  \n","Epoch:43/50     Step:3|6   loss:0.48583200573921204  \n","Epoch:43/50     Step:4|6   loss:0.48670706152915955  \n","Epoch:43/50     Step:5|6   loss:0.48717349767684937  \n","Epoch:43/50     Step:6|6   loss:0.48603349924087524  \n","Epoch:43/50     Step:7|6   loss:0.4865790903568268  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4867531955242157  \n","Epoch:44/50     Step:2|6   loss:0.48654016852378845  \n","Epoch:44/50     Step:3|6   loss:0.48640769720077515  \n","Epoch:44/50     Step:4|6   loss:0.48594993352890015  \n","Epoch:44/50     Step:5|6   loss:0.4870244562625885  \n","Epoch:44/50     Step:6|6   loss:0.4862980544567108  \n","Epoch:44/50     Step:7|6   loss:0.48650506138801575  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4859592318534851  \n","Epoch:45/50     Step:2|6   loss:0.4864315986633301  \n","Epoch:45/50     Step:3|6   loss:0.4858297109603882  \n","Epoch:45/50     Step:4|6   loss:0.48598065972328186  \n","Epoch:45/50     Step:5|6   loss:0.48606306314468384  \n","Epoch:45/50     Step:6|6   loss:0.4859461188316345  \n","Epoch:45/50     Step:7|6   loss:0.4862910211086273  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4858579635620117  \n","Epoch:46/50     Step:2|6   loss:0.48616084456443787  \n","Epoch:46/50     Step:3|6   loss:0.4863343834877014  \n","Epoch:46/50     Step:4|6   loss:0.4869743287563324  \n","Epoch:46/50     Step:5|6   loss:0.4860855042934418  \n","Epoch:46/50     Step:6|6   loss:0.4859808385372162  \n","Epoch:46/50     Step:7|6   loss:0.4860639274120331  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4859940707683563  \n","Epoch:47/50     Step:2|6   loss:0.4859706461429596  \n","Epoch:47/50     Step:3|6   loss:0.48607224225997925  \n","Epoch:47/50     Step:4|6   loss:0.4859456717967987  \n","Epoch:47/50     Step:5|6   loss:0.4858701229095459  \n","Epoch:47/50     Step:6|6   loss:0.48577743768692017  \n","Epoch:47/50     Step:7|6   loss:0.48596036434173584  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.48562970757484436  \n","Epoch:48/50     Step:2|6   loss:0.4857785701751709  \n","Epoch:48/50     Step:3|6   loss:0.4857467710971832  \n","Epoch:48/50     Step:4|6   loss:0.486875057220459  \n","Epoch:48/50     Step:5|6   loss:0.4863036274909973  \n","Epoch:48/50     Step:6|6   loss:0.48591840267181396  \n","Epoch:48/50     Step:7|6   loss:0.4870433807373047  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48641908168792725  \n","Epoch:49/50     Step:2|6   loss:0.48555970191955566  \n","Epoch:49/50     Step:3|6   loss:0.48589637875556946  \n","Epoch:49/50     Step:4|6   loss:0.48583006858825684  \n","Epoch:49/50     Step:5|6   loss:0.4862484335899353  \n","Epoch:49/50     Step:6|6   loss:0.4859195947647095  \n","Epoch:49/50     Step:7|6   loss:0.4866059720516205  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4867062270641327  \n","Epoch:50/50     Step:2|6   loss:0.48587507009506226  \n","Epoch:50/50     Step:3|6   loss:0.487059623003006  \n","Epoch:50/50     Step:4|6   loss:0.4856501817703247  \n","Epoch:50/50     Step:5|6   loss:0.4876757860183716  \n","Epoch:50/50     Step:6|6   loss:0.48875391483306885  \n","Epoch:50/50     Step:7|6   loss:0.48565009236335754  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Accuracy on test_set: 96.26 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4  --model Logistic_two_stream --mode both --index {i}"},{"cell_type":"code","execution_count":6,"id":"ae6012d7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='rgb', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.2903778553009033  \n","Epoch:1/50     Step:2|6   loss:1.2858625650405884  \n","Epoch:1/50     Step:3|6   loss:1.1968562602996826  \n","Epoch:1/50     Step:4|6   loss:1.2630480527877808  \n","Epoch:1/50     Step:5|6   loss:1.2651827335357666  \n","Epoch:1/50     Step:6|6   loss:1.3700251579284668  \n","Epoch:1/50     Step:7|6   loss:1.16273832321167  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 24.59 %\n","current max accuracy\t test set:31.78%\t train set:24.59%\n","Epoch:2/50     Step:1|6   loss:1.2143287658691406  \n","Epoch:2/50     Step:2|6   loss:1.1778678894042969  \n","Epoch:2/50     Step:3|6   loss:1.2348037958145142  \n","Epoch:2/50     Step:4|6   loss:1.2324495315551758  \n","Epoch:2/50     Step:5|6   loss:1.1128419637680054  \n","Epoch:2/50     Step:6|6   loss:1.2879716157913208  \n","Epoch:2/50     Step:7|6   loss:1.1981767416000366  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 24.59 %\n","current max accuracy\t test set:31.78%\t train set:24.59%\n","Epoch:3/50     Step:1|6   loss:1.2408620119094849  \n","Epoch:3/50     Step:2|6   loss:1.1106696128845215  \n","Epoch:3/50     Step:3|6   loss:1.1626827716827393  \n","Epoch:3/50     Step:4|6   loss:1.1515012979507446  \n","Epoch:3/50     Step:5|6   loss:1.1827055215835571  \n","Epoch:3/50     Step:6|6   loss:1.204147219657898  \n","Epoch:3/50     Step:7|6   loss:1.129689335823059  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 24.59 %\n","current max accuracy\t test set:31.78%\t train set:24.59%\n","Epoch:4/50     Step:1|6   loss:1.180959939956665  \n","Epoch:4/50     Step:2|6   loss:1.1781549453735352  \n","Epoch:4/50     Step:3|6   loss:1.11722993850708  \n","Epoch:4/50     Step:4|6   loss:1.1004579067230225  \n","Epoch:4/50     Step:5|6   loss:1.17433762550354  \n","Epoch:4/50     Step:6|6   loss:1.130637288093567  \n","Epoch:4/50     Step:7|6   loss:1.2079846858978271  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 24.59 %\n","current max accuracy\t test set:31.78%\t train set:24.59%\n","Epoch:5/50     Step:1|6   loss:1.1375582218170166  \n","Epoch:5/50     Step:2|6   loss:1.127780795097351  \n","Epoch:5/50     Step:3|6   loss:1.0889567136764526  \n","Epoch:5/50     Step:4|6   loss:1.1475543975830078  \n","Epoch:5/50     Step:5|6   loss:1.134666085243225  \n","Epoch:5/50     Step:6|6   loss:1.137772560119629  \n","Epoch:5/50     Step:7|6   loss:1.0661559104919434  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 24.59 %\n","current max accuracy\t test set:31.78%\t train set:24.59%\n","Epoch:6/50     Step:1|6   loss:1.112858533859253  \n","Epoch:6/50     Step:2|6   loss:1.1077468395233154  \n","Epoch:6/50     Step:3|6   loss:1.0801628828048706  \n","Epoch:6/50     Step:4|6   loss:1.037276268005371  \n","Epoch:6/50     Step:5|6   loss:1.126956582069397  \n","Epoch:6/50     Step:6|6   loss:1.1286646127700806  \n","Epoch:6/50     Step:7|6   loss:1.0627470016479492  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 24.82 %\n","current max accuracy\t test set:31.78%\t train set:24.82%\n","Epoch:7/50     Step:1|6   loss:1.0844616889953613  \n","Epoch:7/50     Step:2|6   loss:1.0815675258636475  \n","Epoch:7/50     Step:3|6   loss:1.054366111755371  \n","Epoch:7/50     Step:4|6   loss:1.0696239471435547  \n","Epoch:7/50     Step:5|6   loss:1.0669678449630737  \n","Epoch:7/50     Step:6|6   loss:1.0633299350738525  \n","Epoch:7/50     Step:7|6   loss:1.177165150642395  \n","Accuracy on test_set: 48.60 %\n","Accuracy on train_set: 43.33 %\n","current max accuracy\t test set:48.6%\t train set:43.33%\n","Epoch:8/50     Step:1|6   loss:1.0748693943023682  \n","Epoch:8/50     Step:2|6   loss:1.0329241752624512  \n","Epoch:8/50     Step:3|6   loss:1.0287535190582275  \n","Epoch:8/50     Step:4|6   loss:1.0586966276168823  \n","Epoch:8/50     Step:5|6   loss:1.0394747257232666  \n","Epoch:8/50     Step:6|6   loss:1.0584125518798828  \n","Epoch:8/50     Step:7|6   loss:1.0038121938705444  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 48.01 %\n","current max accuracy\t test set:49.53%\t train set:48.01%\n","Epoch:9/50     Step:1|6   loss:1.0446367263793945  \n","Epoch:9/50     Step:2|6   loss:1.0693737268447876  \n","Epoch:9/50     Step:3|6   loss:1.0088000297546387  \n","Epoch:9/50     Step:4|6   loss:1.0334277153015137  \n","Epoch:9/50     Step:5|6   loss:1.0189208984375  \n","Epoch:9/50     Step:6|6   loss:1.0450257062911987  \n","Epoch:9/50     Step:7|6   loss:1.0131624937057495  \n","Accuracy on test_set: 58.88 %\n","Accuracy on train_set: 55.74 %\n","current max accuracy\t test set:58.88%\t train set:55.74%\n","Epoch:10/50     Step:1|6   loss:1.0160305500030518  \n","Epoch:10/50     Step:2|6   loss:1.032561182975769  \n","Epoch:10/50     Step:3|6   loss:1.0266766548156738  \n","Epoch:10/50     Step:4|6   loss:1.0268374681472778  \n","Epoch:10/50     Step:5|6   loss:1.024579405784607  \n","Epoch:10/50     Step:6|6   loss:0.9674416780471802  \n","Epoch:10/50     Step:7|6   loss:1.0431537628173828  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 63.23 %\n","current max accuracy\t test set:65.42%\t train set:63.23%\n","Epoch:11/50     Step:1|6   loss:1.013728141784668  \n","Epoch:11/50     Step:2|6   loss:0.9757124185562134  \n","Epoch:11/50     Step:3|6   loss:0.9829143285751343  \n","Epoch:11/50     Step:4|6   loss:0.9998934268951416  \n","Epoch:11/50     Step:5|6   loss:0.9808676242828369  \n","Epoch:11/50     Step:6|6   loss:0.9993475675582886  \n","Epoch:11/50     Step:7|6   loss:0.9856805205345154  \n","Accuracy on test_set: 67.29 %\n","Accuracy on train_set: 63.23 %\n","current max accuracy\t test set:67.29%\t train set:63.23%\n","Epoch:12/50     Step:1|6   loss:0.9865180850028992  \n","Epoch:12/50     Step:2|6   loss:1.005922555923462  \n","Epoch:12/50     Step:3|6   loss:0.9405241012573242  \n","Epoch:12/50     Step:4|6   loss:1.0110102891921997  \n","Epoch:12/50     Step:5|6   loss:0.9634552001953125  \n","Epoch:12/50     Step:6|6   loss:1.0304112434387207  \n","Epoch:12/50     Step:7|6   loss:1.0050455331802368  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 65.11 %\n","current max accuracy\t test set:68.22%\t train set:65.11%\n","Epoch:13/50     Step:1|6   loss:0.9723125696182251  \n","Epoch:13/50     Step:2|6   loss:1.0174256563186646  \n","Epoch:13/50     Step:3|6   loss:1.004273533821106  \n","Epoch:13/50     Step:4|6   loss:0.9726362228393555  \n","Epoch:13/50     Step:5|6   loss:0.9709603786468506  \n","Epoch:13/50     Step:6|6   loss:0.9957192540168762  \n","Epoch:13/50     Step:7|6   loss:0.9195832014083862  \n","Accuracy on test_set: 67.29 %\n","Accuracy on train_set: 67.21 %\n","current max accuracy\t test set:68.22%\t train set:67.21%\n","Epoch:14/50     Step:1|6   loss:0.9386147260665894  \n","Epoch:14/50     Step:2|6   loss:0.9459472298622131  \n","Epoch:14/50     Step:3|6   loss:0.9707238078117371  \n","Epoch:14/50     Step:4|6   loss:0.9792139530181885  \n","Epoch:14/50     Step:5|6   loss:0.9610617756843567  \n","Epoch:14/50     Step:6|6   loss:0.9580659866333008  \n","Epoch:14/50     Step:7|6   loss:0.9654021859169006  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 75.41 %\n","current max accuracy\t test set:78.5%\t train set:75.41%\n","Epoch:15/50     Step:1|6   loss:0.9455550312995911  \n","Epoch:15/50     Step:2|6   loss:0.9524985551834106  \n","Epoch:15/50     Step:3|6   loss:0.9851179122924805  \n","Epoch:15/50     Step:4|6   loss:0.9441368579864502  \n","Epoch:15/50     Step:5|6   loss:0.9341411590576172  \n","Epoch:15/50     Step:6|6   loss:0.9262415766716003  \n","Epoch:15/50     Step:7|6   loss:0.9631149768829346  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 77.05 %\n","current max accuracy\t test set:78.5%\t train set:77.05%\n","Epoch:16/50     Step:1|6   loss:0.928511381149292  \n","Epoch:16/50     Step:2|6   loss:0.9538079500198364  \n","Epoch:16/50     Step:3|6   loss:0.9559930562973022  \n","Epoch:16/50     Step:4|6   loss:0.9759734869003296  \n","Epoch:16/50     Step:5|6   loss:0.9381882548332214  \n","Epoch:16/50     Step:6|6   loss:0.9071901440620422  \n","Epoch:16/50     Step:7|6   loss:0.9380173683166504  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 74.47 %\n","current max accuracy\t test set:78.5%\t train set:77.05%\n","Epoch:17/50     Step:1|6   loss:0.8969072699546814  \n","Epoch:17/50     Step:2|6   loss:0.914444625377655  \n","Epoch:17/50     Step:3|6   loss:0.994711697101593  \n","Epoch:17/50     Step:4|6   loss:0.9488933682441711  \n","Epoch:17/50     Step:5|6   loss:0.9107924103736877  \n","Epoch:17/50     Step:6|6   loss:0.8793038725852966  \n","Epoch:17/50     Step:7|6   loss:0.9575717449188232  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 80.09 %\n","current max accuracy\t test set:83.18%\t train set:80.09%\n","Epoch:18/50     Step:1|6   loss:0.9610573649406433  \n","Epoch:18/50     Step:2|6   loss:0.8787201046943665  \n","Epoch:18/50     Step:3|6   loss:0.9008423686027527  \n","Epoch:18/50     Step:4|6   loss:0.9182847738265991  \n","Epoch:18/50     Step:5|6   loss:0.9215652942657471  \n","Epoch:18/50     Step:6|6   loss:0.8842755556106567  \n","Epoch:18/50     Step:7|6   loss:0.9323689937591553  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:85.05%\t train set:83.84%\n","Epoch:19/50     Step:1|6   loss:0.9171867966651917  \n","Epoch:19/50     Step:2|6   loss:0.9192131757736206  \n","Epoch:19/50     Step:3|6   loss:0.9153705835342407  \n","Epoch:19/50     Step:4|6   loss:0.901556670665741  \n","Epoch:19/50     Step:5|6   loss:0.9044147729873657  \n","Epoch:19/50     Step:6|6   loss:0.8734429478645325  \n","Epoch:19/50     Step:7|6   loss:0.9131459593772888  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 76.35 %\n","current max accuracy\t test set:85.05%\t train set:83.84%\n","Epoch:20/50     Step:1|6   loss:0.9133354425430298  \n","Epoch:20/50     Step:2|6   loss:0.9393070936203003  \n","Epoch:20/50     Step:3|6   loss:0.9033709764480591  \n","Epoch:20/50     Step:4|6   loss:0.893474817276001  \n","Epoch:20/50     Step:5|6   loss:0.8966127038002014  \n","Epoch:20/50     Step:6|6   loss:0.8536312580108643  \n","Epoch:20/50     Step:7|6   loss:0.8827614784240723  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:93.46%\t train set:91.33%\n","Epoch:21/50     Step:1|6   loss:0.8778255581855774  \n","Epoch:21/50     Step:2|6   loss:0.9383251667022705  \n","Epoch:21/50     Step:3|6   loss:0.8403151631355286  \n","Epoch:21/50     Step:4|6   loss:0.8831573724746704  \n","Epoch:21/50     Step:5|6   loss:0.8888528943061829  \n","Epoch:21/50     Step:6|6   loss:0.8713531494140625  \n","Epoch:21/50     Step:7|6   loss:0.8506395816802979  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:93.46%\t train set:91.33%\n","Epoch:22/50     Step:1|6   loss:0.9092825055122375  \n","Epoch:22/50     Step:2|6   loss:0.8765678405761719  \n","Epoch:22/50     Step:3|6   loss:0.8671873807907104  \n","Epoch:22/50     Step:4|6   loss:0.901108980178833  \n","Epoch:22/50     Step:5|6   loss:0.8728616833686829  \n","Epoch:22/50     Step:6|6   loss:0.8600212931632996  \n","Epoch:22/50     Step:7|6   loss:0.8297456502914429  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:95.33%\t train set:91.33%\n","Epoch:23/50     Step:1|6   loss:0.8303396701812744  \n","Epoch:23/50     Step:2|6   loss:0.8814634084701538  \n","Epoch:23/50     Step:3|6   loss:0.8351519703865051  \n","Epoch:23/50     Step:4|6   loss:0.894950270652771  \n","Epoch:23/50     Step:5|6   loss:0.8230842351913452  \n","Epoch:23/50     Step:6|6   loss:0.895960807800293  \n","Epoch:23/50     Step:7|6   loss:0.9329169988632202  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:95.33%\t train set:91.33%\n","Epoch:24/50     Step:1|6   loss:0.8388278484344482  \n","Epoch:24/50     Step:2|6   loss:0.8420871496200562  \n","Epoch:24/50     Step:3|6   loss:0.8561595678329468  \n","Epoch:24/50     Step:4|6   loss:0.8701158761978149  \n","Epoch:24/50     Step:5|6   loss:0.8597151041030884  \n","Epoch:24/50     Step:6|6   loss:0.8757140636444092  \n","Epoch:24/50     Step:7|6   loss:0.8702295422554016  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:95.33%\t train set:93.21%\n","Epoch:25/50     Step:1|6   loss:0.8855345249176025  \n","Epoch:25/50     Step:2|6   loss:0.836007833480835  \n","Epoch:25/50     Step:3|6   loss:0.852039098739624  \n","Epoch:25/50     Step:4|6   loss:0.8328701257705688  \n","Epoch:25/50     Step:5|6   loss:0.8091210126876831  \n","Epoch:25/50     Step:6|6   loss:0.8430896997451782  \n","Epoch:25/50     Step:7|6   loss:0.846051812171936  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:95.33%\t train set:93.21%\n","Epoch:26/50     Step:1|6   loss:0.9190826416015625  \n","Epoch:26/50     Step:2|6   loss:0.8364717364311218  \n","Epoch:26/50     Step:3|6   loss:0.8109045028686523  \n","Epoch:26/50     Step:4|6   loss:0.8452017307281494  \n","Epoch:26/50     Step:5|6   loss:0.857595682144165  \n","Epoch:26/50     Step:6|6   loss:0.8547843098640442  \n","Epoch:26/50     Step:7|6   loss:0.8759195804595947  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:27/50     Step:1|6   loss:0.90995854139328  \n","Epoch:27/50     Step:2|6   loss:0.8210790753364563  \n","Epoch:27/50     Step:3|6   loss:0.8370105028152466  \n","Epoch:27/50     Step:4|6   loss:0.7878245115280151  \n","Epoch:27/50     Step:5|6   loss:0.8526508808135986  \n","Epoch:27/50     Step:6|6   loss:0.8021605014801025  \n","Epoch:27/50     Step:7|6   loss:0.8157635927200317  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:28/50     Step:1|6   loss:0.833063006401062  \n","Epoch:28/50     Step:2|6   loss:0.8054447174072266  \n","Epoch:28/50     Step:3|6   loss:0.8149992227554321  \n","Epoch:28/50     Step:4|6   loss:0.8244996070861816  \n","Epoch:28/50     Step:5|6   loss:0.8445323705673218  \n","Epoch:28/50     Step:6|6   loss:0.8371812105178833  \n","Epoch:28/50     Step:7|6   loss:0.8347755670547485  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:29/50     Step:1|6   loss:0.8406040668487549  \n","Epoch:29/50     Step:2|6   loss:0.8164273500442505  \n","Epoch:29/50     Step:3|6   loss:0.7883232235908508  \n","Epoch:29/50     Step:4|6   loss:0.8024113178253174  \n","Epoch:29/50     Step:5|6   loss:0.8399107456207275  \n","Epoch:29/50     Step:6|6   loss:0.8405414819717407  \n","Epoch:29/50     Step:7|6   loss:0.8329815864562988  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:30/50     Step:1|6   loss:0.8168479800224304  \n","Epoch:30/50     Step:2|6   loss:0.7694188356399536  \n","Epoch:30/50     Step:3|6   loss:0.8460432291030884  \n","Epoch:30/50     Step:4|6   loss:0.8053237199783325  \n","Epoch:30/50     Step:5|6   loss:0.8291241526603699  \n","Epoch:30/50     Step:6|6   loss:0.8228728771209717  \n","Epoch:30/50     Step:7|6   loss:0.8119677305221558  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:31/50     Step:1|6   loss:0.8347457647323608  \n","Epoch:31/50     Step:2|6   loss:0.8272377848625183  \n","Epoch:31/50     Step:3|6   loss:0.8555521965026855  \n","Epoch:31/50     Step:4|6   loss:0.8597977161407471  \n","Epoch:31/50     Step:5|6   loss:0.7948261499404907  \n","Epoch:31/50     Step:6|6   loss:0.8075395822525024  \n","Epoch:31/50     Step:7|6   loss:0.7628589272499084  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:32/50     Step:1|6   loss:0.8192476630210876  \n","Epoch:32/50     Step:2|6   loss:0.847011148929596  \n","Epoch:32/50     Step:3|6   loss:0.808707594871521  \n","Epoch:32/50     Step:4|6   loss:0.8103225827217102  \n","Epoch:32/50     Step:5|6   loss:0.8313592672348022  \n","Epoch:32/50     Step:6|6   loss:0.7971640825271606  \n","Epoch:32/50     Step:7|6   loss:0.8113954067230225  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:33/50     Step:1|6   loss:0.7694998383522034  \n","Epoch:33/50     Step:2|6   loss:0.872035026550293  \n","Epoch:33/50     Step:3|6   loss:0.8005748987197876  \n","Epoch:33/50     Step:4|6   loss:0.8485449552536011  \n","Epoch:33/50     Step:5|6   loss:0.7741292119026184  \n","Epoch:33/50     Step:6|6   loss:0.7827564477920532  \n","Epoch:33/50     Step:7|6   loss:0.8243639469146729  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:34/50     Step:1|6   loss:0.7936685085296631  \n","Epoch:34/50     Step:2|6   loss:0.8109604120254517  \n","Epoch:34/50     Step:3|6   loss:0.7706426382064819  \n","Epoch:34/50     Step:4|6   loss:0.8457584977149963  \n","Epoch:34/50     Step:5|6   loss:0.8127557039260864  \n","Epoch:34/50     Step:6|6   loss:0.827738881111145  \n","Epoch:34/50     Step:7|6   loss:0.8252187967300415  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:35/50     Step:1|6   loss:0.7800579071044922  \n","Epoch:35/50     Step:2|6   loss:0.7825726270675659  \n","Epoch:35/50     Step:3|6   loss:0.8350105285644531  \n","Epoch:35/50     Step:4|6   loss:0.8243885040283203  \n","Epoch:35/50     Step:5|6   loss:0.7654117345809937  \n","Epoch:35/50     Step:6|6   loss:0.7983331680297852  \n","Epoch:35/50     Step:7|6   loss:0.8323541283607483  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:36/50     Step:1|6   loss:0.8122068643569946  \n","Epoch:36/50     Step:2|6   loss:0.7880572080612183  \n","Epoch:36/50     Step:3|6   loss:0.8192601799964905  \n","Epoch:36/50     Step:4|6   loss:0.7647171020507812  \n","Epoch:36/50     Step:5|6   loss:0.7495499849319458  \n","Epoch:36/50     Step:6|6   loss:0.7413888573646545  \n","Epoch:36/50     Step:7|6   loss:0.8194198608398438  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:37/50     Step:1|6   loss:0.7794269323348999  \n","Epoch:37/50     Step:2|6   loss:0.7863986492156982  \n","Epoch:37/50     Step:3|6   loss:0.8114749193191528  \n","Epoch:37/50     Step:4|6   loss:0.8211090564727783  \n","Epoch:37/50     Step:5|6   loss:0.7466683983802795  \n","Epoch:37/50     Step:6|6   loss:0.7714520692825317  \n","Epoch:37/50     Step:7|6   loss:0.7595125436782837  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:38/50     Step:1|6   loss:0.7824888229370117  \n","Epoch:38/50     Step:2|6   loss:0.7519657611846924  \n","Epoch:38/50     Step:3|6   loss:0.7368000745773315  \n","Epoch:38/50     Step:4|6   loss:0.8417450189590454  \n","Epoch:38/50     Step:5|6   loss:0.8086233139038086  \n","Epoch:38/50     Step:6|6   loss:0.7584222555160522  \n","Epoch:38/50     Step:7|6   loss:0.8010396361351013  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:39/50     Step:1|6   loss:0.7792500257492065  \n","Epoch:39/50     Step:2|6   loss:0.7454472184181213  \n","Epoch:39/50     Step:3|6   loss:0.818804919719696  \n","Epoch:39/50     Step:4|6   loss:0.72757887840271  \n","Epoch:39/50     Step:5|6   loss:0.7979137897491455  \n","Epoch:39/50     Step:6|6   loss:0.8179028630256653  \n","Epoch:39/50     Step:7|6   loss:0.8595133423805237  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:40/50     Step:1|6   loss:0.8061290979385376  \n","Epoch:40/50     Step:2|6   loss:0.8009104132652283  \n","Epoch:40/50     Step:3|6   loss:0.76775723695755  \n","Epoch:40/50     Step:4|6   loss:0.8256653547286987  \n","Epoch:40/50     Step:5|6   loss:0.8186694383621216  \n","Epoch:40/50     Step:6|6   loss:0.7728055715560913  \n","Epoch:40/50     Step:7|6   loss:0.7598322629928589  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:41/50     Step:1|6   loss:0.7787333726882935  \n","Epoch:41/50     Step:2|6   loss:0.7585976123809814  \n","Epoch:41/50     Step:3|6   loss:0.7801529169082642  \n","Epoch:41/50     Step:4|6   loss:0.8048871755599976  \n","Epoch:41/50     Step:5|6   loss:0.7700191140174866  \n","Epoch:41/50     Step:6|6   loss:0.761372447013855  \n","Epoch:41/50     Step:7|6   loss:0.8095645904541016  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:98.13%\t train set:96.49%\n","Epoch:42/50     Step:1|6   loss:0.7658900618553162  \n","Epoch:42/50     Step:2|6   loss:0.754339873790741  \n","Epoch:42/50     Step:3|6   loss:0.7774218916893005  \n","Epoch:42/50     Step:4|6   loss:0.8095259070396423  \n","Epoch:42/50     Step:5|6   loss:0.7860430479049683  \n","Epoch:42/50     Step:6|6   loss:0.7431818246841431  \n","Epoch:42/50     Step:7|6   loss:0.7828672528266907  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:43/50     Step:1|6   loss:0.7724319100379944  \n","Epoch:43/50     Step:2|6   loss:0.775117039680481  \n","Epoch:43/50     Step:3|6   loss:0.7426899671554565  \n","Epoch:43/50     Step:4|6   loss:0.7396807670593262  \n","Epoch:43/50     Step:5|6   loss:0.7842450141906738  \n","Epoch:43/50     Step:6|6   loss:0.7560064792633057  \n","Epoch:43/50     Step:7|6   loss:0.8405024409294128  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:44/50     Step:1|6   loss:0.7762758135795593  \n","Epoch:44/50     Step:2|6   loss:0.7710309028625488  \n","Epoch:44/50     Step:3|6   loss:0.7728586196899414  \n","Epoch:44/50     Step:4|6   loss:0.7741934061050415  \n","Epoch:44/50     Step:5|6   loss:0.7922998666763306  \n","Epoch:44/50     Step:6|6   loss:0.7773441076278687  \n","Epoch:44/50     Step:7|6   loss:0.75538170337677  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:45/50     Step:1|6   loss:0.7732352018356323  \n","Epoch:45/50     Step:2|6   loss:0.7696946859359741  \n","Epoch:45/50     Step:3|6   loss:0.7561620473861694  \n","Epoch:45/50     Step:4|6   loss:0.7952501773834229  \n","Epoch:45/50     Step:5|6   loss:0.7664093971252441  \n","Epoch:45/50     Step:6|6   loss:0.7756342887878418  \n","Epoch:45/50     Step:7|6   loss:0.7953523993492126  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:46/50     Step:1|6   loss:0.7908310890197754  \n","Epoch:46/50     Step:2|6   loss:0.7489598989486694  \n","Epoch:46/50     Step:3|6   loss:0.7859553098678589  \n","Epoch:46/50     Step:4|6   loss:0.8197433948516846  \n","Epoch:46/50     Step:5|6   loss:0.7802963256835938  \n","Epoch:46/50     Step:6|6   loss:0.7495497465133667  \n","Epoch:46/50     Step:7|6   loss:0.7763440608978271  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:47/50     Step:1|6   loss:0.8271671533584595  \n","Epoch:47/50     Step:2|6   loss:0.8211928606033325  \n","Epoch:47/50     Step:3|6   loss:0.7974254488945007  \n","Epoch:47/50     Step:4|6   loss:0.733789324760437  \n","Epoch:47/50     Step:5|6   loss:0.6986076235771179  \n","Epoch:47/50     Step:6|6   loss:0.7998813390731812  \n","Epoch:47/50     Step:7|6   loss:0.7549633979797363  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:48/50     Step:1|6   loss:0.7678577303886414  \n","Epoch:48/50     Step:2|6   loss:0.780792236328125  \n","Epoch:48/50     Step:3|6   loss:0.7836730480194092  \n","Epoch:48/50     Step:4|6   loss:0.7801672220230103  \n","Epoch:48/50     Step:5|6   loss:0.7481427192687988  \n","Epoch:48/50     Step:6|6   loss:0.7165566086769104  \n","Epoch:48/50     Step:7|6   loss:0.8113389015197754  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:49/50     Step:1|6   loss:0.7253751754760742  \n","Epoch:49/50     Step:2|6   loss:0.8167926073074341  \n","Epoch:49/50     Step:3|6   loss:0.7700128555297852  \n","Epoch:49/50     Step:4|6   loss:0.7778153419494629  \n","Epoch:49/50     Step:5|6   loss:0.745387077331543  \n","Epoch:49/50     Step:6|6   loss:0.7946345806121826  \n","Epoch:49/50     Step:7|6   loss:0.7244724035263062  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:50/50     Step:1|6   loss:0.7529447078704834  \n","Epoch:50/50     Step:2|6   loss:0.7761589288711548  \n","Epoch:50/50     Step:3|6   loss:0.7993852496147156  \n","Epoch:50/50     Step:4|6   loss:0.7661457061767578  \n","Epoch:50/50     Step:5|6   loss:0.8287818431854248  \n","Epoch:50/50     Step:6|6   loss:0.7661943435668945  \n","Epoch:50/50     Step:7|6   loss:0.7788501977920532  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Accuracy on test_set: 94.39 %\n","1\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='rgb', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.115030288696289  \n","Epoch:1/50     Step:2|6   loss:1.1170905828475952  \n","Epoch:1/50     Step:3|6   loss:1.1161859035491943  \n","Epoch:1/50     Step:4|6   loss:1.097867727279663  \n","Epoch:1/50     Step:5|6   loss:1.1011407375335693  \n","Epoch:1/50     Step:6|6   loss:1.1088510751724243  \n","Epoch:1/50     Step:7|6   loss:1.076566219329834  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 47.07 %\n","current max accuracy\t test set:42.06%\t train set:47.07%\n","Epoch:2/50     Step:1|6   loss:1.092706322669983  \n","Epoch:2/50     Step:2|6   loss:1.10282301902771  \n","Epoch:2/50     Step:3|6   loss:1.055385947227478  \n","Epoch:2/50     Step:4|6   loss:1.077807068824768  \n","Epoch:2/50     Step:5|6   loss:1.0327059030532837  \n","Epoch:2/50     Step:6|6   loss:1.0464357137680054  \n","Epoch:2/50     Step:7|6   loss:1.0162582397460938  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 47.07 %\n","current max accuracy\t test set:42.06%\t train set:47.07%\n","Epoch:3/50     Step:1|6   loss:1.0297819375991821  \n","Epoch:3/50     Step:2|6   loss:1.031902551651001  \n","Epoch:3/50     Step:3|6   loss:1.0501598119735718  \n","Epoch:3/50     Step:4|6   loss:1.030874490737915  \n","Epoch:3/50     Step:5|6   loss:1.0191147327423096  \n","Epoch:3/50     Step:6|6   loss:1.048182725906372  \n","Epoch:3/50     Step:7|6   loss:1.0349091291427612  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 47.07 %\n","current max accuracy\t test set:42.06%\t train set:47.07%\n","Epoch:4/50     Step:1|6   loss:1.0212770700454712  \n","Epoch:4/50     Step:2|6   loss:1.0016613006591797  \n","Epoch:4/50     Step:3|6   loss:0.99224454164505  \n","Epoch:4/50     Step:4|6   loss:0.974679172039032  \n","Epoch:4/50     Step:5|6   loss:1.0237058401107788  \n","Epoch:4/50     Step:6|6   loss:1.0257912874221802  \n","Epoch:4/50     Step:7|6   loss:1.0030573606491089  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 47.07 %\n","current max accuracy\t test set:42.06%\t train set:47.07%\n","Epoch:5/50     Step:1|6   loss:0.9612598419189453  \n","Epoch:5/50     Step:2|6   loss:0.9897581338882446  \n","Epoch:5/50     Step:3|6   loss:0.9468815922737122  \n","Epoch:5/50     Step:4|6   loss:0.9984181523323059  \n","Epoch:5/50     Step:5|6   loss:0.9728602170944214  \n","Epoch:5/50     Step:6|6   loss:0.963590145111084  \n","Epoch:5/50     Step:7|6   loss:0.950884222984314  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 47.07 %\n","current max accuracy\t test set:42.06%\t train set:47.07%\n","Epoch:6/50     Step:1|6   loss:0.9630165100097656  \n","Epoch:6/50     Step:2|6   loss:0.9664703607559204  \n","Epoch:6/50     Step:3|6   loss:0.9338333010673523  \n","Epoch:6/50     Step:4|6   loss:0.9610249996185303  \n","Epoch:6/50     Step:5|6   loss:0.9408808946609497  \n","Epoch:6/50     Step:6|6   loss:0.9368484616279602  \n","Epoch:6/50     Step:7|6   loss:0.9740347266197205  \n","Accuracy on test_set: 45.79 %\n","Accuracy on train_set: 51.99 %\n","current max accuracy\t test set:45.79%\t train set:51.99%\n","Epoch:7/50     Step:1|6   loss:0.9852153062820435  \n","Epoch:7/50     Step:2|6   loss:0.991263747215271  \n","Epoch:7/50     Step:3|6   loss:0.9525187611579895  \n","Epoch:7/50     Step:4|6   loss:0.96680748462677  \n","Epoch:7/50     Step:5|6   loss:0.9202719926834106  \n","Epoch:7/50     Step:6|6   loss:0.9210338592529297  \n","Epoch:7/50     Step:7|6   loss:0.9673203825950623  \n","Accuracy on test_set: 47.66 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:47.66%\t train set:53.86%\n","Epoch:8/50     Step:1|6   loss:0.949232816696167  \n","Epoch:8/50     Step:2|6   loss:0.9354936480522156  \n","Epoch:8/50     Step:3|6   loss:0.9492348432540894  \n","Epoch:8/50     Step:4|6   loss:0.9327738285064697  \n","Epoch:8/50     Step:5|6   loss:0.9211148023605347  \n","Epoch:8/50     Step:6|6   loss:0.8922265768051147  \n","Epoch:8/50     Step:7|6   loss:0.9020386338233948  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 80.56 %\n","current max accuracy\t test set:73.83%\t train set:80.56%\n","Epoch:9/50     Step:1|6   loss:0.9131609797477722  \n","Epoch:9/50     Step:2|6   loss:0.8950693011283875  \n","Epoch:9/50     Step:3|6   loss:0.9194049835205078  \n","Epoch:9/50     Step:4|6   loss:0.8743181228637695  \n","Epoch:9/50     Step:5|6   loss:0.9199222922325134  \n","Epoch:9/50     Step:6|6   loss:0.9004849195480347  \n","Epoch:9/50     Step:7|6   loss:0.9554736614227295  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:10/50     Step:1|6   loss:0.9000745415687561  \n","Epoch:10/50     Step:2|6   loss:0.8889821767807007  \n","Epoch:10/50     Step:3|6   loss:0.90822434425354  \n","Epoch:10/50     Step:4|6   loss:0.8963475227355957  \n","Epoch:10/50     Step:5|6   loss:0.897171139717102  \n","Epoch:10/50     Step:6|6   loss:0.8846994042396545  \n","Epoch:10/50     Step:7|6   loss:0.8855218887329102  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 74.00 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:11/50     Step:1|6   loss:0.8630551099777222  \n","Epoch:11/50     Step:2|6   loss:0.8960253000259399  \n","Epoch:11/50     Step:3|6   loss:0.851270854473114  \n","Epoch:11/50     Step:4|6   loss:0.8617186546325684  \n","Epoch:11/50     Step:5|6   loss:0.8806216716766357  \n","Epoch:11/50     Step:6|6   loss:0.8928781747817993  \n","Epoch:11/50     Step:7|6   loss:0.8628378510475159  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 80.80 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:12/50     Step:1|6   loss:0.8789305090904236  \n","Epoch:12/50     Step:2|6   loss:0.8814061880111694  \n","Epoch:12/50     Step:3|6   loss:0.911083459854126  \n","Epoch:12/50     Step:4|6   loss:0.9314695596694946  \n","Epoch:12/50     Step:5|6   loss:0.9039329886436462  \n","Epoch:12/50     Step:6|6   loss:0.8285102844238281  \n","Epoch:12/50     Step:7|6   loss:0.8524096012115479  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:90.65%\t train set:93.21%\n","Epoch:13/50     Step:1|6   loss:0.8955355882644653  \n","Epoch:13/50     Step:2|6   loss:0.8366150856018066  \n","Epoch:13/50     Step:3|6   loss:0.8954038023948669  \n","Epoch:13/50     Step:4|6   loss:0.8521649837493896  \n","Epoch:13/50     Step:5|6   loss:0.8465024828910828  \n","Epoch:13/50     Step:6|6   loss:0.8190783262252808  \n","Epoch:13/50     Step:7|6   loss:0.8044480681419373  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:90.65%\t train set:93.21%\n","Epoch:14/50     Step:1|6   loss:0.8315650224685669  \n","Epoch:14/50     Step:2|6   loss:0.8235829472541809  \n","Epoch:14/50     Step:3|6   loss:0.8372915983200073  \n","Epoch:14/50     Step:4|6   loss:0.8726748824119568  \n","Epoch:14/50     Step:5|6   loss:0.8209118247032166  \n","Epoch:14/50     Step:6|6   loss:0.8766152858734131  \n","Epoch:14/50     Step:7|6   loss:0.8984525799751282  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:90.65%\t train set:93.21%\n","Epoch:15/50     Step:1|6   loss:0.8419607877731323  \n","Epoch:15/50     Step:2|6   loss:0.8804218769073486  \n","Epoch:15/50     Step:3|6   loss:0.8954743146896362  \n","Epoch:15/50     Step:4|6   loss:0.8854650259017944  \n","Epoch:15/50     Step:5|6   loss:0.8284873962402344  \n","Epoch:15/50     Step:6|6   loss:0.8272960186004639  \n","Epoch:15/50     Step:7|6   loss:0.8900696039199829  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:16/50     Step:1|6   loss:0.873661994934082  \n","Epoch:16/50     Step:2|6   loss:0.8634510040283203  \n","Epoch:16/50     Step:3|6   loss:0.8772545456886292  \n","Epoch:16/50     Step:4|6   loss:0.8742270469665527  \n","Epoch:16/50     Step:5|6   loss:0.7836887836456299  \n","Epoch:16/50     Step:6|6   loss:0.8221942782402039  \n","Epoch:16/50     Step:7|6   loss:0.8743758201599121  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:17/50     Step:1|6   loss:0.864456295967102  \n","Epoch:17/50     Step:2|6   loss:0.8724172115325928  \n","Epoch:17/50     Step:3|6   loss:0.8337464332580566  \n","Epoch:17/50     Step:4|6   loss:0.8236676454544067  \n","Epoch:17/50     Step:5|6   loss:0.8567701578140259  \n","Epoch:17/50     Step:6|6   loss:0.8382318615913391  \n","Epoch:17/50     Step:7|6   loss:0.8172298669815063  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:18/50     Step:1|6   loss:0.8622410297393799  \n","Epoch:18/50     Step:2|6   loss:0.8184170722961426  \n","Epoch:18/50     Step:3|6   loss:0.8071275949478149  \n","Epoch:18/50     Step:4|6   loss:0.8185405731201172  \n","Epoch:18/50     Step:5|6   loss:0.8134104013442993  \n","Epoch:18/50     Step:6|6   loss:0.8354803323745728  \n","Epoch:18/50     Step:7|6   loss:0.8044779896736145  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:19/50     Step:1|6   loss:0.8493317365646362  \n","Epoch:19/50     Step:2|6   loss:0.7809785604476929  \n","Epoch:19/50     Step:3|6   loss:0.83184814453125  \n","Epoch:19/50     Step:4|6   loss:0.8231836557388306  \n","Epoch:19/50     Step:5|6   loss:0.7622820138931274  \n","Epoch:19/50     Step:6|6   loss:0.8196371793746948  \n","Epoch:19/50     Step:7|6   loss:0.8409003019332886  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 76.58 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:20/50     Step:1|6   loss:0.8100006580352783  \n","Epoch:20/50     Step:2|6   loss:0.7642287015914917  \n","Epoch:20/50     Step:3|6   loss:0.787214994430542  \n","Epoch:20/50     Step:4|6   loss:0.803038477897644  \n","Epoch:20/50     Step:5|6   loss:0.8228708505630493  \n","Epoch:20/50     Step:6|6   loss:0.8027294874191284  \n","Epoch:20/50     Step:7|6   loss:0.8374571800231934  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:21/50     Step:1|6   loss:0.8407279849052429  \n","Epoch:21/50     Step:2|6   loss:0.8074278831481934  \n","Epoch:21/50     Step:3|6   loss:0.8050242066383362  \n","Epoch:21/50     Step:4|6   loss:0.7764355540275574  \n","Epoch:21/50     Step:5|6   loss:0.8348641395568848  \n","Epoch:21/50     Step:6|6   loss:0.8363121747970581  \n","Epoch:21/50     Step:7|6   loss:0.7739090919494629  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:22/50     Step:1|6   loss:0.8230694532394409  \n","Epoch:22/50     Step:2|6   loss:0.7829638719558716  \n","Epoch:22/50     Step:3|6   loss:0.7745906710624695  \n","Epoch:22/50     Step:4|6   loss:0.802531361579895  \n","Epoch:22/50     Step:5|6   loss:0.8064046502113342  \n","Epoch:22/50     Step:6|6   loss:0.7633785605430603  \n","Epoch:22/50     Step:7|6   loss:0.7900950908660889  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 79.39 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:23/50     Step:1|6   loss:0.8033854365348816  \n","Epoch:23/50     Step:2|6   loss:0.7693756818771362  \n","Epoch:23/50     Step:3|6   loss:0.7981650233268738  \n","Epoch:23/50     Step:4|6   loss:0.7817490100860596  \n","Epoch:23/50     Step:5|6   loss:0.7729191780090332  \n","Epoch:23/50     Step:6|6   loss:0.813868522644043  \n","Epoch:23/50     Step:7|6   loss:0.8167309165000916  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:24/50     Step:1|6   loss:0.7720849514007568  \n","Epoch:24/50     Step:2|6   loss:0.7904022336006165  \n","Epoch:24/50     Step:3|6   loss:0.7347478270530701  \n","Epoch:24/50     Step:4|6   loss:0.795336902141571  \n","Epoch:24/50     Step:5|6   loss:0.7678360939025879  \n","Epoch:24/50     Step:6|6   loss:0.7822420597076416  \n","Epoch:24/50     Step:7|6   loss:0.8073793053627014  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:25/50     Step:1|6   loss:0.7395520806312561  \n","Epoch:25/50     Step:2|6   loss:0.7530666589736938  \n","Epoch:25/50     Step:3|6   loss:0.7342877388000488  \n","Epoch:25/50     Step:4|6   loss:0.8554173707962036  \n","Epoch:25/50     Step:5|6   loss:0.8094226121902466  \n","Epoch:25/50     Step:6|6   loss:0.7874664068222046  \n","Epoch:25/50     Step:7|6   loss:0.7926889061927795  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:26/50     Step:1|6   loss:0.7824438214302063  \n","Epoch:26/50     Step:2|6   loss:0.7756048440933228  \n","Epoch:26/50     Step:3|6   loss:0.7913379669189453  \n","Epoch:26/50     Step:4|6   loss:0.8163228034973145  \n","Epoch:26/50     Step:5|6   loss:0.8128321766853333  \n","Epoch:26/50     Step:6|6   loss:0.8002995252609253  \n","Epoch:26/50     Step:7|6   loss:0.787838339805603  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:27/50     Step:1|6   loss:0.778426468372345  \n","Epoch:27/50     Step:2|6   loss:0.7628575563430786  \n","Epoch:27/50     Step:3|6   loss:0.8044925928115845  \n","Epoch:27/50     Step:4|6   loss:0.809301495552063  \n","Epoch:27/50     Step:5|6   loss:0.8015022277832031  \n","Epoch:27/50     Step:6|6   loss:0.8090411424636841  \n","Epoch:27/50     Step:7|6   loss:0.7828711271286011  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:28/50     Step:1|6   loss:0.7641559839248657  \n","Epoch:28/50     Step:2|6   loss:0.780315637588501  \n","Epoch:28/50     Step:3|6   loss:0.7600616216659546  \n","Epoch:28/50     Step:4|6   loss:0.7541979551315308  \n","Epoch:28/50     Step:5|6   loss:0.7701389193534851  \n","Epoch:28/50     Step:6|6   loss:0.8282846212387085  \n","Epoch:28/50     Step:7|6   loss:0.7838472127914429  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:91.59%\t train set:95.78%\n","Epoch:29/50     Step:1|6   loss:0.7866885662078857  \n","Epoch:29/50     Step:2|6   loss:0.8307007551193237  \n","Epoch:29/50     Step:3|6   loss:0.7786374092102051  \n","Epoch:29/50     Step:4|6   loss:0.7331197261810303  \n","Epoch:29/50     Step:5|6   loss:0.8035616874694824  \n","Epoch:29/50     Step:6|6   loss:0.780234694480896  \n","Epoch:29/50     Step:7|6   loss:0.7852447032928467  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:91.59%\t train set:96.02%\n","Epoch:30/50     Step:1|6   loss:0.7736929655075073  \n","Epoch:30/50     Step:2|6   loss:0.7587949633598328  \n","Epoch:30/50     Step:3|6   loss:0.7760220766067505  \n","Epoch:30/50     Step:4|6   loss:0.7847210168838501  \n","Epoch:30/50     Step:5|6   loss:0.7313737869262695  \n","Epoch:30/50     Step:6|6   loss:0.7293486595153809  \n","Epoch:30/50     Step:7|6   loss:0.7237515449523926  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 81.50 %\n","current max accuracy\t test set:91.59%\t train set:96.02%\n","Epoch:31/50     Step:1|6   loss:0.7671570777893066  \n","Epoch:31/50     Step:2|6   loss:0.8028662204742432  \n","Epoch:31/50     Step:3|6   loss:0.7872648239135742  \n","Epoch:31/50     Step:4|6   loss:0.8081365823745728  \n","Epoch:31/50     Step:5|6   loss:0.7324651479721069  \n","Epoch:31/50     Step:6|6   loss:0.7865027189254761  \n","Epoch:31/50     Step:7|6   loss:0.7767177820205688  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:91.59%\t train set:96.02%\n","Epoch:32/50     Step:1|6   loss:0.7811650633811951  \n","Epoch:32/50     Step:2|6   loss:0.7690285444259644  \n","Epoch:32/50     Step:3|6   loss:0.7401537895202637  \n","Epoch:32/50     Step:4|6   loss:0.8071348667144775  \n","Epoch:32/50     Step:5|6   loss:0.7255871295928955  \n","Epoch:32/50     Step:6|6   loss:0.7535317540168762  \n","Epoch:32/50     Step:7|6   loss:0.7797759771347046  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:33/50     Step:1|6   loss:0.7846318483352661  \n","Epoch:33/50     Step:2|6   loss:0.7703032493591309  \n","Epoch:33/50     Step:3|6   loss:0.7594906687736511  \n","Epoch:33/50     Step:4|6   loss:0.7736249566078186  \n","Epoch:33/50     Step:5|6   loss:0.7677657604217529  \n","Epoch:33/50     Step:6|6   loss:0.7396221160888672  \n","Epoch:33/50     Step:7|6   loss:0.7515989542007446  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:34/50     Step:1|6   loss:0.7623507976531982  \n","Epoch:34/50     Step:2|6   loss:0.8365535736083984  \n","Epoch:34/50     Step:3|6   loss:0.7510082125663757  \n","Epoch:34/50     Step:4|6   loss:0.7498995661735535  \n","Epoch:34/50     Step:5|6   loss:0.7592619061470032  \n","Epoch:34/50     Step:6|6   loss:0.7629251480102539  \n","Epoch:34/50     Step:7|6   loss:0.7723541259765625  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:35/50     Step:1|6   loss:0.7455931305885315  \n","Epoch:35/50     Step:2|6   loss:0.74479740858078  \n","Epoch:35/50     Step:3|6   loss:0.794106125831604  \n","Epoch:35/50     Step:4|6   loss:0.7697889804840088  \n","Epoch:35/50     Step:5|6   loss:0.7805864810943604  \n","Epoch:35/50     Step:6|6   loss:0.7799612283706665  \n","Epoch:35/50     Step:7|6   loss:0.7655640840530396  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:36/50     Step:1|6   loss:0.8026466965675354  \n","Epoch:36/50     Step:2|6   loss:0.7463299036026001  \n","Epoch:36/50     Step:3|6   loss:0.7261561155319214  \n","Epoch:36/50     Step:4|6   loss:0.7215481996536255  \n","Epoch:36/50     Step:5|6   loss:0.7194149494171143  \n","Epoch:36/50     Step:6|6   loss:0.7925716638565063  \n","Epoch:36/50     Step:7|6   loss:0.7495661973953247  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:37/50     Step:1|6   loss:0.7141928672790527  \n","Epoch:37/50     Step:2|6   loss:0.7201981544494629  \n","Epoch:37/50     Step:3|6   loss:0.7421543002128601  \n","Epoch:37/50     Step:4|6   loss:0.8291206359863281  \n","Epoch:37/50     Step:5|6   loss:0.796479344367981  \n","Epoch:37/50     Step:6|6   loss:0.7759361267089844  \n","Epoch:37/50     Step:7|6   loss:0.688493013381958  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:38/50     Step:1|6   loss:0.7298089861869812  \n","Epoch:38/50     Step:2|6   loss:0.7598758339881897  \n","Epoch:38/50     Step:3|6   loss:0.8088433742523193  \n","Epoch:38/50     Step:4|6   loss:0.7492955923080444  \n","Epoch:38/50     Step:5|6   loss:0.8286213278770447  \n","Epoch:38/50     Step:6|6   loss:0.7349113821983337  \n","Epoch:38/50     Step:7|6   loss:0.7899661660194397  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 77.05 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:39/50     Step:1|6   loss:0.7566010355949402  \n","Epoch:39/50     Step:2|6   loss:0.7790536880493164  \n","Epoch:39/50     Step:3|6   loss:0.7605637907981873  \n","Epoch:39/50     Step:4|6   loss:0.7591567039489746  \n","Epoch:39/50     Step:5|6   loss:0.7341145873069763  \n","Epoch:39/50     Step:6|6   loss:0.7809947729110718  \n","Epoch:39/50     Step:7|6   loss:0.7765555381774902  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:40/50     Step:1|6   loss:0.7405244708061218  \n","Epoch:40/50     Step:2|6   loss:0.7278189063072205  \n","Epoch:40/50     Step:3|6   loss:0.7615782022476196  \n","Epoch:40/50     Step:4|6   loss:0.8017233610153198  \n","Epoch:40/50     Step:5|6   loss:0.7901926636695862  \n","Epoch:40/50     Step:6|6   loss:0.7368332147598267  \n","Epoch:40/50     Step:7|6   loss:0.7063202857971191  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:41/50     Step:1|6   loss:0.7850857973098755  \n","Epoch:41/50     Step:2|6   loss:0.748206615447998  \n","Epoch:41/50     Step:3|6   loss:0.7903715968132019  \n","Epoch:41/50     Step:4|6   loss:0.7594127655029297  \n","Epoch:41/50     Step:5|6   loss:0.7403119206428528  \n","Epoch:41/50     Step:6|6   loss:0.8004690408706665  \n","Epoch:41/50     Step:7|6   loss:0.7520256042480469  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 82.90 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:42/50     Step:1|6   loss:0.7791067361831665  \n","Epoch:42/50     Step:2|6   loss:0.7704532146453857  \n","Epoch:42/50     Step:3|6   loss:0.7101746201515198  \n","Epoch:42/50     Step:4|6   loss:0.8140436410903931  \n","2Epoch:42/50     Step:5|6   loss:0.7863283753395081  \n","Epoch:42/50     Step:6|6   loss:0.7575047612190247  \n","Epoch:42/50     Step:7|6   loss:0.8138310313224792  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:43/50     Step:1|6   loss:0.7496600151062012  \n","Epoch:43/50     Step:2|6   loss:0.7291197180747986  \n","Epoch:43/50     Step:3|6   loss:0.7548842430114746  \n","Epoch:43/50     Step:4|6   loss:0.7908228039741516  \n","Epoch:43/50     Step:5|6   loss:0.7575616240501404  \n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:43/50     Step:6|6   loss:0.7701442241668701  \n","Epoch:43/50     Step:7|6   loss:0.7367690801620483  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:44/50     Step:1|6   loss:0.7697783708572388  \n","Epoch:44/50     Step:2|6   loss:0.779678463935852  \n","Epoch:44/50     Step:3|6   loss:0.7470183968544006  \n","Epoch:44/50     Step:4|6   loss:0.8326990604400635  \n","Epoch:44/50     Step:5|6   loss:0.7521144151687622  \n","Epoch:44/50     Step:6|6   loss:0.7919963598251343  \n","Epoch:44/50     Step:7|6   loss:0.6903990507125854  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:45/50     Step:1|6   loss:0.7301019430160522  \n","Epoch:45/50     Step:2|6   loss:0.7775331735610962  \n","Epoch:45/50     Step:3|6   loss:0.7470178604125977  \n","Epoch:45/50     Step:4|6   loss:0.7188640832901001  \n","Epoch:45/50     Step:5|6   loss:0.7559666633605957  \n","Epoch:45/50     Step:6|6   loss:0.7916662693023682  \n","Epoch:45/50     Step:7|6   loss:0.7036432027816772  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 62.76 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:46/50     Step:1|6   loss:0.8038302063941956  \n","Epoch:46/50     Step:2|6   loss:0.8000024557113647  \n","Epoch:46/50     Step:3|6   loss:0.7172814607620239  \n","Epoch:46/50     Step:4|6   loss:0.7982629537582397  \n","Epoch:46/50     Step:5|6   loss:0.757707953453064  \n","Epoch:46/50     Step:6|6   loss:0.7260351181030273  \n","Epoch:46/50     Step:7|6   loss:0.7377910614013672  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:47/50     Step:1|6   loss:0.7932615280151367  \n","Epoch:47/50     Step:2|6   loss:0.7518390417098999  \n","Epoch:47/50     Step:3|6   loss:0.7455078363418579  \n","Epoch:47/50     Step:4|6   loss:0.7228653430938721  \n","Epoch:47/50     Step:5|6   loss:0.7430641651153564  \n","Epoch:47/50     Step:6|6   loss:0.7713266015052795  \n","Epoch:47/50     Step:7|6   loss:0.7359893321990967  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:48/50     Step:1|6   loss:0.7721945643424988  \n","Epoch:48/50     Step:2|6   loss:0.7142163515090942  \n","Epoch:48/50     Step:3|6   loss:0.7479758262634277  \n","Epoch:48/50     Step:4|6   loss:0.7955605387687683  \n","Epoch:48/50     Step:5|6   loss:0.7783612012863159  \n","Epoch:48/50     Step:6|6   loss:0.7821609973907471  \n","Epoch:48/50     Step:7|6   loss:0.7092592716217041  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:49/50     Step:1|6   loss:0.7380011081695557  \n","Epoch:49/50     Step:2|6   loss:0.7695927023887634  \n","Epoch:49/50     Step:3|6   loss:0.734389066696167  \n","Epoch:49/50     Step:4|6   loss:0.7531721591949463  \n","Epoch:49/50     Step:5|6   loss:0.7008059620857239  \n","Epoch:49/50     Step:6|6   loss:0.7679598927497864  \n","Epoch:49/50     Step:7|6   loss:0.7986364364624023  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:94.39%\t train set:97.42%\n","Epoch:50/50     Step:1|6   loss:0.7157230377197266  \n","Epoch:50/50     Step:2|6   loss:0.7470373511314392  \n","Epoch:50/50     Step:3|6   loss:0.7164334654808044  \n","Epoch:50/50     Step:4|6   loss:0.7329950928688049  \n","Epoch:50/50     Step:5|6   loss:0.7875268459320068  \n","Epoch:50/50     Step:6|6   loss:0.7352132797241211  \n","Epoch:50/50     Step:7|6   loss:0.7506605386734009  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:94.39%\t train set:98.36%\n","Accuracy on test_set: 94.39 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='rgb', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.13399076461792  \n","Epoch:1/50     Step:2|6   loss:1.07656729221344  \n","Epoch:1/50     Step:3|6   loss:1.1415376663208008  \n","Epoch:1/50     Step:4|6   loss:1.082599401473999  \n","Epoch:1/50     Step:5|6   loss:1.0369175672531128  \n","Epoch:1/50     Step:6|6   loss:1.0372614860534668  \n","Epoch:1/50     Step:7|6   loss:1.042282223701477  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 47.31 %\n","current max accuracy\t test set:42.99%\t train set:47.31%\n","Epoch:2/50     Step:1|6   loss:1.051474928855896  \n","Epoch:2/50     Step:2|6   loss:1.089859127998352  \n","Epoch:2/50     Step:3|6   loss:1.0438841581344604  \n","Epoch:2/50     Step:4|6   loss:1.053848385810852  \n","Epoch:2/50     Step:5|6   loss:1.0608536005020142  \n","Epoch:2/50     Step:6|6   loss:1.0246906280517578  \n","Epoch:2/50     Step:7|6   loss:0.9975396394729614  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 47.31 %\n","current max accuracy\t test set:42.99%\t train set:47.31%\n","Epoch:3/50     Step:1|6   loss:1.0475276708602905  \n","Epoch:3/50     Step:2|6   loss:1.0099709033966064  \n","Epoch:3/50     Step:3|6   loss:1.102595567703247  \n","Epoch:3/50     Step:4|6   loss:1.0114006996154785  \n","Epoch:3/50     Step:5|6   loss:1.0242550373077393  \n","Epoch:3/50     Step:6|6   loss:0.9676205515861511  \n","Epoch:3/50     Step:7|6   loss:1.0390262603759766  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 47.31 %\n","current max accuracy\t test set:42.99%\t train set:47.31%\n","Epoch:4/50     Step:1|6   loss:1.025244951248169  \n","Epoch:4/50     Step:2|6   loss:1.0184189081192017  \n","Epoch:4/50     Step:3|6   loss:1.0130621194839478  \n","Epoch:4/50     Step:4|6   loss:0.97538822889328  \n","Epoch:4/50     Step:5|6   loss:0.9811131358146667  \n","Epoch:4/50     Step:6|6   loss:1.0133702754974365  \n","Epoch:4/50     Step:7|6   loss:0.9897452592849731  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 47.31 %\n","current max accuracy\t test set:42.99%\t train set:47.31%\n","Epoch:5/50     Step:1|6   loss:0.9619096517562866  \n","Epoch:5/50     Step:2|6   loss:0.9340431690216064  \n","Epoch:5/50     Step:3|6   loss:1.0349218845367432  \n","Epoch:5/50     Step:4|6   loss:1.0189319849014282  \n","Epoch:5/50     Step:5|6   loss:0.9971848130226135  \n","Epoch:5/50     Step:6|6   loss:0.9736848473548889  \n","Epoch:5/50     Step:7|6   loss:0.9732024073600769  \n","Accuracy on test_set: 54.21 %\n","Accuracy on train_set: 59.02 %\n","current max accuracy\t test set:54.21%\t train set:59.02%\n","Epoch:6/50     Step:1|6   loss:0.9657324552536011  \n","Epoch:6/50     Step:2|6   loss:0.9565752744674683  \n","Epoch:6/50     Step:3|6   loss:1.0140602588653564  \n","Epoch:6/50     Step:4|6   loss:0.9438315033912659  \n","Epoch:6/50     Step:5|6   loss:0.9277647733688354  \n","Epoch:6/50     Step:6|6   loss:0.943382978439331  \n","Epoch:6/50     Step:7|6   loss:0.9376106262207031  \n","Accuracy on test_set: 57.94 %\n","Accuracy on train_set: 63.23 %\n","current max accuracy\t test set:57.94%\t train set:63.23%\n","Epoch:7/50     Step:1|6   loss:0.9260692000389099  \n","Epoch:7/50     Step:2|6   loss:0.9367172718048096  \n","Epoch:7/50     Step:3|6   loss:0.9654264450073242  \n","Epoch:7/50     Step:4|6   loss:0.9719027876853943  \n","Epoch:7/50     Step:5|6   loss:0.9282466769218445  \n","Epoch:7/50     Step:6|6   loss:0.9293738007545471  \n","Epoch:7/50     Step:7|6   loss:0.9776747226715088  \n","Accuracy on test_set: 57.94 %\n","Accuracy on train_set: 63.23 %\n","current max accuracy\t test set:57.94%\t train set:63.23%\n","Epoch:8/50     Step:1|6   loss:0.9086694121360779  \n","Epoch:8/50     Step:2|6   loss:0.977410614490509  \n","Epoch:8/50     Step:3|6   loss:0.9290155172348022  \n","Epoch:8/50     Step:4|6   loss:0.9195846319198608  \n","Epoch:8/50     Step:5|6   loss:0.894841730594635  \n","Epoch:8/50     Step:6|6   loss:0.9042450189590454  \n","Epoch:8/50     Step:7|6   loss:0.9266148805618286  \n","Accuracy on test_set: 58.88 %\n","Accuracy on train_set: 63.47 %\n","current max accuracy\t test set:58.88%\t train set:63.47%\n","Epoch:9/50     Step:1|6   loss:0.8808613419532776  \n","Epoch:9/50     Step:2|6   loss:0.9198813438415527  \n","Epoch:9/50     Step:3|6   loss:0.9428662061691284  \n","Epoch:9/50     Step:4|6   loss:0.9036921262741089  \n","Epoch:9/50     Step:5|6   loss:0.8844785094261169  \n","Epoch:9/50     Step:6|6   loss:0.8612726926803589  \n","Epoch:9/50     Step:7|6   loss:0.9229903817176819  \n","Accuracy on test_set: 51.40 %\n","Accuracy on train_set: 56.91 %\n","current max accuracy\t test set:58.88%\t train set:63.47%\n","Epoch:10/50     Step:1|6   loss:0.9373979568481445  \n","Epoch:10/50     Step:2|6   loss:0.8634464144706726  \n","Epoch:10/50     Step:3|6   loss:0.8869811296463013  \n","Epoch:10/50     Step:4|6   loss:0.9631602168083191  \n","Epoch:10/50     Step:5|6   loss:0.9044020175933838  \n","Epoch:10/50     Step:6|6   loss:0.8566991686820984  \n","Epoch:10/50     Step:7|6   loss:0.8578979969024658  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:83.18%\t train set:88.52%\n","Epoch:11/50     Step:1|6   loss:0.9144704937934875  \n","Epoch:11/50     Step:2|6   loss:0.8672915101051331  \n","Epoch:11/50     Step:3|6   loss:0.8665190935134888  \n","Epoch:11/50     Step:4|6   loss:0.8678501844406128  \n","Epoch:11/50     Step:5|6   loss:0.9229697585105896  \n","Epoch:11/50     Step:6|6   loss:0.9063658714294434  \n","Epoch:11/50     Step:7|6   loss:0.8557372689247131  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 82.20 %\n","current max accuracy\t test set:83.18%\t train set:88.52%\n","Epoch:12/50     Step:1|6   loss:0.8905259370803833  \n","Epoch:12/50     Step:2|6   loss:0.8705216646194458  \n","Epoch:12/50     Step:3|6   loss:0.8644559383392334  \n","Epoch:12/50     Step:4|6   loss:0.8533728122711182  \n","Epoch:12/50     Step:5|6   loss:0.8346240520477295  \n","Epoch:12/50     Step:6|6   loss:0.8922645449638367  \n","Epoch:12/50     Step:7|6   loss:0.9498623013496399  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 71.90 %\n","current max accuracy\t test set:83.18%\t train set:88.52%\n","Epoch:13/50     Step:1|6   loss:0.8751670122146606  \n","Epoch:13/50     Step:2|6   loss:0.8574531078338623  \n","Epoch:13/50     Step:3|6   loss:0.9024339914321899  \n","Epoch:13/50     Step:4|6   loss:0.8195602297782898  \n","Epoch:13/50     Step:5|6   loss:0.8189486265182495  \n","Epoch:13/50     Step:6|6   loss:0.8837080001831055  \n","Epoch:13/50     Step:7|6   loss:0.8758489489555359  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:91.59%\t train set:89.23%\n","Epoch:14/50     Step:1|6   loss:0.8232308626174927  \n","Epoch:14/50     Step:2|6   loss:0.8458430171012878  \n","Epoch:14/50     Step:3|6   loss:0.8287185430526733  \n","Epoch:14/50     Step:4|6   loss:0.8428904414176941  \n","Epoch:14/50     Step:5|6   loss:0.8983868360519409  \n","Epoch:14/50     Step:6|6   loss:0.8204373121261597  \n","Epoch:14/50     Step:7|6   loss:0.8736464381217957  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:91.59%\t train set:89.23%\n","Epoch:15/50     Step:1|6   loss:0.8366525769233704  \n","Epoch:15/50     Step:2|6   loss:0.8609422445297241  \n","Epoch:15/50     Step:3|6   loss:0.807093620300293  \n","Epoch:15/50     Step:4|6   loss:0.8249673247337341  \n","Epoch:15/50     Step:5|6   loss:0.8823233842849731  \n","Epoch:15/50     Step:6|6   loss:0.8341866731643677  \n","Epoch:15/50     Step:7|6   loss:0.862891435623169  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:16/50     Step:1|6   loss:0.8123995065689087  \n","Epoch:16/50     Step:2|6   loss:0.826704204082489  \n","Epoch:16/50     Step:3|6   loss:0.8329713344573975  \n","Epoch:16/50     Step:4|6   loss:0.8184080123901367  \n","Epoch:16/50     Step:5|6   loss:0.8548610210418701  \n","Epoch:16/50     Step:6|6   loss:0.8210890293121338  \n","Epoch:16/50     Step:7|6   loss:0.8321648240089417  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:17/50     Step:1|6   loss:0.8458831906318665  \n","Epoch:17/50     Step:2|6   loss:0.794563889503479  \n","Epoch:17/50     Step:3|6   loss:0.7874106168746948  \n","Epoch:17/50     Step:4|6   loss:0.8235613107681274  \n","Epoch:17/50     Step:5|6   loss:0.8200478553771973  \n","Epoch:17/50     Step:6|6   loss:0.8616311550140381  \n","Epoch:17/50     Step:7|6   loss:0.7679060101509094  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:18/50     Step:1|6   loss:0.8099490404129028  \n","Epoch:18/50     Step:2|6   loss:0.8248810768127441  \n","Epoch:18/50     Step:3|6   loss:0.8579207062721252  \n","Epoch:18/50     Step:4|6   loss:0.799572229385376  \n","Epoch:18/50     Step:5|6   loss:0.7653286457061768  \n","Epoch:18/50     Step:6|6   loss:0.8021067380905151  \n","Epoch:18/50     Step:7|6   loss:0.8083019256591797  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:19/50     Step:1|6   loss:0.822265625  \n","Epoch:19/50     Step:2|6   loss:0.8582615256309509  \n","Epoch:19/50     Step:3|6   loss:0.7882411479949951  \n","Epoch:19/50     Step:4|6   loss:0.815674901008606  \n","Epoch:19/50     Step:5|6   loss:0.8138980865478516  \n","Epoch:19/50     Step:6|6   loss:0.7935868501663208  \n","Epoch:19/50     Step:7|6   loss:0.8252575397491455  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:20/50     Step:1|6   loss:0.8373801708221436  \n","Epoch:20/50     Step:2|6   loss:0.8121209144592285  \n","Epoch:20/50     Step:3|6   loss:0.8252045512199402  \n","Epoch:20/50     Step:4|6   loss:0.7889451384544373  \n","Epoch:20/50     Step:5|6   loss:0.8175475597381592  \n","Epoch:20/50     Step:6|6   loss:0.854189932346344  \n","Epoch:20/50     Step:7|6   loss:0.8114570379257202  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:21/50     Step:1|6   loss:0.7965233325958252  \n","Epoch:21/50     Step:2|6   loss:0.8224904537200928  \n","Epoch:21/50     Step:3|6   loss:0.8418543338775635  \n","Epoch:21/50     Step:4|6   loss:0.7735375165939331  \n","Epoch:21/50     Step:5|6   loss:0.8090928792953491  \n","Epoch:21/50     Step:6|6   loss:0.7808805108070374  \n","Epoch:21/50     Step:7|6   loss:0.7850965261459351  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:22/50     Step:1|6   loss:0.8385927081108093  \n","Epoch:22/50     Step:2|6   loss:0.7564213275909424  \n","Epoch:22/50     Step:3|6   loss:0.7986468076705933  \n","Epoch:22/50     Step:4|6   loss:0.788820743560791  \n","Epoch:22/50     Step:5|6   loss:0.822975218296051  \n","Epoch:22/50     Step:6|6   loss:0.7893550992012024  \n","Epoch:22/50     Step:7|6   loss:0.8945318460464478  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:23/50     Step:1|6   loss:0.79795241355896  \n","Epoch:23/50     Step:2|6   loss:0.7660112380981445  \n","Epoch:23/50     Step:3|6   loss:0.805115818977356  \n","Epoch:23/50     Step:4|6   loss:0.7657332420349121  \n","Epoch:23/50     Step:5|6   loss:0.7559777498245239  \n","Epoch:23/50     Step:6|6   loss:0.7799551486968994  \n","Epoch:23/50     Step:7|6   loss:0.773565411567688  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:100.0%\t train set:98.13%\n","Epoch:24/50     Step:1|6   loss:0.8036272525787354  \n","Epoch:24/50     Step:2|6   loss:0.7368006706237793  \n","Epoch:24/50     Step:3|6   loss:0.7791084051132202  \n","Epoch:24/50     Step:4|6   loss:0.7988744974136353  \n","Epoch:24/50     Step:5|6   loss:0.7808754444122314  \n","Epoch:24/50     Step:6|6   loss:0.7979792356491089  \n","Epoch:24/50     Step:7|6   loss:0.7529195547103882  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:100.0%\t train set:98.13%\n","Epoch:25/50     Step:1|6   loss:0.7532500624656677  \n","Epoch:25/50     Step:2|6   loss:0.7725296020507812  \n","Epoch:25/50     Step:3|6   loss:0.7818043828010559  \n","Epoch:25/50     Step:4|6   loss:0.7706042528152466  \n","Epoch:25/50     Step:5|6   loss:0.7871947288513184  \n","Epoch:25/50     Step:6|6   loss:0.759652853012085  \n","Epoch:25/50     Step:7|6   loss:0.7252720594406128  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:100.0%\t train set:98.13%\n","Epoch:26/50     Step:1|6   loss:0.7158428430557251  \n","Epoch:26/50     Step:2|6   loss:0.7435284852981567  \n","Epoch:26/50     Step:3|6   loss:0.7984501123428345  \n","Epoch:26/50     Step:4|6   loss:0.7588910460472107  \n","Epoch:26/50     Step:5|6   loss:0.7990835905075073  \n","Epoch:26/50     Step:6|6   loss:0.6872645616531372  \n","Epoch:26/50     Step:7|6   loss:0.7962871789932251  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:27/50     Step:1|6   loss:0.7322372198104858  \n","Epoch:27/50     Step:2|6   loss:0.7805073857307434  \n","Epoch:27/50     Step:3|6   loss:0.7874952554702759  \n","Epoch:27/50     Step:4|6   loss:0.7734016180038452  \n","Epoch:27/50     Step:5|6   loss:0.8307122588157654  \n","Epoch:27/50     Step:6|6   loss:0.7677960395812988  \n","Epoch:27/50     Step:7|6   loss:0.7972815632820129  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:28/50     Step:1|6   loss:0.7726883888244629  \n","Epoch:28/50     Step:2|6   loss:0.7550384998321533  \n","Epoch:28/50     Step:3|6   loss:0.7663071155548096  \n","Epoch:28/50     Step:4|6   loss:0.7813994288444519  \n","Epoch:28/50     Step:5|6   loss:0.7352876663208008  \n","Epoch:28/50     Step:6|6   loss:0.7869288921356201  \n","Epoch:28/50     Step:7|6   loss:0.7988101243972778  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:29/50     Step:1|6   loss:0.767676830291748  \n","Epoch:29/50     Step:2|6   loss:0.8385459184646606  \n","Epoch:29/50     Step:3|6   loss:0.7782315611839294  \n","Epoch:29/50     Step:4|6   loss:0.7772589325904846  \n","Epoch:29/50     Step:5|6   loss:0.7265728712081909  \n","3\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:29/50     Step:6|6   loss:0.7634055614471436  \n","Epoch:29/50     Step:7|6   loss:0.7572296857833862  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:30/50     Step:1|6   loss:0.738890528678894  \n","Epoch:30/50     Step:2|6   loss:0.8137298822402954  \n","Epoch:30/50     Step:3|6   loss:0.7546449303627014  \n","Epoch:30/50     Step:4|6   loss:0.7337652444839478  \n","Epoch:30/50     Step:5|6   loss:0.7377884387969971  \n","Epoch:30/50     Step:6|6   loss:0.744825541973114  \n","Epoch:30/50     Step:7|6   loss:0.8611412048339844  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:31/50     Step:1|6   loss:0.786329984664917  \n","Epoch:31/50     Step:2|6   loss:0.7735639810562134  \n","Epoch:31/50     Step:3|6   loss:0.7527869939804077  \n","Epoch:31/50     Step:4|6   loss:0.765282154083252  \n","Epoch:31/50     Step:5|6   loss:0.7553666830062866  \n","Epoch:31/50     Step:6|6   loss:0.7106776237487793  \n","Epoch:31/50     Step:7|6   loss:0.7102729082107544  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:32/50     Step:1|6   loss:0.8078374862670898  \n","Epoch:32/50     Step:2|6   loss:0.7751927375793457  \n","Epoch:32/50     Step:3|6   loss:0.7663426399230957  \n","Epoch:32/50     Step:4|6   loss:0.7705802917480469  \n","Epoch:32/50     Step:5|6   loss:0.7695378065109253  \n","Epoch:32/50     Step:6|6   loss:0.782671332359314  \n","Epoch:32/50     Step:7|6   loss:0.7262328267097473  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:33/50     Step:1|6   loss:0.7553011775016785  \n","Epoch:33/50     Step:2|6   loss:0.7680073976516724  \n","Epoch:33/50     Step:3|6   loss:0.8010441660881042  \n","Epoch:33/50     Step:4|6   loss:0.7634867429733276  \n","Epoch:33/50     Step:5|6   loss:0.7590160369873047  \n","Epoch:33/50     Step:6|6   loss:0.785794734954834  \n","Epoch:33/50     Step:7|6   loss:0.7060122489929199  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:34/50     Step:1|6   loss:0.7951953411102295  \n","Epoch:34/50     Step:2|6   loss:0.783983588218689  \n","Epoch:34/50     Step:3|6   loss:0.796878457069397  \n","Epoch:34/50     Step:4|6   loss:0.7863667607307434  \n","Epoch:34/50     Step:5|6   loss:0.7264331579208374  \n","Epoch:34/50     Step:6|6   loss:0.7619760632514954  \n","Epoch:34/50     Step:7|6   loss:0.836804211139679  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:35/50     Step:1|6   loss:0.7614465355873108  \n","Epoch:35/50     Step:2|6   loss:0.7825862169265747  \n","Epoch:35/50     Step:3|6   loss:0.7391889095306396  \n","Epoch:35/50     Step:4|6   loss:0.7772197723388672  \n","Epoch:35/50     Step:5|6   loss:0.6820308566093445  \n","Epoch:35/50     Step:6|6   loss:0.7405290603637695  \n","Epoch:35/50     Step:7|6   loss:0.8060259819030762  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:36/50     Step:1|6   loss:0.7319082617759705  \n","Epoch:36/50     Step:2|6   loss:0.7350143194198608  \n","Epoch:36/50     Step:3|6   loss:0.7467299699783325  \n","Epoch:36/50     Step:4|6   loss:0.7556893229484558  \n","Epoch:36/50     Step:5|6   loss:0.7738094329833984  \n","Epoch:36/50     Step:6|6   loss:0.7653870582580566  \n","Epoch:36/50     Step:7|6   loss:0.7577868700027466  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:37/50     Step:1|6   loss:0.7603622674942017  \n","Epoch:37/50     Step:2|6   loss:0.742754340171814  \n","Epoch:37/50     Step:3|6   loss:0.7974461317062378  \n","Epoch:37/50     Step:4|6   loss:0.7766550183296204  \n","Epoch:37/50     Step:5|6   loss:0.7280898094177246  \n","Epoch:37/50     Step:6|6   loss:0.7701590061187744  \n","Epoch:37/50     Step:7|6   loss:0.7364624738693237  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:38/50     Step:1|6   loss:0.756953239440918  \n","Epoch:38/50     Step:2|6   loss:0.743979811668396  \n","Epoch:38/50     Step:3|6   loss:0.7292983531951904  \n","Epoch:38/50     Step:4|6   loss:0.764502763748169  \n","Epoch:38/50     Step:5|6   loss:0.7630608081817627  \n","Epoch:38/50     Step:6|6   loss:0.7838516235351562  \n","Epoch:38/50     Step:7|6   loss:0.7729151844978333  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:39/50     Step:1|6   loss:0.7703627347946167  \n","Epoch:39/50     Step:2|6   loss:0.7690443396568298  \n","Epoch:39/50     Step:3|6   loss:0.7695604562759399  \n","Epoch:39/50     Step:4|6   loss:0.7478863000869751  \n","Epoch:39/50     Step:5|6   loss:0.7423593997955322  \n","Epoch:39/50     Step:6|6   loss:0.7989241480827332  \n","Epoch:39/50     Step:7|6   loss:0.7948274612426758  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:40/50     Step:1|6   loss:0.7465894222259521  \n","Epoch:40/50     Step:2|6   loss:0.7501754760742188  \n","Epoch:40/50     Step:3|6   loss:0.7275807857513428  \n","Epoch:40/50     Step:4|6   loss:0.7452490329742432  \n","Epoch:40/50     Step:5|6   loss:0.7418363690376282  \n","Epoch:40/50     Step:6|6   loss:0.751970648765564  \n","Epoch:40/50     Step:7|6   loss:0.6872419714927673  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:41/50     Step:1|6   loss:0.7037320733070374  \n","Epoch:41/50     Step:2|6   loss:0.7922245264053345  \n","Epoch:41/50     Step:3|6   loss:0.7717508673667908  \n","Epoch:41/50     Step:4|6   loss:0.7659538984298706  \n","Epoch:41/50     Step:5|6   loss:0.743449866771698  \n","Epoch:41/50     Step:6|6   loss:0.7586434483528137  \n","Epoch:41/50     Step:7|6   loss:0.7577030658721924  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:42/50     Step:1|6   loss:0.7357146739959717  \n","Epoch:42/50     Step:2|6   loss:0.7733137607574463  \n","Epoch:42/50     Step:3|6   loss:0.7454628944396973  \n","Epoch:42/50     Step:4|6   loss:0.719301700592041  \n","Epoch:42/50     Step:5|6   loss:0.7249769568443298  \n","Epoch:42/50     Step:6|6   loss:0.7532845735549927  \n","Epoch:42/50     Step:7|6   loss:0.7228043675422668  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 81.26 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:43/50     Step:1|6   loss:0.7646816372871399  \n","Epoch:43/50     Step:2|6   loss:0.7494881749153137  \n","Epoch:43/50     Step:3|6   loss:0.7865014672279358  \n","Epoch:43/50     Step:4|6   loss:0.7894802093505859  \n","Epoch:43/50     Step:5|6   loss:0.7345908880233765  \n","Epoch:43/50     Step:6|6   loss:0.7476696968078613  \n","Epoch:43/50     Step:7|6   loss:0.8029216527938843  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:44/50     Step:1|6   loss:0.7478061318397522  \n","Epoch:44/50     Step:2|6   loss:0.7570496797561646  \n","Epoch:44/50     Step:3|6   loss:0.7905375957489014  \n","Epoch:44/50     Step:4|6   loss:0.7779643535614014  \n","Epoch:44/50     Step:5|6   loss:0.7611492872238159  \n","Epoch:44/50     Step:6|6   loss:0.7175827026367188  \n","Epoch:44/50     Step:7|6   loss:0.7286138534545898  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:45/50     Step:1|6   loss:0.7381991744041443  \n","Epoch:45/50     Step:2|6   loss:0.7690648436546326  \n","Epoch:45/50     Step:3|6   loss:0.7165902256965637  \n","Epoch:45/50     Step:4|6   loss:0.7221384644508362  \n","Epoch:45/50     Step:5|6   loss:0.7594829797744751  \n","Epoch:45/50     Step:6|6   loss:0.760755181312561  \n","Epoch:45/50     Step:7|6   loss:0.7717016339302063  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:46/50     Step:1|6   loss:0.725385844707489  \n","Epoch:46/50     Step:2|6   loss:0.772384524345398  \n","Epoch:46/50     Step:3|6   loss:0.760786771774292  \n","Epoch:46/50     Step:4|6   loss:0.7915643453598022  \n","Epoch:46/50     Step:5|6   loss:0.7700955271720886  \n","Epoch:46/50     Step:6|6   loss:0.7024628520011902  \n","Epoch:46/50     Step:7|6   loss:0.7521737813949585  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:47/50     Step:1|6   loss:0.7449833154678345  \n","Epoch:47/50     Step:2|6   loss:0.7467457056045532  \n","Epoch:47/50     Step:3|6   loss:0.7289249300956726  \n","Epoch:47/50     Step:4|6   loss:0.7209246158599854  \n","Epoch:47/50     Step:5|6   loss:0.7325106859207153  \n","Epoch:47/50     Step:6|6   loss:0.7499352693557739  \n","Epoch:47/50     Step:7|6   loss:0.7309294939041138  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:48/50     Step:1|6   loss:0.7100516557693481  \n","Epoch:48/50     Step:2|6   loss:0.7201275825500488  \n","Epoch:48/50     Step:3|6   loss:0.7450348138809204  \n","Epoch:48/50     Step:4|6   loss:0.7523307800292969  \n","Epoch:48/50     Step:5|6   loss:0.7451167702674866  \n","Epoch:48/50     Step:6|6   loss:0.7674413323402405  \n","Epoch:48/50     Step:7|6   loss:0.7637242078781128  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:49/50     Step:1|6   loss:0.7440968751907349  \n","Epoch:49/50     Step:2|6   loss:0.7846391797065735  \n","Epoch:49/50     Step:3|6   loss:0.7729039192199707  \n","Epoch:49/50     Step:4|6   loss:0.7598526477813721  \n","Epoch:49/50     Step:5|6   loss:0.7667712569236755  \n","Epoch:49/50     Step:6|6   loss:0.8060697317123413  \n","Epoch:49/50     Step:7|6   loss:0.7170453071594238  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Epoch:50/50     Step:1|6   loss:0.73921138048172  \n","Epoch:50/50     Step:2|6   loss:0.7413820028305054  \n","Epoch:50/50     Step:3|6   loss:0.7306466102600098  \n","Epoch:50/50     Step:4|6   loss:0.7304674386978149  \n","Epoch:50/50     Step:5|6   loss:0.701604962348938  \n","Epoch:50/50     Step:6|6   loss:0.7091189622879028  \n","Epoch:50/50     Step:7|6   loss:0.7671428322792053  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:100.0%\t train set:98.36%\n","Accuracy on test_set: 97.20 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='rgb', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)4\n","\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0926438570022583  \n","Epoch:1/50     Step:2|6   loss:1.1213805675506592  \n","Epoch:1/50     Step:3|6   loss:1.075264573097229  \n","Epoch:1/50     Step:4|6   loss:1.090435266494751  \n","Epoch:1/50     Step:5|6   loss:1.057884693145752  \n","Epoch:1/50     Step:6|6   loss:1.0606478452682495  \n","Epoch:1/50     Step:7|6   loss:1.0470515489578247  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 27.63 %\n","current max accuracy\t test set:25.23%\t train set:27.63%\n","Epoch:2/50     Step:1|6   loss:1.0795276165008545  \n","Epoch:2/50     Step:2|6   loss:1.0298197269439697  \n","Epoch:2/50     Step:3|6   loss:1.033588171005249  \n","Epoch:2/50     Step:4|6   loss:1.0300958156585693  \n","Epoch:2/50     Step:5|6   loss:1.0200830698013306  \n","Epoch:2/50     Step:6|6   loss:1.0082296133041382  \n","Epoch:2/50     Step:7|6   loss:0.9926304221153259  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 27.63 %\n","current max accuracy\t test set:25.23%\t train set:27.63%\n","Epoch:3/50     Step:1|6   loss:1.0016224384307861  \n","Epoch:3/50     Step:2|6   loss:0.9969915747642517  \n","Epoch:3/50     Step:3|6   loss:1.015812635421753  \n","Epoch:3/50     Step:4|6   loss:1.0076030492782593  \n","Epoch:3/50     Step:5|6   loss:0.9857362508773804  \n","Epoch:3/50     Step:6|6   loss:0.9599447250366211  \n","Epoch:3/50     Step:7|6   loss:0.9670429229736328  \n","Accuracy on test_set: 41.12 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:41.12%\t train set:49.18%\n","Epoch:4/50     Step:1|6   loss:0.9659837484359741  \n","Epoch:4/50     Step:2|6   loss:0.9632124900817871  \n","Epoch:4/50     Step:3|6   loss:0.979404866695404  \n","Epoch:4/50     Step:4|6   loss:0.9544206857681274  \n","Epoch:4/50     Step:5|6   loss:0.981968879699707  \n","Epoch:4/50     Step:6|6   loss:0.9829652309417725  \n","Epoch:4/50     Step:7|6   loss:0.9356518387794495  \n","Accuracy on test_set: 41.12 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:41.12%\t train set:49.18%\n","Epoch:5/50     Step:1|6   loss:0.966262698173523  \n","Epoch:5/50     Step:2|6   loss:0.9580727219581604  \n","Epoch:5/50     Step:3|6   loss:0.951025128364563  \n","Epoch:5/50     Step:4|6   loss:0.9536880254745483  \n","Epoch:5/50     Step:5|6   loss:0.9366888999938965  \n","Epoch:5/50     Step:6|6   loss:0.9016720056533813  \n","Epoch:5/50     Step:7|6   loss:0.9733659029006958  \n","Accuracy on test_set: 41.12 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:41.12%\t train set:49.18%\n","Epoch:6/50     Step:1|6   loss:0.9344265460968018  \n","Epoch:6/50     Step:2|6   loss:0.93589848279953  \n","Epoch:6/50     Step:3|6   loss:0.926006555557251  \n","Epoch:6/50     Step:4|6   loss:0.9309160113334656  \n","Epoch:6/50     Step:5|6   loss:0.9402588605880737  \n","Epoch:6/50     Step:6|6   loss:0.8990331292152405  \n","Epoch:6/50     Step:7|6   loss:0.9845039248466492  \n","Accuracy on test_set: 41.12 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:41.12%\t train set:49.18%\n","Epoch:7/50     Step:1|6   loss:0.9010123014450073  \n","Epoch:7/50     Step:2|6   loss:0.9084153175354004  \n","Epoch:7/50     Step:3|6   loss:0.9121608734130859  \n","Epoch:7/50     Step:4|6   loss:0.8919690847396851  \n","Epoch:7/50     Step:5|6   loss:0.9241418242454529  \n","Epoch:7/50     Step:6|6   loss:0.8857517242431641  \n","Epoch:7/50     Step:7|6   loss:0.9690902233123779  \n","Accuracy on test_set: 41.12 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:41.12%\t train set:49.18%\n","Epoch:8/50     Step:1|6   loss:0.9264669418334961  \n","Epoch:8/50     Step:2|6   loss:0.9074434638023376  \n","Epoch:8/50     Step:3|6   loss:0.9117424488067627  \n","Epoch:8/50     Step:4|6   loss:0.8981707096099854  \n","Epoch:8/50     Step:5|6   loss:0.8487901091575623  \n","Epoch:8/50     Step:6|6   loss:0.9178969264030457  \n","Epoch:8/50     Step:7|6   loss:0.9046053886413574  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 50.35 %\n","current max accuracy\t test set:43.93%\t train set:50.35%\n","Epoch:9/50     Step:1|6   loss:0.8987104892730713  \n","Epoch:9/50     Step:2|6   loss:0.8814084529876709  \n","Epoch:9/50     Step:3|6   loss:0.919120192527771  \n","Epoch:9/50     Step:4|6   loss:0.8899635076522827  \n","Epoch:9/50     Step:5|6   loss:0.8920467495918274  \n","Epoch:9/50     Step:6|6   loss:0.8459839820861816  \n","Epoch:9/50     Step:7|6   loss:0.8610215783119202  \n","Accuracy on test_set: 57.01 %\n","Accuracy on train_set: 61.83 %\n","current max accuracy\t test set:57.01%\t train set:61.83%\n","Epoch:10/50     Step:1|6   loss:0.8858906030654907  \n","Epoch:10/50     Step:2|6   loss:0.9013821482658386  \n","Epoch:10/50     Step:3|6   loss:0.8905299305915833  \n","Epoch:10/50     Step:4|6   loss:0.8871387243270874  \n","Epoch:10/50     Step:5|6   loss:0.8593721389770508  \n","Epoch:10/50     Step:6|6   loss:0.8627887964248657  \n","Epoch:10/50     Step:7|6   loss:0.8813328146934509  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 69.79 %\n","current max accuracy\t test set:71.96%\t train set:69.79%\n","Epoch:11/50     Step:1|6   loss:0.8522439002990723  \n","Epoch:11/50     Step:2|6   loss:0.8382240533828735  \n","Epoch:11/50     Step:3|6   loss:0.8207249641418457  \n","Epoch:11/50     Step:4|6   loss:0.8886057734489441  \n","Epoch:11/50     Step:5|6   loss:0.8704133033752441  \n","Epoch:11/50     Step:6|6   loss:0.8727839589118958  \n","Epoch:11/50     Step:7|6   loss:0.9052826762199402  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 70.02 %\n","current max accuracy\t test set:71.96%\t train set:70.02%\n","Epoch:12/50     Step:1|6   loss:0.8582260608673096  \n","Epoch:12/50     Step:2|6   loss:0.8656174540519714  \n","Epoch:12/50     Step:3|6   loss:0.8747996091842651  \n","Epoch:12/50     Step:4|6   loss:0.8478668928146362  \n","Epoch:12/50     Step:5|6   loss:0.8067479133605957  \n","Epoch:12/50     Step:6|6   loss:0.8350789546966553  \n","Epoch:12/50     Step:7|6   loss:0.8815123438835144  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:94.39%\t train set:93.68%\n","Epoch:13/50     Step:1|6   loss:0.828662097454071  \n","Epoch:13/50     Step:2|6   loss:0.8436213135719299  \n","Epoch:13/50     Step:3|6   loss:0.7993100881576538  \n","Epoch:13/50     Step:4|6   loss:0.8535816669464111  \n","Epoch:13/50     Step:5|6   loss:0.8466598987579346  \n","Epoch:13/50     Step:6|6   loss:0.7843190431594849  \n","Epoch:13/50     Step:7|6   loss:0.821336030960083  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:94.39%\t train set:93.68%\n","Epoch:14/50     Step:1|6   loss:0.8063007593154907  \n","Epoch:14/50     Step:2|6   loss:0.8255524635314941  \n","Epoch:14/50     Step:3|6   loss:0.8422497510910034  \n","Epoch:14/50     Step:4|6   loss:0.8474172353744507  \n","Epoch:14/50     Step:5|6   loss:0.8267021179199219  \n","Epoch:14/50     Step:6|6   loss:0.8492635488510132  \n","Epoch:14/50     Step:7|6   loss:0.8254045248031616  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:94.39%\t train set:93.68%\n","Epoch:15/50     Step:1|6   loss:0.8103905916213989  \n","Epoch:15/50     Step:2|6   loss:0.8097659349441528  \n","Epoch:15/50     Step:3|6   loss:0.8102996349334717  \n","Epoch:15/50     Step:4|6   loss:0.7884035110473633  \n","Epoch:15/50     Step:5|6   loss:0.8480007648468018  \n","Epoch:15/50     Step:6|6   loss:0.8745794296264648  \n","Epoch:15/50     Step:7|6   loss:0.8291796445846558  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:16/50     Step:1|6   loss:0.805169939994812  \n","Epoch:16/50     Step:2|6   loss:0.778293251991272  \n","Epoch:16/50     Step:3|6   loss:0.7940469980239868  \n","Epoch:16/50     Step:4|6   loss:0.818115234375  \n","Epoch:16/50     Step:5|6   loss:0.8391047716140747  \n","Epoch:16/50     Step:6|6   loss:0.8067106008529663  \n","Epoch:16/50     Step:7|6   loss:0.8195458650588989  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:17/50     Step:1|6   loss:0.8002114295959473  \n","Epoch:17/50     Step:2|6   loss:0.8352894186973572  \n","Epoch:17/50     Step:3|6   loss:0.8149015307426453  \n","Epoch:17/50     Step:4|6   loss:0.8198139667510986  \n","Epoch:17/50     Step:5|6   loss:0.8185139894485474  \n","Epoch:17/50     Step:6|6   loss:0.7964495420455933  \n","Epoch:17/50     Step:7|6   loss:0.7767670154571533  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 89.46 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:18/50     Step:1|6   loss:0.8397567272186279  \n","Epoch:18/50     Step:2|6   loss:0.7938883304595947  \n","Epoch:18/50     Step:3|6   loss:0.8065317273139954  \n","Epoch:18/50     Step:4|6   loss:0.8079296350479126  \n","Epoch:18/50     Step:5|6   loss:0.7574106454849243  \n","Epoch:18/50     Step:6|6   loss:0.8463034629821777  \n","Epoch:18/50     Step:7|6   loss:0.769088625907898  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:19/50     Step:1|6   loss:0.8108457326889038  \n","Epoch:19/50     Step:2|6   loss:0.806398332118988  \n","Epoch:19/50     Step:3|6   loss:0.8137134313583374  \n","Epoch:19/50     Step:4|6   loss:0.7679593563079834  \n","Epoch:19/50     Step:5|6   loss:0.7806053757667542  \n","Epoch:19/50     Step:6|6   loss:0.775276780128479  \n","Epoch:19/50     Step:7|6   loss:0.7817988991737366  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:20/50     Step:1|6   loss:0.7882710099220276  \n","Epoch:20/50     Step:2|6   loss:0.8151402473449707  \n","Epoch:20/50     Step:3|6   loss:0.780217170715332  \n","Epoch:20/50     Step:4|6   loss:0.842271089553833  \n","Epoch:20/50     Step:5|6   loss:0.7767243385314941  \n","Epoch:20/50     Step:6|6   loss:0.7900879383087158  \n","Epoch:20/50     Step:7|6   loss:0.819333553314209  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:21/50     Step:1|6   loss:0.8148094415664673  \n","Epoch:21/50     Step:2|6   loss:0.8084875345230103  \n","Epoch:21/50     Step:3|6   loss:0.8183434009552002  \n","Epoch:21/50     Step:4|6   loss:0.7488675117492676  \n","Epoch:21/50     Step:5|6   loss:0.8663672208786011  \n","Epoch:21/50     Step:6|6   loss:0.8249415755271912  \n","Epoch:21/50     Step:7|6   loss:0.8235388994216919  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:22/50     Step:1|6   loss:0.7835807800292969  \n","Epoch:22/50     Step:2|6   loss:0.7934815883636475  \n","Epoch:22/50     Step:3|6   loss:0.8068041801452637  \n","Epoch:22/50     Step:4|6   loss:0.8365768194198608  \n","Epoch:22/50     Step:5|6   loss:0.7958697080612183  \n","Epoch:22/50     Step:6|6   loss:0.797856330871582  \n","Epoch:22/50     Step:7|6   loss:0.7516721487045288  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:23/50     Step:1|6   loss:0.76092529296875  \n","Epoch:23/50     Step:2|6   loss:0.8143766522407532  \n","Epoch:23/50     Step:3|6   loss:0.7733353972434998  \n","Epoch:23/50     Step:4|6   loss:0.7696903944015503  \n","Epoch:23/50     Step:5|6   loss:0.8263260126113892  \n","Epoch:23/50     Step:6|6   loss:0.7715764045715332  \n","Epoch:23/50     Step:7|6   loss:0.7334798574447632  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:24/50     Step:1|6   loss:0.776907205581665  \n","Epoch:24/50     Step:2|6   loss:0.7650750875473022  \n","Epoch:24/50     Step:3|6   loss:0.7951647639274597  \n","Epoch:24/50     Step:4|6   loss:0.8170742988586426  \n","Epoch:24/50     Step:5|6   loss:0.804781436920166  \n","Epoch:24/50     Step:6|6   loss:0.7350664138793945  \n","Epoch:24/50     Step:7|6   loss:0.7526857852935791  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:25/50     Step:1|6   loss:0.7244977951049805  \n","Epoch:25/50     Step:2|6   loss:0.8019461631774902  \n","Epoch:25/50     Step:3|6   loss:0.8239754438400269  \n","Epoch:25/50     Step:4|6   loss:0.7664107084274292  \n","Epoch:25/50     Step:5|6   loss:0.7789624929428101  \n","Epoch:25/50     Step:6|6   loss:0.8338228464126587  \n","Epoch:25/50     Step:7|6   loss:0.7817932367324829  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:26/50     Step:1|6   loss:0.7512694597244263  \n","Epoch:26/50     Step:2|6   loss:0.7632749080657959  \n","Epoch:26/50     Step:3|6   loss:0.8161568641662598  \n","Epoch:26/50     Step:4|6   loss:0.7815011739730835  \n","Epoch:26/50     Step:5|6   loss:0.7677552700042725  \n","Epoch:26/50     Step:6|6   loss:0.7397845387458801  \n","Epoch:26/50     Step:7|6   loss:0.7694476246833801  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:27/50     Step:1|6   loss:0.7907099723815918  \n","Epoch:27/50     Step:2|6   loss:0.7715721726417542  \n","Epoch:27/50     Step:3|6   loss:0.7253525257110596  \n","Epoch:27/50     Step:4|6   loss:0.7753283977508545  \n","Epoch:27/50     Step:5|6   loss:0.798612654209137  \n","Epoch:27/50     Step:6|6   loss:0.7472860217094421  \n","Epoch:27/50     Step:7|6   loss:0.765703558921814  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 76.35 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:28/50     Step:1|6   loss:0.7640360593795776  \n","Epoch:28/50     Step:2|6   loss:0.8010768890380859  \n","Epoch:28/50     Step:3|6   loss:0.7643920183181763  \n","Epoch:28/50     Step:4|6   loss:0.7683173418045044  \n","Epoch:28/50     Step:5|6   loss:0.7542476654052734  \n","Epoch:28/50     Step:6|6   loss:0.8186947703361511  \n","Epoch:28/50     Step:7|6   loss:0.7906007766723633  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:29/50     Step:1|6   loss:0.7652299404144287  \n","Epoch:29/50     Step:2|6   loss:0.8009952306747437  \n","Epoch:29/50     Step:3|6   loss:0.7621445655822754  \n","Epoch:29/50     Step:4|6   loss:0.7832530736923218  \n","Epoch:29/50     Step:5|6   loss:0.7406154274940491  \n","Epoch:29/50     Step:6|6   loss:0.7678038477897644  \n","Epoch:29/50     Step:7|6   loss:0.7820992469787598  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:30/50     Step:1|6   loss:0.8004590272903442  \n","Epoch:30/50     Step:2|6   loss:0.751416802406311  \n","Epoch:30/50     Step:3|6   loss:0.7244364023208618  \n","Epoch:30/50     Step:4|6   loss:0.7640182971954346  \n","Epoch:30/50     Step:5|6   loss:0.7865544557571411  \n","Epoch:30/50     Step:6|6   loss:0.7502199411392212  \n","Epoch:30/50     Step:7|6   loss:0.7919756174087524  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:31/50     Step:1|6   loss:0.751390278339386  \n","Epoch:31/50     Step:2|6   loss:0.806387186050415  \n","Epoch:31/50     Step:3|6   loss:0.7546064853668213  \n","Epoch:31/50     Step:4|6   loss:0.7469283938407898  \n","Epoch:31/50     Step:5|6   loss:0.8642198443412781  \n","Epoch:31/50     Step:6|6   loss:0.774268627166748  \n","Epoch:31/50     Step:7|6   loss:0.822284996509552  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 79.63 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:32/50     Step:1|6   loss:0.7968867421150208  \n","Epoch:32/50     Step:2|6   loss:0.740309476852417  \n","Epoch:32/50     Step:3|6   loss:0.7753442525863647  \n","Epoch:32/50     Step:4|6   loss:0.7210928201675415  \n","Epoch:32/50     Step:5|6   loss:0.8067029118537903  \n","Epoch:32/50     Step:6|6   loss:0.7547324895858765  \n","Epoch:32/50     Step:7|6   loss:0.6610221266746521  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:33/50     Step:1|6   loss:0.759244441986084  \n","Epoch:33/50     Step:2|6   loss:0.7748808860778809  \n","Epoch:33/50     Step:3|6   loss:0.8407725095748901  \n","Epoch:33/50     Step:4|6   loss:0.7331746816635132  \n","Epoch:33/50     Step:5|6   loss:0.749746561050415  \n","Epoch:33/50     Step:6|6   loss:0.6912053823471069  \n","Epoch:33/50     Step:7|6   loss:0.7473584413528442  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:34/50     Step:1|6   loss:0.7450953722000122  \n","Epoch:34/50     Step:2|6   loss:0.7861392498016357  \n","Epoch:34/50     Step:3|6   loss:0.7978759407997131  \n","Epoch:34/50     Step:4|6   loss:0.7616020441055298  \n","Epoch:34/50     Step:5|6   loss:0.7464503049850464  \n","Epoch:34/50     Step:6|6   loss:0.7530494332313538  \n","Epoch:34/50     Step:7|6   loss:0.6640633940696716  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:35/50     Step:1|6   loss:0.7293946743011475  \n","Epoch:35/50     Step:2|6   loss:0.736948549747467  \n","Epoch:35/50     Step:3|6   loss:0.7448861598968506  \n","Epoch:35/50     Step:4|6   loss:0.7624390125274658  \n","Epoch:35/50     Step:5|6   loss:0.7442349195480347  \n","Epoch:35/50     Step:6|6   loss:0.7719714045524597  \n","Epoch:35/50     Step:7|6   loss:0.7418123483657837  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:36/50     Step:1|6   loss:0.7020910978317261  \n","Epoch:36/50     Step:2|6   loss:0.7480365037918091  \n","Epoch:36/50     Step:3|6   loss:0.7600077390670776  \n","Epoch:36/50     Step:4|6   loss:0.8160971403121948  \n","Epoch:36/50     Step:5|6   loss:0.7599294185638428  \n","Epoch:36/50     Step:6|6   loss:0.756533682346344  \n","Epoch:36/50     Step:7|6   loss:0.8117730617523193  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:37/50     Step:1|6   loss:0.7145320177078247  \n","Epoch:37/50     Step:2|6   loss:0.7852692604064941  \n","Epoch:37/50     Step:3|6   loss:0.722196102142334  \n","Epoch:37/50     Step:4|6   loss:0.779184103012085  \n","Epoch:37/50     Step:5|6   loss:0.7635675668716431  \n","Epoch:37/50     Step:6|6   loss:0.7707580924034119  \n","Epoch:37/50     Step:7|6   loss:0.7346352338790894  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:38/50     Step:1|6   loss:0.7776368856430054  \n","Epoch:38/50     Step:2|6   loss:0.8068466782569885  \n","Epoch:38/50     Step:3|6   loss:0.7990260124206543  \n","Epoch:38/50     Step:4|6   loss:0.7285830974578857  \n","Epoch:38/50     Step:5|6   loss:0.7312480807304382  \n","Epoch:38/50     Step:6|6   loss:0.7907676100730896  \n","Epoch:38/50     Step:7|6   loss:0.8152687549591064  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:39/50     Step:1|6   loss:0.718838095664978  \n","Epoch:39/50     Step:2|6   loss:0.7364686131477356  \n","Epoch:39/50     Step:3|6   loss:0.7525964379310608  \n","Epoch:39/50     Step:4|6   loss:0.7090069055557251  \n","Epoch:39/50     Step:5|6   loss:0.7073642015457153  \n","Epoch:39/50     Step:6|6   loss:0.7723593711853027  \n","Epoch:39/50     Step:7|6   loss:0.7887069582939148  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:40/50     Step:1|6   loss:0.748221218585968  \n","Epoch:40/50     Step:2|6   loss:0.7314624786376953  \n","Epoch:40/50     Step:3|6   loss:0.7238080501556396  \n","Epoch:40/50     Step:4|6   loss:0.8232265710830688  \n","Epoch:40/50     Step:5|6   loss:0.7388235926628113  \n","Epoch:40/50     Step:6|6   loss:0.7865017652511597  \n","Epoch:40/50     Step:7|6   loss:0.7577609419822693  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:41/50     Step:1|6   loss:0.7782449722290039  \n","Epoch:41/50     Step:2|6   loss:0.7684004902839661  \n","Epoch:41/50     Step:3|6   loss:0.7626460790634155  \n","Epoch:41/50     Step:4|6   loss:0.7310751676559448  \n","Epoch:41/50     Step:5|6   loss:0.7721315026283264  \n","Epoch:41/50     Step:6|6   loss:0.7507185935974121  \n","Epoch:41/50     Step:7|6   loss:0.8012744188308716  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:42/50     Step:1|6   loss:0.7565507888793945  \n","Epoch:42/50     Step:2|6   loss:0.7876781225204468  \n","Epoch:42/50     Step:3|6   loss:0.7268350124359131  \n","Epoch:42/50     Step:4|6   loss:0.7442901134490967  \n","Epoch:42/50     Step:5|6   loss:0.6796882748603821  \n","Epoch:42/50     Step:6|6   loss:0.7798962593078613  \n","Epoch:42/50     Step:7|6   loss:0.7670929431915283  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:43/50     Step:1|6   loss:0.7045843005180359  \n","Epoch:43/50     Step:2|6   loss:0.7227292060852051  \n","Epoch:43/50     Step:3|6   loss:0.7668833136558533  \n","Epoch:43/50     Step:4|6   loss:0.7834612131118774  \n","Epoch:43/50     Step:5|6   loss:0.8146542310714722  \n","Epoch:43/50     Step:6|6   loss:0.7375035285949707  \n","Epoch:43/50     Step:7|6   loss:0.7426057457923889  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:44/50     Step:1|6   loss:0.774619996547699  \n","Epoch:44/50     Step:2|6   loss:0.7636090517044067  \n","Epoch:44/50     Step:3|6   loss:0.7858670949935913  \n","Epoch:44/50     Step:4|6   loss:0.7744678854942322  \n","Epoch:44/50     Step:5|6   loss:0.7298154234886169  \n","Epoch:44/50     Step:6|6   loss:0.6902248859405518  \n","Epoch:44/50     Step:7|6   loss:0.733043372631073  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:45/50     Step:1|6   loss:0.7011150121688843  \n","Epoch:45/50     Step:2|6   loss:0.7532694935798645  \n","Epoch:45/50     Step:3|6   loss:0.7094458341598511  \n","Epoch:45/50     Step:4|6   loss:0.7176077365875244  \n","Epoch:45/50     Step:5|6   loss:0.745378851890564  \n","Epoch:45/50     Step:6|6   loss:0.7855184078216553  \n","Epoch:45/50     Step:7|6   loss:0.7853261232376099  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:46/50     Step:1|6   loss:0.7867084741592407  \n","Epoch:46/50     Step:2|6   loss:0.744147777557373  \n","Epoch:46/50     Step:3|6   loss:0.7403789758682251  \n","Epoch:46/50     Step:4|6   loss:0.722209095954895  \n","Epoch:46/50     Step:5|6   loss:0.7432283163070679  \n","Epoch:46/50     Step:6|6   loss:0.7714016437530518  \n","Epoch:46/50     Step:7|6   loss:0.8013393878936768  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:47/50     Step:1|6   loss:0.736819863319397  \n","Epoch:47/50     Step:2|6   loss:0.7183715105056763  \n","Epoch:47/50     Step:3|6   loss:0.7448359727859497  \n","Epoch:47/50     Step:4|6   loss:0.7024999856948853  \n","Epoch:47/50     Step:5|6   loss:0.8163672685623169  \n","Epoch:47/50     Step:6|6   loss:0.7417951226234436  \n","Epoch:47/50     Step:7|6   loss:0.7805687189102173  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:48/50     Step:1|6   loss:0.7338013648986816  \n","Epoch:48/50     Step:2|6   loss:0.7163320183753967  \n","Epoch:48/50     Step:3|6   loss:0.7499915361404419  \n","Epoch:48/50     Step:4|6   loss:0.7704180479049683  \n","Epoch:48/50     Step:5|6   loss:0.7652860283851624  \n","Epoch:48/50     Step:6|6   loss:0.6802488565444946  \n","Epoch:48/50     Step:7|6   loss:0.7546836137771606  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:49/50     Step:1|6   loss:0.7558996677398682  \n","Epoch:49/50     Step:2|6   loss:0.7374268770217896  \n","Epoch:49/50     Step:3|6   loss:0.7547929286956787  \n","Epoch:49/50     Step:4|6   loss:0.7880730628967285  \n","Epoch:49/50     Step:5|6   loss:0.7458264827728271  \n","Epoch:49/50     Step:6|6   loss:0.7789661884307861  \n","Epoch:49/50     Step:7|6   loss:0.7157279253005981  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:50/50     Step:1|6   loss:0.7403368949890137  \n","Epoch:50/50     Step:2|6   loss:0.7180282473564148  \n","Epoch:50/50     Step:3|6   loss:0.7091678380966187  \n","Epoch:50/50     Step:4|6   loss:0.7154558897018433  \n","Epoch:50/50     Step:5|6   loss:0.7715959548950195  \n","Epoch:50/50     Step:6|6   loss:0.7467422485351562  \n","Epoch:50/50     Step:7|6   loss:0.7290503978729248  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='rgb', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0971770286560059  \n","Epoch:1/50     Step:2|6   loss:1.0872045755386353  \n","Epoch:1/50     Step:3|6   loss:1.089127540588379  \n","Epoch:1/50     Step:4|6   loss:1.1183996200561523  \n","Epoch:1/50     Step:5|6   loss:1.0975574254989624  \n","Epoch:1/50     Step:6|6   loss:1.0927081108093262  \n","Epoch:1/50     Step:7|6   loss:1.1449915170669556  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 45.43 %\n","current max accuracy\t test set:49.53%\t train set:45.43%\n","Epoch:2/50     Step:1|6   loss:1.0751607418060303  \n","Epoch:2/50     Step:2|6   loss:1.0673866271972656  \n","Epoch:2/50     Step:3|6   loss:1.074861764907837  \n","Epoch:2/50     Step:4|6   loss:1.0598714351654053  \n","Epoch:2/50     Step:5|6   loss:1.0789995193481445  \n","Epoch:2/50     Step:6|6   loss:1.0969033241271973  \n","Epoch:2/50     Step:7|6   loss:1.070271372795105  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 45.43 %\n","current max accuracy\t test set:49.53%\t train set:45.43%\n","Epoch:3/50     Step:1|6   loss:1.1422284841537476  \n","Epoch:3/50     Step:2|6   loss:1.0179015398025513  \n","Epoch:3/50     Step:3|6   loss:1.0831010341644287  \n","Epoch:3/50     Step:4|6   loss:1.0744048357009888  \n","Epoch:3/50     Step:5|6   loss:1.0089830160140991  \n","Epoch:3/50     Step:6|6   loss:1.0122003555297852  \n","Epoch:3/50     Step:7|6   loss:1.0952816009521484  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 45.43 %\n","current max accuracy\t test set:49.53%\t train set:45.43%\n","Epoch:4/50     Step:1|6   loss:1.0873626470565796  \n","Epoch:4/50     Step:2|6   loss:1.031448245048523  \n","Epoch:4/50     Step:3|6   loss:0.9990940690040588  \n","Epoch:4/50     Step:4|6   loss:1.074318766593933  \n","Epoch:4/50     Step:5|6   loss:1.0111981630325317  \n","Epoch:4/50     Step:6|6   loss:1.0456833839416504  \n","Epoch:4/50     Step:7|6   loss:1.1452785730361938  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 45.43 %\n","current max accuracy\t test set:49.53%\t train set:45.43%\n","Epoch:5/50     Step:1|6   loss:1.0926676988601685  \n","Epoch:5/50     Step:2|6   loss:1.0659033060073853  \n","Epoch:5/50     Step:3|6   loss:1.0087504386901855  \n","Epoch:5/50     Step:4|6   loss:0.9989408850669861  \n","Epoch:5/50     Step:5|6   loss:1.0663676261901855  \n","Epoch:5/50     Step:6|6   loss:1.014788031578064  \n","Epoch:5/50     Step:7|6   loss:0.9913851618766785  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 45.43 %\n","current max accuracy\t test set:49.53%\t train set:45.43%\n","Epoch:6/50     Step:1|6   loss:1.0049586296081543  \n","Epoch:6/50     Step:2|6   loss:1.0260210037231445  \n","Epoch:6/50     Step:3|6   loss:1.0118221044540405  \n","Epoch:6/50     Step:4|6   loss:1.0158759355545044  \n","Epoch:6/50     Step:5|6   loss:1.0209708213806152  \n","Epoch:6/50     Step:6|6   loss:1.0124155282974243  \n","Epoch:6/50     Step:7|6   loss:1.0289151668548584  \n","Accuracy on test_set: 49.53 %\n","Accuracy on train_set: 45.43 %\n","current max accuracy\t test set:49.53%\t train set:45.43%\n","Epoch:7/50     Step:1|6   loss:0.9698269963264465  \n","Epoch:7/50     Step:2|6   loss:1.049118995666504  \n","Epoch:7/50     Step:3|6   loss:0.9736641645431519  \n","Epoch:7/50     Step:4|6   loss:0.9963331818580627  \n","Epoch:7/50     Step:5|6   loss:1.005483627319336  \n","Epoch:7/50     Step:6|6   loss:0.9922744631767273  \n","Epoch:7/50     Step:7|6   loss:1.0246026515960693  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 46.60 %\n","current max accuracy\t test set:50.47%\t train set:46.6%\n","Epoch:8/50     Step:1|6   loss:0.9726627469062805  \n","Epoch:8/50     Step:2|6   loss:1.0003726482391357  \n","Epoch:8/50     Step:3|6   loss:0.9896276593208313  \n","Epoch:8/50     Step:4|6   loss:0.9665180444717407  \n","Epoch:8/50     Step:5|6   loss:0.9806514382362366  \n","Epoch:8/50     Step:6|6   loss:0.9684876799583435  \n","Epoch:8/50     Step:7|6   loss:1.070009708404541  \n","Accuracy on test_set: 52.34 %\n","Accuracy on train_set: 51.05 %\n","current max accuracy\t test set:52.34%\t train set:51.05%\n","Epoch:9/50     Step:1|6   loss:1.01823890209198  \n","Epoch:9/50     Step:2|6   loss:0.9393308758735657  \n","Epoch:9/50     Step:3|6   loss:0.9981235265731812  \n","Epoch:9/50     Step:4|6   loss:0.926598072052002  \n","Epoch:9/50     Step:5|6   loss:1.0203821659088135  \n","Epoch:9/50     Step:6|6   loss:0.941569447517395  \n","Epoch:9/50     Step:7|6   loss:0.9563750624656677  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 66.28 %\n","current max accuracy\t test set:65.42%\t train set:66.28%\n","Epoch:10/50     Step:1|6   loss:0.9403454661369324  \n","Epoch:10/50     Step:2|6   loss:0.9162570238113403  \n","Epoch:10/50     Step:3|6   loss:0.918624997138977  \n","Epoch:10/50     Step:4|6   loss:0.9420689940452576  \n","Epoch:10/50     Step:5|6   loss:0.9710483551025391  \n","Epoch:10/50     Step:6|6   loss:0.9511590600013733  \n","Epoch:10/50     Step:7|6   loss:0.9688305258750916  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 70.26 %\n","current max accuracy\t test set:74.77%\t train set:70.26%\n","Epoch:11/50     Step:1|6   loss:0.9122569561004639  \n","Epoch:11/50     Step:2|6   loss:0.9317090511322021  \n","Epoch:11/50     Step:3|6   loss:0.9414684772491455  \n","Epoch:11/50     Step:4|6   loss:0.9259992241859436  \n","Epoch:11/50     Step:5|6   loss:0.9948639869689941  \n","Epoch:11/50     Step:6|6   loss:0.925900936126709  \n","Epoch:11/50     Step:7|6   loss:0.9267986416816711  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 68.38 %\n","current max accuracy\t test set:74.77%\t train set:70.26%\n","Epoch:12/50     Step:1|6   loss:0.9403343796730042  \n","Epoch:12/50     Step:2|6   loss:0.9106766581535339  \n","Epoch:12/50     Step:3|6   loss:0.9200119972229004  \n","Epoch:12/50     Step:4|6   loss:0.9184519648551941  \n","Epoch:12/50     Step:5|6   loss:0.9343116879463196  \n","Epoch:12/50     Step:6|6   loss:0.9632530212402344  \n","Epoch:12/50     Step:7|6   loss:0.9599990844726562  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 62.06 %\n","current max accuracy\t test set:74.77%\t train set:70.26%\n","Epoch:13/50     Step:1|6   loss:0.9175907373428345  \n","Epoch:13/50     Step:2|6   loss:0.9278724193572998  \n","Epoch:13/50     Step:3|6   loss:0.9529816508293152  \n","Epoch:13/50     Step:4|6   loss:0.9279689192771912  \n","Epoch:13/50     Step:5|6   loss:0.9287198781967163  \n","Epoch:13/50     Step:6|6   loss:0.8831490278244019  \n","Epoch:13/50     Step:7|6   loss:0.9065500497817993  \n","Accuracy on test_set: 66.36 %\n","Accuracy on train_set: 62.76 %\n","current max accuracy\t test set:74.77%\t train set:70.26%\n","Epoch:14/50     Step:1|6   loss:0.898421049118042  \n","Epoch:14/50     Step:2|6   loss:0.90840744972229  \n","Epoch:14/50     Step:3|6   loss:0.9260256290435791  \n","Epoch:14/50     Step:4|6   loss:0.8905491828918457  \n","Epoch:14/50     Step:5|6   loss:0.9063689708709717  \n","Epoch:14/50     Step:6|6   loss:0.9190129041671753  \n","Epoch:14/50     Step:7|6   loss:0.9008128643035889  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 68.62 %\n","current max accuracy\t test set:74.77%\t train set:70.26%\n","Epoch:15/50     Step:1|6   loss:0.9248347282409668  \n","Epoch:15/50     Step:2|6   loss:0.9157141447067261  \n","Epoch:15/50     Step:3|6   loss:0.9020836353302002  \n","Epoch:15/50     Step:4|6   loss:0.8799027800559998  \n","Epoch:15/50     Step:5|6   loss:0.8929951786994934  \n","Epoch:15/50     Step:6|6   loss:0.8912097215652466  \n","Epoch:15/50     Step:7|6   loss:0.8924895524978638  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 71.43 %\n","current max accuracy\t test set:74.77%\t train set:71.43%\n","Epoch:16/50     Step:1|6   loss:0.963960587978363  \n","Epoch:16/50     Step:2|6   loss:0.9499837756156921  \n","Epoch:16/50     Step:3|6   loss:0.8638100624084473  \n","Epoch:16/50     Step:4|6   loss:0.8635255098342896  \n","Epoch:16/50     Step:5|6   loss:0.8776655793190002  \n","Epoch:16/50     Step:6|6   loss:0.875466525554657  \n","Epoch:16/50     Step:7|6   loss:0.8804763555526733  \n","Accuracy on test_set: 70.09 %\n","Accuracy on train_set: 69.32 %\n","current max accuracy\t test set:74.77%\t train set:71.43%\n","Epoch:17/50     Step:1|6   loss:0.9099770188331604  \n","Epoch:17/50     Step:2|6   loss:0.8667998313903809  \n","Epoch:17/50     Step:3|6   loss:0.9159786701202393  \n","Epoch:17/50     Step:4|6   loss:0.9174566268920898  \n","Epoch:17/50     Step:5|6   loss:0.840610921382904  \n","Epoch:17/50     Step:6|6   loss:0.9019289016723633  \n","Epoch:17/50     Step:7|6   loss:0.8838151097297668  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 81.03 %\n","current max accuracy\t test set:76.64%\t train set:81.03%\n","Epoch:18/50     Step:1|6   loss:0.8891680836677551  \n","Epoch:18/50     Step:2|6   loss:0.910261332988739  \n","Epoch:18/50     Step:3|6   loss:0.8840188980102539  \n","Epoch:18/50     Step:4|6   loss:0.9002759456634521  \n","Epoch:18/50     Step:5|6   loss:0.8157850503921509  \n","Epoch:18/50     Step:6|6   loss:0.8679895997047424  \n","Epoch:18/50     Step:7|6   loss:0.9641909599304199  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 81.73 %\n","current max accuracy\t test set:81.31%\t train set:81.73%\n","Epoch:19/50     Step:1|6   loss:0.828280508518219  \n","Epoch:19/50     Step:2|6   loss:0.8415618538856506  \n","Epoch:19/50     Step:3|6   loss:0.8229519128799438  \n","Epoch:19/50     Step:4|6   loss:0.8155710697174072  \n","Epoch:19/50     Step:5|6   loss:0.8509159088134766  \n","Epoch:19/50     Step:6|6   loss:0.937095046043396  \n","Epoch:19/50     Step:7|6   loss:0.8949042558670044  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:87.85%\t train set:86.18%\n","Epoch:20/50     Step:1|6   loss:0.8766387701034546  \n","Epoch:20/50     Step:2|6   loss:0.8527495861053467  \n","Epoch:20/50     Step:3|6   loss:0.8508172035217285  \n","Epoch:20/50     Step:4|6   loss:0.818406879901886  \n","Epoch:20/50     Step:5|6   loss:0.8485099077224731  \n","Epoch:20/50     Step:6|6   loss:0.8871128559112549  \n","Epoch:20/50     Step:7|6   loss:0.8514417409896851  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 74.47 %\n","current max accuracy\t test set:87.85%\t train set:86.18%\n","Epoch:21/50     Step:1|6   loss:0.8514134287834167  \n","Epoch:21/50     Step:2|6   loss:0.9089264869689941  \n","Epoch:21/50     Step:3|6   loss:0.8303705453872681  \n","Epoch:21/50     Step:4|6   loss:0.9055668115615845  \n","Epoch:21/50     Step:5|6   loss:0.8318085670471191  \n","Epoch:21/50     Step:6|6   loss:0.8139746189117432  \n","Epoch:21/50     Step:7|6   loss:0.9083021879196167  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:22/50     Step:1|6   loss:0.8871339559555054  \n","Epoch:22/50     Step:2|6   loss:0.8509324193000793  \n","Epoch:22/50     Step:3|6   loss:0.8730632066726685  \n","Epoch:22/50     Step:4|6   loss:0.7941446304321289  \n","Epoch:22/50     Step:5|6   loss:0.8715283870697021  \n","Epoch:22/50     Step:6|6   loss:0.8573466539382935  \n","Epoch:22/50     Step:7|6   loss:0.8371877074241638  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:23/50     Step:1|6   loss:0.8303830623626709  \n","Epoch:23/50     Step:2|6   loss:0.8277852535247803  \n","Epoch:23/50     Step:3|6   loss:0.9148739576339722  \n","Epoch:23/50     Step:4|6   loss:0.8076626062393188  \n","Epoch:23/50     Step:5|6   loss:0.8748880624771118  \n","Epoch:23/50     Step:6|6   loss:0.8610061407089233  \n","Epoch:23/50     Step:7|6   loss:0.8455855250358582  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:94.39%\t train set:95.32%\n","Epoch:24/50     Step:1|6   loss:0.7966463565826416  \n","Epoch:24/50     Step:2|6   loss:0.8172590136528015  \n","Epoch:24/50     Step:3|6   loss:0.8184757828712463  \n","Epoch:24/50     Step:4|6   loss:0.8060613870620728  \n","Epoch:24/50     Step:5|6   loss:0.8569738864898682  \n","Epoch:24/50     Step:6|6   loss:0.8382643461227417  \n","Epoch:24/50     Step:7|6   loss:0.7698704600334167  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:97.2%\t train set:95.55%\n","Epoch:25/50     Step:1|6   loss:0.8737508058547974  \n","Epoch:25/50     Step:2|6   loss:0.8190857172012329  \n","Epoch:25/50     Step:3|6   loss:0.853762686252594  \n","Epoch:25/50     Step:4|6   loss:0.855297863483429  \n","Epoch:25/50     Step:5|6   loss:0.8309458494186401  \n","Epoch:25/50     Step:6|6   loss:0.8235825300216675  \n","Epoch:25/50     Step:7|6   loss:0.8613427877426147  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:97.2%\t train set:96.49%\n","Epoch:26/50     Step:1|6   loss:0.8469647169113159  \n","Epoch:26/50     Step:2|6   loss:0.7981228828430176  \n","Epoch:26/50     Step:3|6   loss:0.8039959669113159  \n","Epoch:26/50     Step:4|6   loss:0.8558162450790405  \n","Epoch:26/50     Step:5|6   loss:0.7731043100357056  \n","Epoch:26/50     Step:6|6   loss:0.8172063827514648  \n","Epoch:26/50     Step:7|6   loss:0.7832213640213013  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:97.2%\t train set:96.49%\n","Epoch:27/50     Step:1|6   loss:0.8127086162567139  \n","Epoch:27/50     Step:2|6   loss:0.8081672191619873  \n","Epoch:27/50     Step:3|6   loss:0.8126181364059448  \n","Epoch:27/50     Step:4|6   loss:0.8304368257522583  \n","Epoch:27/50     Step:5|6   loss:0.8040834069252014  \n","Epoch:27/50     Step:6|6   loss:0.8212804794311523  \n","Epoch:27/50     Step:7|6   loss:0.7751544713973999  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:28/50     Step:1|6   loss:0.8514003753662109  \n","Epoch:28/50     Step:2|6   loss:0.8230493068695068  \n","Epoch:28/50     Step:3|6   loss:0.8128448128700256  \n","Epoch:28/50     Step:4|6   loss:0.8412092328071594  \n","Epoch:28/50     Step:5|6   loss:0.8618963956832886  \n","Epoch:28/50     Step:6|6   loss:0.8200521469116211  \n","Epoch:28/50     Step:7|6   loss:0.766326904296875  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:29/50     Step:1|6   loss:0.8077816963195801  \n","Epoch:29/50     Step:2|6   loss:0.8113111853599548  \n","Epoch:29/50     Step:3|6   loss:0.8240944743156433  \n","Epoch:29/50     Step:4|6   loss:0.8155305981636047  \n","Epoch:29/50     Step:5|6   loss:0.8302550315856934  \n","Epoch:29/50     Step:6|6   loss:0.76885986328125  \n","Epoch:29/50     Step:7|6   loss:0.8089727163314819  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:30/50     Step:1|6   loss:0.8075048923492432  \n","Epoch:30/50     Step:2|6   loss:0.7590072751045227  \n","Epoch:30/50     Step:3|6   loss:0.8381664752960205  \n","Epoch:30/50     Step:4|6   loss:0.8220455050468445  \n","Epoch:30/50     Step:5|6   loss:0.8044356107711792  \n","Epoch:30/50     Step:6|6   loss:0.8171378374099731  \n","Epoch:30/50     Step:7|6   loss:0.8141297101974487  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:31/50     Step:1|6   loss:0.8113720417022705  \n","Epoch:31/50     Step:2|6   loss:0.7421367168426514  \n","Epoch:31/50     Step:3|6   loss:0.7002741694450378  \n","Epoch:31/50     Step:4|6   loss:0.8197354078292847  \n","Epoch:31/50     Step:5|6   loss:0.8055388927459717  \n","Epoch:31/50     Step:6|6   loss:0.7891995906829834  \n","Epoch:31/50     Step:7|6   loss:0.8347185254096985  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:32/50     Step:1|6   loss:0.782770037651062  \n","Epoch:32/50     Step:2|6   loss:0.7904388904571533  \n","Epoch:32/50     Step:3|6   loss:0.796082615852356  \n","Epoch:32/50     Step:4|6   loss:0.77802973985672  \n","Epoch:32/50     Step:5|6   loss:0.7670067548751831  \n","Epoch:32/50     Step:6|6   loss:0.7903925180435181  \n","Epoch:32/50     Step:7|6   loss:0.8051263689994812  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:33/50     Step:1|6   loss:0.772554874420166  \n","Epoch:33/50     Step:2|6   loss:0.7962496280670166  \n","Epoch:33/50     Step:3|6   loss:0.8243677616119385  \n","Epoch:33/50     Step:4|6   loss:0.8220429420471191  \n","Epoch:33/50     Step:5|6   loss:0.8601787686347961  \n","Epoch:33/50     Step:6|6   loss:0.8474617600440979  \n","Epoch:33/50     Step:7|6   loss:0.7764267325401306  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:34/50     Step:1|6   loss:0.7803379893302917  \n","Epoch:34/50     Step:2|6   loss:0.8112369775772095  \n","Epoch:34/50     Step:3|6   loss:0.7705153822898865  \n","Epoch:34/50     Step:4|6   loss:0.7448673248291016  \n","Epoch:34/50     Step:5|6   loss:0.8510869741439819  \n","Epoch:34/50     Step:6|6   loss:0.821211576461792  \n","Epoch:34/50     Step:7|6   loss:0.8267717361450195  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:35/50     Step:1|6   loss:0.798998236656189  \n","Epoch:35/50     Step:2|6   loss:0.7716614603996277  \n","Epoch:35/50     Step:3|6   loss:0.7856135368347168  \n","Epoch:35/50     Step:4|6   loss:0.7938209772109985  \n","Epoch:35/50     Step:5|6   loss:0.7864795923233032  \n","Epoch:35/50     Step:6|6   loss:0.8018327951431274  \n","Epoch:35/50     Step:7|6   loss:0.7207745909690857  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:36/50     Step:1|6   loss:0.7609647512435913  \n","Epoch:36/50     Step:2|6   loss:0.8151660561561584  \n","Epoch:36/50     Step:3|6   loss:0.7712814807891846  \n","Epoch:36/50     Step:4|6   loss:0.7631280422210693  \n","Epoch:36/50     Step:5|6   loss:0.7794115543365479  \n","Epoch:36/50     Step:6|6   loss:0.7766023874282837  \n","Epoch:36/50     Step:7|6   loss:0.8164211511611938  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:37/50     Step:1|6   loss:0.7438511848449707  \n","Epoch:37/50     Step:2|6   loss:0.8161063194274902  \n","Epoch:37/50     Step:3|6   loss:0.7954856157302856  \n","Epoch:37/50     Step:4|6   loss:0.8094029426574707  \n","Epoch:37/50     Step:5|6   loss:0.7341251373291016  \n","Epoch:37/50     Step:6|6   loss:0.7992616891860962  \n","Epoch:37/50     Step:7|6   loss:0.7554041147232056  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:97.2%\t train set:96.96%\n","Epoch:38/50     Step:1|6   loss:0.8069453835487366  \n","Epoch:38/50     Step:2|6   loss:0.8062461614608765  \n","Epoch:38/50     Step:3|6   loss:0.8023301362991333  \n","Epoch:38/50     Step:4|6   loss:0.7910190224647522  \n","Epoch:38/50     Step:5|6   loss:0.7909011840820312  \n","Epoch:38/50     Step:6|6   loss:0.7394795417785645  \n","Epoch:38/50     Step:7|6   loss:0.7183858156204224  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:97.2%\t train set:96.96%\n","Epoch:39/50     Step:1|6   loss:0.7502120733261108  \n","Epoch:39/50     Step:2|6   loss:0.7915442585945129  \n","Epoch:39/50     Step:3|6   loss:0.7536338567733765  \n","Epoch:39/50     Step:4|6   loss:0.7765732407569885  \n","Epoch:39/50     Step:5|6   loss:0.7787642478942871  \n","Epoch:39/50     Step:6|6   loss:0.7831137180328369  \n","Epoch:39/50     Step:7|6   loss:0.8297910690307617  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:97.2%\t train set:96.96%\n","Epoch:40/50     Step:1|6   loss:0.7893894910812378  \n","Epoch:40/50     Step:2|6   loss:0.8014671206474304  \n","Epoch:40/50     Step:3|6   loss:0.7165834903717041  \n","Epoch:40/50     Step:4|6   loss:0.7781071662902832  \n","Epoch:40/50     Step:5|6   loss:0.7843600511550903  \n","Epoch:40/50     Step:6|6   loss:0.7981826066970825  \n","Epoch:40/50     Step:7|6   loss:0.7381381988525391  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:41/50     Step:1|6   loss:0.769721508026123  \n","Epoch:41/50     Step:2|6   loss:0.7917293906211853  \n","Epoch:41/50     Step:3|6   loss:0.8461014628410339  \n","Epoch:41/50     Step:4|6   loss:0.7396619915962219  \n","Epoch:41/50     Step:5|6   loss:0.7972773313522339  \n","Epoch:41/50     Step:6|6   loss:0.7626549005508423  \n","Epoch:41/50     Step:7|6   loss:0.7520806789398193  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:42/50     Step:1|6   loss:0.7530293464660645  \n","Epoch:42/50     Step:2|6   loss:0.7907721996307373  \n","Epoch:42/50     Step:3|6   loss:0.7649335265159607  \n","Epoch:42/50     Step:4|6   loss:0.7648471593856812  \n","Epoch:42/50     Step:5|6   loss:0.8035585880279541  \n","Epoch:42/50     Step:6|6   loss:0.7796415090560913  \n","Epoch:42/50     Step:7|6   loss:0.7609255909919739  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:43/50     Step:1|6   loss:0.7741602659225464  \n","Epoch:43/50     Step:2|6   loss:0.812494158744812  \n","Epoch:43/50     Step:3|6   loss:0.7932400703430176  \n","Epoch:43/50     Step:4|6   loss:0.783960223197937  \n","Epoch:43/50     Step:5|6   loss:0.8148564696311951  \n","Epoch:43/50     Step:6|6   loss:0.7742695808410645  \n","Epoch:43/50     Step:7|6   loss:0.8140625953674316  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:44/50     Step:1|6   loss:0.7705440521240234  \n","Epoch:44/50     Step:2|6   loss:0.7241581082344055  \n","Epoch:44/50     Step:3|6   loss:0.7909715175628662  \n","Epoch:44/50     Step:4|6   loss:0.7551743984222412  \n","Epoch:44/50     Step:5|6   loss:0.7666051387786865  \n","Epoch:44/50     Step:6|6   loss:0.7775369882583618  \n","Epoch:44/50     Step:7|6   loss:0.7713111639022827  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:45/50     Step:1|6   loss:0.744461178779602  \n","Epoch:45/50     Step:2|6   loss:0.7597963809967041  \n","Epoch:45/50     Step:3|6   loss:0.7786630988121033  \n","Epoch:45/50     Step:4|6   loss:0.7800570726394653  \n","Epoch:45/50     Step:5|6   loss:0.7223728895187378  \n","Epoch:45/50     Step:6|6   loss:0.7949541211128235  \n","Epoch:45/50     Step:7|6   loss:0.7932409048080444  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:46/50     Step:1|6   loss:0.7265450358390808  \n","Epoch:46/50     Step:2|6   loss:0.8004204034805298  \n","Epoch:46/50     Step:3|6   loss:0.8255528211593628  \n","Epoch:46/50     Step:4|6   loss:0.7528321743011475  \n","Epoch:46/50     Step:5|6   loss:0.7890276908874512  \n","Epoch:46/50     Step:6|6   loss:0.7478746771812439  \n","Epoch:46/50     Step:7|6   loss:0.7161543369293213  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:47/50     Step:1|6   loss:0.7328643798828125  \n","Epoch:47/50     Step:2|6   loss:0.7993570566177368  \n","Epoch:47/50     Step:3|6   loss:0.7382717728614807  \n","Epoch:47/50     Step:4|6   loss:0.7697888016700745  \n","Epoch:47/50     Step:5|6   loss:0.7715766429901123  \n","Epoch:47/50     Step:6|6   loss:0.7480993270874023  \n","Epoch:47/50     Step:7|6   loss:0.831196665763855  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:48/50     Step:1|6   loss:0.7984899282455444  \n","Epoch:48/50     Step:2|6   loss:0.7765061259269714  \n","Epoch:48/50     Step:3|6   loss:0.7992314100265503  \n","Epoch:48/50     Step:4|6   loss:0.775241494178772  \n","Epoch:48/50     Step:5|6   loss:0.7583745718002319  \n","Epoch:48/50     Step:6|6   loss:0.7262973189353943  \n","Epoch:48/50     Step:7|6   loss:0.7904771566390991  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:49/50     Step:1|6   loss:0.8140017986297607  \n","Epoch:49/50     Step:2|6   loss:0.7726421356201172  \n","Epoch:49/50     Step:3|6   loss:0.7752282619476318  \n","Epoch:49/50     Step:4|6   loss:0.7855718731880188  \n","Epoch:49/50     Step:5|6   loss:0.7579754590988159  \n","Epoch:49/50     Step:6|6   loss:0.7332992553710938  \n","Epoch:49/50     Step:7|6   loss:0.772324800491333  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:50/50     Step:1|6   loss:0.7716116905212402  \n","Epoch:50/50     Step:2|6   loss:0.782325804233551  \n","Epoch:50/50     Step:3|6   loss:0.7467547655105591  \n","Epoch:50/50     Step:4|6   loss:0.7941080331802368  \n","Epoch:50/50     Step:5|6   loss:0.7646356225013733  \n","Epoch:50/50     Step:6|6   loss:0.7547619342803955  \n","Epoch:50/50     Step:7|6   loss:0.7245683670043945  \n","Accuracy on test_set: 57.01 %\n","Accuracy on train_set: 58.55 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Accuracy on test_set: 57.01 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-3 --model Flame_one_stream --mode rgb --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":7,"id":"1297b4f8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='ir', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.20529305934906  \n","Epoch:1/50     Step:2|6   loss:1.1141481399536133  \n","Epoch:1/50     Step:3|6   loss:1.1988548040390015  \n","Epoch:1/50     Step:4|6   loss:1.0946365594863892  \n","Epoch:1/50     Step:5|6   loss:1.172996163368225  \n","Epoch:1/50     Step:6|6   loss:1.1760907173156738  \n","Epoch:1/50     Step:7|6   loss:1.0397757291793823  \n","Accuracy on test_set: 28.97 %\n","Accuracy on train_set: 30.44 %\n","current max accuracy\t test set:28.97%\t train set:30.44%\n","Epoch:2/50     Step:1|6   loss:1.1053998470306396  \n","Epoch:2/50     Step:2|6   loss:1.0424964427947998  \n","Epoch:2/50     Step:3|6   loss:1.024903416633606  \n","Epoch:2/50     Step:4|6   loss:1.1032623052597046  \n","Epoch:2/50     Step:5|6   loss:1.1201412677764893  \n","Epoch:2/50     Step:6|6   loss:1.1273317337036133  \n","Epoch:2/50     Step:7|6   loss:1.1091135740280151  \n","Accuracy on test_set: 28.97 %\n","Accuracy on train_set: 30.44 %\n","current max accuracy\t test set:28.97%\t train set:30.44%\n","Epoch:3/50     Step:1|6   loss:1.1280303001403809  \n","Epoch:3/50     Step:2|6   loss:1.065094232559204  \n","Epoch:3/50     Step:3|6   loss:1.0523557662963867  \n","Epoch:3/50     Step:4|6   loss:1.070117712020874  \n","Epoch:3/50     Step:5|6   loss:1.0854429006576538  \n","Epoch:3/50     Step:6|6   loss:1.05303955078125  \n","Epoch:3/50     Step:7|6   loss:1.0737950801849365  \n","Accuracy on test_set: 28.97 %\n","Accuracy on train_set: 30.44 %\n","current max accuracy\t test set:28.97%\t train set:30.44%\n","Epoch:4/50     Step:1|6   loss:1.013455867767334  \n","Epoch:4/50     Step:2|6   loss:1.0284020900726318  \n","Epoch:4/50     Step:3|6   loss:1.0398554801940918  \n","Epoch:4/50     Step:4|6   loss:1.0650811195373535  \n","Epoch:4/50     Step:5|6   loss:1.1152771711349487  \n","Epoch:4/50     Step:6|6   loss:1.0290281772613525  \n","Epoch:4/50     Step:7|6   loss:1.0186662673950195  \n","Accuracy on test_set: 29.91 %\n","Accuracy on train_set: 30.44 %\n","current max accuracy\t test set:29.91%\t train set:30.44%\n","Epoch:5/50     Step:1|6   loss:1.027674913406372  \n","Epoch:5/50     Step:2|6   loss:1.0097421407699585  \n","Epoch:5/50     Step:3|6   loss:1.0249733924865723  \n","Epoch:5/50     Step:4|6   loss:0.9908339381217957  \n","Epoch:5/50     Step:5|6   loss:1.051330804824829  \n","Epoch:5/50     Step:6|6   loss:1.0007274150848389  \n","Epoch:5/50     Step:7|6   loss:1.0256637334823608  \n","Accuracy on test_set: 37.38 %\n","Accuracy on train_set: 43.33 %\n","current max accuracy\t test set:37.38%\t train set:43.33%\n","Epoch:6/50     Step:1|6   loss:0.9854751229286194  \n","Epoch:6/50     Step:2|6   loss:1.031125783920288  \n","Epoch:6/50     Step:3|6   loss:0.9744403958320618  \n","Epoch:6/50     Step:4|6   loss:1.0122661590576172  \n","Epoch:6/50     Step:5|6   loss:0.9938579797744751  \n","Epoch:6/50     Step:6|6   loss:1.018738865852356  \n","Epoch:6/50     Step:7|6   loss:0.9673947095870972  \n","Accuracy on test_set: 40.19 %\n","Accuracy on train_set: 48.95 %\n","current max accuracy\t test set:40.19%\t train set:48.95%\n","Epoch:7/50     Step:1|6   loss:1.0329978466033936  \n","Epoch:7/50     Step:2|6   loss:0.9562655091285706  \n","Epoch:7/50     Step:3|6   loss:1.02024245262146  \n","Epoch:7/50     Step:4|6   loss:0.9734384417533875  \n","Epoch:7/50     Step:5|6   loss:1.015813946723938  \n","Epoch:7/50     Step:6|6   loss:0.9786627888679504  \n","Epoch:7/50     Step:7|6   loss:1.0326849222183228  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 53.40 %\n","current max accuracy\t test set:42.99%\t train set:53.4%\n","Epoch:8/50     Step:1|6   loss:0.954737663269043  \n","Epoch:8/50     Step:2|6   loss:1.0082526206970215  \n","Epoch:8/50     Step:3|6   loss:0.9153512716293335  \n","Epoch:8/50     Step:4|6   loss:0.9215234518051147  \n","Epoch:8/50     Step:5|6   loss:0.984371542930603  \n","Epoch:8/50     Step:6|6   loss:0.9742075204849243  \n","Epoch:8/50     Step:7|6   loss:0.9514864683151245  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 75.18 %\n","current max accuracy\t test set:68.22%\t train set:75.18%\n","Epoch:9/50     Step:1|6   loss:0.9332305192947388  \n","Epoch:9/50     Step:2|6   loss:0.9244038462638855  \n","Epoch:9/50     Step:3|6   loss:0.9711929559707642  \n","Epoch:9/50     Step:4|6   loss:1.0115474462509155  \n","Epoch:9/50     Step:5|6   loss:0.9058856964111328  \n","Epoch:9/50     Step:6|6   loss:0.942706823348999  \n","Epoch:9/50     Step:7|6   loss:0.8851611018180847  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 80.33 %\n","current max accuracy\t test set:75.7%\t train set:80.33%\n","Epoch:10/50     Step:1|6   loss:0.9542418718338013  \n","Epoch:10/50     Step:2|6   loss:0.8958311080932617  \n","Epoch:10/50     Step:3|6   loss:0.8961236476898193  \n","Epoch:10/50     Step:4|6   loss:0.9671907424926758  \n","Epoch:10/50     Step:5|6   loss:0.9208531379699707  \n","Epoch:10/50     Step:6|6   loss:0.917056679725647  \n","Epoch:10/50     Step:7|6   loss:0.9004538059234619  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 81.73 %\n","current max accuracy\t test set:75.7%\t train set:81.73%\n","Epoch:11/50     Step:1|6   loss:0.858574628829956  \n","Epoch:11/50     Step:2|6   loss:0.9400583505630493  \n","Epoch:11/50     Step:3|6   loss:0.8805553913116455  \n","Epoch:11/50     Step:4|6   loss:0.9876375198364258  \n","Epoch:11/50     Step:5|6   loss:0.9452810883522034  \n","Epoch:11/50     Step:6|6   loss:1.0032225847244263  \n","Epoch:11/50     Step:7|6   loss:0.9744136333465576  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 82.44 %\n","current max accuracy\t test set:75.7%\t train set:82.44%\n","Epoch:12/50     Step:1|6   loss:0.9689399003982544  \n","Epoch:12/50     Step:2|6   loss:0.8864355087280273  \n","Epoch:12/50     Step:3|6   loss:0.9354981780052185  \n","Epoch:12/50     Step:4|6   loss:0.9170331358909607  \n","Epoch:12/50     Step:5|6   loss:0.9298514127731323  \n","Epoch:12/50     Step:6|6   loss:0.9200668334960938  \n","Epoch:12/50     Step:7|6   loss:0.901121973991394  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 83.14 %\n","current max accuracy\t test set:75.7%\t train set:83.14%\n","Epoch:13/50     Step:1|6   loss:0.8598703742027283  \n","Epoch:13/50     Step:2|6   loss:0.847858190536499  \n","Epoch:13/50     Step:3|6   loss:0.8797652721405029  \n","Epoch:13/50     Step:4|6   loss:0.8532652854919434  \n","Epoch:13/50     Step:5|6   loss:0.8984849452972412  \n","Epoch:13/50     Step:6|6   loss:0.8725024461746216  \n","Epoch:13/50     Step:7|6   loss:0.9624240398406982  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:78.5%\t train set:83.84%\n","Epoch:14/50     Step:1|6   loss:0.8723281621932983  \n","Epoch:14/50     Step:2|6   loss:0.9046381711959839  \n","Epoch:14/50     Step:3|6   loss:0.9092700481414795  \n","Epoch:14/50     Step:4|6   loss:0.9674525260925293  \n","Epoch:14/50     Step:5|6   loss:0.8681575059890747  \n","Epoch:14/50     Step:6|6   loss:0.9063389301300049  \n","Epoch:14/50     Step:7|6   loss:0.8918545246124268  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:78.5%\t train set:84.78%\n","Epoch:15/50     Step:1|6   loss:0.946968674659729  \n","Epoch:15/50     Step:2|6   loss:0.8638433814048767  \n","Epoch:15/50     Step:3|6   loss:0.8805991411209106  \n","Epoch:15/50     Step:4|6   loss:0.8220017552375793  \n","Epoch:15/50     Step:5|6   loss:0.9347383379936218  \n","Epoch:15/50     Step:6|6   loss:0.8973312377929688  \n","Epoch:15/50     Step:7|6   loss:0.9072667360305786  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:79.44%\t train set:85.71%\n","Epoch:16/50     Step:1|6   loss:0.8652664422988892  \n","Epoch:16/50     Step:2|6   loss:0.8825125098228455  \n","Epoch:16/50     Step:3|6   loss:0.8385937213897705  \n","Epoch:16/50     Step:4|6   loss:0.9301206469535828  \n","Epoch:16/50     Step:5|6   loss:0.863014817237854  \n","Epoch:16/50     Step:6|6   loss:0.8929538726806641  \n","Epoch:16/50     Step:7|6   loss:0.872099757194519  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:79.44%\t train set:85.95%\n","Epoch:17/50     Step:1|6   loss:0.8803473711013794  \n","Epoch:17/50     Step:2|6   loss:0.8557944297790527  \n","Epoch:17/50     Step:3|6   loss:0.886254608631134  \n","Epoch:17/50     Step:4|6   loss:0.9423759579658508  \n","Epoch:17/50     Step:5|6   loss:0.8918585777282715  \n","Epoch:17/50     Step:6|6   loss:0.9061216115951538  \n","Epoch:17/50     Step:7|6   loss:0.8704372644424438  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:79.44%\t train set:85.95%\n","Epoch:18/50     Step:1|6   loss:0.8379553556442261  \n","Epoch:18/50     Step:2|6   loss:0.8666723966598511  \n","Epoch:18/50     Step:3|6   loss:0.8747273683547974  \n","Epoch:18/50     Step:4|6   loss:0.8807797431945801  \n","Epoch:18/50     Step:5|6   loss:0.9034824371337891  \n","Epoch:18/50     Step:6|6   loss:0.8664499521255493  \n","Epoch:18/50     Step:7|6   loss:0.8281357288360596  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:79.44%\t train set:85.95%\n","Epoch:19/50     Step:1|6   loss:0.8648346662521362  \n","Epoch:19/50     Step:2|6   loss:0.8598719835281372  \n","Epoch:19/50     Step:3|6   loss:0.8396845459938049  \n","Epoch:19/50     Step:4|6   loss:0.8529693484306335  \n","Epoch:19/50     Step:5|6   loss:0.8318601846694946  \n","Epoch:19/50     Step:6|6   loss:0.8831098079681396  \n","Epoch:19/50     Step:7|6   loss:0.7929569482803345  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:79.44%\t train set:86.42%\n","Epoch:20/50     Step:1|6   loss:0.8638210296630859  \n","Epoch:20/50     Step:2|6   loss:0.8653496503829956  \n","Epoch:20/50     Step:3|6   loss:0.8381993770599365  \n","Epoch:20/50     Step:4|6   loss:0.8494998216629028  \n","Epoch:20/50     Step:5|6   loss:0.8503889441490173  \n","Epoch:20/50     Step:6|6   loss:0.8937841653823853  \n","Epoch:20/50     Step:7|6   loss:0.9332979917526245  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:79.44%\t train set:86.65%\n","Epoch:21/50     Step:1|6   loss:0.8544837236404419  \n","Epoch:21/50     Step:2|6   loss:0.8467966318130493  \n","Epoch:21/50     Step:3|6   loss:0.8466281890869141  \n","Epoch:21/50     Step:4|6   loss:0.8605535626411438  \n","Epoch:21/50     Step:5|6   loss:0.9206849336624146  \n","Epoch:21/50     Step:6|6   loss:0.8808995485305786  \n","Epoch:21/50     Step:7|6   loss:0.9084606170654297  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:79.44%\t train set:86.65%\n","Epoch:22/50     Step:1|6   loss:0.8285359144210815  \n","Epoch:22/50     Step:2|6   loss:0.8980576992034912  \n","Epoch:22/50     Step:3|6   loss:0.8592197299003601  \n","Epoch:22/50     Step:4|6   loss:0.8100417852401733  \n","Epoch:22/50     Step:5|6   loss:0.8236398100852966  \n","Epoch:22/50     Step:6|6   loss:0.857649028301239  \n","Epoch:22/50     Step:7|6   loss:0.866308331489563  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:79.44%\t train set:86.65%\n","Epoch:23/50     Step:1|6   loss:0.8850904107093811  \n","Epoch:23/50     Step:2|6   loss:0.8883465528488159  \n","Epoch:23/50     Step:3|6   loss:0.8221998810768127  \n","Epoch:23/50     Step:4|6   loss:0.8752049207687378  \n","Epoch:23/50     Step:5|6   loss:0.899055004119873  \n","Epoch:23/50     Step:6|6   loss:0.8388092517852783  \n","Epoch:23/50     Step:7|6   loss:0.8227307200431824  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:79.44%\t train set:86.65%\n","Epoch:24/50     Step:1|6   loss:0.8697322010993958  \n","Epoch:24/50     Step:2|6   loss:0.8550664186477661  \n","Epoch:24/50     Step:3|6   loss:0.9056028723716736  \n","Epoch:24/50     Step:4|6   loss:0.8725782036781311  \n","Epoch:24/50     Step:5|6   loss:0.8421584367752075  \n","Epoch:24/50     Step:6|6   loss:0.8553028106689453  \n","Epoch:24/50     Step:7|6   loss:0.8943396210670471  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:79.44%\t train set:86.65%\n","Epoch:25/50     Step:1|6   loss:0.8422641754150391  \n","Epoch:25/50     Step:2|6   loss:0.8514434695243835  \n","Epoch:25/50     Step:3|6   loss:0.8719924688339233  \n","Epoch:25/50     Step:4|6   loss:0.8630838394165039  \n","Epoch:25/50     Step:5|6   loss:0.8537791967391968  \n","Epoch:25/50     Step:6|6   loss:0.8442891836166382  \n","Epoch:25/50     Step:7|6   loss:0.8384692668914795  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:80.37%\t train set:86.65%\n","Epoch:26/50     Step:1|6   loss:0.9003238677978516  \n","Epoch:26/50     Step:2|6   loss:0.8556362986564636  \n","Epoch:26/50     Step:3|6   loss:0.8021731972694397  \n","Epoch:26/50     Step:4|6   loss:0.8484611511230469  \n","Epoch:26/50     Step:5|6   loss:0.8585237264633179  \n","Epoch:26/50     Step:6|6   loss:0.8308202028274536  \n","Epoch:26/50     Step:7|6   loss:0.8553814888000488  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:80.37%\t train set:86.65%\n","Epoch:27/50     Step:1|6   loss:0.8792069554328918  \n","Epoch:27/50     Step:2|6   loss:0.827730119228363  \n","Epoch:27/50     Step:3|6   loss:0.8826966285705566  \n","Epoch:27/50     Step:4|6   loss:0.8253568410873413  \n","Epoch:27/50     Step:5|6   loss:0.8770848512649536  \n","Epoch:27/50     Step:6|6   loss:0.8431073427200317  \n","Epoch:27/50     Step:7|6   loss:0.7527448534965515  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:80.37%\t train set:86.65%\n","Epoch:28/50     Step:1|6   loss:0.8560715913772583  \n","Epoch:28/50     Step:2|6   loss:0.8420143723487854  \n","Epoch:28/50     Step:3|6   loss:0.8404155969619751  \n","Epoch:28/50     Step:4|6   loss:0.8793904185295105  \n","Epoch:28/50     Step:5|6   loss:0.8421201109886169  \n","Epoch:28/50     Step:6|6   loss:0.8186245560646057  \n","Epoch:28/50     Step:7|6   loss:0.860670804977417  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:80.37%\t train set:86.65%\n","Epoch:29/50     Step:1|6   loss:0.8884167671203613  \n","Epoch:29/50     Step:2|6   loss:0.8486173152923584  \n","Epoch:29/50     Step:3|6   loss:0.8403083086013794  \n","Epoch:29/50     Step:4|6   loss:0.875237226486206  \n","Epoch:29/50     Step:5|6   loss:0.8519530296325684  \n","Epoch:29/50     Step:6|6   loss:0.8541350364685059  \n","Epoch:29/50     Step:7|6   loss:0.7860301733016968  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:80.37%\t train set:86.65%\n","Epoch:30/50     Step:1|6   loss:0.8012782335281372  \n","Epoch:30/50     Step:2|6   loss:0.8527506589889526  \n","Epoch:30/50     Step:3|6   loss:0.9058542251586914  \n","Epoch:30/50     Step:4|6   loss:0.8702991008758545  \n","Epoch:30/50     Step:5|6   loss:0.8378342390060425  \n","Epoch:30/50     Step:6|6   loss:0.8524423837661743  \n","Epoch:30/50     Step:7|6   loss:0.8251248598098755  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:31/50     Step:1|6   loss:0.8317174315452576  \n","Epoch:31/50     Step:2|6   loss:0.8539230227470398  \n","Epoch:31/50     Step:3|6   loss:0.8569316864013672  \n","Epoch:31/50     Step:4|6   loss:0.7645783424377441  \n","Epoch:31/50     Step:5|6   loss:0.8693400025367737  \n","Epoch:31/50     Step:6|6   loss:0.7866590023040771  \n","Epoch:31/50     Step:7|6   loss:0.8222880959510803  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:32/50     Step:1|6   loss:0.8191989064216614  \n","Epoch:32/50     Step:2|6   loss:0.8726373910903931  \n","Epoch:32/50     Step:3|6   loss:0.8510183095932007  \n","Epoch:32/50     Step:4|6   loss:0.8067350387573242  \n","Epoch:32/50     Step:5|6   loss:0.8142799735069275  \n","Epoch:32/50     Step:6|6   loss:0.7816899418830872  \n","Epoch:32/50     Step:7|6   loss:0.8540524244308472  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:33/50     Step:1|6   loss:0.8292896747589111  \n","Epoch:33/50     Step:2|6   loss:0.7982498407363892  \n","Epoch:33/50     Step:3|6   loss:0.8374511003494263  \n","Epoch:33/50     Step:4|6   loss:0.8338013887405396  \n","Epoch:33/50     Step:5|6   loss:0.8153448104858398  \n","Epoch:33/50     Step:6|6   loss:0.8125249147415161  \n","Epoch:33/50     Step:7|6   loss:0.8139234781265259  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:34/50     Step:1|6   loss:0.8840833902359009  \n","Epoch:34/50     Step:2|6   loss:0.8505666255950928  \n","Epoch:34/50     Step:3|6   loss:0.8483595848083496  \n","Epoch:34/50     Step:4|6   loss:0.7954796552658081  \n","Epoch:34/50     Step:5|6   loss:0.8386186361312866  \n","Epoch:34/50     Step:6|6   loss:0.7794671058654785  \n","Epoch:34/50     Step:7|6   loss:0.8244912028312683  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:35/50     Step:1|6   loss:0.7914526462554932  \n","Epoch:35/50     Step:2|6   loss:0.8500018119812012  \n","Epoch:35/50     Step:3|6   loss:0.8247900009155273  \n","Epoch:35/50     Step:4|6   loss:0.8263229131698608  \n","Epoch:35/50     Step:5|6   loss:0.7742840051651001  \n","Epoch:35/50     Step:6|6   loss:0.8053779602050781  \n","Epoch:35/50     Step:7|6   loss:0.8371632099151611  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:36/50     Step:1|6   loss:0.8377106189727783  \n","1Epoch:36/50     Step:2|6   loss:0.860662579536438  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:36/50     Step:3|6   loss:0.8414293527603149  \n","Epoch:36/50     Step:4|6   loss:0.7758795022964478  \n","Epoch:36/50     Step:5|6   loss:0.7730464935302734  \n","Epoch:36/50     Step:6|6   loss:0.8344924449920654  \n","Epoch:36/50     Step:7|6   loss:0.9047094583511353  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:37/50     Step:1|6   loss:0.7761328816413879  \n","Epoch:37/50     Step:2|6   loss:0.8158653974533081  \n","Epoch:37/50     Step:3|6   loss:0.8825103044509888  \n","Epoch:37/50     Step:4|6   loss:0.8084560632705688  \n","Epoch:37/50     Step:5|6   loss:0.8202387094497681  \n","Epoch:37/50     Step:6|6   loss:0.8190371990203857  \n","Epoch:37/50     Step:7|6   loss:0.782583475112915  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:38/50     Step:1|6   loss:0.8133499622344971  \n","Epoch:38/50     Step:2|6   loss:0.8298996686935425  \n","Epoch:38/50     Step:3|6   loss:0.7697405815124512  \n","Epoch:38/50     Step:4|6   loss:0.7819797396659851  \n","Epoch:38/50     Step:5|6   loss:0.8482769727706909  \n","Epoch:38/50     Step:6|6   loss:0.7934461832046509  \n","Epoch:38/50     Step:7|6   loss:0.8223146200180054  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:39/50     Step:1|6   loss:0.7907677888870239  \n","Epoch:39/50     Step:2|6   loss:0.8491334915161133  \n","Epoch:39/50     Step:3|6   loss:0.7279451489448547  \n","Epoch:39/50     Step:4|6   loss:0.8451232314109802  \n","Epoch:39/50     Step:5|6   loss:0.8594145774841309  \n","Epoch:39/50     Step:6|6   loss:0.8417962789535522  \n","Epoch:39/50     Step:7|6   loss:0.8194525241851807  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:40/50     Step:1|6   loss:0.7752427458763123  \n","Epoch:40/50     Step:2|6   loss:0.8303796648979187  \n","Epoch:40/50     Step:3|6   loss:0.8265261054039001  \n","Epoch:40/50     Step:4|6   loss:0.7488911151885986  \n","Epoch:40/50     Step:5|6   loss:0.7992819547653198  \n","Epoch:40/50     Step:6|6   loss:0.8405153155326843  \n","Epoch:40/50     Step:7|6   loss:0.8520851135253906  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:41/50     Step:1|6   loss:0.8145183324813843  \n","Epoch:41/50     Step:2|6   loss:0.8021929264068604  \n","Epoch:41/50     Step:3|6   loss:0.8681855201721191  \n","Epoch:41/50     Step:4|6   loss:0.8013617396354675  \n","Epoch:41/50     Step:5|6   loss:0.824112057685852  \n","Epoch:41/50     Step:6|6   loss:0.8460289239883423  \n","Epoch:41/50     Step:7|6   loss:0.7743530869483948  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:86.65%\n","Epoch:42/50     Step:1|6   loss:0.8046503067016602  \n","Epoch:42/50     Step:2|6   loss:0.7651780843734741  \n","Epoch:42/50     Step:3|6   loss:0.8510568141937256  \n","Epoch:42/50     Step:4|6   loss:0.8532322645187378  \n","Epoch:42/50     Step:5|6   loss:0.8581184148788452  \n","Epoch:42/50     Step:6|6   loss:0.7856834530830383  \n","Epoch:42/50     Step:7|6   loss:0.8411558866500854  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:84.11%\t train set:86.89%\n","Epoch:43/50     Step:1|6   loss:0.7829331159591675  \n","Epoch:43/50     Step:2|6   loss:0.831430196762085  \n","Epoch:43/50     Step:3|6   loss:0.8320719003677368  \n","Epoch:43/50     Step:4|6   loss:0.8459936380386353  \n","Epoch:43/50     Step:5|6   loss:0.8003431558609009  \n","Epoch:43/50     Step:6|6   loss:0.8076837062835693  \n","Epoch:43/50     Step:7|6   loss:0.8601584434509277  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:85.05%\t train set:88.06%\n","Epoch:44/50     Step:1|6   loss:0.8595697283744812  \n","Epoch:44/50     Step:2|6   loss:0.8291777968406677  \n","Epoch:44/50     Step:3|6   loss:0.8165444731712341  \n","Epoch:44/50     Step:4|6   loss:0.8123846054077148  \n","Epoch:44/50     Step:5|6   loss:0.8211619853973389  \n","Epoch:44/50     Step:6|6   loss:0.8306484818458557  \n","Epoch:44/50     Step:7|6   loss:0.7767053842544556  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:85.05%\t train set:88.06%\n","Epoch:45/50     Step:1|6   loss:0.7996920347213745  \n","Epoch:45/50     Step:2|6   loss:0.8035982847213745  \n","Epoch:45/50     Step:3|6   loss:0.7891296148300171  \n","Epoch:45/50     Step:4|6   loss:0.752204418182373  \n","Epoch:45/50     Step:5|6   loss:0.8096637725830078  \n","Epoch:45/50     Step:6|6   loss:0.8400804996490479  \n","Epoch:45/50     Step:7|6   loss:0.794174313545227  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:85.98%\t train set:88.06%\n","Epoch:46/50     Step:1|6   loss:0.8437633514404297  \n","Epoch:46/50     Step:2|6   loss:0.8768775463104248  \n","Epoch:46/50     Step:3|6   loss:0.8164000511169434  \n","Epoch:46/50     Step:4|6   loss:0.7748472690582275  \n","Epoch:46/50     Step:5|6   loss:0.7393233776092529  \n","Epoch:46/50     Step:6|6   loss:0.7863011360168457  \n","Epoch:46/50     Step:7|6   loss:0.8203368782997131  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:85.98%\t train set:88.06%\n","Epoch:47/50     Step:1|6   loss:0.8790712356567383  \n","Epoch:47/50     Step:2|6   loss:0.804945707321167  \n","Epoch:47/50     Step:3|6   loss:0.8889397382736206  \n","Epoch:47/50     Step:4|6   loss:0.85783851146698  \n","Epoch:47/50     Step:5|6   loss:0.8087868690490723  \n","Epoch:47/50     Step:6|6   loss:0.7900168299674988  \n","Epoch:47/50     Step:7|6   loss:0.8576698899269104  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:85.98%\t train set:88.06%\n","Epoch:48/50     Step:1|6   loss:0.7624502182006836  \n","Epoch:48/50     Step:2|6   loss:0.8242015838623047  \n","Epoch:48/50     Step:3|6   loss:0.8543922901153564  \n","Epoch:48/50     Step:4|6   loss:0.7998249530792236  \n","Epoch:48/50     Step:5|6   loss:0.8416458964347839  \n","Epoch:48/50     Step:6|6   loss:0.7590866088867188  \n","Epoch:48/50     Step:7|6   loss:0.8263338804244995  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:85.98%\t train set:88.06%\n","Epoch:49/50     Step:1|6   loss:0.8443170785903931  \n","Epoch:49/50     Step:2|6   loss:0.790638267993927  \n","Epoch:49/50     Step:3|6   loss:0.8283947706222534  \n","Epoch:49/50     Step:4|6   loss:0.8339733481407166  \n","Epoch:49/50     Step:5|6   loss:0.7880433201789856  \n","Epoch:49/50     Step:6|6   loss:0.8196890354156494  \n","Epoch:49/50     Step:7|6   loss:0.7613577842712402  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:85.98%\t train set:88.06%\n","Epoch:50/50     Step:1|6   loss:0.8730028867721558  \n","Epoch:50/50     Step:2|6   loss:0.8180943727493286  \n","Epoch:50/50     Step:3|6   loss:0.8462663888931274  \n","Epoch:50/50     Step:4|6   loss:0.7943367958068848  \n","Epoch:50/50     Step:5|6   loss:0.8566325902938843  \n","Epoch:50/50     Step:6|6   loss:0.760549783706665  \n","Epoch:50/50     Step:7|6   loss:0.8250795602798462  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:85.98%\t train set:88.06%\n","Accuracy on test_set: 83.18 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='ir', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1932783126831055  \n","Epoch:1/50     Step:2|6   loss:1.2274255752563477  \n","Epoch:1/50     Step:3|6   loss:1.2353495359420776  \n","Epoch:1/50     Step:4|6   loss:1.2112723588943481  \n","Epoch:1/50     Step:5|6   loss:1.155458688735962  \n","Epoch:1/50     Step:6|6   loss:1.156690001487732  \n","Epoch:1/50     Step:7|6   loss:1.081544280052185  \n","Accuracy on test_set: 33.64 %\n","Accuracy on train_set: 25.76 %\n","current max accuracy\t test set:33.64%\t train set:25.76%\n","Epoch:2/50     Step:1|6   loss:1.2650965452194214  \n","Epoch:2/50     Step:2|6   loss:1.0919976234436035  \n","Epoch:2/50     Step:3|6   loss:1.1921616792678833  \n","Epoch:2/50     Step:4|6   loss:1.1382633447647095  \n","Epoch:2/50     Step:5|6   loss:1.1134357452392578  \n","Epoch:2/50     Step:6|6   loss:1.0267953872680664  \n","Epoch:2/50     Step:7|6   loss:1.1188414096832275  \n","Accuracy on test_set: 33.64 %\n","Accuracy on train_set: 25.76 %\n","current max accuracy\t test set:33.64%\t train set:25.76%\n","Epoch:3/50     Step:1|6   loss:1.1654393672943115  \n","Epoch:3/50     Step:2|6   loss:1.112803339958191  2\n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:3/50     Step:3|6   loss:1.1379677057266235  \n","Epoch:3/50     Step:4|6   loss:1.1302270889282227  \n","Epoch:3/50     Step:5|6   loss:1.1794164180755615  \n","Epoch:3/50     Step:6|6   loss:1.1016653776168823  \n","Epoch:3/50     Step:7|6   loss:1.1971393823623657  \n","Accuracy on test_set: 33.64 %\n","Accuracy on train_set: 25.76 %\n","current max accuracy\t test set:33.64%\t train set:25.76%\n","Epoch:4/50     Step:1|6   loss:1.098146677017212  \n","Epoch:4/50     Step:2|6   loss:1.1674919128417969  \n","Epoch:4/50     Step:3|6   loss:1.1004576683044434  \n","Epoch:4/50     Step:4|6   loss:1.1296064853668213  \n","Epoch:4/50     Step:5|6   loss:1.0993289947509766  \n","Epoch:4/50     Step:6|6   loss:1.0582364797592163  \n","Epoch:4/50     Step:7|6   loss:1.1047289371490479  \n","Accuracy on test_set: 33.64 %\n","Accuracy on train_set: 25.76 %\n","current max accuracy\t test set:33.64%\t train set:25.76%\n","Epoch:5/50     Step:1|6   loss:1.132596731185913  \n","Epoch:5/50     Step:2|6   loss:1.150051474571228  \n","Epoch:5/50     Step:3|6   loss:1.1317193508148193  \n","Epoch:5/50     Step:4|6   loss:1.1405518054962158  \n","Epoch:5/50     Step:5|6   loss:1.0006539821624756  \n","Epoch:5/50     Step:6|6   loss:1.0940957069396973  \n","Epoch:5/50     Step:7|6   loss:0.9675218462944031  \n","Accuracy on test_set: 35.51 %\n","Accuracy on train_set: 29.98 %\n","current max accuracy\t test set:35.51%\t train set:29.98%\n","Epoch:6/50     Step:1|6   loss:1.084736704826355  \n","Epoch:6/50     Step:2|6   loss:1.07979416847229  \n","Epoch:6/50     Step:3|6   loss:1.0523878335952759  \n","Epoch:6/50     Step:4|6   loss:1.0697102546691895  \n","Epoch:6/50     Step:5|6   loss:1.0336498022079468  \n","Epoch:6/50     Step:6|6   loss:1.006842851638794  \n","Epoch:6/50     Step:7|6   loss:1.0745644569396973  \n","Accuracy on test_set: 52.34 %\n","Accuracy on train_set: 57.14 %\n","current max accuracy\t test set:52.34%\t train set:57.14%\n","Epoch:7/50     Step:1|6   loss:1.0896024703979492  \n","Epoch:7/50     Step:2|6   loss:1.0604941844940186  \n","Epoch:7/50     Step:3|6   loss:1.0455764532089233  \n","Epoch:7/50     Step:4|6   loss:1.0173625946044922  \n","Epoch:7/50     Step:5|6   loss:1.0810667276382446  \n","Epoch:7/50     Step:6|6   loss:0.9953616857528687  \n","Epoch:7/50     Step:7|6   loss:1.013198971748352  \n","Accuracy on test_set: 57.01 %\n","Accuracy on train_set: 61.36 %\n","current max accuracy\t test set:57.01%\t train set:61.36%\n","Epoch:8/50     Step:1|6   loss:0.9277536273002625  \n","Epoch:8/50     Step:2|6   loss:1.0736368894577026  \n","Epoch:8/50     Step:3|6   loss:0.9760254621505737  \n","Epoch:8/50     Step:4|6   loss:1.0450316667556763  \n","Epoch:8/50     Step:5|6   loss:1.0653119087219238  \n","Epoch:8/50     Step:6|6   loss:1.120226502418518  \n","Epoch:8/50     Step:7|6   loss:1.0123298168182373  \n","Accuracy on test_set: 59.81 %\n","Accuracy on train_set: 63.47 %\n","current max accuracy\t test set:59.81%\t train set:63.47%\n","Epoch:9/50     Step:1|6   loss:1.104118824005127  \n","Epoch:9/50     Step:2|6   loss:1.063150405883789  \n","Epoch:9/50     Step:3|6   loss:1.1168324947357178  \n","Epoch:9/50     Step:4|6   loss:1.0441340208053589  \n","Epoch:9/50     Step:5|6   loss:0.968735933303833  \n","Epoch:9/50     Step:6|6   loss:0.9658063054084778  \n","Epoch:9/50     Step:7|6   loss:0.9758761525154114  \n","Accuracy on test_set: 62.62 %\n","Accuracy on train_set: 63.47 %\n","current max accuracy\t test set:62.62%\t train set:63.47%\n","Epoch:10/50     Step:1|6   loss:1.004547357559204  \n","Epoch:10/50     Step:2|6   loss:0.9945753216743469  \n","Epoch:10/50     Step:3|6   loss:0.9726157188415527  \n","Epoch:10/50     Step:4|6   loss:0.9937178492546082  \n","Epoch:10/50     Step:5|6   loss:0.954473078250885  \n","Epoch:10/50     Step:6|6   loss:0.9737255573272705  \n","Epoch:10/50     Step:7|6   loss:1.0016309022903442  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 66.51 %\n","current max accuracy\t test set:65.42%\t train set:66.51%\n","Epoch:11/50     Step:1|6   loss:1.0516836643218994  \n","Epoch:11/50     Step:2|6   loss:0.9816321730613708  \n","Epoch:11/50     Step:3|6   loss:0.9533382654190063  \n","Epoch:11/50     Step:4|6   loss:0.9052011370658875  \n","Epoch:11/50     Step:5|6   loss:1.0306822061538696  \n","Epoch:11/50     Step:6|6   loss:0.9815371632575989  \n","Epoch:11/50     Step:7|6   loss:0.963971734046936  \n","Accuracy on test_set: 70.09 %\n","Accuracy on train_set: 72.37 %\n","current max accuracy\t test set:70.09%\t train set:72.37%\n","Epoch:12/50     Step:1|6   loss:0.9798527956008911  \n","Epoch:12/50     Step:2|6   loss:1.0019127130508423  \n","Epoch:12/50     Step:3|6   loss:1.0022399425506592  \n","Epoch:12/50     Step:4|6   loss:0.9995955228805542  \n","Epoch:12/50     Step:5|6   loss:0.9870412945747375  \n","Epoch:12/50     Step:6|6   loss:1.012351632118225  \n","Epoch:12/50     Step:7|6   loss:0.9526447057723999  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 73.77 %\n","current max accuracy\t test set:71.96%\t train set:73.77%\n","Epoch:13/50     Step:1|6   loss:0.9770063161849976  \n","Epoch:13/50     Step:2|6   loss:0.9764607548713684  \n","Epoch:13/50     Step:3|6   loss:0.9551829099655151  \n","Epoch:13/50     Step:4|6   loss:1.0258084535598755  \n","Epoch:13/50     Step:5|6   loss:0.9794867634773254  \n","Epoch:13/50     Step:6|6   loss:0.9327917098999023  \n","Epoch:13/50     Step:7|6   loss:1.0556269884109497  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 79.63 %\n","current max accuracy\t test set:79.44%\t train set:79.63%\n","Epoch:14/50     Step:1|6   loss:0.9278265833854675  \n","Epoch:14/50     Step:2|6   loss:0.9394931197166443  \n","Epoch:14/50     Step:3|6   loss:0.9799985289573669  \n","Epoch:14/50     Step:4|6   loss:0.9340918064117432  \n","Epoch:14/50     Step:5|6   loss:0.9521015286445618  \n","Epoch:14/50     Step:6|6   loss:0.9979692101478577  \n","Epoch:14/50     Step:7|6   loss:1.0107170343399048  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:88.79%\t train set:85.48%\n","Epoch:15/50     Step:1|6   loss:0.9180892705917358  \n","Epoch:15/50     Step:2|6   loss:1.0006239414215088  \n","Epoch:15/50     Step:3|6   loss:0.9732071757316589  \n","Epoch:15/50     Step:4|6   loss:0.9845612049102783  \n","Epoch:15/50     Step:5|6   loss:0.9417229890823364  \n","Epoch:15/50     Step:6|6   loss:0.9236254692077637  \n","Epoch:15/50     Step:7|6   loss:0.9713853597640991  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:88.79%\t train set:85.48%\n","Epoch:16/50     Step:1|6   loss:1.0313475131988525  \n","Epoch:16/50     Step:2|6   loss:0.9492350816726685  \n","Epoch:16/50     Step:3|6   loss:0.902030885219574  \n","Epoch:16/50     Step:4|6   loss:0.909648060798645  \n","Epoch:16/50     Step:5|6   loss:0.9837266206741333  \n","Epoch:16/50     Step:6|6   loss:0.9584783315658569  \n","Epoch:16/50     Step:7|6   loss:0.9213656187057495  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:88.79%\t train set:86.42%\n","Epoch:17/50     Step:1|6   loss:0.9292175769805908  \n","Epoch:17/50     Step:2|6   loss:0.9398472905158997  \n","Epoch:17/50     Step:3|6   loss:0.9196630716323853  \n","Epoch:17/50     Step:4|6   loss:0.9381676912307739  \n","Epoch:17/50     Step:5|6   loss:0.9004939794540405  \n","Epoch:17/50     Step:6|6   loss:0.9638993144035339  \n","Epoch:17/50     Step:7|6   loss:0.8897870779037476  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:88.79%\t train set:87.35%\n","Epoch:18/50     Step:1|6   loss:0.9282286167144775  \n","Epoch:18/50     Step:2|6   loss:0.9444431066513062  \n","Epoch:18/50     Step:3|6   loss:0.8773036003112793  \n","Epoch:18/50     Step:4|6   loss:0.9324234127998352  \n","Epoch:18/50     Step:5|6   loss:0.9353570938110352  \n","Epoch:18/50     Step:6|6   loss:0.9469537138938904  \n","Epoch:18/50     Step:7|6   loss:0.9218724966049194  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:88.79%\t train set:88.06%\n","Epoch:19/50     Step:1|6   loss:0.928898811340332  \n","Epoch:19/50     Step:2|6   loss:0.9109431505203247  \n","Epoch:19/50     Step:3|6   loss:0.9332315325737  \n","Epoch:19/50     Step:4|6   loss:0.9487760066986084  \n","Epoch:19/50     Step:5|6   loss:0.9181791543960571  \n","Epoch:19/50     Step:6|6   loss:0.9523581266403198  \n","Epoch:19/50     Step:7|6   loss:0.9318351149559021  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:20/50     Step:1|6   loss:0.8748446702957153  \n","Epoch:20/50     Step:2|6   loss:0.8887119293212891  \n","Epoch:20/50     Step:3|6   loss:0.9616195559501648  \n","Epoch:20/50     Step:4|6   loss:0.9252879619598389  \n","Epoch:20/50     Step:5|6   loss:0.9628884196281433  \n","Epoch:20/50     Step:6|6   loss:0.9267435073852539  \n","Epoch:20/50     Step:7|6   loss:0.9869850277900696  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:21/50     Step:1|6   loss:0.8898512125015259  \n","Epoch:21/50     Step:2|6   loss:0.9291955232620239  \n","Epoch:21/50     Step:3|6   loss:0.9116314649581909  \n","Epoch:21/50     Step:4|6   loss:0.8854411840438843  \n","Epoch:21/50     Step:5|6   loss:0.8785886764526367  \n","Epoch:21/50     Step:6|6   loss:0.9775235652923584  \n","Epoch:21/50     Step:7|6   loss:0.825700581073761  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:22/50     Step:1|6   loss:0.976117730140686  \n","Epoch:22/50     Step:2|6   loss:0.8644481897354126  \n","Epoch:22/50     Step:3|6   loss:0.9142317771911621  \n","Epoch:22/50     Step:4|6   loss:0.9368314146995544  \n","Epoch:22/50     Step:5|6   loss:0.9486175775527954  \n","Epoch:22/50     Step:6|6   loss:0.8952608108520508  \n","Epoch:22/50     Step:7|6   loss:0.8656341433525085  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:23/50     Step:1|6   loss:0.9406508207321167  \n","Epoch:23/50     Step:2|6   loss:0.8551957011222839  \n","Epoch:23/50     Step:3|6   loss:0.8948640823364258  \n","Epoch:23/50     Step:4|6   loss:0.8796496391296387  \n","Epoch:23/50     Step:5|6   loss:0.8974642753601074  \n","Epoch:23/50     Step:6|6   loss:0.8808743953704834  \n","Epoch:23/50     Step:7|6   loss:0.9129438400268555  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:24/50     Step:1|6   loss:0.9056806564331055  \n","Epoch:24/50     Step:2|6   loss:0.8907812833786011  \n","Epoch:24/50     Step:3|6   loss:0.9096542596817017  \n","Epoch:24/50     Step:4|6   loss:0.8434538841247559  \n","Epoch:24/50     Step:5|6   loss:0.9010248184204102  \n","Epoch:24/50     Step:6|6   loss:0.8827828168869019  \n","Epoch:24/50     Step:7|6   loss:0.91998291015625  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:25/50     Step:1|6   loss:0.9336105585098267  \n","Epoch:25/50     Step:2|6   loss:0.8760979175567627  \n","Epoch:25/50     Step:3|6   loss:0.8343824744224548  \n","Epoch:25/50     Step:4|6   loss:0.8496794104576111  \n","Epoch:25/50     Step:5|6   loss:0.8943373560905457  \n","Epoch:25/50     Step:6|6   loss:0.858954668045044  \n","Epoch:25/50     Step:7|6   loss:0.9321359992027283  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:26/50     Step:1|6   loss:0.8800304532051086  \n","Epoch:26/50     Step:2|6   loss:0.8567377328872681  \n","Epoch:26/50     Step:3|6   loss:0.8963153958320618  \n","Epoch:26/50     Step:4|6   loss:0.8369811177253723  \n","Epoch:26/50     Step:5|6   loss:0.9173920750617981  \n","Epoch:26/50     Step:6|6   loss:0.8327782154083252  \n","Epoch:26/50     Step:7|6   loss:0.8683784604072571  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:27/50     Step:1|6   loss:0.8868159055709839  \n","Epoch:27/50     Step:2|6   loss:0.8723539710044861  \n","Epoch:27/50     Step:3|6   loss:0.9217119216918945  \n","Epoch:27/50     Step:4|6   loss:0.8515128493309021  \n","Epoch:27/50     Step:5|6   loss:0.8552308082580566  \n","Epoch:27/50     Step:6|6   loss:0.8632542490959167  \n","Epoch:27/50     Step:7|6   loss:0.9491348266601562  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:28/50     Step:1|6   loss:0.8799890279769897  \n","Epoch:28/50     Step:2|6   loss:0.8818941712379456  \n","Epoch:28/50     Step:3|6   loss:0.8014380931854248  \n","Epoch:28/50     Step:4|6   loss:0.911422610282898  \n","Epoch:28/50     Step:5|6   loss:0.8225566148757935  \n","Epoch:28/50     Step:6|6   loss:0.8638390302658081  \n","Epoch:28/50     Step:7|6   loss:0.8590341806411743  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:29/50     Step:1|6   loss:0.8765760064125061  \n","Epoch:29/50     Step:2|6   loss:0.8941017985343933  \n","Epoch:29/50     Step:3|6   loss:0.9124996066093445  \n","Epoch:29/50     Step:4|6   loss:0.8697806000709534  \n","Epoch:29/50     Step:5|6   loss:0.8464242815971375  \n","Epoch:29/50     Step:6|6   loss:0.8805714249610901  \n","Epoch:29/50     Step:7|6   loss:0.8448781967163086  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:30/50     Step:1|6   loss:0.8879512548446655  \n","Epoch:30/50     Step:2|6   loss:0.8406211733818054  \n","Epoch:30/50     Step:3|6   loss:0.840080201625824  \n","Epoch:30/50     Step:4|6   loss:0.8712054491043091  \n","Epoch:30/50     Step:5|6   loss:0.8173230886459351  \n","Epoch:30/50     Step:6|6   loss:0.8407859802246094  \n","Epoch:30/50     Step:7|6   loss:0.8922622203826904  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:31/50     Step:1|6   loss:0.8045413494110107  \n","Epoch:31/50     Step:2|6   loss:0.8127143383026123  \n","Epoch:31/50     Step:3|6   loss:0.8434698581695557  \n","Epoch:31/50     Step:4|6   loss:0.8768062591552734  \n","Epoch:31/50     Step:5|6   loss:0.8403807878494263  \n","Epoch:31/50     Step:6|6   loss:0.852390706539154  \n","Epoch:31/50     Step:7|6   loss:0.848131000995636  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:32/50     Step:1|6   loss:0.8473144769668579  \n","Epoch:32/50     Step:2|6   loss:0.8132716417312622  \n","Epoch:32/50     Step:3|6   loss:0.8121451139450073  \n","Epoch:32/50     Step:4|6   loss:0.8884838819503784  \n","Epoch:32/50     Step:5|6   loss:0.8778761625289917  \n","Epoch:32/50     Step:6|6   loss:0.8506618738174438  \n","Epoch:32/50     Step:7|6   loss:0.9467148184776306  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:33/50     Step:1|6   loss:0.862184464931488  \n","Epoch:33/50     Step:2|6   loss:0.8768877983093262  \n","Epoch:33/50     Step:3|6   loss:0.866730809211731  \n","Epoch:33/50     Step:4|6   loss:0.8099560737609863  \n","Epoch:33/50     Step:5|6   loss:0.826433002948761  \n","Epoch:33/50     Step:6|6   loss:0.8131335377693176  \n","Epoch:33/50     Step:7|6   loss:0.7845284938812256  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:34/50     Step:1|6   loss:0.815136730670929  \n","Epoch:34/50     Step:2|6   loss:0.7911937832832336  \n","Epoch:34/50     Step:3|6   loss:0.8532888293266296  \n","Epoch:34/50     Step:4|6   loss:0.8596526384353638  \n","Epoch:34/50     Step:5|6   loss:0.8401286602020264  \n","Epoch:34/50     Step:6|6   loss:0.8635950088500977  \n","Epoch:34/50     Step:7|6   loss:0.7327350974082947  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:35/50     Step:1|6   loss:0.8043012619018555  \n","Epoch:35/50     Step:2|6   loss:0.8009822368621826  \n","Epoch:35/50     Step:3|6   loss:0.8626394271850586  \n","Epoch:35/50     Step:4|6   loss:0.7772328853607178  \n","Epoch:35/50     Step:5|6   loss:0.8276516199111938  \n","Epoch:35/50     Step:6|6   loss:0.8035861253738403  \n","Epoch:35/50     Step:7|6   loss:0.8755252361297607  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:36/50     Step:1|6   loss:0.8925857543945312  \n","Epoch:36/50     Step:2|6   loss:0.8137909173965454  \n","Epoch:36/50     Step:3|6   loss:0.8604958057403564  \n","Epoch:36/50     Step:4|6   loss:0.7945046424865723  \n","Epoch:36/50     Step:5|6   loss:0.8475497961044312  \n","Epoch:36/50     Step:6|6   loss:0.826626181602478  \n","Epoch:36/50     Step:7|6   loss:0.8953031897544861  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:37/50     Step:1|6   loss:0.8191522359848022  \n","Epoch:37/50     Step:2|6   loss:0.8218086957931519  \n","Epoch:37/50     Step:3|6   loss:0.8599106073379517  \n","Epoch:37/50     Step:4|6   loss:0.815711259841919  \n","Epoch:37/50     Step:5|6   loss:0.8610450029373169  \n","Epoch:37/50     Step:6|6   loss:0.7999625205993652  \n","Epoch:37/50     Step:7|6   loss:0.8510470390319824  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:38/50     Step:1|6   loss:0.8554648160934448  \n","Epoch:38/50     Step:2|6   loss:0.799706220626831  \n","Epoch:38/50     Step:3|6   loss:0.8375681042671204  \n","Epoch:38/50     Step:4|6   loss:0.8564575910568237  \n","Epoch:38/50     Step:5|6   loss:0.8530694246292114  \n","Epoch:38/50     Step:6|6   loss:0.7805006504058838  \n","Epoch:38/50     Step:7|6   loss:0.8458489179611206  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:39/50     Step:1|6   loss:0.8187371492385864  \n","Epoch:39/50     Step:2|6   loss:0.8240445256233215  \n","Epoch:39/50     Step:3|6   loss:0.7579045295715332  \n","Epoch:39/50     Step:4|6   loss:0.8415179252624512  \n","Epoch:39/50     Step:5|6   loss:0.8306881189346313  \n","Epoch:39/50     Step:6|6   loss:0.8272583484649658  \n","Epoch:39/50     Step:7|6   loss:0.8304091691970825  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:40/50     Step:1|6   loss:0.78986656665802  \n","Epoch:40/50     Step:2|6   loss:0.8245171308517456  \n","Epoch:40/50     Step:3|6   loss:0.7751467227935791  \n","Epoch:40/50     Step:4|6   loss:0.8070493936538696  \n","Epoch:40/50     Step:5|6   loss:0.8354446887969971  \n","Epoch:40/50     Step:6|6   loss:0.8190532922744751  \n","Epoch:40/50     Step:7|6   loss:0.8081161975860596  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:41/50     Step:1|6   loss:0.7877298593521118  \n","Epoch:41/50     Step:2|6   loss:0.8036037683486938  \n","Epoch:41/50     Step:3|6   loss:0.869234561920166  \n","Epoch:41/50     Step:4|6   loss:0.8680089712142944  \n","Epoch:41/50     Step:5|6   loss:0.8633847236633301  \n","Epoch:41/50     Step:6|6   loss:0.8066962957382202  \n","Epoch:41/50     Step:7|6   loss:0.855456531047821  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:42/50     Step:1|6   loss:0.8053148984909058  \n","Epoch:42/50     Step:2|6   loss:0.8060258626937866  \n","Epoch:42/50     Step:3|6   loss:0.8167639970779419  \n","Epoch:42/50     Step:4|6   loss:0.769012451171875  \n","Epoch:42/50     Step:5|6   loss:0.7973455190658569  \n","Epoch:42/50     Step:6|6   loss:0.8672465085983276  \n","Epoch:42/50     Step:7|6   loss:0.8254383206367493  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:43/50     Step:1|6   loss:0.7914031744003296  \n","Epoch:43/50     Step:2|6   loss:0.7759698629379272  \n","Epoch:43/50     Step:3|6   loss:0.8091667890548706  \n","Epoch:43/50     Step:4|6   loss:0.7942646741867065  \n","Epoch:43/50     Step:5|6   loss:0.8614979982376099  \n","Epoch:43/50     Step:6|6   loss:0.8426586389541626  \n","Epoch:43/50     Step:7|6   loss:0.7978915572166443  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:44/50     Step:1|6   loss:0.8024688959121704  \n","Epoch:44/50     Step:2|6   loss:0.7767786383628845  \n","Epoch:44/50     Step:3|6   loss:0.8109488487243652  \n","Epoch:44/50     Step:4|6   loss:0.8425024747848511  \n","Epoch:44/50     Step:5|6   loss:0.8180487155914307  \n","Epoch:44/50     Step:6|6   loss:0.8250983953475952  \n","Epoch:44/50     Step:7|6   loss:0.8133670091629028  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:45/50     Step:1|6   loss:0.7616328001022339  \n","Epoch:45/50     Step:2|6   loss:0.7915147542953491  \n","Epoch:45/50     Step:3|6   loss:0.8214446306228638  \n","Epoch:45/50     Step:4|6   loss:0.8418716192245483  \n","Epoch:45/50     Step:5|6   loss:0.8183387517929077  \n","Epoch:45/50     Step:6|6   loss:0.7991474270820618  \n","Epoch:45/50     Step:7|6   loss:0.8126445412635803  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:46/50     Step:1|6   loss:0.8568100929260254  \n","Epoch:46/50     Step:2|6   loss:0.8364838361740112  \n","Epoch:46/50     Step:3|6   loss:0.7943061590194702  \n","Epoch:46/50     Step:4|6   loss:0.8178936243057251  \n","Epoch:46/50     Step:5|6   loss:0.8083508014678955  \n","Epoch:46/50     Step:6|6   loss:0.810462236404419  \n","Epoch:46/50     Step:7|6   loss:0.790971040725708  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:47/50     Step:1|6   loss:0.8435186147689819  \n","Epoch:47/50     Step:2|6   loss:0.853148341178894  \n","Epoch:47/50     Step:3|6   loss:0.7293340563774109  \n","Epoch:47/50     Step:4|6   loss:0.8437943458557129  \n","Epoch:47/50     Step:5|6   loss:0.785386323928833  \n","Epoch:47/50     Step:6|6   loss:0.8200175166130066  \n","Epoch:47/50     Step:7|6   loss:0.7525702714920044  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:48/50     Step:1|6   loss:0.827991247177124  \n","Epoch:48/50     Step:2|6   loss:0.7891794443130493  \n","Epoch:48/50     Step:3|6   loss:0.8301441669464111  \n","Epoch:48/50     Step:4|6   loss:0.7935038805007935  \n","Epoch:48/50     Step:5|6   loss:0.8418885469436646  \n","Epoch:48/50     Step:6|6   loss:0.8283898830413818  \n","Epoch:48/50     Step:7|6   loss:0.8270478248596191  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:49/50     Step:1|6   loss:0.7828932404518127  \n","Epoch:49/50     Step:2|6   loss:0.8344376087188721  \n","Epoch:49/50     Step:3|6   loss:0.8573068380355835  \n","Epoch:49/50     Step:4|6   loss:0.8922409415245056  \n","Epoch:49/50     Step:5|6   loss:0.7869688272476196  \n","Epoch:49/50     Step:6|6   loss:0.8460556268692017  \n","Epoch:49/50     Step:7|6   loss:0.7741973996162415  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:90.65%\t train set:89.23%\n","Epoch:50/50     Step:1|6   loss:0.8635340929031372  \n","Epoch:50/50     Step:2|6   loss:0.8057476878166199  \n","Epoch:50/50     Step:3|6   loss:0.8165518641471863  \n","Epoch:50/50     Step:4|6   loss:0.7988491058349609  \n","Epoch:50/50     Step:5|6   loss:0.7983415722846985  \n","Epoch:50/50     Step:6|6   loss:0.7618403434753418  \n","Epoch:50/50     Step:7|6   loss:0.8107203245162964  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 89.93 %\n","current max accuracy\t test set:90.65%\t train set:89.93%\n","Accuracy on test_set: 90.65 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='ir', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1458523273468018  \n","Epoch:1/50     Step:2|6   loss:1.127847671508789  \n","Epoch:1/50     Step:3|6   loss:1.0873326063156128  \n","Epoch:1/50     Step:4|6   loss:1.0657427310943604  \n","Epoch:1/50     Step:5|6   loss:1.1331664323806763  \n","Epoch:1/50     Step:6|6   loss:1.094541072845459  \n","Epoch:1/50     Step:7|6   loss:1.0763272047042847  \n","Accuracy on test_set: 24.30 %\n","Accuracy on train_set: 26.46 %\n","current max accuracy\t test set:24.3%\t train set:26.46%\n","Epoch:2/50     Step:1|6   loss:1.0727609395980835  \n","Epoch:2/50     Step:2|6   loss:1.1033964157104492  \n","Epoch:2/50     Step:3|6   loss:1.093256950378418  \n","Epoch:2/50     Step:4|6   loss:1.039136290550232  \n","Epoch:2/50     Step:5|6   loss:1.0543607473373413  \n","Epoch:2/50     Step:6|6   loss:1.0896556377410889  \n","Epoch:2/50     Step:7|6   loss:1.0325605869293213  \n","Accuracy on test_set: 53.27 %\n","Accuracy on train_set: 48.01 %\n","current max accuracy\t test set:53.27%\t train set:48.01%\n","Epoch:3/50     Step:1|6   loss:1.083045482635498  \n","Epoch:3/50     Step:2|6   loss:1.0299837589263916  \n","Epoch:3/50     Step:3|6   loss:1.031628131866455  \n","Epoch:3/50     Step:4|6   loss:1.0492613315582275  \n","Epoch:3/50     Step:5|6   loss:1.0543346405029297  \n","Epoch:3/50     Step:6|6   loss:0.9755318760871887  \n","Epoch:3/50     Step:7|6   loss:1.0209084749221802  \n","Accuracy on test_set: 53.27 %\n","Accuracy on train_set: 48.01 %\n","current max accuracy\t test set:53.27%\t train set:48.01%\n","Epoch:4/50     Step:1|6   loss:0.9990496039390564  \n","Epoch:4/50     Step:2|6   loss:1.0283526182174683  \n","Epoch:4/50     Step:3|6   loss:0.9926401376724243  \n","Epoch:4/50     Step:4|6   loss:0.979996919631958  \n","Epoch:4/50     Step:5|6   loss:1.0559606552124023  \n","Epoch:4/50     Step:6|6   loss:0.9996017217636108  \n","Epoch:4/50     Step:7|6   loss:1.0167956352233887  \n","Accuracy on test_set: 53.27 %\n","Accuracy on train_set: 48.01 %\n","current max accuracy\t test set:53.27%\t train set:48.01%\n","Epoch:5/50     Step:1|6   loss:0.9508636593818665  \n","Epoch:5/50     Step:2|6   loss:0.9980300664901733  \n","Epoch:5/50     Step:3|6   loss:1.046117901802063  \n","Epoch:5/50     Step:4|6   loss:0.9910041093826294  \n","Epoch:5/50     Step:5|6   loss:0.9856833815574646  \n","Epoch:5/50     Step:6|6   loss:0.9732158184051514  \n","Epoch:5/50     Step:7|6   loss:1.0109679698944092  \n","Accuracy on test_set: 63.55 %\n","Accuracy on train_set: 57.85 %\n","current max accuracy\t test set:63.55%\t train set:57.85%\n","Epoch:6/50     Step:1|6   loss:0.9566494226455688  \n","Epoch:6/50     Step:2|6   loss:0.9789633750915527  \n","Epoch:6/50     Step:3|6   loss:0.9862837791442871  \n","Epoch:6/50     Step:4|6   loss:0.9607239365577698  \n","Epoch:6/50     Step:5|6   loss:0.9917083382606506  \n","Epoch:6/50     Step:6|6   loss:1.0103981494903564  \n","Epoch:6/50     Step:7|6   loss:1.0734034776687622  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 76.35 %\n","current max accuracy\t test set:81.31%\t train set:76.35%\n","Epoch:7/50     Step:1|6   loss:0.9652149081230164  \n","Epoch:7/50     Step:2|6   loss:0.9379026889801025  \n","Epoch:7/50     Step:3|6   loss:0.9215396642684937  \n","Epoch:7/50     Step:4|6   loss:0.9884037971496582  \n","Epoch:7/50     Step:5|6   loss:0.9477184414863586  \n","Epoch:7/50     Step:6|6   loss:0.9750087261199951  \n","Epoch:7/50     Step:7|6   loss:0.9501447081565857  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:8/50     Step:1|6   loss:0.9920570850372314  \n","Epoch:8/50     Step:2|6   loss:0.9086310863494873  \n","Epoch:8/50     Step:3|6   loss:0.9740333557128906  \n","Epoch:8/50     Step:4|6   loss:0.9428409934043884  \n","Epoch:8/50     Step:5|6   loss:0.9635981321334839  \n","Epoch:8/50     Step:6|6   loss:0.8737577199935913  \n","Epoch:8/50     Step:7|6   loss:0.8880205750465393  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:9/50     Step:1|6   loss:0.9339300394058228  \n","Epoch:9/50     Step:2|6   loss:0.8983061909675598  \n","Epoch:9/50     Step:3|6   loss:0.9101685881614685  \n","Epoch:9/50     Step:4|6   loss:0.9414602518081665  \n","Epoch:9/50     Step:5|6   loss:0.9178873300552368  \n","Epoch:9/50     Step:6|6   loss:0.9748449325561523  \n","Epoch:9/50     Step:7|6   loss:0.8664060235023499  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:10/50     Step:1|6   loss:0.8884113430976868  \n","Epoch:10/50     Step:2|6   loss:0.962864100933075  \n","Epoch:10/50     Step:3|6   loss:0.8952089548110962  \n","Epoch:10/50     Step:4|6   loss:0.9348481893539429  \n","Epoch:10/50     Step:5|6   loss:0.916646420955658  \n","Epoch:10/50     Step:6|6   loss:0.8936208486557007  \n","Epoch:10/50     Step:7|6   loss:0.8893355131149292  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:11/50     Step:1|6   loss:0.8227673768997192  \n","Epoch:11/50     Step:2|6   loss:0.849683403968811  \n","Epoch:11/50     Step:3|6   loss:0.9074628949165344  \n","Epoch:11/50     Step:4|6   loss:0.9028884172439575  \n","Epoch:11/50     Step:5|6   loss:0.8702841401100159  \n","Epoch:11/50     Step:6|6   loss:0.8782437443733215  \n","Epoch:11/50     Step:7|6   loss:0.951166570186615  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:12/50     Step:1|6   loss:0.9231393337249756  \n","Epoch:12/50     Step:2|6   loss:0.9495634436607361  \n","Epoch:12/50     Step:3|6   loss:0.8881446123123169  \n","Epoch:12/50     Step:4|6   loss:0.9169146418571472  \n","Epoch:12/50     Step:5|6   loss:0.9279268980026245  \n","Epoch:12/50     Step:6|6   loss:0.8780319690704346  \n","Epoch:12/50     Step:7|6   loss:0.8543935418128967  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:13/50     Step:1|6   loss:0.8770551681518555  \n","Epoch:13/50     Step:2|6   loss:0.9165982007980347  \n","Epoch:13/50     Step:3|6   loss:0.8878358602523804  \n","Epoch:13/50     Step:4|6   loss:0.8759734630584717  \n","Epoch:13/50     Step:5|6   loss:0.8694130182266235  \n","Epoch:13/50     Step:6|6   loss:0.9627777934074402  \n","Epoch:13/50     Step:7|6   loss:0.8720802068710327  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:14/50     Step:1|6   loss:0.8680651187896729  \n","Epoch:14/50     Step:2|6   loss:0.8186909556388855  \n","Epoch:14/50     Step:3|6   loss:0.8707098960876465  \n","Epoch:14/50     Step:4|6   loss:0.9595815539360046  \n","Epoch:14/50     Step:5|6   loss:0.8872097730636597  \n","Epoch:14/50     Step:6|6   loss:0.8822673559188843  \n","Epoch:14/50     Step:7|6   loss:0.8440483808517456  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:15/50     Step:1|6   loss:0.8380723595619202  \n","Epoch:15/50     Step:2|6   loss:0.795649528503418  \n","Epoch:15/50     Step:3|6   loss:0.8436453342437744  \n","Epoch:15/50     Step:4|6   loss:0.8576627373695374  \n","Epoch:15/50     Step:5|6   loss:0.8861096501350403  \n","Epoch:15/50     Step:6|6   loss:0.8181661367416382  \n","Epoch:15/50     Step:7|6   loss:0.8613417148590088  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:16/50     Step:1|6   loss:0.8784630298614502  \n","Epoch:16/50     Step:2|6   loss:0.8589884042739868  \n","Epoch:16/50     Step:3|6   loss:0.8908168077468872  \n","Epoch:16/50     Step:4|6   loss:0.9164254069328308  \n","Epoch:16/50     Step:5|6   loss:0.8499095439910889  \n","Epoch:16/50     Step:6|6   loss:0.876397967338562  \n","Epoch:16/50     Step:7|6   loss:0.874701201915741  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:17/50     Step:1|6   loss:0.874996542930603  \n","Epoch:17/50     Step:2|6   loss:0.850297212600708  \n","Epoch:17/50     Step:3|6   loss:0.8641688823699951  \n","Epoch:17/50     Step:4|6   loss:0.9006408452987671  \n","Epoch:17/50     Step:5|6   loss:0.87986159324646  \n","Epoch:17/50     Step:6|6   loss:0.821277916431427  \n","Epoch:17/50     Step:7|6   loss:0.9196386933326721  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:18/50     Step:1|6   loss:0.8764413595199585  \n","Epoch:18/50     Step:2|6   loss:0.9220722317695618  \n","Epoch:18/50     Step:3|6   loss:0.8268528580665588  \n","Epoch:18/50     Step:4|6   loss:0.8507826328277588  \n","Epoch:18/50     Step:5|6   loss:0.8770763874053955  \n","Epoch:18/50     Step:6|6   loss:0.8728684186935425  \n","Epoch:18/50     Step:7|6   loss:0.9037419557571411  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:19/50     Step:1|6   loss:0.8598175048828125  \n","Epoch:19/50     Step:2|6   loss:0.8231397271156311  \n","Epoch:19/50     Step:3|6   loss:0.8953424096107483  \n","Epoch:19/50     Step:4|6   loss:0.9684004783630371  \n","Epoch:19/50     Step:5|6   loss:0.8828845620155334  \n","Epoch:19/50     Step:6|6   loss:0.8264929056167603  \n","Epoch:19/50     Step:7|6   loss:0.8977164030075073  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:20/50     Step:1|6   loss:0.8400673866271973  \n","Epoch:20/50     Step:2|6   loss:0.8140144348144531  \n","Epoch:20/50     Step:3|6   loss:0.9352638125419617  \n","Epoch:20/50     Step:4|6   loss:0.8973720073699951  \n","Epoch:20/50     Step:5|6   loss:0.8329885005950928  \n","Epoch:20/50     Step:6|6   loss:0.7990634441375732  \n","Epoch:20/50     Step:7|6   loss:0.8800259828567505  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:21/50     Step:1|6   loss:0.9052466750144958  \n","Epoch:21/50     Step:2|6   loss:0.7904883623123169  \n","Epoch:21/50     Step:3|6   loss:0.8262287378311157  \n","Epoch:21/50     Step:4|6   loss:0.8119350671768188  \n","Epoch:21/50     Step:5|6   loss:0.8859948515892029  \n","Epoch:21/50     Step:6|6   loss:0.8274195194244385  \n","Epoch:21/50     Step:7|6   loss:0.8901223540306091  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:22/50     Step:1|6   loss:0.8467904329299927  \n","Epoch:22/50     Step:2|6   loss:0.8493244647979736  \n","Epoch:22/50     Step:3|6   loss:0.8862248659133911  \n","Epoch:22/50     Step:4|6   loss:0.8499658107757568  \n","Epoch:22/50     Step:5|6   loss:0.8148748874664307  \n","Epoch:22/50     Step:6|6   loss:0.8670916557312012  \n","Epoch:22/50     Step:7|6   loss:0.8595185279846191  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:23/50     Step:1|6   loss:0.8510755300521851  \n","Epoch:23/50     Step:2|6   loss:0.8198211789131165  \n","Epoch:23/50     Step:3|6   loss:0.793735921382904  \n","Epoch:23/50     Step:4|6   loss:0.8160922527313232  \n","Epoch:23/50     Step:5|6   loss:0.8660606145858765  \n","Epoch:23/50     Step:6|6   loss:0.8424525260925293  \n","Epoch:23/50     Step:7|6   loss:0.7714709043502808  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:24/50     Step:1|6   loss:0.8391338586807251  \n","Epoch:24/50     Step:2|6   loss:0.8305373191833496  \n","Epoch:24/50     Step:3|6   loss:0.8012068271636963  \n","Epoch:24/50     Step:4|6   loss:0.8845632672309875  \n","Epoch:24/50     Step:5|6   loss:0.8471565246582031  \n","Epoch:24/50     Step:6|6   loss:0.8674364686012268  \n","Epoch:24/50     Step:7|6   loss:0.8409649729728699  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:25/50     Step:1|6   loss:0.8203141689300537  \n","Epoch:25/50     Step:2|6   loss:0.8015390634536743  \n","Epoch:25/50     Step:3|6   loss:0.881732702255249  \n","Epoch:25/50     Step:4|6   loss:0.812501072883606  \n","Epoch:25/50     Step:5|6   loss:0.8536285161972046  \n","Epoch:25/50     Step:6|6   loss:0.8459618091583252  \n","Epoch:25/50     Step:7|6   loss:0.942766547203064  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:26/50     Step:1|6   loss:0.8484799861907959  \n","Epoch:26/50     Step:2|6   loss:0.8115168809890747  \n","Epoch:26/50     Step:3|6   loss:0.7985160946846008  \n","Epoch:26/50     Step:4|6   loss:0.8705734610557556  \n","Epoch:26/50     Step:5|6   loss:0.8236433267593384  \n","Epoch:26/50     Step:6|6   loss:0.8329691886901855  \n","Epoch:26/50     Step:7|6   loss:0.8329501152038574  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:27/50     Step:1|6   loss:0.8001137971878052  \n","Epoch:27/50     Step:2|6   loss:0.8434655666351318  \n","Epoch:27/50     Step:3|6   loss:0.850450873374939  \n","Epoch:27/50     Step:4|6   loss:0.8622522354125977  \n","Epoch:27/50     Step:5|6   loss:0.8242069482803345  \n","Epoch:27/50     Step:6|6   loss:0.83515465259552  \n","Epoch:27/50     Step:7|6   loss:0.8618410229682922  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:28/50     Step:1|6   loss:0.8380234241485596  \n","Epoch:28/50     Step:2|6   loss:0.8163820505142212  \n","Epoch:28/50     Step:3|6   loss:0.779096782207489  \n","Epoch:28/50     Step:4|6   loss:0.8502492904663086  \n","Epoch:28/50     Step:5|6   loss:0.8555577993392944  \n","Epoch:28/50     Step:6|6   loss:0.858494758605957  \n","Epoch:28/50     Step:7|6   loss:0.8819490671157837  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:29/50     Step:1|6   loss:0.837406575679779  \n","Epoch:29/50     Step:2|6   loss:0.8448797464370728  \n","Epoch:29/50     Step:3|6   loss:0.8442742824554443  \n","Epoch:29/50     Step:4|6   loss:0.8351684212684631  \n","Epoch:29/50     Step:5|6   loss:0.7925494909286499  \n","Epoch:29/50     Step:6|6   loss:0.8660919666290283  \n","Epoch:29/50     Step:7|6   loss:0.9206670522689819  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:30/50     Step:1|6   loss:0.7772843837738037  \n","Epoch:30/50     Step:2|6   loss:0.8637884855270386  \n","Epoch:30/50     Step:3|6   loss:0.8133819103240967  \n","Epoch:30/50     Step:4|6   loss:0.9017245173454285  \n","Epoch:30/50     Step:5|6   loss:0.8234506249427795  \n","Epoch:30/50     Step:6|6   loss:0.8071819543838501  \n","Epoch:30/50     Step:7|6   loss:0.8072493076324463  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:31/50     Step:1|6   loss:0.7795405387878418  \n","Epoch:31/50     Step:2|6   loss:0.8051149845123291  \n","Epoch:31/50     Step:3|6   loss:0.8376450538635254  \n","Epoch:31/50     Step:4|6   loss:0.8669880628585815  \n","Epoch:31/50     Step:5|6   loss:0.792181670665741  \n","Epoch:31/50     Step:6|6   loss:0.7743905782699585  \n","Epoch:31/50     Step:7|6   loss:0.8226276636123657  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:32/50     Step:1|6   loss:0.8016656637191772  \n","Epoch:32/50     Step:2|6   loss:0.8181799650192261  \n","Epoch:32/50     Step:3|6   loss:0.8607202768325806  \n","Epoch:32/50     Step:4|6   loss:0.8106131553649902  \n","Epoch:32/50     Step:5|6   loss:0.8226960301399231  \n","Epoch:32/50     Step:6|6   loss:0.8389855623245239  \n","Epoch:32/50     Step:7|6   loss:0.8210368156433105  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:33/50     Step:1|6   loss:0.8688783645629883  \n","Epoch:33/50     Step:2|6   loss:0.7934427261352539  \n","Epoch:33/50     Step:3|6   loss:0.8062459230422974  \n","Epoch:33/50     Step:4|6   loss:0.8200477361679077  \n","Epoch:33/50     Step:5|6   loss:0.8266887664794922  \n","Epoch:33/50     Step:6|6   loss:0.7868779897689819  \n","Epoch:33/50     Step:7|6   loss:0.8575273752212524  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:34/50     Step:1|6   loss:0.8099987506866455  \n","Epoch:34/50     Step:2|6   loss:0.767177939414978  \n","Epoch:34/50     Step:3|6   loss:0.790285587310791  \n","Epoch:34/50     Step:4|6   loss:0.7217657566070557  \n","Epoch:34/50     Step:5|6   loss:0.7694965600967407  \n","Epoch:34/50     Step:6|6   loss:0.750777006149292  \n","Epoch:34/50     Step:7|6   loss:0.8527423739433289  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 83.14 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:35/50     Step:1|6   loss:0.8501030206680298  \n","Epoch:35/50     Step:2|6   loss:0.8258655071258545  \n","Epoch:35/50     Step:3|6   loss:0.9026036262512207  \n","Epoch:35/50     Step:4|6   loss:0.8270777463912964  \n","Epoch:35/50     Step:5|6   loss:0.8423374891281128  \n","Epoch:35/50     Step:6|6   loss:0.7903529405593872  \n","Epoch:35/50     Step:7|6   loss:0.8040355443954468  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:36/50     Step:1|6   loss:0.8550246953964233  \n","Epoch:36/50     Step:2|6   loss:0.8771567940711975  \n","Epoch:36/50     Step:3|6   loss:0.8338972926139832  \n","Epoch:36/50     Step:4|6   loss:0.8099822402000427  \n","Epoch:36/50     Step:5|6   loss:0.7809130549430847  \n","Epoch:36/50     Step:6|6   loss:0.7891229391098022  \n","Epoch:36/50     Step:7|6   loss:0.8099520802497864  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:37/50     Step:1|6   loss:0.890639066696167  \n","Epoch:37/50     Step:2|6   loss:0.7560133934020996  \n","Epoch:37/50     Step:3|6   loss:0.7623674869537354  \n","Epoch:37/50     Step:4|6   loss:0.8033897280693054  \n","Epoch:37/50     Step:5|6   loss:0.8079233765602112  \n","Epoch:37/50     Step:6|6   loss:0.8658747673034668  \n","Epoch:37/50     Step:7|6   loss:0.8432774543762207  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:38/50     Step:1|6   loss:0.8125858306884766  \n","Epoch:38/50     Step:2|6   loss:0.7975232601165771  \n","Epoch:38/50     Step:3|6   loss:0.8865712881088257  \n","Epoch:38/50     Step:4|6   loss:0.8443244695663452  \n","Epoch:38/50     Step:5|6   loss:0.8087195754051208  \n","Epoch:38/50     Step:6|6   loss:0.7904380559921265  \n","Epoch:38/50     Step:7|6   loss:0.7684160470962524  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:39/50     Step:1|6   loss:0.8351962566375732  \n","Epoch:39/50     Step:2|6   loss:0.8015191555023193  \n","Epoch:39/50     Step:3|6   loss:0.790657103061676  \n","Epoch:39/50     Step:4|6   loss:0.8707020282745361  \n","Epoch:39/50     Step:5|6   loss:0.8382847309112549  \n","Epoch:39/50     Step:6|6   loss:0.8227194547653198  \n","Epoch:39/50     Step:7|6   loss:0.86683189868927  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:40/50     Step:1|6   loss:0.880540132522583  \n","Epoch:40/50     Step:2|6   loss:0.846807599067688  \n","Epoch:40/50     Step:3|6   loss:0.8048689365386963  \n","Epoch:40/50     Step:4|6   loss:0.8011910319328308  \n","Epoch:40/50     Step:5|6   loss:0.847790002822876  \n","Epoch:40/50     Step:6|6   loss:0.7973240613937378  \n","Epoch:40/50     Step:7|6   loss:0.8084234595298767  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:41/50     Step:1|6   loss:0.7726812362670898  \n","Epoch:41/50     Step:2|6   loss:0.8332405090332031  \n","Epoch:41/50     Step:3|6   loss:0.8495216369628906  \n","Epoch:41/50     Step:4|6   loss:0.8008401989936829  \n","Epoch:41/50     Step:5|6   loss:0.7715673446655273  \n","Epoch:41/50     Step:6|6   loss:0.8238329887390137  \n","Epoch:41/50     Step:7|6   loss:0.815970778465271  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:42/50     Step:1|6   loss:0.7842035889625549  \n","Epoch:42/50     Step:2|6   loss:0.8266843557357788  \n","Epoch:42/50     Step:3|6   loss:0.8222246766090393  \n","Epoch:42/50     Step:4|6   loss:0.8093006610870361  \n","Epoch:42/50     Step:5|6   loss:0.8255419135093689  \n","Epoch:42/50     Step:6|6   loss:0.8240412473678589  \n","Epoch:42/50     Step:7|6   loss:0.7723162770271301  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:43/50     Step:1|6   loss:0.8317285776138306  \n","Epoch:43/50     Step:2|6   loss:0.8164829611778259  \n","Epoch:43/50     Step:3|6   loss:0.8263000249862671  \n","Epoch:43/50     Step:4|6   loss:0.7983929514884949  \n","Epoch:43/50     Step:5|6   loss:0.7650160193443298  \n","Epoch:43/50     Step:6|6   loss:0.8146058320999146  \n","Epoch:43/50     Step:7|6   loss:0.8166875839233398  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:44/50     Step:1|6   loss:0.8036198616027832  \n","Epoch:44/50     Step:2|6   loss:0.8410413265228271  \n","Epoch:44/50     Step:3|6   loss:0.80638587474823  \n","Epoch:44/50     Step:4|6   loss:0.7899067401885986  \n","Epoch:44/50     Step:5|6   loss:0.8150862455368042  \n","Epoch:44/50     Step:6|6   loss:0.7896943092346191  \n","Epoch:44/50     Step:7|6   loss:0.8372138738632202  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:45/50     Step:1|6   loss:0.7558480501174927  \n","Epoch:45/50     Step:2|6   loss:0.8167452812194824  \n","Epoch:45/50     Step:3|6   loss:0.7552717924118042  \n","Epoch:45/50     Step:4|6   loss:0.8329986333847046  \n","Epoch:45/50     Step:5|6   loss:0.7636198997497559  \n","Epoch:45/50     Step:6|6   loss:0.8277987241744995  \n","Epoch:45/50     Step:7|6   loss:0.7967053651809692  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:46/50     Step:1|6   loss:0.8610744476318359  \n","Epoch:46/50     Step:2|6   loss:0.8185080289840698  \n","Epoch:46/50     Step:3|6   loss:0.8157839775085449  \n","Epoch:46/50     Step:4|6   loss:0.8272049427032471  \n","Epoch:46/50     Step:5|6   loss:0.7848590612411499  \n","Epoch:46/50     Step:6|6   loss:0.7929114103317261  \n","Epoch:46/50     Step:7|6   loss:0.8318564891815186  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:47/50     Step:1|6   loss:0.8184465169906616  \n","Epoch:47/50     Step:2|6   loss:0.8592059016227722  \n","Epoch:47/50     Step:3|6   loss:0.8438037633895874  \n","Epoch:47/50     Step:4|6   loss:0.8207367658615112  \n","Epoch:47/50     Step:5|6   loss:0.7683563828468323  \n","Epoch:47/50     Step:6|6   loss:0.7978546619415283  \n","Epoch:47/50     Step:7|6   loss:0.8139152526855469  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:48/50     Step:1|6   loss:0.7965549230575562  \n","Epoch:48/50     Step:2|6   loss:0.7322750091552734  \n","Epoch:48/50     Step:3|6   loss:0.8128466010093689  \n","Epoch:48/50     Step:4|6   loss:0.7076243758201599  \n","Epoch:48/50     Step:5|6   loss:0.8657305836677551  \n","Epoch:48/50     Step:6|6   loss:0.8129260540008545  \n","Epoch:48/50     Step:7|6   loss:0.7817077040672302  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:93.46%\t train set:86.89%\n","Epoch:49/50     Step:1|6   loss:0.8143125772476196  \n","Epoch:49/50     Step:2|6   loss:0.7868976593017578  \n","Epoch:49/50     Step:3|6   loss:0.8025323152542114  \n","Epoch:49/50     Step:4|6   loss:0.8214682340621948  \n","Epoch:49/50     Step:5|6   loss:0.8440656661987305  \n","Epoch:49/50     Step:6|6   loss:0.7878488898277283  \n","Epoch:49/50     Step:7|6   loss:0.8579500913619995  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:93.46%\t train set:88.06%\n","Epoch:50/50     Step:1|6   loss:0.8122553825378418  \n","Epoch:50/50     Step:2|6   loss:0.802379310131073  \n","Epoch:50/50     Step:3|6   loss:0.8078203201293945  \n","Epoch:50/50     Step:4|6   loss:0.7805038690567017  \n","Epoch:50/50     Step:5|6   loss:0.8610490560531616  \n","Epoch:50/50     Step:6|6   loss:0.7765716314315796  \n","Epoch:50/50     Step:7|6   loss:0.8131375908851624  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:88.06%\n","Accuracy on test_set: 89.72 %\n","3\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='ir', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.2624166011810303  \n","Epoch:1/50     Step:2|6   loss:1.199733853340149  \n","Epoch:1/50     Step:3|6   loss:1.2145882844924927  \n","Epoch:1/50     Step:4|6   loss:1.3171015977859497  \n","Epoch:1/50     Step:5|6   loss:1.2271215915679932  \n","Epoch:1/50     Step:6|6   loss:1.1590405702590942  \n","Epoch:1/50     Step:7|6   loss:1.2279646396636963  \n","Accuracy on test_set: 23.36 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:23.36%\t train set:23.89%\n","Epoch:2/50     Step:1|6   loss:1.1264030933380127  \n","Epoch:2/50     Step:2|6   loss:1.1448677778244019  \n","Epoch:2/50     Step:3|6   loss:1.190445065498352  \n","Epoch:2/50     Step:4|6   loss:1.2052429914474487  \n","Epoch:2/50     Step:5|6   loss:1.186028003692627  \n","Epoch:2/50     Step:6|6   loss:1.193813443183899  \n","Epoch:2/50     Step:7|6   loss:1.1332454681396484  \n","Accuracy on test_set: 23.36 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:23.36%\t train set:23.89%\n","Epoch:3/50     Step:1|6   loss:1.1913825273513794  \n","Epoch:3/50     Step:2|6   loss:1.1093693971633911  \n","Epoch:3/50     Step:3|6   loss:1.1396173238754272  \n","Epoch:3/50     Step:4|6   loss:1.1808640956878662  \n","Epoch:3/50     Step:5|6   loss:1.0972543954849243  \n","Epoch:3/50     Step:6|6   loss:1.129753828048706  \n","Epoch:3/50     Step:7|6   loss:1.1730005741119385  \n","Accuracy on test_set: 23.36 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:23.36%\t train set:23.89%\n","Epoch:4/50     Step:1|6   loss:1.1068490743637085  \n","Epoch:4/50     Step:2|6   loss:1.1792851686477661  \n","Epoch:4/50     Step:3|6   loss:1.081136703491211  \n","Epoch:4/50     Step:4|6   loss:1.0926411151885986  \n","Epoch:4/50     Step:5|6   loss:1.081585168838501  \n","Epoch:4/50     Step:6|6   loss:1.1122581958770752  \n","Epoch:4/50     Step:7|6   loss:1.0522143840789795  \n","Accuracy on test_set: 23.36 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:23.36%\t train set:23.89%\n","Epoch:5/50     Step:1|6   loss:1.0652073621749878  \n","Epoch:5/50     Step:2|6   loss:1.0224862098693848  \n","Epoch:5/50     Step:3|6   loss:1.1594513654708862  \n","Epoch:5/50     Step:4|6   loss:1.1378310918807983  \n","Epoch:5/50     Step:5|6   loss:1.083433747291565  \n","Epoch:5/50     Step:6|6   loss:1.0457189083099365  \n","Epoch:5/50     Step:7|6   loss:1.0435335636138916  \n","Accuracy on test_set: 26.17 %\n","Accuracy on train_set: 25.29 %\n","current max accuracy\t test set:26.17%\t train set:25.29%\n","Epoch:6/50     Step:1|6   loss:1.0229378938674927  \n","Epoch:6/50     Step:2|6   loss:1.0687215328216553  \n","Epoch:6/50     Step:3|6   loss:1.0523631572723389  \n","Epoch:6/50     Step:4|6   loss:1.067556619644165  \n","Epoch:6/50     Step:5|6   loss:1.0089882612228394  \n","Epoch:6/50     Step:6|6   loss:0.9682374000549316  \n","Epoch:6/50     Step:7|6   loss:1.0850342512130737  \n","Accuracy on test_set: 38.32 %\n","Accuracy on train_set: 32.55 %\n","current max accuracy\t test set:38.32%\t train set:32.55%\n","Epoch:7/50     Step:1|6   loss:1.0094878673553467  \n","Epoch:7/50     Step:2|6   loss:1.0220125913619995  \n","Epoch:7/50     Step:3|6   loss:1.0098210573196411  \n","Epoch:7/50     Step:4|6   loss:0.9642487168312073  \n","Epoch:7/50     Step:5|6   loss:1.039907455444336  \n","Epoch:7/50     Step:6|6   loss:1.0536279678344727  \n","Epoch:7/50     Step:7|6   loss:1.0131237506866455  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 41.22 %\n","current max accuracy\t test set:44.86%\t train set:41.22%\n","Epoch:8/50     Step:1|6   loss:1.0639656782150269  \n","Epoch:8/50     Step:2|6   loss:0.9847463369369507  \n","Epoch:8/50     Step:3|6   loss:1.0129380226135254  \n","Epoch:8/50     Step:4|6   loss:1.033373475074768  \n","Epoch:8/50     Step:5|6   loss:1.0212575197219849  \n","Epoch:8/50     Step:6|6   loss:0.9741358160972595  \n","Epoch:8/50     Step:7|6   loss:0.9744649529457092  \n","Accuracy on test_set: 66.36 %\n","Accuracy on train_set: 70.02 %\n","current max accuracy\t test set:66.36%\t train set:70.02%\n","Epoch:9/50     Step:1|6   loss:1.0055809020996094  \n","Epoch:9/50     Step:2|6   loss:1.0235906839370728  \n","Epoch:9/50     Step:3|6   loss:1.0225555896759033  \n","Epoch:9/50     Step:4|6   loss:0.9866222143173218  \n","Epoch:9/50     Step:5|6   loss:0.9240972995758057  \n","Epoch:9/50     Step:6|6   loss:0.9811810255050659  \n","Epoch:9/50     Step:7|6   loss:0.9824782609939575  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 75.64 %\n","current max accuracy\t test set:72.9%\t train set:75.64%\n","Epoch:10/50     Step:1|6   loss:0.9990965127944946  \n","Epoch:10/50     Step:2|6   loss:0.9716478586196899  \n","Epoch:10/50     Step:3|6   loss:0.9678738117218018  \n","Epoch:10/50     Step:4|6   loss:1.0014350414276123  \n","Epoch:10/50     Step:5|6   loss:0.9127978682518005  \n","Epoch:10/50     Step:6|6   loss:0.8874024152755737  \n","Epoch:10/50     Step:7|6   loss:0.9709118604660034  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 78.45 %\n","current max accuracy\t test set:75.7%\t train set:78.45%\n","Epoch:11/50     Step:1|6   loss:0.9269943833351135  \n","Epoch:11/50     Step:2|6   loss:0.972934365272522  \n","Epoch:11/50     Step:3|6   loss:0.9023231267929077  \n","Epoch:11/50     Step:4|6   loss:0.9388673305511475  \n","Epoch:11/50     Step:5|6   loss:0.9484910368919373  \n","Epoch:11/50     Step:6|6   loss:0.9402624368667603  \n","Epoch:11/50     Step:7|6   loss:1.0280349254608154  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 81.50 %\n","current max accuracy\t test set:75.7%\t train set:81.5%\n","Epoch:12/50     Step:1|6   loss:0.9468153119087219  \n","Epoch:12/50     Step:2|6   loss:0.9461194276809692  \n","Epoch:12/50     Step:3|6   loss:0.8833197355270386  \n","Epoch:12/50     Step:4|6   loss:0.9434559941291809  \n","Epoch:12/50     Step:5|6   loss:0.961097002029419  \n","Epoch:12/50     Step:6|6   loss:0.9136556386947632  \n","Epoch:12/50     Step:7|6   loss:0.9350253343582153  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 82.20 %\n","current max accuracy\t test set:77.57%\t train set:82.2%\n","Epoch:13/50     Step:1|6   loss:0.9918976426124573  \n","Epoch:13/50     Step:2|6   loss:0.9713180065155029  \n","Epoch:13/50     Step:3|6   loss:0.9239503741264343  \n","Epoch:13/50     Step:4|6   loss:0.9257316589355469  \n","Epoch:13/50     Step:5|6   loss:0.9212068915367126  \n","Epoch:13/50     Step:6|6   loss:0.9116188287734985  \n","Epoch:13/50     Step:7|6   loss:0.9100613594055176  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 82.44 %\n","current max accuracy\t test set:77.57%\t train set:82.44%\n","Epoch:14/50     Step:1|6   loss:0.9615734219551086  \n","Epoch:14/50     Step:2|6   loss:0.9857227802276611  \n","Epoch:14/50     Step:3|6   loss:0.878724217414856  \n","Epoch:14/50     Step:4|6   loss:0.9043611288070679  \n","Epoch:14/50     Step:5|6   loss:0.9417485594749451  \n","Epoch:14/50     Step:6|6   loss:0.8890262842178345  \n","Epoch:14/50     Step:7|6   loss:0.9152618646621704  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:78.5%\t train set:83.37%\n","Epoch:15/50     Step:1|6   loss:0.8983231782913208  \n","Epoch:15/50     Step:2|6   loss:0.9500695466995239  \n","Epoch:15/50     Step:3|6   loss:0.8436806201934814  \n","Epoch:15/50     Step:4|6   loss:0.9088257551193237  \n","Epoch:15/50     Step:5|6   loss:0.8958096504211426  \n","Epoch:15/50     Step:6|6   loss:0.8706033229827881  \n","Epoch:15/50     Step:7|6   loss:0.8506891131401062  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:81.31%\t train set:83.61%\n","Epoch:16/50     Step:1|6   loss:0.9171923995018005  \n","Epoch:16/50     Step:2|6   loss:0.8963937163352966  \n","Epoch:16/50     Step:3|6   loss:0.9236581921577454  \n","Epoch:16/50     Step:4|6   loss:0.8593357801437378  \n","Epoch:16/50     Step:5|6   loss:0.9215015172958374  \n","Epoch:16/50     Step:6|6   loss:0.9474549889564514  \n","Epoch:16/50     Step:7|6   loss:0.9216300845146179  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:81.31%\t train set:83.84%\n","Epoch:17/50     Step:1|6   loss:0.8849472999572754  \n","Epoch:17/50     Step:2|6   loss:0.923184871673584  \n","Epoch:17/50     Step:3|6   loss:0.8917899131774902  \n","Epoch:17/50     Step:4|6   loss:0.9057285785675049  \n","Epoch:17/50     Step:5|6   loss:0.8670694231987  \n","Epoch:17/50     Step:6|6   loss:0.8832619190216064  \n","Epoch:17/50     Step:7|6   loss:0.9293566346168518  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:81.31%\t train set:83.84%\n","Epoch:18/50     Step:1|6   loss:0.8677598834037781  \n","Epoch:18/50     Step:2|6   loss:0.9058734178543091  \n","Epoch:18/50     Step:3|6   loss:0.939692497253418  \n","Epoch:18/50     Step:4|6   loss:0.9083921313285828  \n","Epoch:18/50     Step:5|6   loss:0.8860230445861816  \n","Epoch:18/50     Step:6|6   loss:0.8758411407470703  \n","Epoch:18/50     Step:7|6   loss:0.9137825965881348  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:82.24%\t train set:84.31%\n","Epoch:19/50     Step:1|6   loss:0.8546237945556641  \n","Epoch:19/50     Step:2|6   loss:0.9161601066589355  \n","Epoch:19/50     Step:3|6   loss:0.8832719326019287  \n","Epoch:19/50     Step:4|6   loss:0.8986312747001648  \n","Epoch:19/50     Step:5|6   loss:0.8607460856437683  \n","Epoch:19/50     Step:6|6   loss:0.8690715432167053  \n","Epoch:19/50     Step:7|6   loss:0.9273898005485535  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:85.05%\t train set:84.78%\n","Epoch:20/50     Step:1|6   loss:0.8737115859985352  \n","Epoch:20/50     Step:2|6   loss:0.9243713617324829  \n","Epoch:20/50     Step:3|6   loss:0.8594503998756409  \n","Epoch:20/50     Step:4|6   loss:0.8564162254333496  \n","Epoch:20/50     Step:5|6   loss:0.8726183772087097  \n","Epoch:20/50     Step:6|6   loss:0.9460613131523132  \n","Epoch:20/50     Step:7|6   loss:0.8429907560348511  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:85.98%\t train set:85.71%\n","Epoch:21/50     Step:1|6   loss:0.8525159955024719  \n","Epoch:21/50     Step:2|6   loss:0.9409111738204956  \n","Epoch:21/50     Step:3|6   loss:0.9141194224357605  \n","Epoch:21/50     Step:4|6   loss:0.8773823380470276  \n","Epoch:21/50     Step:5|6   loss:0.8126543760299683  \n","Epoch:21/50     Step:6|6   loss:0.8342388272285461  \n","Epoch:21/50     Step:7|6   loss:0.8775606155395508  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:85.98%\t train set:85.71%\n","Epoch:22/50     Step:1|6   loss:0.9021266102790833  \n","Epoch:22/50     Step:2|6   loss:0.9096179008483887  \n","Epoch:22/50     Step:3|6   loss:0.8363730907440186  \n","Epoch:22/50     Step:4|6   loss:0.8846534490585327  \n","Epoch:22/50     Step:5|6   loss:0.866576611995697  \n","Epoch:22/50     Step:6|6   loss:0.8349292874336243  \n","Epoch:22/50     Step:7|6   loss:0.9242340922355652  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:85.98%\t train set:85.71%\n","Epoch:23/50     Step:1|6   loss:0.8696841597557068  \n","Epoch:23/50     Step:2|6   loss:0.8325871229171753  \n","Epoch:23/50     Step:3|6   loss:0.810391902923584  \n","Epoch:23/50     Step:4|6   loss:0.8637338876724243  \n","Epoch:23/50     Step:5|6   loss:0.896773099899292  \n","Epoch:23/50     Step:6|6   loss:0.9016265869140625  \n","Epoch:23/50     Step:7|6   loss:0.8313616514205933  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:85.98%\t train set:85.71%\n","Epoch:24/50     Step:1|6   loss:0.8068870902061462  \n","Epoch:24/50     Step:2|6   loss:0.8483531475067139  \n","Epoch:24/50     Step:3|6   loss:0.8796688914299011  \n","Epoch:24/50     Step:4|6   loss:0.8165283203125  \n","Epoch:24/50     Step:5|6   loss:0.8773221969604492  \n","Epoch:24/50     Step:6|6   loss:0.9039415121078491  \n","Epoch:24/50     Step:7|6   loss:0.8715156316757202  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:85.98%\t train set:85.95%\n","Epoch:25/50     Step:1|6   loss:0.8422458171844482  \n","Epoch:25/50     Step:2|6   loss:0.8054906725883484  \n","Epoch:25/50     Step:3|6   loss:0.8769547939300537  \n","Epoch:25/50     Step:4|6   loss:0.8451910018920898  \n","Epoch:25/50     Step:5|6   loss:0.8546451330184937  \n","Epoch:25/50     Step:6|6   loss:0.897594690322876  \n","Epoch:25/50     Step:7|6   loss:0.8845947980880737  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 82.90 %\n","current max accuracy\t test set:85.98%\t train set:85.95%\n","Epoch:26/50     Step:1|6   loss:0.881182074546814  \n","Epoch:26/50     Step:2|6   loss:0.8778271079063416  \n","Epoch:26/50     Step:3|6   loss:0.8561818599700928  \n","Epoch:26/50     Step:4|6   loss:0.844768762588501  \n","Epoch:26/50     Step:5|6   loss:0.7828539609909058  \n","Epoch:26/50     Step:6|6   loss:0.8190333843231201  \n","Epoch:26/50     Step:7|6   loss:0.9156157970428467  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:85.98%\t train set:86.18%\n","Epoch:27/50     Step:1|6   loss:0.8471643924713135  \n","Epoch:27/50     Step:2|6   loss:0.8563796281814575  \n","Epoch:27/50     Step:3|6   loss:0.7864166498184204  \n","Epoch:27/50     Step:4|6   loss:0.8933351039886475  \n","Epoch:27/50     Step:5|6   loss:0.8366096615791321  \n","Epoch:27/50     Step:6|6   loss:0.8714302778244019  \n","Epoch:27/50     Step:7|6   loss:0.9015170335769653  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:85.98%\t train set:86.65%\n","Epoch:28/50     Step:1|6   loss:0.8407583832740784  \n","Epoch:28/50     Step:2|6   loss:0.9114646911621094  \n","Epoch:28/50     Step:3|6   loss:0.8175884485244751  \n","Epoch:28/50     Step:4|6   loss:0.8367893695831299  \n","Epoch:28/50     Step:5|6   loss:0.8475711941719055  \n","Epoch:28/50     Step:6|6   loss:0.8422942161560059  \n","Epoch:28/50     Step:7|6   loss:0.8173595666885376  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:85.98%\t train set:86.65%\n","Epoch:29/50     Step:1|6   loss:0.8575353026390076  \n","Epoch:29/50     Step:2|6   loss:0.8583698272705078  \n","Epoch:29/50     Step:3|6   loss:0.8539713621139526  \n","Epoch:29/50     Step:4|6   loss:0.8542607426643372  \n","Epoch:29/50     Step:5|6   loss:0.8919658660888672  \n","Epoch:29/50     Step:6|6   loss:0.833310604095459  4\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:29/50     Step:7|6   loss:0.8293814659118652  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:86.92%\t train set:86.65%\n","Epoch:30/50     Step:1|6   loss:0.904791533946991  \n","Epoch:30/50     Step:2|6   loss:0.884215235710144  \n","Epoch:30/50     Step:3|6   loss:0.7885118722915649  \n","Epoch:30/50     Step:4|6   loss:0.8934574723243713  \n","Epoch:30/50     Step:5|6   loss:0.8676918745040894  \n","Epoch:30/50     Step:6|6   loss:0.8851654529571533  \n","Epoch:30/50     Step:7|6   loss:0.8378528356552124  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:31/50     Step:1|6   loss:0.8623088002204895  \n","Epoch:31/50     Step:2|6   loss:0.8323771357536316  \n","Epoch:31/50     Step:3|6   loss:0.8328498005867004  \n","Epoch:31/50     Step:4|6   loss:0.8350555896759033  \n","Epoch:31/50     Step:5|6   loss:0.7734279036521912  \n","Epoch:31/50     Step:6|6   loss:0.8871465921401978  \n","Epoch:31/50     Step:7|6   loss:0.8376081585884094  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:32/50     Step:1|6   loss:0.8322387337684631  \n","Epoch:32/50     Step:2|6   loss:0.8251729011535645  \n","Epoch:32/50     Step:3|6   loss:0.8824149370193481  \n","Epoch:32/50     Step:4|6   loss:0.8433321714401245  \n","Epoch:32/50     Step:5|6   loss:0.7913055419921875  \n","Epoch:32/50     Step:6|6   loss:0.8274825215339661  \n","Epoch:32/50     Step:7|6   loss:0.9436120986938477  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:33/50     Step:1|6   loss:0.7761255502700806  \n","Epoch:33/50     Step:2|6   loss:0.8380662202835083  \n","Epoch:33/50     Step:3|6   loss:0.8250975012779236  \n","Epoch:33/50     Step:4|6   loss:0.8020933866500854  \n","Epoch:33/50     Step:5|6   loss:0.8036203980445862  \n","Epoch:33/50     Step:6|6   loss:0.8742005228996277  \n","Epoch:33/50     Step:7|6   loss:0.9038392305374146  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:34/50     Step:1|6   loss:0.8583718538284302  \n","Epoch:34/50     Step:2|6   loss:0.8593625426292419  \n","Epoch:34/50     Step:3|6   loss:0.7557740211486816  \n","Epoch:34/50     Step:4|6   loss:0.8387377262115479  \n","Epoch:34/50     Step:5|6   loss:0.8001998066902161  \n","Epoch:34/50     Step:6|6   loss:0.7755206227302551  \n","Epoch:34/50     Step:7|6   loss:0.818827748298645  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:35/50     Step:1|6   loss:0.8355193734169006  \n","Epoch:35/50     Step:2|6   loss:0.8406824469566345  \n","Epoch:35/50     Step:3|6   loss:0.7949523329734802  \n","Epoch:35/50     Step:4|6   loss:0.8439040184020996  \n","Epoch:35/50     Step:5|6   loss:0.8752722144126892  \n","Epoch:35/50     Step:6|6   loss:0.8757970333099365  \n","Epoch:35/50     Step:7|6   loss:0.8104061484336853  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:36/50     Step:1|6   loss:0.7757238745689392  \n","Epoch:36/50     Step:2|6   loss:0.7658935189247131  \n","Epoch:36/50     Step:3|6   loss:0.8663760423660278  \n","Epoch:36/50     Step:4|6   loss:0.8914213180541992  \n","Epoch:36/50     Step:5|6   loss:0.7924438714981079  \n","Epoch:36/50     Step:6|6   loss:0.8459917306900024  \n","Epoch:36/50     Step:7|6   loss:0.8964910507202148  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:37/50     Step:1|6   loss:0.9021849632263184  \n","Epoch:37/50     Step:2|6   loss:0.8497699499130249  \n","Epoch:37/50     Step:3|6   loss:0.8187453746795654  \n","Epoch:37/50     Step:4|6   loss:0.7994764447212219  \n","Epoch:37/50     Step:5|6   loss:0.8321309089660645  \n","Epoch:37/50     Step:6|6   loss:0.8381314277648926  \n","Epoch:37/50     Step:7|6   loss:0.8072841167449951  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:38/50     Step:1|6   loss:0.7405102252960205  \n","Epoch:38/50     Step:2|6   loss:0.8765503168106079  \n","Epoch:38/50     Step:3|6   loss:0.8376468420028687  \n","Epoch:38/50     Step:4|6   loss:0.8116175532341003  \n","Epoch:38/50     Step:5|6   loss:0.830876350402832  \n","Epoch:38/50     Step:6|6   loss:0.8134907484054565  \n","Epoch:38/50     Step:7|6   loss:0.8412108421325684  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:39/50     Step:1|6   loss:0.8345954418182373  \n","Epoch:39/50     Step:2|6   loss:0.872524082660675  \n","Epoch:39/50     Step:3|6   loss:0.868634045124054  \n","Epoch:39/50     Step:4|6   loss:0.8674756288528442  \n","Epoch:39/50     Step:5|6   loss:0.854932963848114  \n","Epoch:39/50     Step:6|6   loss:0.7867887020111084  \n","Epoch:39/50     Step:7|6   loss:0.8265631198883057  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 82.90 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:40/50     Step:1|6   loss:0.8741710186004639  \n","Epoch:40/50     Step:2|6   loss:0.8714406490325928  \n","Epoch:40/50     Step:3|6   loss:0.8320856094360352  \n","Epoch:40/50     Step:4|6   loss:0.8308181166648865  \n","Epoch:40/50     Step:5|6   loss:0.8293696641921997  \n","Epoch:40/50     Step:6|6   loss:0.7992074489593506  \n","Epoch:40/50     Step:7|6   loss:0.7884528636932373  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:41/50     Step:1|6   loss:0.762744665145874  \n","Epoch:41/50     Step:2|6   loss:0.7854108810424805  \n","Epoch:41/50     Step:3|6   loss:0.7685940265655518  \n","Epoch:41/50     Step:4|6   loss:0.8366656303405762  \n","Epoch:41/50     Step:5|6   loss:0.8040704727172852  \n","Epoch:41/50     Step:6|6   loss:0.8451350331306458  \n","Epoch:41/50     Step:7|6   loss:0.7919710874557495  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:42/50     Step:1|6   loss:0.8368320465087891  \n","Epoch:42/50     Step:2|6   loss:0.8152938485145569  \n","Epoch:42/50     Step:3|6   loss:0.8733006715774536  \n","Epoch:42/50     Step:4|6   loss:0.7924885749816895  \n","Epoch:42/50     Step:5|6   loss:0.8252101540565491  \n","Epoch:42/50     Step:6|6   loss:0.8094788789749146  \n","Epoch:42/50     Step:7|6   loss:0.8495277166366577  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:88.79%\t train set:86.89%\n","Epoch:43/50     Step:1|6   loss:0.7967513799667358  \n","Epoch:43/50     Step:2|6   loss:0.8117661476135254  \n","Epoch:43/50     Step:3|6   loss:0.8366955518722534  \n","Epoch:43/50     Step:4|6   loss:0.8561888933181763  \n","Epoch:43/50     Step:5|6   loss:0.8378585577011108  \n","Epoch:43/50     Step:6|6   loss:0.8776414394378662  \n","Epoch:43/50     Step:7|6   loss:0.793228805065155  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:44/50     Step:1|6   loss:0.8233106136322021  \n","Epoch:44/50     Step:2|6   loss:0.8472451567649841  \n","Epoch:44/50     Step:3|6   loss:0.8005472421646118  \n","Epoch:44/50     Step:4|6   loss:0.8457682132720947  \n","Epoch:44/50     Step:5|6   loss:0.8771745562553406  \n","Epoch:44/50     Step:6|6   loss:0.852929949760437  \n","Epoch:44/50     Step:7|6   loss:0.9201428890228271  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:45/50     Step:1|6   loss:0.8352375030517578  \n","Epoch:45/50     Step:2|6   loss:0.8025528192520142  \n","Epoch:45/50     Step:3|6   loss:0.8399471044540405  \n","Epoch:45/50     Step:4|6   loss:0.8486461043357849  \n","Epoch:45/50     Step:5|6   loss:0.8511152863502502  \n","Epoch:45/50     Step:6|6   loss:0.7499001026153564  \n","Epoch:45/50     Step:7|6   loss:0.8203302025794983  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:46/50     Step:1|6   loss:0.8463927507400513  \n","Epoch:46/50     Step:2|6   loss:0.882246732711792  \n","Epoch:46/50     Step:3|6   loss:0.7729419469833374  \n","Epoch:46/50     Step:4|6   loss:0.8515594601631165  \n","Epoch:46/50     Step:5|6   loss:0.824233889579773  \n","Epoch:46/50     Step:6|6   loss:0.8745971918106079  \n","Epoch:46/50     Step:7|6   loss:0.8188639879226685  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:47/50     Step:1|6   loss:0.7882156372070312  \n","Epoch:47/50     Step:2|6   loss:0.8264333009719849  \n","Epoch:47/50     Step:3|6   loss:0.7799677848815918  \n","Epoch:47/50     Step:4|6   loss:0.836358368396759  \n","Epoch:47/50     Step:5|6   loss:0.7692569494247437  \n","Epoch:47/50     Step:6|6   loss:0.8291881084442139  \n","Epoch:47/50     Step:7|6   loss:0.8217518329620361  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:48/50     Step:1|6   loss:0.8267359733581543  \n","Epoch:48/50     Step:2|6   loss:0.737547755241394  \n","Epoch:48/50     Step:3|6   loss:0.8720202445983887  \n","Epoch:48/50     Step:4|6   loss:0.766183614730835  \n","Epoch:48/50     Step:5|6   loss:0.80797278881073  \n","Epoch:48/50     Step:6|6   loss:0.784143328666687  \n","Epoch:48/50     Step:7|6   loss:0.901289701461792  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:49/50     Step:1|6   loss:0.8358001112937927  \n","Epoch:49/50     Step:2|6   loss:0.8348714113235474  \n","Epoch:49/50     Step:3|6   loss:0.752945601940155  \n","Epoch:49/50     Step:4|6   loss:0.8064686059951782  \n","Epoch:49/50     Step:5|6   loss:0.819791853427887  \n","Epoch:49/50     Step:6|6   loss:0.8246911764144897  \n","Epoch:49/50     Step:7|6   loss:0.8263674974441528  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Epoch:50/50     Step:1|6   loss:0.8005644679069519  \n","Epoch:50/50     Step:2|6   loss:0.7396337985992432  \n","Epoch:50/50     Step:3|6   loss:0.8551091551780701  \n","Epoch:50/50     Step:4|6   loss:0.863318920135498  \n","Epoch:50/50     Step:5|6   loss:0.8087894916534424  \n","Epoch:50/50     Step:6|6   loss:0.8020132780075073  \n","Epoch:50/50     Step:7|6   loss:0.9186411499977112  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:88.79%\t train set:87.59%\n","Accuracy on test_set: 82.24 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='ir', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1743481159210205  \n","Epoch:1/50     Step:2|6   loss:1.1706068515777588  \n","Epoch:1/50     Step:3|6   loss:1.2464168071746826  \n","Epoch:1/50     Step:4|6   loss:1.1941510438919067  \n","Epoch:1/50     Step:5|6   loss:1.1254258155822754  \n","Epoch:1/50     Step:6|6   loss:1.2067394256591797  \n","Epoch:1/50     Step:7|6   loss:1.2160143852233887  \n","Accuracy on test_set: 30.84 %\n","Accuracy on train_set: 24.82 %\n","current max accuracy\t test set:30.84%\t train set:24.82%\n","Epoch:2/50     Step:1|6   loss:1.1165692806243896  \n","Epoch:2/50     Step:2|6   loss:1.1625884771347046  \n","Epoch:2/50     Step:3|6   loss:1.2427960634231567  \n","Epoch:2/50     Step:4|6   loss:1.0479028224945068  \n","Epoch:2/50     Step:5|6   loss:1.1158429384231567  \n","Epoch:2/50     Step:6|6   loss:1.154343605041504  \n","Epoch:2/50     Step:7|6   loss:1.096871018409729  \n","Accuracy on test_set: 30.84 %\n","Accuracy on train_set: 24.82 %\n","current max accuracy\t test set:30.84%\t train set:24.82%\n","Epoch:3/50     Step:1|6   loss:1.0505726337432861  \n","Epoch:3/50     Step:2|6   loss:1.0918575525283813  \n","Epoch:3/50     Step:3|6   loss:1.150917410850525  \n","Epoch:3/50     Step:4|6   loss:1.0769144296646118  \n","Epoch:3/50     Step:5|6   loss:1.042886734008789  \n","Epoch:3/50     Step:6|6   loss:1.0567482709884644  \n","Epoch:3/50     Step:7|6   loss:1.090018630027771  \n","Accuracy on test_set: 30.84 %\n","Accuracy on train_set: 24.82 %\n","current max accuracy\t test set:30.84%\t train set:24.82%\n","Epoch:4/50     Step:1|6   loss:1.008456826210022  \n","Epoch:4/50     Step:2|6   loss:1.0607759952545166  \n","Epoch:4/50     Step:3|6   loss:1.0909966230392456  \n","Epoch:4/50     Step:4|6   loss:1.0495938062667847  \n","Epoch:4/50     Step:5|6   loss:1.0428329706192017  \n","Epoch:4/50     Step:6|6   loss:1.0266724824905396  \n","Epoch:4/50     Step:7|6   loss:1.0577987432479858  \n","Accuracy on test_set: 30.84 %\n","Accuracy on train_set: 24.82 %\n","current max accuracy\t test set:30.84%\t train set:24.82%\n","Epoch:5/50     Step:1|6   loss:1.0623035430908203  \n","Epoch:5/50     Step:2|6   loss:1.0706589221954346  \n","Epoch:5/50     Step:3|6   loss:0.9993879795074463  \n","Epoch:5/50     Step:4|6   loss:1.0148519277572632  \n","Epoch:5/50     Step:5|6   loss:1.0614099502563477  \n","Epoch:5/50     Step:6|6   loss:1.0281883478164673  \n","Epoch:5/50     Step:7|6   loss:1.020037055015564  \n","Accuracy on test_set: 30.84 %\n","Accuracy on train_set: 24.82 %\n","current max accuracy\t test set:30.84%\t train set:24.82%\n","Epoch:6/50     Step:1|6   loss:0.992242693901062  \n","Epoch:6/50     Step:2|6   loss:1.0067105293273926  \n","Epoch:6/50     Step:3|6   loss:1.0075680017471313  \n","Epoch:6/50     Step:4|6   loss:0.9515149593353271  \n","Epoch:6/50     Step:5|6   loss:1.0675127506256104  \n","Epoch:6/50     Step:6|6   loss:1.0432510375976562  \n","Epoch:6/50     Step:7|6   loss:1.0269575119018555  \n","Accuracy on test_set: 51.40 %\n","Accuracy on train_set: 43.09 %\n","current max accuracy\t test set:51.4%\t train set:43.09%\n","Epoch:7/50     Step:1|6   loss:1.0377869606018066  \n","Epoch:7/50     Step:2|6   loss:0.9709319472312927  \n","Epoch:7/50     Step:3|6   loss:0.9999046325683594  \n","Epoch:7/50     Step:4|6   loss:1.0339363813400269  \n","Epoch:7/50     Step:5|6   loss:1.019640564918518  \n","Epoch:7/50     Step:6|6   loss:0.9838539361953735  \n","Epoch:7/50     Step:7|6   loss:0.9837228655815125  \n","Accuracy on test_set: 69.16 %\n","Accuracy on train_set: 63.70 %\n","current max accuracy\t test set:69.16%\t train set:63.7%\n","Epoch:8/50     Step:1|6   loss:0.9655869007110596  \n","Epoch:8/50     Step:2|6   loss:1.0073224306106567  \n","Epoch:8/50     Step:3|6   loss:0.9864755868911743  \n","Epoch:8/50     Step:4|6   loss:1.0003993511199951  \n","Epoch:8/50     Step:5|6   loss:0.9878416061401367  \n","Epoch:8/50     Step:6|6   loss:0.9681573510169983  \n","Epoch:8/50     Step:7|6   loss:0.9542686939239502  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 72.37 %\n","current max accuracy\t test set:74.77%\t train set:72.37%\n","Epoch:9/50     Step:1|6   loss:1.0134857892990112  \n","Epoch:9/50     Step:2|6   loss:0.9396380186080933  \n","Epoch:9/50     Step:3|6   loss:1.0093727111816406  \n","Epoch:9/50     Step:4|6   loss:0.9253299236297607  \n","Epoch:9/50     Step:5|6   loss:0.9865939617156982  \n","Epoch:9/50     Step:6|6   loss:0.9332629442214966  \n","Epoch:9/50     Step:7|6   loss:1.0378202199935913  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 77.99 %\n","current max accuracy\t test set:80.37%\t train set:77.99%\n","Epoch:10/50     Step:1|6   loss:0.960918128490448  \n","Epoch:10/50     Step:2|6   loss:0.955901026725769  \n","Epoch:10/50     Step:3|6   loss:0.9204022884368896  \n","Epoch:10/50     Step:4|6   loss:1.0312323570251465  \n","Epoch:10/50     Step:5|6   loss:0.9647189974784851  \n","Epoch:10/50     Step:6|6   loss:0.935836672782898  \n","Epoch:10/50     Step:7|6   loss:0.9377507567405701  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 81.26 %\n","current max accuracy\t test set:86.92%\t train set:81.26%\n","Epoch:11/50     Step:1|6   loss:0.9993974566459656  \n","Epoch:11/50     Step:2|6   loss:0.9206367135047913  \n","Epoch:11/50     Step:3|6   loss:1.007739782333374  \n","Epoch:11/50     Step:4|6   loss:0.9941085577011108  \n","Epoch:11/50     Step:5|6   loss:0.9444855451583862  \n","Epoch:11/50     Step:6|6   loss:0.8909966945648193  \n","Epoch:11/50     Step:7|6   loss:0.9078432321548462  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 82.67 %\n","current max accuracy\t test set:87.85%\t train set:82.67%\n","Epoch:12/50     Step:1|6   loss:0.950186014175415  \n","Epoch:12/50     Step:2|6   loss:0.8996108770370483  \n","Epoch:12/50     Step:3|6   loss:0.9188663363456726  \n","Epoch:12/50     Step:4|6   loss:0.9088477492332458  \n","Epoch:12/50     Step:5|6   loss:0.896573543548584  \n","Epoch:12/50     Step:6|6   loss:0.9010772705078125  \n","Epoch:12/50     Step:7|6   loss:0.9406358003616333  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 83.14 %\n","current max accuracy\t test set:89.72%\t train set:83.14%\n","Epoch:13/50     Step:1|6   loss:0.9582890868186951  \n","Epoch:13/50     Step:2|6   loss:0.8845028281211853  \n","Epoch:13/50     Step:3|6   loss:0.8971447944641113  \n","Epoch:13/50     Step:4|6   loss:0.8943755626678467  \n","Epoch:13/50     Step:5|6   loss:0.9561581611633301  \n","Epoch:13/50     Step:6|6   loss:0.9313036203384399  \n","Epoch:13/50     Step:7|6   loss:0.9248719811439514  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:90.65%\t train set:83.61%\n","Epoch:14/50     Step:1|6   loss:0.897465169429779  \n","Epoch:14/50     Step:2|6   loss:0.9347105026245117  \n","Epoch:14/50     Step:3|6   loss:0.8725454807281494  \n","Epoch:14/50     Step:4|6   loss:0.9390694499015808  \n","Epoch:14/50     Step:5|6   loss:0.9002758860588074  \n","Epoch:14/50     Step:6|6   loss:0.9016921520233154  \n","Epoch:14/50     Step:7|6   loss:0.9209938049316406  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:90.65%\t train set:83.61%\n","Epoch:15/50     Step:1|6   loss:0.8996740579605103  \n","Epoch:15/50     Step:2|6   loss:0.9359145760536194  \n","Epoch:15/50     Step:3|6   loss:0.9408695697784424  \n","Epoch:15/50     Step:4|6   loss:0.9251226186752319  \n","Epoch:15/50     Step:5|6   loss:0.9066224694252014  \n","Epoch:15/50     Step:6|6   loss:0.8576287031173706  \n","Epoch:15/50     Step:7|6   loss:0.8598095774650574  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:90.65%\t train set:87.59%\n","Epoch:16/50     Step:1|6   loss:0.8994321823120117  \n","Epoch:16/50     Step:2|6   loss:0.9029833674430847  \n","Epoch:16/50     Step:3|6   loss:0.8905254006385803  \n","Epoch:16/50     Step:4|6   loss:0.8501975536346436  \n","Epoch:16/50     Step:5|6   loss:0.9307534098625183  \n","Epoch:16/50     Step:6|6   loss:0.8640136122703552  \n","Epoch:16/50     Step:7|6   loss:0.9701372981071472  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:91.59%\t train set:88.29%\n","Epoch:17/50     Step:1|6   loss:0.9795374870300293  \n","Epoch:17/50     Step:2|6   loss:0.8774420022964478  \n","Epoch:17/50     Step:3|6   loss:0.9076803922653198  \n","Epoch:17/50     Step:4|6   loss:0.859254002571106  \n","Epoch:17/50     Step:5|6   loss:0.8688881993293762  \n","Epoch:17/50     Step:6|6   loss:0.9169045090675354  \n","Epoch:17/50     Step:7|6   loss:0.8999205827713013  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:92.52%\t train set:88.29%\n","Epoch:18/50     Step:1|6   loss:0.9379189014434814  \n","Epoch:18/50     Step:2|6   loss:0.8430054783821106  \n","Epoch:18/50     Step:3|6   loss:0.8862488269805908  \n","Epoch:18/50     Step:4|6   loss:0.888805627822876  \n","Epoch:18/50     Step:5|6   loss:0.8554442524909973  \n","Epoch:18/50     Step:6|6   loss:0.8361859321594238  \n","Epoch:18/50     Step:7|6   loss:0.9035345911979675  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:92.52%\t train set:88.29%\n","Epoch:19/50     Step:1|6   loss:0.8744888305664062  \n","Epoch:19/50     Step:2|6   loss:0.8936223387718201  \n","Epoch:19/50     Step:3|6   loss:0.8837594389915466  \n","Epoch:19/50     Step:4|6   loss:0.8857871294021606  \n","Epoch:19/50     Step:5|6   loss:0.861531138420105  \n","Epoch:19/50     Step:6|6   loss:0.8460357189178467  \n","Epoch:19/50     Step:7|6   loss:0.8889161348342896  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:20/50     Step:1|6   loss:0.8979856967926025  \n","Epoch:20/50     Step:2|6   loss:0.8625224828720093  \n","Epoch:20/50     Step:3|6   loss:0.8865374326705933  \n","Epoch:20/50     Step:4|6   loss:0.853440523147583  \n","Epoch:20/50     Step:5|6   loss:0.853985071182251  \n","Epoch:20/50     Step:6|6   loss:0.866268515586853  \n","Epoch:20/50     Step:7|6   loss:0.9434245824813843  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:21/50     Step:1|6   loss:0.9121778011322021  \n","Epoch:21/50     Step:2|6   loss:0.8537034392356873  \n","Epoch:21/50     Step:3|6   loss:0.8638168573379517  \n","Epoch:21/50     Step:4|6   loss:0.8864456415176392  \n","Epoch:21/50     Step:5|6   loss:0.8284024000167847  \n","Epoch:21/50     Step:6|6   loss:0.868323802947998  \n","Epoch:21/50     Step:7|6   loss:0.8885269165039062  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:22/50     Step:1|6   loss:0.8896728754043579  \n","Epoch:22/50     Step:2|6   loss:0.8711968660354614  \n","Epoch:22/50     Step:3|6   loss:0.8412538766860962  \n","Epoch:22/50     Step:4|6   loss:0.8542675375938416  \n","Epoch:22/50     Step:5|6   loss:0.8548411130905151  \n","Epoch:22/50     Step:6|6   loss:0.8209182024002075  \n","Epoch:22/50     Step:7|6   loss:0.8858674168586731  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:23/50     Step:1|6   loss:0.8410943150520325  \n","Epoch:23/50     Step:2|6   loss:0.9104320406913757  \n","Epoch:23/50     Step:3|6   loss:0.8450155258178711  \n","Epoch:23/50     Step:4|6   loss:0.8438056707382202  \n","Epoch:23/50     Step:5|6   loss:0.8497886657714844  \n","Epoch:23/50     Step:6|6   loss:0.889487624168396  \n","Epoch:23/50     Step:7|6   loss:0.9104698896408081  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:24/50     Step:1|6   loss:0.8856948614120483  \n","Epoch:24/50     Step:2|6   loss:0.8773057460784912  \n","Epoch:24/50     Step:3|6   loss:0.8461369276046753  \n","Epoch:24/50     Step:4|6   loss:0.8821050524711609  \n","Epoch:24/50     Step:5|6   loss:0.8686438798904419  \n","Epoch:24/50     Step:6|6   loss:0.8539701700210571  \n","Epoch:24/50     Step:7|6   loss:0.9000145196914673  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:25/50     Step:1|6   loss:0.8201181292533875  \n","Epoch:25/50     Step:2|6   loss:0.8529955148696899  \n","Epoch:25/50     Step:3|6   loss:0.8972927331924438  \n","Epoch:25/50     Step:4|6   loss:0.8791326284408569  \n","Epoch:25/50     Step:5|6   loss:0.8121782541275024  \n","Epoch:25/50     Step:6|6   loss:0.8318997025489807  \n","Epoch:25/50     Step:7|6   loss:0.8184235095977783  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:26/50     Step:1|6   loss:0.8493380546569824  \n","Epoch:26/50     Step:2|6   loss:0.8312267065048218  \n","Epoch:26/50     Step:3|6   loss:0.8375641107559204  \n","Epoch:26/50     Step:4|6   loss:0.8378156423568726  \n","Epoch:26/50     Step:5|6   loss:0.8175578117370605  \n","Epoch:26/50     Step:6|6   loss:0.900362491607666  \n","Epoch:26/50     Step:7|6   loss:0.7831422090530396  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:27/50     Step:1|6   loss:0.8147417306900024  \n","Epoch:27/50     Step:2|6   loss:0.8517528772354126  \n","Epoch:27/50     Step:3|6   loss:0.8957411050796509  \n","Epoch:27/50     Step:4|6   loss:0.8177766799926758  \n","Epoch:27/50     Step:5|6   loss:0.7990267276763916  \n","Epoch:27/50     Step:6|6   loss:0.8803262710571289  \n","Epoch:27/50     Step:7|6   loss:0.8726423978805542  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:28/50     Step:1|6   loss:0.8979595899581909  \n","Epoch:28/50     Step:2|6   loss:0.8408206105232239  \n","Epoch:28/50     Step:3|6   loss:0.8536041975021362  \n","Epoch:28/50     Step:4|6   loss:0.8601607084274292  \n","Epoch:28/50     Step:5|6   loss:0.8198803663253784  \n","Epoch:28/50     Step:6|6   loss:0.8480513095855713  \n","Epoch:28/50     Step:7|6   loss:0.8190434575080872  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:29/50     Step:1|6   loss:0.8514288663864136  \n","Epoch:29/50     Step:2|6   loss:0.839841365814209  \n","Epoch:29/50     Step:3|6   loss:0.855800986289978  \n","Epoch:29/50     Step:4|6   loss:0.8052116632461548  \n","Epoch:29/50     Step:5|6   loss:0.8344305753707886  \n","Epoch:29/50     Step:6|6   loss:0.8754837512969971  \n","Epoch:29/50     Step:7|6   loss:0.8006479740142822  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:30/50     Step:1|6   loss:0.7958965301513672  \n","Epoch:30/50     Step:2|6   loss:0.8309154510498047  \n","Epoch:30/50     Step:3|6   loss:0.9046294689178467  \n","Epoch:30/50     Step:4|6   loss:0.8119379878044128  \n","Epoch:30/50     Step:5|6   loss:0.8189759254455566  \n","Epoch:30/50     Step:6|6   loss:0.8827747106552124  \n","Epoch:30/50     Step:7|6   loss:0.9142211675643921  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:31/50     Step:1|6   loss:0.8670947551727295  \n","Epoch:31/50     Step:2|6   loss:0.8091164827346802  \n","Epoch:31/50     Step:3|6   loss:0.8435404300689697  \n","Epoch:31/50     Step:4|6   loss:0.8010881543159485  \n","Epoch:31/50     Step:5|6   loss:0.8474891781806946  \n","Epoch:31/50     Step:6|6   loss:0.7587628364562988  \n","Epoch:31/50     Step:7|6   loss:0.9491769075393677  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 85.01 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:32/50     Step:1|6   loss:0.8178234696388245  \n","Epoch:32/50     Step:2|6   loss:0.808944821357727  \n","Epoch:32/50     Step:3|6   loss:0.8434120416641235  \n","Epoch:32/50     Step:4|6   loss:0.8732057213783264  \n","Epoch:32/50     Step:5|6   loss:0.8318301439285278  \n","Epoch:32/50     Step:6|6   loss:0.8653155565261841  \n","Epoch:32/50     Step:7|6   loss:0.8223545551300049  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:33/50     Step:1|6   loss:0.8459118604660034  \n","Epoch:33/50     Step:2|6   loss:0.7613469362258911  \n","Epoch:33/50     Step:3|6   loss:0.8134952783584595  \n","Epoch:33/50     Step:4|6   loss:0.8434680104255676  \n","Epoch:33/50     Step:5|6   loss:0.8906072378158569  \n","Epoch:33/50     Step:6|6   loss:0.8205883502960205  \n","Epoch:33/50     Step:7|6   loss:0.8921295404434204  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:93.46%\t train set:88.29%\n","Epoch:34/50     Step:1|6   loss:0.8176116943359375  \n","Epoch:34/50     Step:2|6   loss:0.8884398937225342  \n","Epoch:34/50     Step:3|6   loss:0.8407628536224365  \n","Epoch:34/50     Step:4|6   loss:0.8417270183563232  \n","Epoch:34/50     Step:5|6   loss:0.8126348257064819  \n","Epoch:34/50     Step:6|6   loss:0.8285200595855713  \n","Epoch:34/50     Step:7|6   loss:0.7731552720069885  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:94.39%\t train set:88.29%\n","Epoch:35/50     Step:1|6   loss:0.8676274418830872  \n","Epoch:35/50     Step:2|6   loss:0.873749852180481  \n","Epoch:35/50     Step:3|6   loss:0.814615786075592  \n","Epoch:35/50     Step:4|6   loss:0.7908521294593811  \n","Epoch:35/50     Step:5|6   loss:0.7842592000961304  \n","Epoch:35/50     Step:6|6   loss:0.8441016674041748  \n","Epoch:35/50     Step:7|6   loss:0.7388807535171509  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:94.39%\t train set:88.29%\n","Epoch:36/50     Step:1|6   loss:0.8115739822387695  \n","Epoch:36/50     Step:2|6   loss:0.8527432084083557  \n","Epoch:36/50     Step:3|6   loss:0.8045072555541992  \n","Epoch:36/50     Step:4|6   loss:0.8013596534729004  \n","Epoch:36/50     Step:5|6   loss:0.8597635626792908  \n","Epoch:36/50     Step:6|6   loss:0.7977876663208008  \n","Epoch:36/50     Step:7|6   loss:0.745273232460022  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:94.39%\t train set:88.29%\n","Epoch:37/50     Step:1|6   loss:0.7940863370895386  \n","Epoch:37/50     Step:2|6   loss:0.8552863597869873  \n","Epoch:37/50     Step:3|6   loss:0.8122336864471436  \n","Epoch:37/50     Step:4|6   loss:0.8243366479873657  \n","Epoch:37/50     Step:5|6   loss:0.8528215885162354  \n","Epoch:37/50     Step:6|6   loss:0.8209667801856995  \n","Epoch:37/50     Step:7|6   loss:0.8609200119972229  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:38/50     Step:1|6   loss:0.7490555047988892  \n","Epoch:38/50     Step:2|6   loss:0.8113172054290771  \n","Epoch:38/50     Step:3|6   loss:0.7922300100326538  \n","Epoch:38/50     Step:4|6   loss:0.8218276500701904  \n","Epoch:38/50     Step:5|6   loss:0.7853894233703613  \n","Epoch:38/50     Step:6|6   loss:0.8376014232635498  \n","Epoch:38/50     Step:7|6   loss:0.8228539824485779  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 82.90 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:39/50     Step:1|6   loss:0.800430417060852  \n","Epoch:39/50     Step:2|6   loss:0.7767542004585266  \n","Epoch:39/50     Step:3|6   loss:0.823296308517456  \n","Epoch:39/50     Step:4|6   loss:0.8440408706665039  \n","Epoch:39/50     Step:5|6   loss:0.7963762879371643  \n","Epoch:39/50     Step:6|6   loss:0.826410174369812  \n","Epoch:39/50     Step:7|6   loss:0.822126030921936  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 83.84 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:40/50     Step:1|6   loss:0.8935208916664124  \n","Epoch:40/50     Step:2|6   loss:0.9275736212730408  \n","Epoch:40/50     Step:3|6   loss:0.8563641309738159  \n","Epoch:40/50     Step:4|6   loss:0.7478320598602295  \n","Epoch:40/50     Step:5|6   loss:0.7891821265220642  \n","Epoch:40/50     Step:6|6   loss:0.8392664194107056  \n","Epoch:40/50     Step:7|6   loss:0.7067455649375916  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:41/50     Step:1|6   loss:0.8086282014846802  \n","Epoch:41/50     Step:2|6   loss:0.7890048027038574  \n","Epoch:41/50     Step:3|6   loss:0.7859355211257935  \n","Epoch:41/50     Step:4|6   loss:0.8305836915969849  \n","Epoch:41/50     Step:5|6   loss:0.7672522664070129  \n","Epoch:41/50     Step:6|6   loss:0.8104772567749023  \n","Epoch:41/50     Step:7|6   loss:0.8063642978668213  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:42/50     Step:1|6   loss:0.8127605319023132  \n","Epoch:42/50     Step:2|6   loss:0.7868831157684326  \n","Epoch:42/50     Step:3|6   loss:0.8518804907798767  \n","Epoch:42/50     Step:4|6   loss:0.8322101831436157  \n","Epoch:42/50     Step:5|6   loss:0.7868019342422485  \n","Epoch:42/50     Step:6|6   loss:0.8474510908126831  \n","Epoch:42/50     Step:7|6   loss:0.8447803258895874  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:43/50     Step:1|6   loss:0.7697782516479492  \n","Epoch:43/50     Step:2|6   loss:0.8045334815979004  \n","Epoch:43/50     Step:3|6   loss:0.8155777454376221  \n","Epoch:43/50     Step:4|6   loss:0.8520028591156006  \n","Epoch:43/50     Step:5|6   loss:0.8349456191062927  \n","Epoch:43/50     Step:6|6   loss:0.8366543054580688  \n","Epoch:43/50     Step:7|6   loss:0.850655198097229  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:44/50     Step:1|6   loss:0.8681053519248962  \n","Epoch:44/50     Step:2|6   loss:0.8327031135559082  \n","Epoch:44/50     Step:3|6   loss:0.8714544773101807  \n","Epoch:44/50     Step:4|6   loss:0.8203896284103394  \n","Epoch:44/50     Step:5|6   loss:0.8396739959716797  \n","Epoch:44/50     Step:6|6   loss:0.7600694894790649  \n","Epoch:44/50     Step:7|6   loss:0.7962254285812378  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:45/50     Step:1|6   loss:0.862434983253479  \n","Epoch:45/50     Step:2|6   loss:0.8183835744857788  \n","Epoch:45/50     Step:3|6   loss:0.7261221408843994  \n","Epoch:45/50     Step:4|6   loss:0.8503739237785339  \n","Epoch:45/50     Step:5|6   loss:0.808790922164917  \n","Epoch:45/50     Step:6|6   loss:0.8006536364555359  \n","Epoch:45/50     Step:7|6   loss:0.8615738153457642  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:46/50     Step:1|6   loss:0.7516682147979736  \n","Epoch:46/50     Step:2|6   loss:0.8139808177947998  \n","Epoch:46/50     Step:3|6   loss:0.8233211040496826  \n","Epoch:46/50     Step:4|6   loss:0.8270018100738525  \n","Epoch:46/50     Step:5|6   loss:0.8172309398651123  \n","Epoch:46/50     Step:6|6   loss:0.8072811365127563  \n","Epoch:46/50     Step:7|6   loss:0.7552636861801147  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:47/50     Step:1|6   loss:0.7822771072387695  \n","Epoch:47/50     Step:2|6   loss:0.8072119355201721  \n","Epoch:47/50     Step:3|6   loss:0.8485525846481323  \n","Epoch:47/50     Step:4|6   loss:0.8729922771453857  \n","Epoch:47/50     Step:5|6   loss:0.8362672924995422  \n","Epoch:47/50     Step:6|6   loss:0.7909765243530273  \n","Epoch:47/50     Step:7|6   loss:0.8229361772537231  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:48/50     Step:1|6   loss:0.8316446542739868  \n","Epoch:48/50     Step:2|6   loss:0.8019849061965942  \n","Epoch:48/50     Step:3|6   loss:0.8531205058097839  \n","Epoch:48/50     Step:4|6   loss:0.8176230192184448  \n","Epoch:48/50     Step:5|6   loss:0.7824045419692993  \n","Epoch:48/50     Step:6|6   loss:0.8173112273216248  \n","Epoch:48/50     Step:7|6   loss:0.8187037706375122  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:49/50     Step:1|6   loss:0.8417633175849915  \n","Epoch:49/50     Step:2|6   loss:0.8042725324630737  \n","Epoch:49/50     Step:3|6   loss:0.7968687415122986  \n","Epoch:49/50     Step:4|6   loss:0.758765697479248  \n","Epoch:49/50     Step:5|6   loss:0.839455783367157  \n","Epoch:49/50     Step:6|6   loss:0.8306525945663452  \n","Epoch:49/50     Step:7|6   loss:0.7950977087020874  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Epoch:50/50     Step:1|6   loss:0.8044766187667847  \n","Epoch:50/50     Step:2|6   loss:0.7715083360671997  \n","Epoch:50/50     Step:3|6   loss:0.8196893930435181  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch:50/50     Step:4|6   loss:0.8120951652526855  \n","Epoch:50/50     Step:5|6   loss:0.8114533424377441  \n","Epoch:50/50     Step:6|6   loss:0.8317259550094604  \n","Epoch:50/50     Step:7|6   loss:0.9017347097396851  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:95.33%\t train set:88.29%\n","Accuracy on test_set: 93.46 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-3 --model Flame_one_stream --mode ir --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":8,"id":"f87c86f5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.2107073068618774  \n","Epoch:1/50     Step:2|6   loss:1.14566969871521  \n","Epoch:1/50     Step:3|6   loss:1.2418169975280762  \n","Epoch:1/50     Step:4|6   loss:1.1738876104354858  \n","Epoch:1/50     Step:5|6   loss:1.149350643157959  \n","Epoch:1/50     Step:6|6   loss:1.133608341217041  \n","Epoch:1/50     Step:7|6   loss:1.185516119003296  \n","Accuracy on test_set: 30.84 %\n","Accuracy on train_set: 26.70 %\n","current max accuracy\t test set:30.84%\t train set:26.7%\n","Epoch:2/50     Step:1|6   loss:1.1605080366134644  \n","Epoch:2/50     Step:2|6   loss:1.0564277172088623  \n","Epoch:2/50     Step:3|6   loss:1.1727790832519531  \n","Epoch:2/50     Step:4|6   loss:1.0603998899459839  \n","Epoch:2/50     Step:5|6   loss:1.1093264818191528  \n","Epoch:2/50     Step:6|6   loss:1.1034876108169556  \n","Epoch:2/50     Step:7|6   loss:1.1225427389144897  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 26.70 %\n","current max accuracy\t test set:30.84%\t train set:26.7%\n","Epoch:3/50     Step:1|6   loss:1.072877287864685  \n","Epoch:3/50     Step:2|6   loss:1.0639885663986206  \n","Epoch:3/50     Step:3|6   loss:1.07569420337677  \n","Epoch:3/50     Step:4|6   loss:1.0462461709976196  \n","Epoch:3/50     Step:5|6   loss:1.0713481903076172  \n","Epoch:3/50     Step:6|6   loss:1.086195945739746  \n","Epoch:3/50     Step:7|6   loss:1.062227725982666  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 26.93 %\n","current max accuracy\t test set:30.84%\t train set:26.93%\n","Epoch:4/50     Step:1|6   loss:1.0294442176818848  \n","Epoch:4/50     Step:2|6   loss:1.048311471939087  \n","Epoch:4/50     Step:3|6   loss:1.0351002216339111  \n","Epoch:4/50     Step:4|6   loss:1.0052043199539185  \n","Epoch:4/50     Step:5|6   loss:1.0379441976547241  \n","Epoch:4/50     Step:6|6   loss:1.0053901672363281  \n","Epoch:4/50     Step:7|6   loss:1.0209866762161255  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 26.93 %\n","current max accuracy\t test set:30.84%\t train set:26.93%\n","Epoch:5/50     Step:1|6   loss:1.005832314491272  \n","Epoch:5/50     Step:2|6   loss:0.9807406067848206  \n","Epoch:5/50     Step:3|6   loss:1.0678457021713257  \n","Epoch:5/50     Step:4|6   loss:1.0427675247192383  \n","Epoch:5/50     Step:5|6   loss:0.9726055860519409  \n","Epoch:5/50     Step:6|6   loss:0.9612547159194946  \n","Epoch:5/50     Step:7|6   loss:0.969846248626709  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 28.10 %\n","current max accuracy\t test set:30.84%\t train set:28.1%\n","Epoch:6/50     Step:1|6   loss:0.9715376496315002  \n","Epoch:6/50     Step:2|6   loss:0.9759176969528198  \n","Epoch:6/50     Step:3|6   loss:0.9550464153289795  \n","Epoch:6/50     Step:4|6   loss:0.9395048022270203  \n","Epoch:6/50     Step:5|6   loss:0.9678317308425903  \n","Epoch:6/50     Step:6|6   loss:0.9992188811302185  \n","Epoch:6/50     Step:7|6   loss:0.9834860563278198  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 53.40 %\n","current max accuracy\t test set:50.47%\t train set:53.4%\n","Epoch:7/50     Step:1|6   loss:0.9449599981307983  \n","Epoch:7/50     Step:2|6   loss:0.9617249965667725  \n","Epoch:7/50     Step:3|6   loss:0.9436839818954468  \n","Epoch:7/50     Step:4|6   loss:0.9173622727394104  \n","Epoch:7/50     Step:5|6   loss:0.9555063247680664  \n","Epoch:7/50     Step:6|6   loss:0.9449464082717896  \n","Epoch:7/50     Step:7|6   loss:0.9660113453865051  \n","Accuracy on test_set: 51.40 %\n","Accuracy on train_set: 53.63 %\n","current max accuracy\t test set:51.4%\t train set:53.63%\n","Epoch:8/50     Step:1|6   loss:0.9958465099334717  \n","Epoch:8/50     Step:2|6   loss:0.9260811805725098  \n","Epoch:8/50     Step:3|6   loss:0.9399045705795288  \n","Epoch:8/50     Step:4|6   loss:0.9375914335250854  \n","Epoch:8/50     Step:5|6   loss:0.9113149642944336  \n","Epoch:8/50     Step:6|6   loss:0.938510000705719  \n","Epoch:8/50     Step:7|6   loss:0.8882461786270142  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 77.52 %\n","current max accuracy\t test set:72.9%\t train set:77.52%\n","Epoch:9/50     Step:1|6   loss:0.9126983880996704  \n","Epoch:9/50     Step:2|6   loss:0.8758065104484558  \n","Epoch:9/50     Step:3|6   loss:0.9175122976303101  \n","Epoch:9/50     Step:4|6   loss:0.9337730407714844  \n","Epoch:9/50     Step:5|6   loss:0.9022923707962036  \n","Epoch:9/50     Step:6|6   loss:0.9355562925338745  \n","Epoch:9/50     Step:7|6   loss:0.9499354958534241  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:83.18%\t train set:87.12%\n","Epoch:10/50     Step:1|6   loss:0.861475944519043  \n","Epoch:10/50     Step:2|6   loss:0.8976540565490723  \n","Epoch:10/50     Step:3|6   loss:0.9194518327713013  \n","Epoch:10/50     Step:4|6   loss:0.909037172794342  \n","Epoch:10/50     Step:5|6   loss:0.9091238975524902  \n","Epoch:10/50     Step:6|6   loss:0.8866037130355835  \n","Epoch:10/50     Step:7|6   loss:0.834584653377533  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:85.05%\t train set:91.1%\n","Epoch:11/50     Step:1|6   loss:0.8930328488349915  \n","Epoch:11/50     Step:2|6   loss:0.8812761306762695  \n","Epoch:11/50     Step:3|6   loss:0.8819723725318909  \n","Epoch:11/50     Step:4|6   loss:0.8946917057037354  \n","Epoch:11/50     Step:5|6   loss:0.8595823049545288  \n","Epoch:11/50     Step:6|6   loss:0.9056519269943237  \n","Epoch:11/50     Step:7|6   loss:0.8734568357467651  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:85.05%\t train set:91.1%\n","Epoch:12/50     Step:1|6   loss:0.8666859269142151  \n","Epoch:12/50     Step:2|6   loss:0.8705747127532959  \n","Epoch:12/50     Step:3|6   loss:0.8657605648040771  \n","Epoch:12/50     Step:4|6   loss:0.8892574310302734  \n","Epoch:12/50     Step:5|6   loss:0.8811197876930237  \n","Epoch:12/50     Step:6|6   loss:0.8819814920425415  \n","Epoch:12/50     Step:7|6   loss:0.8642892837524414  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 83.14 %\n","current max accuracy\t test set:85.05%\t train set:91.1%\n","Epoch:13/50     Step:1|6   loss:0.8725793361663818  \n","Epoch:13/50     Step:2|6   loss:0.8570367097854614  \n","Epoch:13/50     Step:3|6   loss:0.8777603507041931  \n","Epoch:13/50     Step:4|6   loss:0.8393402099609375  \n","Epoch:13/50     Step:5|6   loss:0.8924173712730408  \n","Epoch:13/50     Step:6|6   loss:0.8639127612113953  \n","Epoch:13/50     Step:7|6   loss:0.8074892163276672  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:85.05%\t train set:92.51%\n","Epoch:14/50     Step:1|6   loss:0.9004440307617188  \n","Epoch:14/50     Step:2|6   loss:0.8424447178840637  \n","Epoch:14/50     Step:3|6   loss:0.8405622839927673  \n","Epoch:14/50     Step:4|6   loss:0.8361003994941711  \n","Epoch:14/50     Step:5|6   loss:0.8451261520385742  \n","Epoch:14/50     Step:6|6   loss:0.8090125322341919  \n","Epoch:14/50     Step:7|6   loss:0.8501631021499634  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:85.05%\t train set:92.51%\n","Epoch:15/50     Step:1|6   loss:0.8519166707992554  \n","Epoch:15/50     Step:2|6   loss:0.8777644038200378  \n","Epoch:15/50     Step:3|6   loss:0.8497531414031982  \n","Epoch:15/50     Step:4|6   loss:0.7981338500976562  \n","Epoch:15/50     Step:5|6   loss:0.8564090132713318  \n","Epoch:15/50     Step:6|6   loss:0.8588465452194214  \n","Epoch:15/50     Step:7|6   loss:0.8234357833862305  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:85.05%\t train set:92.51%\n","Epoch:16/50     Step:1|6   loss:0.8618946671485901  \n","Epoch:16/50     Step:2|6   loss:0.8247146606445312  \n","Epoch:16/50     Step:3|6   loss:0.8972683548927307  \n","Epoch:16/50     Step:4|6   loss:0.8894610404968262  \n","Epoch:16/50     Step:5|6   loss:0.820923924446106  \n","Epoch:16/50     Step:6|6   loss:0.8815057277679443  \n","Epoch:16/50     Step:7|6   loss:0.8214304447174072  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:17/50     Step:1|6   loss:0.7762924432754517  \n","Epoch:17/50     Step:2|6   loss:0.868110179901123  \n","Epoch:17/50     Step:3|6   loss:0.8043729662895203  \n","Epoch:17/50     Step:4|6   loss:0.8455566167831421  \n","Epoch:17/50     Step:5|6   loss:0.8538980484008789  \n","Epoch:17/50     Step:6|6   loss:0.8248046636581421  \n","Epoch:17/50     Step:7|6   loss:0.8884382247924805  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 90.40 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:18/50     Step:1|6   loss:0.8312630653381348  \n","Epoch:18/50     Step:2|6   loss:0.8491941690444946  \n","Epoch:18/50     Step:3|6   loss:0.8502887487411499  \n","Epoch:18/50     Step:4|6   loss:0.8066852688789368  \n","Epoch:18/50     Step:5|6   loss:0.8654680252075195  \n","Epoch:18/50     Step:6|6   loss:0.8392391204833984  \n","Epoch:18/50     Step:7|6   loss:0.7910643815994263  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:19/50     Step:1|6   loss:0.8505708575248718  \n","Epoch:19/50     Step:2|6   loss:0.8248981833457947  \n","Epoch:19/50     Step:3|6   loss:0.8300007581710815  \n","Epoch:19/50     Step:4|6   loss:0.8262413740158081  \n","Epoch:19/50     Step:5|6   loss:0.8001019954681396  \n","Epoch:19/50     Step:6|6   loss:0.8270783424377441  \n","Epoch:19/50     Step:7|6   loss:0.8126169443130493  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:20/50     Step:1|6   loss:0.8240032196044922  \n","Epoch:20/50     Step:2|6   loss:0.8207197189331055  \n","Epoch:20/50     Step:3|6   loss:0.8211543560028076  \n","Epoch:20/50     Step:4|6   loss:0.806392252445221  \n","Epoch:20/50     Step:5|6   loss:0.8598709106445312  \n","Epoch:20/50     Step:6|6   loss:0.8471555709838867  \n","Epoch:20/50     Step:7|6   loss:0.7971439361572266  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:21/50     Step:1|6   loss:0.8046358823776245  \n","Epoch:21/50     Step:2|6   loss:0.7980619668960571  \n","Epoch:21/50     Step:3|6   loss:0.8680861592292786  \n","Epoch:21/50     Step:4|6   loss:0.8563601970672607  \n","Epoch:21/50     Step:5|6   loss:0.8662644624710083  \n","Epoch:21/50     Step:6|6   loss:0.8518131375312805  \n","Epoch:21/50     Step:7|6   loss:0.7514920234680176  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:22/50     Step:1|6   loss:0.836819052696228  \n","Epoch:22/50     Step:2|6   loss:0.7798135280609131  \n","Epoch:22/50     Step:3|6   loss:0.7768189311027527  \n","Epoch:22/50     Step:4|6   loss:0.8092997074127197  \n","Epoch:22/50     Step:5|6   loss:0.8148009777069092  \n","Epoch:22/50     Step:6|6   loss:0.7860697507858276  \n","Epoch:22/50     Step:7|6   loss:0.7815104722976685  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:89.72%\t train set:93.91%\n","Epoch:23/50     Step:1|6   loss:0.8226881623268127  \n","Epoch:23/50     Step:2|6   loss:0.809109091758728  \n","Epoch:23/50     Step:3|6   loss:0.8582885265350342  \n","Epoch:23/50     Step:4|6   loss:0.8292323350906372  \n","Epoch:23/50     Step:5|6   loss:0.7816826105117798  \n","Epoch:23/50     Step:6|6   loss:0.7869760990142822  \n","Epoch:23/50     Step:7|6   loss:0.8295779228210449  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:90.65%\t train set:93.91%\n","Epoch:24/50     Step:1|6   loss:0.8188614249229431  \n","Epoch:24/50     Step:2|6   loss:0.8071862459182739  \n","Epoch:24/50     Step:3|6   loss:0.8459442853927612  \n","Epoch:24/50     Step:4|6   loss:0.8134667873382568  \n","Epoch:24/50     Step:5|6   loss:0.8044708967208862  \n","Epoch:24/50     Step:6|6   loss:0.8241488933563232  \n","Epoch:24/50     Step:7|6   loss:0.805065929889679  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:25/50     Step:1|6   loss:0.8132100701332092  \n","Epoch:25/50     Step:2|6   loss:0.8423553705215454  \n","Epoch:25/50     Step:3|6   loss:0.7837300300598145  \n","Epoch:25/50     Step:4|6   loss:0.8268830180168152  \n","Epoch:25/50     Step:5|6   loss:0.8219583034515381  \n","Epoch:25/50     Step:6|6   loss:0.823205828666687  \n","Epoch:25/50     Step:7|6   loss:0.8238018751144409  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:26/50     Step:1|6   loss:0.8105359077453613  \n","Epoch:26/50     Step:2|6   loss:0.8206567168235779  \n","Epoch:26/50     Step:3|6   loss:0.779165506362915  \n","Epoch:26/50     Step:4|6   loss:0.8390518426895142  \n","Epoch:26/50     Step:5|6   loss:0.8065721988677979  \n","Epoch:26/50     Step:6|6   loss:0.7599852085113525  \n","Epoch:26/50     Step:7|6   loss:0.7475137710571289  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:27/50     Step:1|6   loss:0.8071402311325073  \n","Epoch:27/50     Step:2|6   loss:0.8261272311210632  \n","Epoch:27/50     Step:3|6   loss:0.7661747932434082  \n","Epoch:27/50     Step:4|6   loss:0.753374457359314  \n","Epoch:27/50     Step:5|6   loss:0.8131093978881836  \n","Epoch:27/50     Step:6|6   loss:0.851998507976532  \n","Epoch:27/50     Step:7|6   loss:0.7911379337310791  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:28/50     Step:1|6   loss:0.7573198080062866  \n","Epoch:28/50     Step:2|6   loss:0.8190546035766602  \n","Epoch:28/50     Step:3|6   loss:0.8347748517990112  \n","Epoch:28/50     Step:4|6   loss:0.7970101833343506  1\n","Epoch:28/50     Step:5|6   loss:0.7608978748321533  \n","Epoch:28/50     Step:6|6   loss:0.7657227516174316  \n","Epoch:28/50     Step:7|6   loss:0.8055065870285034  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:29/50     Step:1|6   loss:0.7989112138748169  \n","Epoch:29/50     Step:2|6   loss:0.7663085460662842  \n","Epoch:29/50     Step:3|6   loss:0.8023704290390015  \n","Epoch:29/50     Step:4|6   loss:0.8456879258155823  \n","Epoch:29/50     Step:5|6   loss:0.7964062690734863  \n","Epoch:29/50     Step:6|6   loss:0.7736414670944214  \n","Epoch:29/50     Step:7|6   loss:0.7761906385421753  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:30/50     Step:1|6   loss:0.8066771030426025  \n","Epoch:30/50     Step:2|6   loss:0.8223676681518555  \n","Epoch:30/50     Step:3|6   loss:0.783972442150116  \n","Epoch:30/50     Step:4|6   loss:0.8177554607391357  \n","Epoch:30/50     Step:5|6   loss:0.8020817041397095  \n","Epoch:30/50     Step:6|6   loss:0.8351948261260986  \n","Epoch:30/50     Step:7|6   loss:0.7906038761138916  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:92.52%\t train set:94.38%\n","Epoch:31/50     Step:1|6   loss:0.7851868867874146  \n","Epoch:31/50     Step:2|6   loss:0.8002485036849976  \n","Epoch:31/50     Step:3|6   loss:0.8146228790283203  \n","Epoch:31/50     Step:4|6   loss:0.7608183026313782  \n","Epoch:31/50     Step:5|6   loss:0.7872164249420166  \n","Epoch:31/50     Step:6|6   loss:0.8082945346832275  \n","Epoch:31/50     Step:7|6   loss:0.8017550110816956  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:92.52%\t train set:94.38%\n","Epoch:32/50     Step:1|6   loss:0.7804266810417175  \n","Epoch:32/50     Step:2|6   loss:0.8096234798431396  \n","Epoch:32/50     Step:3|6   loss:0.7833821773529053  \n","Epoch:32/50     Step:4|6   loss:0.8084612488746643  \n","Epoch:32/50     Step:5|6   loss:0.771621823310852  \n","Epoch:32/50     Step:6|6   loss:0.8066858053207397  \n","Epoch:32/50     Step:7|6   loss:0.7668538689613342  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:93.46%\t train set:94.38%\n","Epoch:33/50     Step:1|6   loss:0.8061440587043762  \n","Epoch:33/50     Step:2|6   loss:0.8031010627746582  \n","Epoch:33/50     Step:3|6   loss:0.8091321587562561  \n","Epoch:33/50     Step:4|6   loss:0.7616117596626282  \n","Epoch:33/50     Step:5|6   loss:0.7808786034584045  \n","Epoch:33/50     Step:6|6   loss:0.756505012512207  \n","Epoch:33/50     Step:7|6   loss:0.8223469257354736  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:93.46%\t train set:94.38%\n","Epoch:34/50     Step:1|6   loss:0.7973965406417847  \n","Epoch:34/50     Step:2|6   loss:0.7827349901199341  \n","Epoch:34/50     Step:3|6   loss:0.7901531457901001  \n","Epoch:34/50     Step:4|6   loss:0.826569676399231  \n","Epoch:34/50     Step:5|6   loss:0.7953362464904785  \n","Epoch:34/50     Step:6|6   loss:0.7849093675613403  \n","Epoch:34/50     Step:7|6   loss:0.730872631072998  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:93.46%\t train set:94.38%\n","Epoch:35/50     Step:1|6   loss:0.7506924867630005  \n","Epoch:35/50     Step:2|6   loss:0.7831993103027344  \n","Epoch:35/50     Step:3|6   loss:0.7583508491516113  \n","Epoch:35/50     Step:4|6   loss:0.8144059777259827  \n","Epoch:35/50     Step:5|6   loss:0.7611995935440063  \n","Epoch:35/50     Step:6|6   loss:0.8010513782501221  \n","Epoch:35/50     Step:7|6   loss:0.7448402643203735  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:93.46%\t train set:94.61%\n","Epoch:36/50     Step:1|6   loss:0.7841975688934326  \n","Epoch:36/50     Step:2|6   loss:0.7697253227233887  \n","Epoch:36/50     Step:3|6   loss:0.763007402420044  \n","Epoch:36/50     Step:4|6   loss:0.745810866355896  \n","Epoch:36/50     Step:5|6   loss:0.7795246839523315  \n","Epoch:36/50     Step:6|6   loss:0.7879632711410522  \n","Epoch:36/50     Step:7|6   loss:0.8340923190116882  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:93.46%\t train set:94.61%\n","Epoch:37/50     Step:1|6   loss:0.7887842059135437  \n","Epoch:37/50     Step:2|6   loss:0.7828871011734009  \n","Epoch:37/50     Step:3|6   loss:0.7686845064163208  \n","Epoch:37/50     Step:4|6   loss:0.8383439779281616  \n","Epoch:37/50     Step:5|6   loss:0.7374886274337769  \n","Epoch:37/50     Step:6|6   loss:0.8129221200942993  \n","Epoch:37/50     Step:7|6   loss:0.7610939741134644  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:93.46%\t train set:94.61%\n","Epoch:38/50     Step:1|6   loss:0.7966533899307251  \n","Epoch:38/50     Step:2|6   loss:0.7765542268753052  \n","Epoch:38/50     Step:3|6   loss:0.7767159938812256  \n","Epoch:38/50     Step:4|6   loss:0.8037692308425903  \n","Epoch:38/50     Step:5|6   loss:0.7897271513938904  \n","Epoch:38/50     Step:6|6   loss:0.7661948800086975  \n","Epoch:38/50     Step:7|6   loss:0.7242701649665833  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:94.39%\t train set:94.85%\n","Epoch:39/50     Step:1|6   loss:0.7959449887275696  \n","Epoch:39/50     Step:2|6   loss:0.7621389627456665  \n","Epoch:39/50     Step:3|6   loss:0.7534445524215698  \n","Epoch:39/50     Step:4|6   loss:0.7471109628677368  \n","Epoch:39/50     Step:5|6   loss:0.7861428260803223  \n","Epoch:39/50     Step:6|6   loss:0.7043078541755676  \n","Epoch:39/50     Step:7|6   loss:0.7816207408905029  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:94.39%\t train set:94.85%\n","Epoch:40/50     Step:1|6   loss:0.7764593362808228  \n","Epoch:40/50     Step:2|6   loss:0.7652866840362549  \n","Epoch:40/50     Step:3|6   loss:0.8036048412322998  \n","Epoch:40/50     Step:4|6   loss:0.801207423210144  \n","Epoch:40/50     Step:5|6   loss:0.7670338153839111  \n","Epoch:40/50     Step:6|6   loss:0.7891507148742676  \n","Epoch:40/50     Step:7|6   loss:0.8113620281219482  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:94.39%\t train set:94.85%\n","Epoch:41/50     Step:1|6   loss:0.7689611911773682  \n","Epoch:41/50     Step:2|6   loss:0.8086696267127991  \n","Epoch:41/50     Step:3|6   loss:0.7412635684013367  \n","Epoch:41/50     Step:4|6   loss:0.7908486127853394  \n","Epoch:41/50     Step:5|6   loss:0.749788761138916  \n","Epoch:41/50     Step:6|6   loss:0.7657063603401184  \n","Epoch:41/50     Step:7|6   loss:0.8138167262077332  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:94.39%\t train set:94.85%\n","Epoch:42/50     Step:1|6   loss:0.7241452932357788  \n","Epoch:42/50     Step:2|6   loss:0.7630785703659058  \n","Epoch:42/50     Step:3|6   loss:0.8188079595565796  \n","Epoch:42/50     Step:4|6   loss:0.7919320464134216  \n","Epoch:42/50     Step:5|6   loss:0.7590948343276978  \n","Epoch:42/50     Step:6|6   loss:0.749346911907196  \n","Epoch:42/50     Step:7|6   loss:0.7485644817352295  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:43/50     Step:1|6   loss:0.7913529872894287  \n","Epoch:43/50     Step:2|6   loss:0.7394163608551025  \n","Epoch:43/50     Step:3|6   loss:0.7137188911437988  \n","Epoch:43/50     Step:4|6   loss:0.7911096811294556  \n","Epoch:43/50     Step:5|6   loss:0.8036115765571594  \n","Epoch:43/50     Step:6|6   loss:0.7653653621673584  \n","Epoch:43/50     Step:7|6   loss:0.8630475997924805  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:44/50     Step:1|6   loss:0.7782402038574219  \n","Epoch:44/50     Step:2|6   loss:0.7263591289520264  \n","Epoch:44/50     Step:3|6   loss:0.7885804176330566  \n","Epoch:44/50     Step:4|6   loss:0.7570274472236633  \n","Epoch:44/50     Step:5|6   loss:0.7777833938598633  \n","Epoch:44/50     Step:6|6   loss:0.8362793326377869  \n","Epoch:44/50     Step:7|6   loss:0.7215284109115601  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:45/50     Step:1|6   loss:0.7720873355865479  \n","Epoch:45/50     Step:2|6   loss:0.6813920736312866  \n","Epoch:45/50     Step:3|6   loss:0.7747113704681396  \n","Epoch:45/50     Step:4|6   loss:0.7617487907409668  \n","Epoch:45/50     Step:5|6   loss:0.7676087617874146  \n","Epoch:45/50     Step:6|6   loss:0.7642496824264526  \n","Epoch:45/50     Step:7|6   loss:0.8132942914962769  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:46/50     Step:1|6   loss:0.748949408531189  \n","Epoch:46/50     Step:2|6   loss:0.7504186630249023  \n","Epoch:46/50     Step:3|6   loss:0.8264656066894531  \n","Epoch:46/50     Step:4|6   loss:0.7395762205123901  \n","Epoch:46/50     Step:5|6   loss:0.7341127395629883  \n","Epoch:46/50     Step:6|6   loss:0.8101208806037903  \n","Epoch:46/50     Step:7|6   loss:0.7470717430114746  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:47/50     Step:1|6   loss:0.7527576684951782  \n","Epoch:47/50     Step:2|6   loss:0.7368866205215454  \n","Epoch:47/50     Step:3|6   loss:0.8110562562942505  \n","Epoch:47/50     Step:4|6   loss:0.7739579081535339  \n","Epoch:47/50     Step:5|6   loss:0.8264602422714233  \n","Epoch:47/50     Step:6|6   loss:0.7794171571731567  \n","Epoch:47/50     Step:7|6   loss:0.753303050994873  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:48/50     Step:1|6   loss:0.768396258354187  \n","Epoch:48/50     Step:2|6   loss:0.7739437222480774  \n","Epoch:48/50     Step:3|6   loss:0.7809492945671082  \n","Epoch:48/50     Step:4|6   loss:0.8461863994598389  \n","Epoch:48/50     Step:5|6   loss:0.765268862247467  \n","Epoch:48/50     Step:6|6   loss:0.7398894429206848  \n","Epoch:48/50     Step:7|6   loss:0.6610731482505798  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 89.93 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:49/50     Step:1|6   loss:0.7747344970703125  \n","Epoch:49/50     Step:2|6   loss:0.8046573996543884  \n","Epoch:49/50     Step:3|6   loss:0.7494330406188965  \n","Epoch:49/50     Step:4|6   loss:0.7693299651145935  \n","Epoch:49/50     Step:5|6   loss:0.8204314112663269  \n","Epoch:49/50     Step:6|6   loss:0.7156718969345093  \n","Epoch:49/50     Step:7|6   loss:0.7525848150253296  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:94.39%\t train set:96.49%\n","Epoch:50/50     Step:1|6   loss:0.7548198103904724  \n","Epoch:50/50     Step:2|6   loss:0.8068747520446777  \n","Epoch:50/50     Step:3|6   loss:0.7644603252410889  \n","Epoch:50/50     Step:4|6   loss:0.8183109760284424  \n","Epoch:50/50     Step:5|6   loss:0.757301926612854  \n","Epoch:50/50     Step:6|6   loss:0.7548896074295044  \n","Epoch:50/50     Step:7|6   loss:0.7714895606040955  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:94.39%\t train set:96.49%\n","Accuracy on test_set: 82.24 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1544092893600464  \n","Epoch:1/50     Step:2|6   loss:1.1010664701461792  \n","Epoch:1/50     Step:3|6   loss:1.1167430877685547  \n","Epoch:1/50     Step:4|6   loss:1.0941154956817627  \n","Epoch:1/50     Step:5|6   loss:1.110164999961853  \n","Epoch:1/50     Step:6|6   loss:1.1135425567626953  \n","Epoch:1/50     Step:7|6   loss:1.125160574913025  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 26.93 %\n","current max accuracy\t test set:20.56%\t train set:26.93%\n","Epoch:2/50     Step:1|6   loss:1.115106225013733  \n","Epoch:2/50     Step:2|6   loss:1.1494269371032715  \n","Epoch:2/50     Step:3|6   loss:1.0794737339019775  \n","Epoch:2/50     Step:4|6   loss:0.9834075570106506  \n","Epoch:2/50     Step:5|6   loss:1.0392829179763794  \n","Epoch:2/50     Step:6|6   loss:1.0325689315795898  \n","Epoch:2/50     Step:7|6   loss:1.059525728225708  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 26.93 %\n","current max accuracy\t test set:20.56%\t train set:26.93%\n","Epoch:3/50     Step:1|6   loss:1.0531857013702393  \n","Epoch:3/50     Step:2|6   loss:1.0009905099868774  \n","Epoch:3/50     Step:3|6   loss:1.0368077754974365  \n","Epoch:3/50     Step:4|6   loss:1.0084232091903687  \n","Epoch:3/50     Step:5|6   loss:1.010472059249878  \n","Epoch:3/50     Step:6|6   loss:1.0378302335739136  \n","Epoch:3/50     Step:7|6   loss:1.0618903636932373  \n","Accuracy on test_set: 39.25 %\n","Accuracy on train_set: 43.79 %\n","current max accuracy\t test set:39.25%\t train set:43.79%\n","Epoch:4/50     Step:1|6   loss:1.0017988681793213  \n","Epoch:4/50     Step:2|6   loss:1.010416030883789  \n","Epoch:4/50     Step:3|6   loss:1.0422934293746948  \n","Epoch:4/50     Step:4|6   loss:1.0016850233078003  \n","Epoch:4/50     Step:5|6   loss:1.0494478940963745  \n","Epoch:4/50     Step:6|6   loss:1.0014969110488892  \n","Epoch:4/50     Step:7|6   loss:1.0228229761123657  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 55.04 %\n","current max accuracy\t test set:50.47%\t train set:55.04%\n","Epoch:5/50     Step:1|6   loss:1.0229730606079102  \n","Epoch:5/50     Step:2|6   loss:0.9982818365097046  \n","Epoch:5/50     Step:3|6   loss:0.982642650604248  \n","Epoch:5/50     Step:4|6   loss:0.9717196822166443  \n","Epoch:5/50     Step:5|6   loss:0.9965076446533203  \n","Epoch:5/50     Step:6|6   loss:1.0002449750900269  \n","Epoch:5/50     Step:7|6   loss:1.0299607515335083  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 55.74 %\n","current max accuracy\t test set:50.47%\t train set:55.74%\n","Epoch:6/50     Step:1|6   loss:0.9890396595001221  \n","Epoch:6/50     Step:2|6   loss:0.9956291913986206  \n","Epoch:6/50     Step:3|6   loss:1.0169858932495117  \n","Epoch:6/50     Step:4|6   loss:0.9980840682983398  \n","Epoch:6/50     Step:5|6   loss:0.9821957349777222  \n","Epoch:6/50     Step:6|6   loss:0.9956857562065125  \n","Epoch:6/50     Step:7|6   loss:0.9711858034133911  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 68.15 %\n","current max accuracy\t test set:68.22%\t train set:68.15%\n","Epoch:7/50     Step:1|6   loss:0.9945306777954102  \n","Epoch:7/50     Step:2|6   loss:0.963516116142273  \n","Epoch:7/50     Step:3|6   loss:0.9968326687812805  \n","Epoch:7/50     Step:4|6   loss:0.9757930636405945  \n","Epoch:7/50     Step:5|6   loss:0.9280199408531189  \n","Epoch:7/50     Step:6|6   loss:1.0041131973266602  \n","Epoch:7/50     Step:7|6   loss:0.8871195316314697  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 82.90 %\n","current max accuracy\t test set:84.11%\t train set:82.9%\n","Epoch:8/50     Step:1|6   loss:0.9492431879043579  \n","Epoch:8/50     Step:2|6   loss:0.9553534388542175  \n","Epoch:8/50     Step:3|6   loss:0.9253653287887573  \n","Epoch:8/50     Step:4|6   loss:0.922171950340271  \n","Epoch:8/50     Step:5|6   loss:0.9752178192138672  \n","Epoch:8/50     Step:6|6   loss:0.9470807909965515  \n","Epoch:8/50     Step:7|6   loss:0.8743950724601746  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:85.98%\t train set:88.76%\n","Epoch:9/50     Step:1|6   loss:0.9432801604270935  \n","Epoch:9/50     Step:2|6   loss:0.9347596764564514  \n","Epoch:9/50     Step:3|6   loss:0.9065090417861938  \n","Epoch:9/50     Step:4|6   loss:0.9212689399719238  \n","Epoch:9/50     Step:5|6   loss:0.9734290242195129  \n","Epoch:9/50     Step:6|6   loss:0.9276120662689209  \n","Epoch:9/50     Step:7|6   loss:0.8670291304588318  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:85.98%\t train set:88.76%\n","Epoch:10/50     Step:1|6   loss:0.9014018774032593  \n","Epoch:10/50     Step:2|6   loss:0.9487534165382385  \n","Epoch:10/50     Step:3|6   loss:0.9085055589675903  \n","Epoch:10/50     Step:4|6   loss:0.837802529335022  \n","Epoch:10/50     Step:5|6   loss:0.8690840005874634  \n","Epoch:10/50     Step:6|6   loss:0.9464210867881775  \n","Epoch:10/50     Step:7|6   loss:0.877507209777832  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 79.39 %\n","current max accuracy\t test set:85.98%\t train set:88.76%\n","Epoch:11/50     Step:1|6   loss:0.8999447226524353  \n","Epoch:11/50     Step:2|6   loss:0.9190264344215393  \n","Epoch:11/50     Step:3|6   loss:0.9152256846427917  \n","Epoch:11/50     Step:4|6   loss:0.8904464244842529  \n","Epoch:11/50     Step:5|6   loss:0.866409182548523  \n","Epoch:11/50     Step:6|6   loss:0.8866331577301025  \n","Epoch:11/50     Step:7|6   loss:0.8933272361755371  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:85.98%\t train set:88.76%\n","Epoch:12/50     Step:1|6   loss:0.9271295666694641  \n","Epoch:12/50     Step:2|6   loss:0.9581678509712219  \n","Epoch:12/50     Step:3|6   loss:0.8659409284591675  \n","Epoch:12/50     Step:4|6   loss:0.8912909626960754  \n","Epoch:12/50     Step:5|6   loss:0.8953816294670105  \n","Epoch:12/50     Step:6|6   loss:0.8502272963523865  \n","Epoch:12/50     Step:7|6   loss:0.896949291229248  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:91.59%\t train set:94.61%\n","Epoch:13/50     Step:1|6   loss:0.8492732048034668  \n","Epoch:13/50     Step:2|6   loss:0.8718792796134949  \n","Epoch:13/50     Step:3|6   loss:0.8636884093284607  \n","Epoch:13/50     Step:4|6   loss:0.8457845449447632  \n","Epoch:13/50     Step:5|6   loss:0.8626706004142761  \n","Epoch:13/50     Step:6|6   loss:0.85181725025177  \n","Epoch:13/50     Step:7|6   loss:0.8631094694137573  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:94.39%\t train set:95.32%\n","Epoch:14/50     Step:1|6   loss:0.8805525302886963  \n","Epoch:14/50     Step:2|6   loss:0.8382688760757446  \n","Epoch:14/50     Step:3|6   loss:0.8532551527023315  \n","Epoch:14/50     Step:4|6   loss:0.844673752784729  \n","Epoch:14/50     Step:5|6   loss:0.8725339770317078  \n","Epoch:14/50     Step:6|6   loss:0.8980957865715027  \n","Epoch:14/50     Step:7|6   loss:0.8675898909568787  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:94.39%\t train set:96.25%\n","Epoch:15/50     Step:1|6   loss:0.8329733610153198  \n","Epoch:15/50     Step:2|6   loss:0.8598827719688416  \n","Epoch:15/50     Step:3|6   loss:0.8153255581855774  \n","Epoch:15/50     Step:4|6   loss:0.8422510623931885  \n","Epoch:15/50     Step:5|6   loss:0.8459829092025757  \n","Epoch:15/50     Step:6|6   loss:0.8439133167266846  \n","Epoch:15/50     Step:7|6   loss:0.8417298793792725  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:94.39%\t train set:96.25%\n","Epoch:16/50     Step:1|6   loss:0.841617226600647  \n","Epoch:16/50     Step:2|6   loss:0.8651729226112366  \n","Epoch:16/50     Step:3|6   loss:0.8165236711502075  \n","Epoch:16/50     Step:4|6   loss:0.8304927349090576  \n","Epoch:16/50     Step:5|6   loss:0.8477283120155334  \n","Epoch:16/50     Step:6|6   loss:0.802017331123352  \n","Epoch:16/50     Step:7|6   loss:0.7947894334793091  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:94.39%\t train set:96.25%\n","Epoch:17/50     Step:1|6   loss:0.8123476505279541  \n","Epoch:17/50     Step:2|6   loss:0.8480203747749329  \n","Epoch:17/50     Step:3|6   loss:0.8241089582443237  \n","Epoch:17/50     Step:4|6   loss:0.8368596434593201  \n","Epoch:17/50     Step:5|6   loss:0.8014969825744629  \n","Epoch:17/50     Step:6|6   loss:0.8373675346374512  \n","Epoch:17/50     Step:7|6   loss:0.823695957660675  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:94.39%\t train set:96.25%\n","Epoch:18/50     Step:1|6   loss:0.840644121170044  \n","Epoch:18/50     Step:2|6   loss:0.8672770261764526  \n","Epoch:18/50     Step:3|6   loss:0.7866203784942627  \n","Epoch:18/50     Step:4|6   loss:0.8300508260726929  \n","Epoch:18/50     Step:5|6   loss:0.837328314781189  \n","Epoch:18/50     Step:6|6   loss:0.886568009853363  \n","Epoch:18/50     Step:7|6   loss:0.8745537996292114  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:95.33%\t train set:96.25%\n","Epoch:19/50     Step:1|6   loss:0.8397148847579956  \n","Epoch:19/50     Step:2|6   loss:0.7896888852119446  \n","Epoch:19/50     Step:3|6   loss:0.8208051919937134  \n","Epoch:19/50     Step:4|6   loss:0.8568442463874817  \n","Epoch:19/50     Step:5|6   loss:0.7672351598739624  \n","Epoch:19/50     Step:6|6   loss:0.8851147890090942  \n","Epoch:19/50     Step:7|6   loss:0.8323417901992798  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:95.33%\t train set:96.25%\n","Epoch:20/50     Step:1|6   loss:0.8699848651885986  \n","Epoch:20/50     Step:2|6   loss:0.8331029415130615  \n","Epoch:20/50     Step:3|6   loss:0.805833101272583  \n","Epoch:20/50     Step:4|6   loss:0.8675898313522339  \n","Epoch:20/50     Step:5|6   loss:0.7701074481010437  \n","Epoch:20/50     Step:6|6   loss:0.7908014059066772  \n","Epoch:20/50     Step:7|6   loss:0.8573957681655884  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:95.33%\t train set:96.25%\n","Epoch:21/50     Step:1|6   loss:0.8201953172683716  \n","Epoch:21/50     Step:2|6   loss:0.7943785190582275  \n","Epoch:21/50     Step:3|6   loss:0.8317645788192749  \n","Epoch:21/50     Step:4|6   loss:0.8378496766090393  \n","Epoch:21/50     Step:5|6   loss:0.7811253070831299  \n","Epoch:21/50     Step:6|6   loss:0.8631910085678101  \n","Epoch:21/50     Step:7|6   loss:0.8499452471733093  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:22/50     Step:1|6   loss:0.8204547762870789  \n","Epoch:22/50     Step:2|6   loss:0.8055765628814697  \n","Epoch:22/50     Step:3|6   loss:0.754030168056488  \n","Epoch:22/50     Step:4|6   loss:0.7959129810333252  \n","Epoch:22/50     Step:5|6   loss:0.8379685878753662  \n","Epoch:22/50     Step:6|6   loss:0.8245162963867188  \n","Epoch:22/50     Step:7|6   loss:0.7706852555274963  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:23/50     Step:1|6   loss:0.8026878237724304  \n","Epoch:23/50     Step:2|6   loss:0.8520909547805786  \n","Epoch:23/50     Step:3|6   loss:0.7835813760757446  \n","Epoch:23/50     Step:4|6   loss:0.8103498816490173  \n","Epoch:23/50     Step:5|6   loss:0.8168536424636841  \n","Epoch:23/50     Step:6|6   loss:0.791458249092102  \n","Epoch:23/50     Step:7|6   loss:0.8448194861412048  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:24/50     Step:1|6   loss:0.7915717363357544  \n","Epoch:24/50     Step:2|6   loss:0.8166152834892273  \n","Epoch:24/50     Step:3|6   loss:0.7912119626998901  \n","Epoch:24/50     Step:4|6   loss:0.7438033819198608  \n","Epoch:24/50     Step:5|6   loss:0.8293691277503967  \n","Epoch:24/50     Step:6|6   loss:0.8038243055343628  \n","Epoch:24/50     Step:7|6   loss:0.8395603895187378  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:25/50     Step:1|6   loss:0.8443115949630737  \n","Epoch:25/50     Step:2|6   loss:0.8660302758216858  \n","Epoch:25/50     Step:3|6   loss:0.8105998635292053  \n","Epoch:25/50     Step:4|6   loss:0.8118505477905273  \n","Epoch:25/50     Step:5|6   loss:0.7631787061691284  \n","Epoch:25/50     Step:6|6   loss:0.7858378887176514  \n","Epoch:25/50     Step:7|6   loss:0.8240446448326111  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:26/50     Step:1|6   loss:0.8024018406867981  \n","Epoch:26/50     Step:2|6   loss:0.7746339440345764  \n","Epoch:26/50     Step:3|6   loss:0.8030434846878052  \n","Epoch:26/50     Step:4|6   loss:0.8079017400741577  \n","Epoch:26/50     Step:5|6   loss:0.7597444653511047  \n","Epoch:26/50     Step:6|6   loss:0.7566763162612915  \n","Epoch:26/50     Step:7|6   loss:0.797133207321167  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:27/50     Step:1|6   loss:0.827778697013855  \n","Epoch:27/50     Step:2|6   loss:0.7978865504264832  \n","Epoch:27/50     Step:3|6   loss:0.7931766510009766  \n","Epoch:27/50     Step:4|6   loss:0.8402037024497986  \n","Epoch:27/50     Step:5|6   loss:0.7845266461372375  \n","Epoch:27/50     Step:6|6   loss:0.7758916616439819  \n","Epoch:27/50     Step:7|6   loss:0.8574341535568237  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:28/50     Step:1|6   loss:0.7761759757995605  \n","Epoch:28/50     Step:2|6   loss:0.7604745030403137  \n","Epoch:28/50     Step:3|6   loss:0.7612038850784302  \n","Epoch:28/50     Step:4|6   loss:0.8199450969696045  \n","Epoch:28/50     Step:5|6   loss:0.7996499538421631  \n","Epoch:28/50     Step:6|6   loss:0.8101069927215576  \n","Epoch:28/50     Step:7|6   loss:0.7875735759735107  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:29/50     Step:1|6   loss:0.7460571527481079  \n","Epoch:29/50     Step:2|6   loss:0.8234527111053467  \n","Epoch:29/50     Step:3|6   loss:0.773296594619751  \n","Epoch:29/50     Step:4|6   loss:0.7842726707458496  \n","Epoch:29/50     Step:5|6   loss:0.7760320901870728  \n","Epoch:29/50     Step:6|6   loss:0.8091799020767212  \n","Epoch:29/50     Step:7|6   loss:0.809004545211792  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:30/50     Step:1|6   loss:0.7694364190101624  \n","Epoch:30/50     Step:2|6   loss:0.7728449702262878  \n","Epoch:30/50     Step:3|6   loss:0.7294166088104248  \n","Epoch:30/50     Step:4|6   loss:0.7699849605560303  \n","Epoch:30/50     Step:5|6   loss:0.7806618213653564  \n","Epoch:30/50     Step:6|6   loss:0.8037992715835571  \n","Epoch:30/50     Step:7|6   loss:0.8297184705734253  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:31/50     Step:1|6   loss:0.8058457374572754  \n","Epoch:31/50     Step:2|6   loss:0.772641658782959  \n","Epoch:31/50     Step:3|6   loss:0.7930268049240112  \n","Epoch:31/50     Step:4|6   loss:0.7520167827606201  \n","Epoch:31/50     Step:5|6   loss:0.8167410492897034  \n","Epoch:31/50     Step:6|6   loss:0.7505625486373901  \n","Epoch:31/50     Step:7|6   loss:0.794546902179718  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:32/50     Step:1|6   loss:0.7591507434844971  \n","Epoch:32/50     Step:2|6   loss:0.7701766490936279  \n","Epoch:32/50     Step:3|6   loss:0.7354053258895874  \n","Epoch:32/50     Step:4|6   loss:0.7389283180236816  \n","Epoch:32/50     Step:5|6   loss:0.8084934949874878  \n","Epoch:32/50     Step:6|6   loss:0.7460229396820068  \n","Epoch:32/50     Step:7|6   loss:0.8297086358070374  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:33/50     Step:1|6   loss:0.8061122298240662  \n","Epoch:33/50     Step:2|6   loss:0.7681179046630859  \n","Epoch:33/50     Step:3|6   loss:0.7473100423812866  \n","Epoch:33/50     Step:4|6   loss:0.7765014171600342  \n","Epoch:33/50     Step:5|6   loss:0.7280150055885315  \n","Epoch:33/50     Step:6|6   loss:0.7974918484687805  \n","Epoch:33/50     Step:7|6   loss:0.733415961265564  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:34/50     Step:1|6   loss:0.7705011963844299  \n","Epoch:34/50     Step:2|6   loss:0.7786352634429932  \n","Epoch:34/50     Step:3|6   loss:0.7726888656616211  \n","Epoch:34/50     Step:4|6   loss:0.7888387441635132  \n","Epoch:34/50     Step:5|6   loss:0.8020877838134766  \n","Epoch:34/50     Step:6|6   loss:0.7097035646438599  \n","Epoch:34/50     Step:7|6   loss:0.7895405292510986  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:35/50     Step:1|6   loss:0.7477262020111084  \n","Epoch:35/50     Step:2|6   loss:0.7648518085479736  \n","Epoch:35/50     Step:3|6   loss:0.7700978517532349  \n","Epoch:35/50     Step:4|6   loss:0.7689238786697388  \n","Epoch:35/50     Step:5|6   loss:0.763493537902832  \n","Epoch:35/50     Step:6|6   loss:0.8013626337051392  \n","Epoch:35/50     Step:7|6   loss:0.7787370085716248  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.96 %2\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:36/50     Step:1|6   loss:0.815281867980957  \n","Epoch:36/50     Step:2|6   loss:0.7806110978126526  \n","Epoch:36/50     Step:3|6   loss:0.7767471075057983  \n","Epoch:36/50     Step:4|6   loss:0.7248634099960327  \n","Epoch:36/50     Step:5|6   loss:0.7472792863845825  \n","Epoch:36/50     Step:6|6   loss:0.8088436126708984  \n","Epoch:36/50     Step:7|6   loss:0.7824659943580627  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:37/50     Step:1|6   loss:0.7329702973365784  \n","Epoch:37/50     Step:2|6   loss:0.7748501896858215  \n","Epoch:37/50     Step:3|6   loss:0.7298241853713989  \n","Epoch:37/50     Step:4|6   loss:0.7615109086036682  \n","Epoch:37/50     Step:5|6   loss:0.7775658965110779  \n","Epoch:37/50     Step:6|6   loss:0.8218111991882324  \n","Epoch:37/50     Step:7|6   loss:0.8059619665145874  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:38/50     Step:1|6   loss:0.7408555746078491  \n","Epoch:38/50     Step:2|6   loss:0.801185131072998  \n","Epoch:38/50     Step:3|6   loss:0.77969890832901  \n","Epoch:38/50     Step:4|6   loss:0.7690295577049255  \n","Epoch:38/50     Step:5|6   loss:0.7800423502922058  \n","Epoch:38/50     Step:6|6   loss:0.7352586984634399  \n","Epoch:38/50     Step:7|6   loss:0.702960193157196  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:39/50     Step:1|6   loss:0.7546019554138184  \n","Epoch:39/50     Step:2|6   loss:0.7421894073486328  \n","Epoch:39/50     Step:3|6   loss:0.7244613170623779  \n","Epoch:39/50     Step:4|6   loss:0.739905059337616  \n","Epoch:39/50     Step:5|6   loss:0.8194692134857178  \n","Epoch:39/50     Step:6|6   loss:0.7646594643592834  \n","Epoch:39/50     Step:7|6   loss:0.7639310956001282  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:40/50     Step:1|6   loss:0.7970815896987915  \n","Epoch:40/50     Step:2|6   loss:0.753371000289917  \n","Epoch:40/50     Step:3|6   loss:0.766558051109314  \n","Epoch:40/50     Step:4|6   loss:0.7696563005447388  \n","Epoch:40/50     Step:5|6   loss:0.7417864799499512  \n","Epoch:40/50     Step:6|6   loss:0.7619639039039612  \n","Epoch:40/50     Step:7|6   loss:0.821907639503479  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:41/50     Step:1|6   loss:0.7622535228729248  \n","Epoch:41/50     Step:2|6   loss:0.7760359644889832  \n","Epoch:41/50     Step:3|6   loss:0.7348630428314209  \n","Epoch:41/50     Step:4|6   loss:0.742074191570282  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:41/50     Step:5|6   loss:0.7301008701324463  \n","Epoch:41/50     Step:6|6   loss:0.7409423589706421  \n","Epoch:41/50     Step:7|6   loss:0.8073596954345703  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:42/50     Step:1|6   loss:0.7170984745025635  \n","Epoch:42/50     Step:2|6   loss:0.8046889901161194  \n","Epoch:42/50     Step:3|6   loss:0.7595324516296387  \n","Epoch:42/50     Step:4|6   loss:0.7319035530090332  \n","Epoch:42/50     Step:5|6   loss:0.7452346086502075  \n","Epoch:42/50     Step:6|6   loss:0.7647237777709961  \n","Epoch:42/50     Step:7|6   loss:0.7370392084121704  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:43/50     Step:1|6   loss:0.7860926389694214  \n","Epoch:43/50     Step:2|6   loss:0.7543300986289978  \n","Epoch:43/50     Step:3|6   loss:0.7250518798828125  \n","Epoch:43/50     Step:4|6   loss:0.7521027326583862  \n","Epoch:43/50     Step:5|6   loss:0.8028637170791626  \n","Epoch:43/50     Step:6|6   loss:0.7974509596824646  \n","Epoch:43/50     Step:7|6   loss:0.7696825265884399  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:44/50     Step:1|6   loss:0.7688130140304565  \n","Epoch:44/50     Step:2|6   loss:0.740760087966919  \n","Epoch:44/50     Step:3|6   loss:0.7955721616744995  \n","Epoch:44/50     Step:4|6   loss:0.7972963452339172  \n","Epoch:44/50     Step:5|6   loss:0.7109271287918091  \n","Epoch:44/50     Step:6|6   loss:0.7243320941925049  \n","Epoch:44/50     Step:7|6   loss:0.7341538071632385  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:45/50     Step:1|6   loss:0.7132868766784668  \n","Epoch:45/50     Step:2|6   loss:0.7646042108535767  \n","Epoch:45/50     Step:3|6   loss:0.7986618280410767  \n","Epoch:45/50     Step:4|6   loss:0.7762002944946289  \n","Epoch:45/50     Step:5|6   loss:0.7836734652519226  \n","Epoch:45/50     Step:6|6   loss:0.7664926052093506  \n","Epoch:45/50     Step:7|6   loss:0.7309973239898682  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:46/50     Step:1|6   loss:0.7328377962112427  \n","Epoch:46/50     Step:2|6   loss:0.8019389510154724  \n","Epoch:46/50     Step:3|6   loss:0.7305467128753662  \n","Epoch:46/50     Step:4|6   loss:0.7331184148788452  \n","Epoch:46/50     Step:5|6   loss:0.748329222202301  \n","Epoch:46/50     Step:6|6   loss:0.7295724153518677  \n","Epoch:46/50     Step:7|6   loss:0.716618537902832  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:47/50     Step:1|6   loss:0.7522674202919006  \n","Epoch:47/50     Step:2|6   loss:0.7298487424850464  \n","Epoch:47/50     Step:3|6   loss:0.7188268899917603  \n","Epoch:47/50     Step:4|6   loss:0.7621152400970459  \n","Epoch:47/50     Step:5|6   loss:0.7475985288619995  \n","Epoch:47/50     Step:6|6   loss:0.7482023239135742  \n","Epoch:47/50     Step:7|6   loss:0.7996416091918945  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:48/50     Step:1|6   loss:0.7505472898483276  \n","Epoch:48/50     Step:2|6   loss:0.7422664761543274  \n","Epoch:48/50     Step:3|6   loss:0.7542806267738342  \n","Epoch:48/50     Step:4|6   loss:0.7005133628845215  \n","Epoch:48/50     Step:5|6   loss:0.7871174812316895  \n","Epoch:48/50     Step:6|6   loss:0.7545264363288879  \n","Epoch:48/50     Step:7|6   loss:0.7755535840988159  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:49/50     Step:1|6   loss:0.7880793809890747  \n","Epoch:49/50     Step:2|6   loss:0.7195971012115479  \n","Epoch:49/50     Step:3|6   loss:0.7344659566879272  \n","Epoch:49/50     Step:4|6   loss:0.7206831574440002  \n","Epoch:49/50     Step:5|6   loss:0.7167439460754395  \n","Epoch:49/50     Step:6|6   loss:0.6900780200958252  \n","Epoch:49/50     Step:7|6   loss:0.7312411069869995  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:50/50     Step:1|6   loss:0.7673568725585938  \n","Epoch:50/50     Step:2|6   loss:0.7424135208129883  \n","Epoch:50/50     Step:3|6   loss:0.7817646265029907  \n","Epoch:50/50     Step:4|6   loss:0.7815195322036743  \n","Epoch:50/50     Step:5|6   loss:0.7202129364013672  \n","Epoch:50/50     Step:6|6   loss:0.7801758646965027  \n","Epoch:50/50     Step:7|6   loss:0.7133302688598633  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Accuracy on test_set: 94.39 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0651311874389648  \n","Epoch:1/50     Step:2|6   loss:1.0421772003173828  \n","Epoch:1/50     Step:3|6   loss:1.0395519733428955  \n","Epoch:1/50     Step:4|6   loss:1.0480763912200928  \n","Epoch:1/50     Step:5|6   loss:1.0549466609954834  \n","Epoch:1/50     Step:6|6   loss:1.0264103412628174  \n","Epoch:1/50     Step:7|6   loss:1.0310156345367432  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 26.23 %\n","current max accuracy\t test set:25.23%\t train set:26.23%\n","Epoch:2/50     Step:1|6   loss:1.0098904371261597  \n","Epoch:2/50     Step:2|6   loss:1.0467026233673096  \n","Epoch:2/50     Step:3|6   loss:0.9938098192214966  \n","Epoch:2/50     Step:4|6   loss:0.9769374132156372  \n","Epoch:2/50     Step:5|6   loss:1.0234861373901367  \n","Epoch:2/50     Step:6|6   loss:1.0263217687606812  \n","Epoch:2/50     Step:7|6   loss:0.9963992238044739  \n","Accuracy on test_set: 33.64 %\n","Accuracy on train_set: 31.15 %\n","current max accuracy\t test set:33.64%\t train set:31.15%\n","Epoch:3/50     Step:1|6   loss:0.9798681735992432  \n","Epoch:3/50     Step:2|6   loss:0.9855574369430542  \n","Epoch:3/50     Step:3|6   loss:0.9900137782096863  \n","Epoch:3/50     Step:4|6   loss:0.9881804585456848  \n","Epoch:3/50     Step:5|6   loss:0.9815201759338379  \n","Epoch:3/50     Step:6|6   loss:1.0101594924926758  \n","Epoch:3/50     Step:7|6   loss:1.0147225856781006  \n","Accuracy on test_set: 55.14 %\n","Accuracy on train_set: 53.16 %\n","current max accuracy\t test set:55.14%\t train set:53.16%\n","Epoch:4/50     Step:1|6   loss:0.9551737308502197  \n","Epoch:4/50     Step:2|6   loss:0.9616103172302246  \n","Epoch:4/50     Step:3|6   loss:0.9647148251533508  \n","Epoch:4/50     Step:4|6   loss:0.9580910801887512  \n","Epoch:4/50     Step:5|6   loss:0.9757571816444397  \n","Epoch:4/50     Step:6|6   loss:0.9670445322990417  \n","Epoch:4/50     Step:7|6   loss:0.9652745127677917  \n","Accuracy on test_set: 57.01 %\n","Accuracy on train_set: 56.91 %\n","current max accuracy\t test set:57.01%\t train set:56.91%\n","Epoch:5/50     Step:1|6   loss:0.9431549906730652  \n","Epoch:5/50     Step:2|6   loss:0.9574662446975708  \n","Epoch:5/50     Step:3|6   loss:0.9646137952804565  \n","Epoch:5/50     Step:4|6   loss:0.922234296798706  \n","Epoch:5/50     Step:5|6   loss:0.9394360780715942  \n","Epoch:5/50     Step:6|6   loss:0.9322851300239563  \n","Epoch:5/50     Step:7|6   loss:0.9480315446853638  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 75.88 %\n","current max accuracy\t test set:71.96%\t train set:75.88%\n","Epoch:6/50     Step:1|6   loss:0.950046181678772  \n","Epoch:6/50     Step:2|6   loss:0.9351744055747986  \n","Epoch:6/50     Step:3|6   loss:0.939111590385437  \n","Epoch:6/50     Step:4|6   loss:0.9265240430831909  \n","Epoch:6/50     Step:5|6   loss:0.9261125326156616  \n","Epoch:6/50     Step:6|6   loss:0.9283031225204468  \n","Epoch:6/50     Step:7|6   loss:0.894713282585144  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:86.92%\t train set:87.12%\n","Epoch:7/50     Step:1|6   loss:0.9077167510986328  \n","Epoch:7/50     Step:2|6   loss:0.8844760060310364  \n","Epoch:7/50     Step:3|6   loss:0.9198770523071289  \n","Epoch:7/50     Step:4|6   loss:0.9126079082489014  \n","Epoch:7/50     Step:5|6   loss:0.9030767679214478  \n","Epoch:7/50     Step:6|6   loss:0.8701081275939941  \n","Epoch:7/50     Step:7|6   loss:0.8839232921600342  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:8/50     Step:1|6   loss:0.8892662525177002  \n","Epoch:8/50     Step:2|6   loss:0.9008066058158875  \n","Epoch:8/50     Step:3|6   loss:0.9212860465049744  \n","Epoch:8/50     Step:4|6   loss:0.8463006019592285  \n","Epoch:8/50     Step:5|6   loss:0.8987558484077454  \n","Epoch:8/50     Step:6|6   loss:0.8899922966957092  \n","Epoch:8/50     Step:7|6   loss:0.9197296500205994  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:9/50     Step:1|6   loss:0.8731162548065186  \n","Epoch:9/50     Step:2|6   loss:0.8666504621505737  \n","Epoch:9/50     Step:3|6   loss:0.9029019474983215  \n","Epoch:9/50     Step:4|6   loss:0.9174823760986328  \n","Epoch:9/50     Step:5|6   loss:0.8655553460121155  \n","Epoch:9/50     Step:6|6   loss:0.8990042805671692  \n","Epoch:9/50     Step:7|6   loss:0.8499950766563416  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:10/50     Step:1|6   loss:0.892662525177002  \n","Epoch:10/50     Step:2|6   loss:0.844978392124176  \n","Epoch:10/50     Step:3|6   loss:0.9131929874420166  \n","Epoch:10/50     Step:4|6   loss:0.9013892412185669  \n","Epoch:10/50     Step:5|6   loss:0.8488198518753052  \n","Epoch:10/50     Step:6|6   loss:0.881793737411499  \n","Epoch:10/50     Step:7|6   loss:0.8629119992256165  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:11/50     Step:1|6   loss:0.8454437851905823  \n","Epoch:11/50     Step:2|6   loss:0.8332326412200928  \n","Epoch:11/50     Step:3|6   loss:0.9027165770530701  \n","Epoch:11/50     Step:4|6   loss:0.8972320556640625  \n","Epoch:11/50     Step:5|6   loss:0.9068338871002197  \n","Epoch:11/50     Step:6|6   loss:0.8542795181274414  \n","Epoch:11/50     Step:7|6   loss:0.8421310186386108  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:12/50     Step:1|6   loss:0.8545002937316895  \n","Epoch:12/50     Step:2|6   loss:0.8618732690811157  \n","Epoch:12/50     Step:3|6   loss:0.881483256816864  \n","Epoch:12/50     Step:4|6   loss:0.8709533214569092  \n","Epoch:12/50     Step:5|6   loss:0.8907052278518677  \n","Epoch:12/50     Step:6|6   loss:0.8329265117645264  \n","Epoch:12/50     Step:7|6   loss:0.8583344221115112  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:13/50     Step:1|6   loss:0.8368192911148071  \n","Epoch:13/50     Step:2|6   loss:0.8625172972679138  \n","Epoch:13/50     Step:3|6   loss:0.8475440740585327  \n","Epoch:13/50     Step:4|6   loss:0.8515137434005737  \n","Epoch:13/50     Step:5|6   loss:0.8471355438232422  \n","Epoch:13/50     Step:6|6   loss:0.8679407835006714  \n","Epoch:13/50     Step:7|6   loss:0.8650344014167786  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:14/50     Step:1|6   loss:0.7984035015106201  \n","Epoch:14/50     Step:2|6   loss:0.8154300451278687  \n","Epoch:14/50     Step:3|6   loss:0.8031675815582275  \n","Epoch:14/50     Step:4|6   loss:0.8465245962142944  \n","Epoch:14/50     Step:5|6   loss:0.8218873739242554  \n","Epoch:14/50     Step:6|6   loss:0.8333277702331543  \n","Epoch:14/50     Step:7|6   loss:0.8295363187789917  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:15/50     Step:1|6   loss:0.8212640285491943  \n","Epoch:15/50     Step:2|6   loss:0.8392096161842346  \n","Epoch:15/50     Step:3|6   loss:0.8178656101226807  \n","Epoch:15/50     Step:4|6   loss:0.8158309459686279  \n","Epoch:15/50     Step:5|6   loss:0.8234346508979797  \n","Epoch:15/50     Step:6|6   loss:0.8468745350837708  \n","Epoch:15/50     Step:7|6   loss:0.8354406356811523  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:16/50     Step:1|6   loss:0.8319289684295654  \n","Epoch:16/50     Step:2|6   loss:0.829596221446991  \n","Epoch:16/50     Step:3|6   loss:0.870938777923584  \n","Epoch:16/50     Step:4|6   loss:0.8261487483978271  \n","Epoch:16/50     Step:5|6   loss:0.8448374271392822  \n","3\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:16/50     Step:6|6   loss:0.8406199216842651  \n","Epoch:16/50     Step:7|6   loss:0.8263527750968933  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:92.52%\t train set:92.27%\n","Epoch:17/50     Step:1|6   loss:0.7991780042648315  \n","Epoch:17/50     Step:2|6   loss:0.8556928038597107  \n","Epoch:17/50     Step:3|6   loss:0.804305911064148  \n","Epoch:17/50     Step:4|6   loss:0.8012106418609619  \n","Epoch:17/50     Step:5|6   loss:0.788925051689148  \n","Epoch:17/50     Step:6|6   loss:0.8215435147285461  \n","Epoch:17/50     Step:7|6   loss:0.814411997795105  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:93.46%\t train set:93.68%\n","Epoch:18/50     Step:1|6   loss:0.8382290601730347  \n","Epoch:18/50     Step:2|6   loss:0.8251670598983765  \n","Epoch:18/50     Step:3|6   loss:0.8485826849937439  \n","Epoch:18/50     Step:4|6   loss:0.8337550163269043  \n","Epoch:18/50     Step:5|6   loss:0.8059832453727722  \n","Epoch:18/50     Step:6|6   loss:0.8019907474517822  \n","Epoch:18/50     Step:7|6   loss:0.836992084980011  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:93.46%\t train set:93.68%\n","Epoch:19/50     Step:1|6   loss:0.8009933829307556  \n","Epoch:19/50     Step:2|6   loss:0.8181689977645874  \n","Epoch:19/50     Step:3|6   loss:0.829146683216095  \n","Epoch:19/50     Step:4|6   loss:0.8776669502258301  \n","Epoch:19/50     Step:5|6   loss:0.8472815752029419  \n","Epoch:19/50     Step:6|6   loss:0.791073739528656  \n","Epoch:19/50     Step:7|6   loss:0.8394193649291992  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:93.46%\t train set:94.15%\n","Epoch:20/50     Step:1|6   loss:0.8345592021942139  \n","Epoch:20/50     Step:2|6   loss:0.7929680347442627  \n","Epoch:20/50     Step:3|6   loss:0.7892290949821472  \n","Epoch:20/50     Step:4|6   loss:0.7933984994888306  \n","Epoch:20/50     Step:5|6   loss:0.8203577399253845  \n","Epoch:20/50     Step:6|6   loss:0.8192998170852661  \n","Epoch:20/50     Step:7|6   loss:0.7940708994865417  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:93.46%\t train set:94.15%\n","Epoch:21/50     Step:1|6   loss:0.7367513179779053  \n","Epoch:21/50     Step:2|6   loss:0.7411459684371948  \n","Epoch:21/50     Step:3|6   loss:0.7865878343582153  \n","Epoch:21/50     Step:4|6   loss:0.8050049543380737  \n","Epoch:21/50     Step:5|6   loss:0.7696738243103027  \n","Epoch:21/50     Step:6|6   loss:0.7940927743911743  \n","Epoch:21/50     Step:7|6   loss:0.8013443350791931  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 90.40 %\n","current max accuracy\t test set:93.46%\t train set:94.15%\n","Epoch:22/50     Step:1|6   loss:0.7822903394699097  \n","Epoch:22/50     Step:2|6   loss:0.7848023176193237  \n","Epoch:22/50     Step:3|6   loss:0.7970921993255615  \n","Epoch:22/50     Step:4|6   loss:0.8283731937408447  \n","Epoch:22/50     Step:5|6   loss:0.7826752662658691  \n","Epoch:22/50     Step:6|6   loss:0.7991604804992676  \n","Epoch:22/50     Step:7|6   loss:0.8059436082839966  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:23/50     Step:1|6   loss:0.8493806719779968  \n","Epoch:23/50     Step:2|6   loss:0.7978390455245972  \n","Epoch:23/50     Step:3|6   loss:0.7559617757797241  \n","Epoch:23/50     Step:4|6   loss:0.7712908983230591  \n","Epoch:23/50     Step:5|6   loss:0.8293968439102173  \n","Epoch:23/50     Step:6|6   loss:0.7802697420120239  \n","Epoch:23/50     Step:7|6   loss:0.7904952764511108  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:24/50     Step:1|6   loss:0.8094078302383423  \n","Epoch:24/50     Step:2|6   loss:0.7646559476852417  \n","Epoch:24/50     Step:3|6   loss:0.816253662109375  \n","Epoch:24/50     Step:4|6   loss:0.7552363872528076  \n","Epoch:24/50     Step:5|6   loss:0.8003027439117432  \n","Epoch:24/50     Step:6|6   loss:0.7820793390274048  \n","Epoch:24/50     Step:7|6   loss:0.7672353982925415  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:97.2%\t train set:96.49%\n","Epoch:25/50     Step:1|6   loss:0.7727240324020386  \n","Epoch:25/50     Step:2|6   loss:0.8687443137168884  \n","Epoch:25/50     Step:3|6   loss:0.783214807510376  \n","Epoch:25/50     Step:4|6   loss:0.7807801961898804  \n","Epoch:25/50     Step:5|6   loss:0.7967762351036072  \n","Epoch:25/50     Step:6|6   loss:0.7542819380760193  \n","Epoch:25/50     Step:7|6   loss:0.7722887396812439  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:97.2%\t train set:96.49%\n","Epoch:26/50     Step:1|6   loss:0.7818441987037659  \n","Epoch:26/50     Step:2|6   loss:0.802791953086853  \n","Epoch:26/50     Step:3|6   loss:0.7744084596633911  \n","Epoch:26/50     Step:4|6   loss:0.7983342409133911  \n","Epoch:26/50     Step:5|6   loss:0.7776697874069214  \n","Epoch:26/50     Step:6|6   loss:0.7889851331710815  \n","Epoch:26/50     Step:7|6   loss:0.7728791236877441  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:97.2%\t train set:96.49%\n","Epoch:27/50     Step:1|6   loss:0.7769247889518738  \n","Epoch:27/50     Step:2|6   loss:0.8102632761001587  \n","Epoch:27/50     Step:3|6   loss:0.7444853782653809  \n","Epoch:27/50     Step:4|6   loss:0.7626841068267822  \n","Epoch:27/50     Step:5|6   loss:0.8005052804946899  \n","Epoch:27/50     Step:6|6   loss:0.7485470771789551  \n","Epoch:27/50     Step:7|6   loss:0.7109549045562744  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:99.07%\t train set:96.49%\n","Epoch:28/50     Step:1|6   loss:0.7569910287857056  \n","Epoch:28/50     Step:2|6   loss:0.7408274412155151  \n","Epoch:28/50     Step:3|6   loss:0.7696916460990906  \n","Epoch:28/50     Step:4|6   loss:0.7738854885101318  \n","Epoch:28/50     Step:5|6   loss:0.800186038017273  \n","Epoch:28/50     Step:6|6   loss:0.7994656562805176  \n","Epoch:28/50     Step:7|6   loss:0.8061506152153015  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:99.07%\t train set:96.49%\n","Epoch:29/50     Step:1|6   loss:0.7795366048812866  \n","Epoch:29/50     Step:2|6   loss:0.7777746915817261  \n","Epoch:29/50     Step:3|6   loss:0.7793811559677124  \n","Epoch:29/50     Step:4|6   loss:0.8155066967010498  \n","Epoch:29/50     Step:5|6   loss:0.7808263301849365  \n","Epoch:29/50     Step:6|6   loss:0.8050819635391235  \n","Epoch:29/50     Step:7|6   loss:0.7409173250198364  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:99.07%\t train set:96.49%\n","Epoch:30/50     Step:1|6   loss:0.730534553527832  \n","Epoch:30/50     Step:2|6   loss:0.7125484943389893  \n","Epoch:30/50     Step:3|6   loss:0.7947074770927429  \n","Epoch:30/50     Step:4|6   loss:0.8048043251037598  \n","Epoch:30/50     Step:5|6   loss:0.8093472719192505  \n","Epoch:30/50     Step:6|6   loss:0.7547628283500671  \n","Epoch:30/50     Step:7|6   loss:0.7831097841262817  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:99.07%\t train set:96.49%\n","Epoch:31/50     Step:1|6   loss:0.7845857739448547  \n","Epoch:31/50     Step:2|6   loss:0.7610681056976318  \n","Epoch:31/50     Step:3|6   loss:0.8083246350288391  \n","Epoch:31/50     Step:4|6   loss:0.804669201374054  \n","Epoch:31/50     Step:5|6   loss:0.7934566736221313  \n","Epoch:31/50     Step:6|6   loss:0.7397235035896301  \n","Epoch:31/50     Step:7|6   loss:0.8064626455307007  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:99.07%\t train set:96.49%\n","Epoch:32/50     Step:1|6   loss:0.7394888401031494  \n","Epoch:32/50     Step:2|6   loss:0.7969889044761658  \n","Epoch:32/50     Step:3|6   loss:0.7983828186988831  \n","Epoch:32/50     Step:4|6   loss:0.8198071718215942  \n","Epoch:32/50     Step:5|6   loss:0.7718227505683899  \n","Epoch:32/50     Step:6|6   loss:0.7329250574111938  \n","Epoch:32/50     Step:7|6   loss:0.7620722055435181  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:99.07%\t train set:96.49%\n","Epoch:33/50     Step:1|6   loss:0.7811696529388428  \n","Epoch:33/50     Step:2|6   loss:0.7153307199478149  \n","Epoch:33/50     Step:3|6   loss:0.7683095932006836  \n","Epoch:33/50     Step:4|6   loss:0.7800047993659973  \n","Epoch:33/50     Step:5|6   loss:0.7834268808364868  \n","Epoch:33/50     Step:6|6   loss:0.7799288034439087  \n","Epoch:33/50     Step:7|6   loss:0.7283923625946045  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:34/50     Step:1|6   loss:0.7671331167221069  \n","Epoch:34/50     Step:2|6   loss:0.7120726704597473  \n","Epoch:34/50     Step:3|6   loss:0.749498188495636  \n","Epoch:34/50     Step:4|6   loss:0.7260199785232544  \n","Epoch:34/50     Step:5|6   loss:0.6951360702514648  \n","Epoch:34/50     Step:6|6   loss:0.7006380558013916  \n","Epoch:34/50     Step:7|6   loss:0.7797046899795532  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:35/50     Step:1|6   loss:0.7375115156173706  \n","Epoch:35/50     Step:2|6   loss:0.7607060670852661  \n","Epoch:35/50     Step:3|6   loss:0.7713683843612671  \n","Epoch:35/50     Step:4|6   loss:0.7465710043907166  \n","Epoch:35/50     Step:5|6   loss:0.7371371984481812  \n","Epoch:35/50     Step:6|6   loss:0.8086575269699097  \n","Epoch:35/50     Step:7|6   loss:0.7331026792526245  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:36/50     Step:1|6   loss:0.7252907156944275  \n","Epoch:36/50     Step:2|6   loss:0.775621235370636  \n","Epoch:36/50     Step:3|6   loss:0.7491708993911743  \n","Epoch:36/50     Step:4|6   loss:0.7313766479492188  \n","Epoch:36/50     Step:5|6   loss:0.7614271640777588  \n","Epoch:36/50     Step:6|6   loss:0.7742345333099365  \n","Epoch:36/50     Step:7|6   loss:0.7460423707962036  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:37/50     Step:1|6   loss:0.7377781867980957  \n","Epoch:37/50     Step:2|6   loss:0.7188818454742432  \n","Epoch:37/50     Step:3|6   loss:0.7376024127006531  \n","Epoch:37/50     Step:4|6   loss:0.7789968252182007  \n","Epoch:37/50     Step:5|6   loss:0.7830055356025696  \n","Epoch:37/50     Step:6|6   loss:0.7693905830383301  \n","Epoch:37/50     Step:7|6   loss:0.7107274532318115  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:38/50     Step:1|6   loss:0.7601772546768188  \n","Epoch:38/50     Step:2|6   loss:0.752344012260437  \n","Epoch:38/50     Step:3|6   loss:0.7569735050201416  \n","Epoch:38/50     Step:4|6   loss:0.7892179489135742  \n","Epoch:38/50     Step:5|6   loss:0.7489444613456726  \n","Epoch:38/50     Step:6|6   loss:0.761515736579895  \n","Epoch:38/50     Step:7|6   loss:0.7152982950210571  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:39/50     Step:1|6   loss:0.6859593391418457  \n","Epoch:39/50     Step:2|6   loss:0.7066457271575928  \n","Epoch:39/50     Step:3|6   loss:0.7470958232879639  \n","Epoch:39/50     Step:4|6   loss:0.7573994994163513  \n","Epoch:39/50     Step:5|6   loss:0.7436306476593018  \n","Epoch:39/50     Step:6|6   loss:0.7392350435256958  \n","Epoch:39/50     Step:7|6   loss:0.737515926361084  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:40/50     Step:1|6   loss:0.7285370826721191  \n","Epoch:40/50     Step:2|6   loss:0.6770038604736328  \n","Epoch:40/50     Step:3|6   loss:0.7462511658668518  \n","Epoch:40/50     Step:4|6   loss:0.7293457984924316  \n","Epoch:40/50     Step:5|6   loss:0.7817211151123047  \n","Epoch:40/50     Step:6|6   loss:0.7763283848762512  \n","Epoch:40/50     Step:7|6   loss:0.7540709376335144  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:41/50     Step:1|6   loss:0.7241430878639221  \n","Epoch:41/50     Step:2|6   loss:0.6850724220275879  \n","Epoch:41/50     Step:3|6   loss:0.733425498008728  \n","Epoch:41/50     Step:4|6   loss:0.77777099609375  \n","Epoch:41/50     Step:5|6   loss:0.7158370018005371  \n","Epoch:41/50     Step:6|6   loss:0.7190883159637451  \n","Epoch:41/50     Step:7|6   loss:0.7897068858146667  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:42/50     Step:1|6   loss:0.7493577003479004  \n","Epoch:42/50     Step:2|6   loss:0.7467910647392273  \n","Epoch:42/50     Step:3|6   loss:0.6748389005661011  \n","Epoch:42/50     Step:4|6   loss:0.7840113639831543  \n","Epoch:42/50     Step:5|6   loss:0.7411289215087891  \n","Epoch:42/50     Step:6|6   loss:0.781577467918396  \n","Epoch:42/50     Step:7|6   loss:0.750220000743866  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:43/50     Step:1|6   loss:0.760148286819458  \n","Epoch:43/50     Step:2|6   loss:0.7387029528617859  \n","Epoch:43/50     Step:3|6   loss:0.7104053497314453  \n","Epoch:43/50     Step:4|6   loss:0.7426143884658813  \n","Epoch:43/50     Step:5|6   loss:0.7326629757881165  \n","Epoch:43/50     Step:6|6   loss:0.7316498160362244  \n","Epoch:43/50     Step:7|6   loss:0.7199971675872803  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:44/50     Step:1|6   loss:0.7249698638916016  \n","Epoch:44/50     Step:2|6   loss:0.7569814324378967  \n","Epoch:44/50     Step:3|6   loss:0.7486892938613892  \n","Epoch:44/50     Step:4|6   loss:0.7655201554298401  \n","Epoch:44/50     Step:5|6   loss:0.768001914024353  \n","Epoch:44/50     Step:6|6   loss:0.7492425441741943  \n","Epoch:44/50     Step:7|6   loss:0.7887240648269653  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:45/50     Step:1|6   loss:0.7333877086639404  \n","Epoch:45/50     Step:2|6   loss:0.70728600025177  \n","Epoch:45/50     Step:3|6   loss:0.7406392097473145  \n","Epoch:45/50     Step:4|6   loss:0.7374176979064941  \n","Epoch:45/50     Step:5|6   loss:0.7354781031608582  \n","Epoch:45/50     Step:6|6   loss:0.7872207164764404  \n","Epoch:45/50     Step:7|6   loss:0.7513083219528198  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:46/50     Step:1|6   loss:0.7647596597671509  \n","Epoch:46/50     Step:2|6   loss:0.725658118724823  \n","Epoch:46/50     Step:3|6   loss:0.7648584246635437  \n","Epoch:46/50     Step:4|6   loss:0.7734694480895996  \n","Epoch:46/50     Step:5|6   loss:0.7072811126708984  \n","Epoch:46/50     Step:6|6   loss:0.7508336901664734  \n","Epoch:46/50     Step:7|6   loss:0.7220925092697144  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:47/50     Step:1|6   loss:0.7096427083015442  \n","Epoch:47/50     Step:2|6   loss:0.7302227020263672  \n","Epoch:47/50     Step:3|6   loss:0.7298097610473633  \n","Epoch:47/50     Step:4|6   loss:0.738895058631897  \n","Epoch:47/50     Step:5|6   loss:0.8129535913467407  \n","Epoch:47/50     Step:6|6   loss:0.6875377893447876  \n","Epoch:47/50     Step:7|6   loss:0.743971049785614  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:48/50     Step:1|6   loss:0.7282257080078125  \n","Epoch:48/50     Step:2|6   loss:0.7676945924758911  \n","Epoch:48/50     Step:3|6   loss:0.7324084043502808  \n","Epoch:48/50     Step:4|6   loss:0.7263367772102356  \n","Epoch:48/50     Step:5|6   loss:0.7370287179946899  \n","Epoch:48/50     Step:6|6   loss:0.7135318517684937  \n","Epoch:48/50     Step:7|6   loss:0.7225160598754883  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:49/50     Step:1|6   loss:0.7436993718147278  \n","Epoch:49/50     Step:2|6   loss:0.6827747225761414  \n","Epoch:49/50     Step:3|6   loss:0.684679388999939  \n","Epoch:49/50     Step:4|6   loss:0.7134133577346802  \n","Epoch:49/50     Step:5|6   loss:0.7456636428833008  \n","Epoch:49/50     Step:6|6   loss:0.7254858613014221  \n","Epoch:49/50     Step:7|6   loss:0.78426194190979  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:50/50     Step:1|6   loss:0.7556167840957642  \n","Epoch:50/50     Step:2|6   loss:0.6905350685119629  \n","Epoch:50/50     Step:3|6   loss:0.731452465057373  \n","Epoch:50/50     Step:4|6   loss:0.7146971821784973  \n","Epoch:50/50     Step:5|6   loss:0.7233494520187378  \n","Epoch:50/50     Step:6|6   loss:0.765477180480957  \n","Epoch:50/50     Step:7|6   loss:0.7030943632125854  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()4\n","\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0825433731079102  \n","Epoch:1/50     Step:2|6   loss:1.1021802425384521  \n","Epoch:1/50     Step:3|6   loss:1.1318532228469849  \n","Epoch:1/50     Step:4|6   loss:1.072409749031067  \n","Epoch:1/50     Step:5|6   loss:1.1131447553634644  \n","Epoch:1/50     Step:6|6   loss:1.080700159072876  \n","Epoch:1/50     Step:7|6   loss:1.09308660030365  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 22.48 %\n","current max accuracy\t test set:28.04%\t train set:22.48%\n","Epoch:2/50     Step:1|6   loss:1.0609755516052246  \n","Epoch:2/50     Step:2|6   loss:1.1030871868133545  \n","Epoch:2/50     Step:3|6   loss:1.0555232763290405  \n","Epoch:2/50     Step:4|6   loss:1.060189962387085  \n","Epoch:2/50     Step:5|6   loss:1.0710633993148804  \n","Epoch:2/50     Step:6|6   loss:1.0721718072891235  \n","Epoch:2/50     Step:7|6   loss:1.060218334197998  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 22.48 %\n","current max accuracy\t test set:28.04%\t train set:22.48%\n","Epoch:3/50     Step:1|6   loss:1.0815471410751343  \n","Epoch:3/50     Step:2|6   loss:1.053657054901123  \n","Epoch:3/50     Step:3|6   loss:1.0431889295578003  \n","Epoch:3/50     Step:4|6   loss:1.0453239679336548  \n","Epoch:3/50     Step:5|6   loss:1.0200623273849487  \n","Epoch:3/50     Step:6|6   loss:1.047536015510559  \n","Epoch:3/50     Step:7|6   loss:0.9839104413986206  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 22.48 %\n","current max accuracy\t test set:28.04%\t train set:22.48%\n","Epoch:4/50     Step:1|6   loss:1.0422412157058716  \n","Epoch:4/50     Step:2|6   loss:0.999901294708252  \n","Epoch:4/50     Step:3|6   loss:0.9864499568939209  \n","Epoch:4/50     Step:4|6   loss:1.0072511434555054  \n","Epoch:4/50     Step:5|6   loss:1.0001853704452515  \n","Epoch:4/50     Step:6|6   loss:1.0097671747207642  \n","Epoch:4/50     Step:7|6   loss:1.0146499872207642  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 22.48 %\n","current max accuracy\t test set:28.04%\t train set:22.48%\n","Epoch:5/50     Step:1|6   loss:0.9785523414611816  \n","Epoch:5/50     Step:2|6   loss:1.0326817035675049  \n","Epoch:5/50     Step:3|6   loss:0.9984806776046753  \n","Epoch:5/50     Step:4|6   loss:0.9984025955200195  \n","Epoch:5/50     Step:5|6   loss:1.0214837789535522  \n","Epoch:5/50     Step:6|6   loss:1.0083612203598022  \n","Epoch:5/50     Step:7|6   loss:0.9963445663452148  \n","Accuracy on test_set: 28.04 %\n","Accuracy on train_set: 22.48 %\n","current max accuracy\t test set:28.04%\t train set:22.48%\n","Epoch:6/50     Step:1|6   loss:0.9763864278793335  \n","Epoch:6/50     Step:2|6   loss:1.0139243602752686  \n","Epoch:6/50     Step:3|6   loss:0.9770185947418213  \n","Epoch:6/50     Step:4|6   loss:0.9731825590133667  \n","Epoch:6/50     Step:5|6   loss:0.990046501159668  \n","Epoch:6/50     Step:6|6   loss:0.9623791575431824  \n","Epoch:6/50     Step:7|6   loss:0.9618428945541382  \n","Accuracy on test_set: 28.97 %\n","Accuracy on train_set: 26.00 %\n","current max accuracy\t test set:28.97%\t train set:26.0%\n","Epoch:7/50     Step:1|6   loss:0.9721943140029907  \n","Epoch:7/50     Step:2|6   loss:0.9542486667633057  \n","Epoch:7/50     Step:3|6   loss:0.9682039022445679  \n","Epoch:7/50     Step:4|6   loss:0.9472431540489197  \n","Epoch:7/50     Step:5|6   loss:0.9850000143051147  \n","Epoch:7/50     Step:6|6   loss:0.978137731552124  \n","Epoch:7/50     Step:7|6   loss:0.9386818408966064  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 71.19 %\n","current max accuracy\t test set:65.42%\t train set:71.19%\n","Epoch:8/50     Step:1|6   loss:0.9104407429695129  \n","Epoch:8/50     Step:2|6   loss:0.9520838260650635  \n","Epoch:8/50     Step:3|6   loss:0.9380271434783936  \n","Epoch:8/50     Step:4|6   loss:0.949752688407898  \n","Epoch:8/50     Step:5|6   loss:0.9409263730049133  \n","Epoch:8/50     Step:6|6   loss:0.9634903073310852  \n","Epoch:8/50     Step:7|6   loss:0.929827868938446  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:87.85%\t train set:89.23%\n","Epoch:9/50     Step:1|6   loss:0.9175477623939514  \n","Epoch:9/50     Step:2|6   loss:0.9731653332710266  \n","Epoch:9/50     Step:3|6   loss:0.9334697723388672  \n","Epoch:9/50     Step:4|6   loss:0.9415351152420044  \n","Epoch:9/50     Step:5|6   loss:0.9220197796821594  \n","Epoch:9/50     Step:6|6   loss:0.9434250593185425  \n","Epoch:9/50     Step:7|6   loss:0.895034670829773  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:87.85%\t train set:92.27%\n","Epoch:10/50     Step:1|6   loss:0.9347710609436035  \n","Epoch:10/50     Step:2|6   loss:0.9211446642875671  \n","Epoch:10/50     Step:3|6   loss:0.9347511529922485  \n","Epoch:10/50     Step:4|6   loss:0.9275920391082764  \n","Epoch:10/50     Step:5|6   loss:0.9116999506950378  \n","Epoch:10/50     Step:6|6   loss:0.909382164478302  \n","Epoch:10/50     Step:7|6   loss:0.886586606502533  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:87.85%\t train set:92.51%\n","Epoch:11/50     Step:1|6   loss:0.9014775156974792  \n","Epoch:11/50     Step:2|6   loss:0.885393500328064  \n","Epoch:11/50     Step:3|6   loss:0.8950393199920654  \n","Epoch:11/50     Step:4|6   loss:0.908444344997406  \n","Epoch:11/50     Step:5|6   loss:0.9073864817619324  \n","Epoch:11/50     Step:6|6   loss:0.8995151519775391  \n","Epoch:11/50     Step:7|6   loss:0.9477273225784302  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:87.85%\t train set:92.51%\n","Epoch:12/50     Step:1|6   loss:0.9318223595619202  \n","Epoch:12/50     Step:2|6   loss:0.8622245192527771  \n","Epoch:12/50     Step:3|6   loss:0.8978132605552673  \n","Epoch:12/50     Step:4|6   loss:0.8731689453125  \n","Epoch:12/50     Step:5|6   loss:0.871587336063385  \n","Epoch:12/50     Step:6|6   loss:0.88272625207901  \n","Epoch:12/50     Step:7|6   loss:0.8793483376502991  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:87.85%\t train set:92.51%\n","Epoch:13/50     Step:1|6   loss:0.8791911005973816  \n","Epoch:13/50     Step:2|6   loss:0.9057786464691162  \n","Epoch:13/50     Step:3|6   loss:0.8706530332565308  \n","Epoch:13/50     Step:4|6   loss:0.925285816192627  \n","Epoch:13/50     Step:5|6   loss:0.842947244644165  \n","Epoch:13/50     Step:6|6   loss:0.8959789276123047  \n","Epoch:13/50     Step:7|6   loss:0.9147137999534607  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:87.85%\t train set:92.51%\n","Epoch:14/50     Step:1|6   loss:0.8794796466827393  \n","Epoch:14/50     Step:2|6   loss:0.8724348545074463  \n","Epoch:14/50     Step:3|6   loss:0.8956463932991028  \n","Epoch:14/50     Step:4|6   loss:0.8533223867416382  \n","Epoch:14/50     Step:5|6   loss:0.8598045706748962  \n","Epoch:14/50     Step:6|6   loss:0.8627032041549683  \n","Epoch:14/50     Step:7|6   loss:0.9162487983703613  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:87.85%\t train set:92.51%\n","Epoch:15/50     Step:1|6   loss:0.8903427124023438  \n","Epoch:15/50     Step:2|6   loss:0.8693494200706482  \n","Epoch:15/50     Step:3|6   loss:0.8576976656913757  \n","Epoch:15/50     Step:4|6   loss:0.9043564796447754  \n","Epoch:15/50     Step:5|6   loss:0.8805464506149292  \n","Epoch:15/50     Step:6|6   loss:0.8531786799430847  \n","Epoch:15/50     Step:7|6   loss:0.857412576675415  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:89.72%\t train set:92.51%\n","Epoch:16/50     Step:1|6   loss:0.8475562334060669  \n","Epoch:16/50     Step:2|6   loss:0.8498209714889526  \n","Epoch:16/50     Step:3|6   loss:0.8369876742362976  \n","Epoch:16/50     Step:4|6   loss:0.861721396446228  \n","Epoch:16/50     Step:5|6   loss:0.8501549363136292  \n","Epoch:16/50     Step:6|6   loss:0.8577829599380493  \n","Epoch:16/50     Step:7|6   loss:0.7847217321395874  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:89.72%\t train set:92.51%\n","Epoch:17/50     Step:1|6   loss:0.8215488195419312  \n","Epoch:17/50     Step:2|6   loss:0.8351756930351257  \n","Epoch:17/50     Step:3|6   loss:0.8387534618377686  \n","Epoch:17/50     Step:4|6   loss:0.8324154019355774  \n","Epoch:17/50     Step:5|6   loss:0.8535168170928955  \n","Epoch:17/50     Step:6|6   loss:0.8677043914794922  \n","Epoch:17/50     Step:7|6   loss:0.8788883686065674  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:91.59%\t train set:92.51%\n","Epoch:18/50     Step:1|6   loss:0.8506746888160706  \n","Epoch:18/50     Step:2|6   loss:0.7971513867378235  \n","Epoch:18/50     Step:3|6   loss:0.8429816365242004  \n","Epoch:18/50     Step:4|6   loss:0.8240881562232971  \n","Epoch:18/50     Step:5|6   loss:0.8715101480484009  \n","Epoch:18/50     Step:6|6   loss:0.8410032987594604  \n","Epoch:18/50     Step:7|6   loss:0.8991291522979736  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 77.52 %\n","current max accuracy\t test set:91.59%\t train set:92.51%\n","Epoch:19/50     Step:1|6   loss:0.8277281522750854  \n","Epoch:19/50     Step:2|6   loss:0.8595942258834839  \n","Epoch:19/50     Step:3|6   loss:0.8393521308898926  \n","Epoch:19/50     Step:4|6   loss:0.8348544836044312  \n","Epoch:19/50     Step:5|6   loss:0.8195549845695496  \n","Epoch:19/50     Step:6|6   loss:0.854163646697998  \n","Epoch:19/50     Step:7|6   loss:0.7878295183181763  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:20/50     Step:1|6   loss:0.8579338788986206  \n","Epoch:20/50     Step:2|6   loss:0.8109722137451172  \n","Epoch:20/50     Step:3|6   loss:0.8415184020996094  \n","Epoch:20/50     Step:4|6   loss:0.8209915161132812  \n","Epoch:20/50     Step:5|6   loss:0.8023885488510132  \n","Epoch:20/50     Step:6|6   loss:0.8790292739868164  \n","Epoch:20/50     Step:7|6   loss:0.8405101895332336  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:92.52%\t train set:94.38%\n","Epoch:21/50     Step:1|6   loss:0.8244998455047607  \n","Epoch:21/50     Step:2|6   loss:0.8103877305984497  \n","Epoch:21/50     Step:3|6   loss:0.8911580443382263  \n","Epoch:21/50     Step:4|6   loss:0.8073806762695312  \n","Epoch:21/50     Step:5|6   loss:0.8265432715415955  \n","Epoch:21/50     Step:6|6   loss:0.8562822937965393  \n","Epoch:21/50     Step:7|6   loss:0.8315290212631226  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:92.52%\t train set:94.38%\n","Epoch:22/50     Step:1|6   loss:0.8087130784988403  \n","Epoch:22/50     Step:2|6   loss:0.7865520715713501  \n","Epoch:22/50     Step:3|6   loss:0.8038333058357239  \n","Epoch:22/50     Step:4|6   loss:0.8241528272628784  \n","Epoch:22/50     Step:5|6   loss:0.7729675769805908  \n","Epoch:22/50     Step:6|6   loss:0.851359486579895  \n","Epoch:22/50     Step:7|6   loss:0.8594205379486084  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:92.52%\t train set:94.38%\n","Epoch:23/50     Step:1|6   loss:0.8039978742599487  \n","Epoch:23/50     Step:2|6   loss:0.8143867254257202  \n","Epoch:23/50     Step:3|6   loss:0.821759819984436  \n","Epoch:23/50     Step:4|6   loss:0.8360162377357483  \n","Epoch:23/50     Step:5|6   loss:0.8381839990615845  \n","Epoch:23/50     Step:6|6   loss:0.8199600577354431  \n","Epoch:23/50     Step:7|6   loss:0.7845213413238525  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:92.52%\t train set:94.61%\n","Epoch:24/50     Step:1|6   loss:0.8195062875747681  \n","Epoch:24/50     Step:2|6   loss:0.8137171864509583  \n","Epoch:24/50     Step:3|6   loss:0.778533935546875  \n","Epoch:24/50     Step:4|6   loss:0.8275938034057617  \n","Epoch:24/50     Step:5|6   loss:0.8328273296356201  \n","Epoch:24/50     Step:6|6   loss:0.831423282623291  \n","Epoch:24/50     Step:7|6   loss:0.839049220085144  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:92.52%\t train set:94.61%\n","Epoch:25/50     Step:1|6   loss:0.8108936548233032  \n","Epoch:25/50     Step:2|6   loss:0.8386659622192383  \n","Epoch:25/50     Step:3|6   loss:0.8259186744689941  \n","Epoch:25/50     Step:4|6   loss:0.8189153075218201  \n","Epoch:25/50     Step:5|6   loss:0.779452383518219  \n","Epoch:25/50     Step:6|6   loss:0.7994310855865479  \n","Epoch:25/50     Step:7|6   loss:0.8042894601821899  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:95.33%\t train set:94.61%\n","Epoch:26/50     Step:1|6   loss:0.8086270689964294  \n","Epoch:26/50     Step:2|6   loss:0.8319108486175537  \n","Epoch:26/50     Step:3|6   loss:0.7979050874710083  \n","Epoch:26/50     Step:4|6   loss:0.8033812046051025  \n","Epoch:26/50     Step:5|6   loss:0.7982643842697144  \n","Epoch:26/50     Step:6|6   loss:0.762219250202179  \n","Epoch:26/50     Step:7|6   loss:0.7544376254081726  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:95.33%\t train set:94.61%\n","Epoch:27/50     Step:1|6   loss:0.791271448135376  \n","Epoch:27/50     Step:2|6   loss:0.7758496403694153  \n","Epoch:27/50     Step:3|6   loss:0.782142162322998  \n","Epoch:27/50     Step:4|6   loss:0.8339595198631287  \n","Epoch:27/50     Step:5|6   loss:0.7482240200042725  \n","Epoch:27/50     Step:6|6   loss:0.8301365375518799  \n","Epoch:27/50     Step:7|6   loss:0.7871582508087158  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:95.33%\t train set:94.61%\n","Epoch:28/50     Step:1|6   loss:0.8072919845581055  \n","Epoch:28/50     Step:2|6   loss:0.8139925599098206  \n","Epoch:28/50     Step:3|6   loss:0.800417423248291  \n","Epoch:28/50     Step:4|6   loss:0.8253046274185181  \n","Epoch:28/50     Step:5|6   loss:0.7686512470245361  \n","Epoch:28/50     Step:6|6   loss:0.8075956106185913  \n","Epoch:28/50     Step:7|6   loss:0.8097984790802002  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:29/50     Step:1|6   loss:0.8147792220115662  \n","Epoch:29/50     Step:2|6   loss:0.764484703540802  \n","Epoch:29/50     Step:3|6   loss:0.8236383199691772  \n","Epoch:29/50     Step:4|6   loss:0.7789919376373291  \n","Epoch:29/50     Step:5|6   loss:0.7540355920791626  \n","Epoch:29/50     Step:6|6   loss:0.8010329008102417  \n","Epoch:29/50     Step:7|6   loss:0.805094838142395  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:30/50     Step:1|6   loss:0.7587296962738037  \n","Epoch:30/50     Step:2|6   loss:0.7848814725875854  \n","Epoch:30/50     Step:3|6   loss:0.7702220678329468  \n","Epoch:30/50     Step:4|6   loss:0.789763331413269  \n","Epoch:30/50     Step:5|6   loss:0.7987993955612183  \n","Epoch:30/50     Step:6|6   loss:0.803964376449585  \n","Epoch:30/50     Step:7|6   loss:0.8668018579483032  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:96.26%\t train set:95.55%\n","Epoch:31/50     Step:1|6   loss:0.7837439179420471  \n","Epoch:31/50     Step:2|6   loss:0.8228014707565308  \n","Epoch:31/50     Step:3|6   loss:0.7793012857437134  \n","Epoch:31/50     Step:4|6   loss:0.8355211019515991  \n","Epoch:31/50     Step:5|6   loss:0.7917689681053162  \n","Epoch:31/50     Step:6|6   loss:0.7712622880935669  \n","Epoch:31/50     Step:7|6   loss:0.8092951774597168  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:96.26%\t train set:95.55%\n","Epoch:32/50     Step:1|6   loss:0.7931838631629944  \n","Epoch:32/50     Step:2|6   loss:0.7877627611160278  \n","Epoch:32/50     Step:3|6   loss:0.8528276681900024  \n","Epoch:32/50     Step:4|6   loss:0.7934445142745972  \n","Epoch:32/50     Step:5|6   loss:0.7638510465621948  \n","Epoch:32/50     Step:6|6   loss:0.778099536895752  \n","Epoch:32/50     Step:7|6   loss:0.7732524871826172  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:96.26%\t train set:95.55%\n","Epoch:33/50     Step:1|6   loss:0.7886240482330322  \n","Epoch:33/50     Step:2|6   loss:0.7444051504135132  \n","Epoch:33/50     Step:3|6   loss:0.7940271496772766  \n","Epoch:33/50     Step:4|6   loss:0.7797874212265015  \n","Epoch:33/50     Step:5|6   loss:0.7779390811920166  \n","Epoch:33/50     Step:6|6   loss:0.8748476505279541  \n","Epoch:33/50     Step:7|6   loss:0.7955541014671326  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:34/50     Step:1|6   loss:0.7898885011672974  \n","Epoch:34/50     Step:2|6   loss:0.7739249467849731  \n","Epoch:34/50     Step:3|6   loss:0.7721483707427979  \n","Epoch:34/50     Step:4|6   loss:0.7804887294769287  \n","Epoch:34/50     Step:5|6   loss:0.7731641530990601  \n","Epoch:34/50     Step:6|6   loss:0.810951828956604  \n","Epoch:34/50     Step:7|6   loss:0.7747276425361633  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:35/50     Step:1|6   loss:0.7565574645996094  \n","Epoch:35/50     Step:2|6   loss:0.7780968546867371  \n","Epoch:35/50     Step:3|6   loss:0.765232264995575  \n","Epoch:35/50     Step:4|6   loss:0.7588877081871033  \n","Epoch:35/50     Step:5|6   loss:0.8307128548622131  \n","Epoch:35/50     Step:6|6   loss:0.7696332931518555  \n","Epoch:35/50     Step:7|6   loss:0.8165020942687988  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 84.78 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:36/50     Step:1|6   loss:0.7912855744361877  \n","Epoch:36/50     Step:2|6   loss:0.8198577761650085  \n","Epoch:36/50     Step:3|6   loss:0.7956864833831787  \n","Epoch:36/50     Step:4|6   loss:0.7644985914230347  \n","Epoch:36/50     Step:5|6   loss:0.7666822671890259  \n","Epoch:36/50     Step:6|6   loss:0.7737724781036377  \n","Epoch:36/50     Step:7|6   loss:0.794566810131073  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:37/50     Step:1|6   loss:0.7653747797012329  \n","Epoch:37/50     Step:2|6   loss:0.7814223766326904  \n","Epoch:37/50     Step:3|6   loss:0.7809457778930664  \n","Epoch:37/50     Step:4|6   loss:0.820568859577179  \n","Epoch:37/50     Step:5|6   loss:0.7381477355957031  \n","Epoch:37/50     Step:6|6   loss:0.7680283784866333  \n","Epoch:37/50     Step:7|6   loss:0.7516719102859497  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:97.2%\t train set:96.25%\n","Epoch:38/50     Step:1|6   loss:0.8076218366622925  \n","Epoch:38/50     Step:2|6   loss:0.8303545713424683  \n","Epoch:38/50     Step:3|6   loss:0.7749128341674805  \n","Epoch:38/50     Step:4|6   loss:0.7977001667022705  \n","Epoch:38/50     Step:5|6   loss:0.7511154413223267  \n","Epoch:38/50     Step:6|6   loss:0.7587721347808838  \n","Epoch:38/50     Step:7|6   loss:0.8111168146133423  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:39/50     Step:1|6   loss:0.7159742116928101  \n","Epoch:39/50     Step:2|6   loss:0.7718105316162109  \n","Epoch:39/50     Step:3|6   loss:0.7849260568618774  \n","Epoch:39/50     Step:4|6   loss:0.7342113256454468  \n","Epoch:39/50     Step:5|6   loss:0.7774248123168945  \n","Epoch:39/50     Step:6|6   loss:0.798394501209259  \n","Epoch:39/50     Step:7|6   loss:0.7388231754302979  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:40/50     Step:1|6   loss:0.7464643716812134  \n","Epoch:40/50     Step:2|6   loss:0.7739006876945496  \n","Epoch:40/50     Step:3|6   loss:0.7712894082069397  \n","Epoch:40/50     Step:4|6   loss:0.7713233828544617  \n","Epoch:40/50     Step:5|6   loss:0.7422325611114502  \n","Epoch:40/50     Step:6|6   loss:0.751406192779541  \n","Epoch:40/50     Step:7|6   loss:0.7317156195640564  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:41/50     Step:1|6   loss:0.7569794058799744  \n","Epoch:41/50     Step:2|6   loss:0.7820315957069397  \n","Epoch:41/50     Step:3|6   loss:0.7808636426925659  \n","Epoch:41/50     Step:4|6   loss:0.7463988065719604  \n","Epoch:41/50     Step:5|6   loss:0.793104887008667  \n","Epoch:41/50     Step:6|6   loss:0.69734126329422  \n","Epoch:41/50     Step:7|6   loss:0.8179763555526733  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:42/50     Step:1|6   loss:0.7568438053131104  \n","Epoch:42/50     Step:2|6   loss:0.7663276195526123  \n","Epoch:42/50     Step:3|6   loss:0.7780759334564209  \n","Epoch:42/50     Step:4|6   loss:0.7729922533035278  \n","Epoch:42/50     Step:5|6   loss:0.7914197444915771  \n","Epoch:42/50     Step:6|6   loss:0.7771186828613281  \n","Epoch:42/50     Step:7|6   loss:0.7950819730758667  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:43/50     Step:1|6   loss:0.7362477779388428  \n","Epoch:43/50     Step:2|6   loss:0.7797993421554565  \n","Epoch:43/50     Step:3|6   loss:0.7378185987472534  \n","Epoch:43/50     Step:4|6   loss:0.7742834091186523  \n","Epoch:43/50     Step:5|6   loss:0.7556259632110596  \n","Epoch:43/50     Step:6|6   loss:0.7561395764350891  \n","Epoch:43/50     Step:7|6   loss:0.7470935583114624  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:44/50     Step:1|6   loss:0.8021520376205444  \n","Epoch:44/50     Step:2|6   loss:0.7962576150894165  \n","Epoch:44/50     Step:3|6   loss:0.7382768392562866  \n","Epoch:44/50     Step:4|6   loss:0.7633651494979858  \n","Epoch:44/50     Step:5|6   loss:0.7888156175613403  \n","Epoch:44/50     Step:6|6   loss:0.7293605804443359  \n","Epoch:44/50     Step:7|6   loss:0.7776046395301819  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:45/50     Step:1|6   loss:0.7641664743423462  \n","Epoch:45/50     Step:2|6   loss:0.6619076728820801  \n","Epoch:45/50     Step:3|6   loss:0.7727985382080078  \n","Epoch:45/50     Step:4|6   loss:0.7433227896690369  \n","Epoch:45/50     Step:5|6   loss:0.7813094258308411  \n","Epoch:45/50     Step:6|6   loss:0.7722368240356445  \n","Epoch:45/50     Step:7|6   loss:0.7243272066116333  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:46/50     Step:1|6   loss:0.7336987853050232  \n","Epoch:46/50     Step:2|6   loss:0.7954210042953491  \n","Epoch:46/50     Step:3|6   loss:0.7576703429222107  \n","Epoch:46/50     Step:4|6   loss:0.758557915687561  \n","Epoch:46/50     Step:5|6   loss:0.7028296589851379  \n","Epoch:46/50     Step:6|6   loss:0.7648853063583374  \n","Epoch:46/50     Step:7|6   loss:0.7666504383087158  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:47/50     Step:1|6   loss:0.7522913813591003  \n","Epoch:47/50     Step:2|6   loss:0.7693296670913696  \n","Epoch:47/50     Step:3|6   loss:0.7707560062408447  \n","Epoch:47/50     Step:4|6   loss:0.755338728427887  \n","Epoch:47/50     Step:5|6   loss:0.7463818192481995  \n","Epoch:47/50     Step:6|6   loss:0.7523618936538696  \n","Epoch:47/50     Step:7|6   loss:0.8262609243392944  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:48/50     Step:1|6   loss:0.7261677980422974  \n","Epoch:48/50     Step:2|6   loss:0.781481146812439  \n","Epoch:48/50     Step:3|6   loss:0.7103084325790405  \n","Epoch:48/50     Step:4|6   loss:0.7629345655441284  \n","Epoch:48/50     Step:5|6   loss:0.7474174499511719  \n","Epoch:48/50     Step:6|6   loss:0.7496129274368286  \n","Epoch:48/50     Step:7|6   loss:0.7529674768447876  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:98.13%\t train set:98.13%\n","Epoch:49/50     Step:1|6   loss:0.7694123983383179  \n","Epoch:49/50     Step:2|6   loss:0.7202401161193848  \n","Epoch:49/50     Step:3|6   loss:0.7116144895553589  \n","Epoch:49/50     Step:4|6   loss:0.7908748388290405  \n","Epoch:49/50     Step:5|6   loss:0.7482659816741943  \n","Epoch:49/50     Step:6|6   loss:0.732435941696167  \n","Epoch:49/50     Step:7|6   loss:0.7240103483200073  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:98.13%\t train set:98.13%\n","Epoch:50/50     Step:1|6   loss:0.7248550057411194  \n","Epoch:50/50     Step:2|6   loss:0.7514472007751465  \n","Epoch:50/50     Step:3|6   loss:0.7498300075531006  \n","Epoch:50/50     Step:4|6   loss:0.7515894770622253  \n","Epoch:50/50     Step:5|6   loss:0.7916081547737122  \n","Epoch:50/50     Step:6|6   loss:0.8025447726249695  \n","Epoch:50/50     Step:7|6   loss:0.7646204233169556  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:98.13%\n","Accuracy on test_set: 97.20 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_one_stream(\n","  (IN): Sequential(\n","    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (IN_both): Sequential(\n","    (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","  (block): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): SeparableConv2d(\n","      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","      (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (out): Sequential(\n","    (0): Linear(in_features=8, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.2223504781723022  \n","Epoch:1/50     Step:2|6   loss:1.2034962177276611  \n","Epoch:1/50     Step:3|6   loss:1.2911707162857056  \n","Epoch:1/50     Step:4|6   loss:1.1771830320358276  \n","Epoch:1/50     Step:5|6   loss:1.1649504899978638  \n","Epoch:1/50     Step:6|6   loss:1.2115658521652222  \n","Epoch:1/50     Step:7|6   loss:1.2080090045928955  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:20.56%\t train set:23.89%\n","Epoch:2/50     Step:1|6   loss:1.1952441930770874  \n","Epoch:2/50     Step:2|6   loss:1.196599006652832  \n","Epoch:2/50     Step:3|6   loss:1.1180486679077148  \n","Epoch:2/50     Step:4|6   loss:1.12563955783844  \n","Epoch:2/50     Step:5|6   loss:1.1063048839569092  \n","Epoch:2/50     Step:6|6   loss:1.1814006567001343  \n","Epoch:2/50     Step:7|6   loss:1.1395069360733032  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:20.56%\t train set:23.89%\n","Epoch:3/50     Step:1|6   loss:1.1191492080688477  \n","Epoch:3/50     Step:2|6   loss:1.123199462890625  \n","Epoch:3/50     Step:3|6   loss:1.0858519077301025  \n","Epoch:3/50     Step:4|6   loss:1.154248595237732  \n","Epoch:3/50     Step:5|6   loss:1.1068828105926514  \n","Epoch:3/50     Step:6|6   loss:1.0654261112213135  \n","Epoch:3/50     Step:7|6   loss:1.1102728843688965  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:20.56%\t train set:23.89%\n","Epoch:4/50     Step:1|6   loss:1.1205973625183105  \n","Epoch:4/50     Step:2|6   loss:1.038111925125122  \n","Epoch:4/50     Step:3|6   loss:1.1063321828842163  \n","Epoch:4/50     Step:4|6   loss:1.064505934715271  \n","Epoch:4/50     Step:5|6   loss:1.0479199886322021  \n","Epoch:4/50     Step:6|6   loss:1.0506561994552612  \n","Epoch:4/50     Step:7|6   loss:1.0881448984146118  \n","Accuracy on test_set: 20.56 %\n","Accuracy on train_set: 23.89 %\n","current max accuracy\t test set:20.56%\t train set:23.89%\n","Epoch:5/50     Step:1|6   loss:1.055397391319275  \n","Epoch:5/50     Step:2|6   loss:1.0051639080047607  \n","Epoch:5/50     Step:3|6   loss:1.0354622602462769  \n","Epoch:5/50     Step:4|6   loss:1.0440008640289307  \n","Epoch:5/50     Step:5|6   loss:1.0149365663528442  \n","Epoch:5/50     Step:6|6   loss:1.0017378330230713  \n","Epoch:5/50     Step:7|6   loss:1.0208745002746582  \n","Accuracy on test_set: 29.91 %\n","Accuracy on train_set: 32.08 %\n","current max accuracy\t test set:29.91%\t train set:32.08%\n","Epoch:6/50     Step:1|6   loss:1.0043771266937256  \n","Epoch:6/50     Step:2|6   loss:1.0284438133239746  \n","Epoch:6/50     Step:3|6   loss:1.0131196975708008  \n","Epoch:6/50     Step:4|6   loss:0.9927088022232056  \n","Epoch:6/50     Step:5|6   loss:1.0213087797164917  \n","Epoch:6/50     Step:6|6   loss:0.9949361085891724  \n","Epoch:6/50     Step:7|6   loss:1.0086040496826172  \n","Accuracy on test_set: 70.09 %\n","Accuracy on train_set: 79.86 %\n","current max accuracy\t test set:70.09%\t train set:79.86%\n","Epoch:7/50     Step:1|6   loss:0.9911549091339111  \n","Epoch:7/50     Step:2|6   loss:1.0166404247283936  \n","Epoch:7/50     Step:3|6   loss:0.9943164587020874  \n","Epoch:7/50     Step:4|6   loss:0.9684368371963501  \n","Epoch:7/50     Step:5|6   loss:0.9670886397361755  \n","Epoch:7/50     Step:6|6   loss:0.9754799008369446  \n","Epoch:7/50     Step:7|6   loss:1.0062599182128906  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 79.86 %\n","current max accuracy\t test set:75.7%\t train set:79.86%\n","Epoch:8/50     Step:1|6   loss:0.939387857913971  \n","Epoch:8/50     Step:2|6   loss:0.9295539855957031  \n","Epoch:8/50     Step:3|6   loss:0.9752913117408752  \n","Epoch:8/50     Step:4|6   loss:0.9111693501472473  \n","Epoch:8/50     Step:5|6   loss:0.948128879070282  \n","Epoch:8/50     Step:6|6   loss:0.9121749997138977  \n","Epoch:8/50     Step:7|6   loss:0.9223259091377258  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 81.03 %\n","current max accuracy\t test set:76.64%\t train set:81.03%\n","Epoch:9/50     Step:1|6   loss:0.9690503478050232  \n","Epoch:9/50     Step:2|6   loss:0.9032090306282043  \n","Epoch:9/50     Step:3|6   loss:0.9621025919914246  \n","Epoch:9/50     Step:4|6   loss:0.9434827566146851  \n","Epoch:9/50     Step:5|6   loss:0.9083130359649658  \n","Epoch:9/50     Step:6|6   loss:0.9187726974487305  \n","Epoch:9/50     Step:7|6   loss:0.9293646812438965  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:84.11%\t train set:86.89%\n","Epoch:10/50     Step:1|6   loss:0.8949549198150635  \n","Epoch:10/50     Step:2|6   loss:0.8955234289169312  \n","Epoch:10/50     Step:3|6   loss:0.9457337260246277  \n","Epoch:10/50     Step:4|6   loss:0.8914798498153687  \n","Epoch:10/50     Step:5|6   loss:0.871647298336029  \n","Epoch:10/50     Step:6|6   loss:0.9288466572761536  \n","Epoch:10/50     Step:7|6   loss:0.9248144030570984  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:84.11%\t train set:86.89%\n","Epoch:11/50     Step:1|6   loss:0.8769480586051941  \n","Epoch:11/50     Step:2|6   loss:0.8845939040184021  \n","Epoch:11/50     Step:3|6   loss:0.9364348649978638  \n","Epoch:11/50     Step:4|6   loss:0.8969978094100952  \n","Epoch:11/50     Step:5|6   loss:0.8706302642822266  \n","Epoch:11/50     Step:6|6   loss:0.9064603447914124  \n","Epoch:11/50     Step:7|6   loss:0.9068971276283264  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:84.11%\t train set:86.89%\n","Epoch:12/50     Step:1|6   loss:0.9111853241920471  \n","Epoch:12/50     Step:2|6   loss:0.8677058815956116  \n","Epoch:12/50     Step:3|6   loss:0.925736129283905  \n","Epoch:12/50     Step:4|6   loss:0.8834101557731628  \n","Epoch:12/50     Step:5|6   loss:0.8989825248718262  \n","Epoch:12/50     Step:6|6   loss:0.8249956965446472  \n","Epoch:12/50     Step:7|6   loss:0.8725830316543579  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 90.40 %\n","current max accuracy\t test set:88.79%\t train set:90.4%\n","Epoch:13/50     Step:1|6   loss:0.8136265277862549  \n","Epoch:13/50     Step:2|6   loss:0.8811867237091064  \n","Epoch:13/50     Step:3|6   loss:0.9024522304534912  \n","Epoch:13/50     Step:4|6   loss:0.9211026430130005  \n","Epoch:13/50     Step:5|6   loss:0.8825795650482178  \n","Epoch:13/50     Step:6|6   loss:0.853319525718689  \n","Epoch:13/50     Step:7|6   loss:0.8789304494857788  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:94.39%\t train set:94.15%\n","Epoch:14/50     Step:1|6   loss:0.8955108523368835  \n","Epoch:14/50     Step:2|6   loss:0.8759652972221375  \n","Epoch:14/50     Step:3|6   loss:0.8704420328140259  \n","Epoch:14/50     Step:4|6   loss:0.8882735967636108  \n","Epoch:14/50     Step:5|6   loss:0.811086893081665  \n","Epoch:14/50     Step:6|6   loss:0.8366588354110718  \n","Epoch:14/50     Step:7|6   loss:0.8596687316894531  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:94.39%\t train set:94.15%\n","Epoch:15/50     Step:1|6   loss:0.8472467660903931  \n","Epoch:15/50     Step:2|6   loss:0.8353624939918518  \n","Epoch:15/50     Step:3|6   loss:0.8662482500076294  \n","Epoch:15/50     Step:4|6   loss:0.9031379222869873  \n","Epoch:15/50     Step:5|6   loss:0.8071697950363159  \n","Epoch:15/50     Step:6|6   loss:0.8420752286911011  \n","Epoch:15/50     Step:7|6   loss:0.845008909702301  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:98.13%\t train set:95.55%\n","Epoch:16/50     Step:1|6   loss:0.8459600806236267  \n","Epoch:16/50     Step:2|6   loss:0.8530290126800537  \n","Epoch:16/50     Step:3|6   loss:0.8442682027816772  \n","Epoch:16/50     Step:4|6   loss:0.8156245946884155  \n","Epoch:16/50     Step:5|6   loss:0.798358678817749  \n","Epoch:16/50     Step:6|6   loss:0.823506772518158  \n","Epoch:16/50     Step:7|6   loss:0.8643543124198914  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:98.13%\t train set:95.55%\n","Epoch:17/50     Step:1|6   loss:0.8029270172119141  \n","Epoch:17/50     Step:2|6   loss:0.8555116653442383  \n","Epoch:17/50     Step:3|6   loss:0.8116946220397949  \n","Epoch:17/50     Step:4|6   loss:0.8667428493499756  \n","Epoch:17/50     Step:5|6   loss:0.8519301414489746  \n","Epoch:17/50     Step:6|6   loss:0.8148245811462402  \n","Epoch:17/50     Step:7|6   loss:0.805518627166748  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:98.13%\t train set:95.55%\n","Epoch:18/50     Step:1|6   loss:0.8033066987991333  \n","Epoch:18/50     Step:2|6   loss:0.8421683311462402  \n","Epoch:18/50     Step:3|6   loss:0.8139865398406982  \n","Epoch:18/50     Step:4|6   loss:0.8124170303344727  \n","Epoch:18/50     Step:5|6   loss:0.8111683130264282  \n","Epoch:18/50     Step:6|6   loss:0.7801185846328735  \n","Epoch:18/50     Step:7|6   loss:0.8328565359115601  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:95.78%\n","Epoch:19/50     Step:1|6   loss:0.8224309682846069  \n","Epoch:19/50     Step:2|6   loss:0.8154304027557373  \n","Epoch:19/50     Step:3|6   loss:0.7798947095870972  \n","Epoch:19/50     Step:4|6   loss:0.8370741605758667  \n","Epoch:19/50     Step:5|6   loss:0.8562259078025818  \n","Epoch:19/50     Step:6|6   loss:0.8388640880584717  \n","Epoch:19/50     Step:7|6   loss:0.8554517030715942  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:98.13%\t train set:95.78%\n","Epoch:20/50     Step:1|6   loss:0.8377031087875366  \n","Epoch:20/50     Step:2|6   loss:0.8138821721076965  \n","Epoch:20/50     Step:3|6   loss:0.8486889600753784  \n","Epoch:20/50     Step:4|6   loss:0.8214534521102905  \n","Epoch:20/50     Step:5|6   loss:0.8151372671127319  \n","Epoch:20/50     Step:6|6   loss:0.7973728775978088  \n","Epoch:20/50     Step:7|6   loss:0.8068681955337524  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:21/50     Step:1|6   loss:0.7984448671340942  \n","Epoch:21/50     Step:2|6   loss:0.829251766204834  \n","Epoch:21/50     Step:3|6   loss:0.8129621744155884  \n","Epoch:21/50     Step:4|6   loss:0.7732894420623779  \n","Epoch:21/50     Step:5|6   loss:0.7879722118377686  \n","Epoch:21/50     Step:6|6   loss:0.8059871196746826  \n","Epoch:21/50     Step:7|6   loss:0.8273579478263855  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:22/50     Step:1|6   loss:0.7815952897071838  \n","Epoch:22/50     Step:2|6   loss:0.8096601963043213  \n","Epoch:22/50     Step:3|6   loss:0.8521798253059387  \n","Epoch:22/50     Step:4|6   loss:0.7553602457046509  \n","Epoch:22/50     Step:5|6   loss:0.8397852182388306  \n","Epoch:22/50     Step:6|6   loss:0.841455340385437  \n","Epoch:22/50     Step:7|6   loss:0.777213454246521  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:23/50     Step:1|6   loss:0.7932733297348022  \n","Epoch:23/50     Step:2|6   loss:0.8175193071365356  \n","Epoch:23/50     Step:3|6   loss:0.7448865175247192  \n","Epoch:23/50     Step:4|6   loss:0.7815539240837097  \n","Epoch:23/50     Step:5|6   loss:0.7977258563041687  \n","Epoch:23/50     Step:6|6   loss:0.7859907746315002  \n","Epoch:23/50     Step:7|6   loss:0.7668473720550537  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:24/50     Step:1|6   loss:0.8110804557800293  \n","Epoch:24/50     Step:2|6   loss:0.8040683269500732  \n","Epoch:24/50     Step:3|6   loss:0.7634831666946411  \n","Epoch:24/50     Step:4|6   loss:0.8029076457023621  \n","Epoch:24/50     Step:5|6   loss:0.809756338596344  \n","Epoch:24/50     Step:6|6   loss:0.8233280777931213  \n","Epoch:24/50     Step:7|6   loss:0.817219614982605  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:25/50     Step:1|6   loss:0.8031717538833618  \n","Epoch:25/50     Step:2|6   loss:0.7773309946060181  \n","Epoch:25/50     Step:3|6   loss:0.8067455291748047  \n","Epoch:25/50     Step:4|6   loss:0.7621924877166748  \n","Epoch:25/50     Step:5|6   loss:0.7715916633605957  \n","Epoch:25/50     Step:6|6   loss:0.819691002368927  \n","Epoch:25/50     Step:7|6   loss:0.8303532600402832  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:26/50     Step:1|6   loss:0.7743176221847534  \n","Epoch:26/50     Step:2|6   loss:0.790688693523407  \n","Epoch:26/50     Step:3|6   loss:0.77032470703125  \n","Epoch:26/50     Step:4|6   loss:0.8142651915550232  \n","Epoch:26/50     Step:5|6   loss:0.7707688212394714  \n","Epoch:26/50     Step:6|6   loss:0.7505245208740234  \n","Epoch:26/50     Step:7|6   loss:0.7416447997093201  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:27/50     Step:1|6   loss:0.79421067237854  \n","Epoch:27/50     Step:2|6   loss:0.792507529258728  \n","Epoch:27/50     Step:3|6   loss:0.8464273810386658  \n","Epoch:27/50     Step:4|6   loss:0.7466575503349304  \n","Epoch:27/50     Step:5|6   loss:0.8170888423919678  \n","Epoch:27/50     Step:6|6   loss:0.7960344552993774  \n","Epoch:27/50     Step:7|6   loss:0.8415940999984741  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:28/50     Step:1|6   loss:0.7920462489128113  \n","Epoch:28/50     Step:2|6   loss:0.8036583662033081  \n","Epoch:28/50     Step:3|6   loss:0.8001664876937866  \n","Epoch:28/50     Step:4|6   loss:0.8027298450469971  \n","Epoch:28/50     Step:5|6   loss:0.7691036462783813  \n","Epoch:28/50     Step:6|6   loss:0.7611419558525085  \n","Epoch:28/50     Step:7|6   loss:0.7569290995597839  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:29/50     Step:1|6   loss:0.8053362369537354  \n","Epoch:29/50     Step:2|6   loss:0.7973518371582031  \n","Epoch:29/50     Step:3|6   loss:0.7911169528961182  \n","Epoch:29/50     Step:4|6   loss:0.7551469802856445  \n","Epoch:29/50     Step:5|6   loss:0.7528823614120483  \n","Epoch:29/50     Step:6|6   loss:0.8094534873962402  \n","Epoch:29/50     Step:7|6   loss:0.7885138988494873  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:30/50     Step:1|6   loss:0.7817045450210571  \n","Epoch:30/50     Step:2|6   loss:0.7749028205871582  \n","Epoch:30/50     Step:3|6   loss:0.7981500625610352  \n","Epoch:30/50     Step:4|6   loss:0.7744447588920593  \n","Epoch:30/50     Step:5|6   loss:0.7291593551635742  \n","Epoch:30/50     Step:6|6   loss:0.7797104120254517  \n","Epoch:30/50     Step:7|6   loss:0.779866635799408  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:31/50     Step:1|6   loss:0.8314821124076843  \n","Epoch:31/50     Step:2|6   loss:0.781304657459259  \n","Epoch:31/50     Step:3|6   loss:0.7559499740600586  \n","Epoch:31/50     Step:4|6   loss:0.8525300621986389  \n","Epoch:31/50     Step:5|6   loss:0.7741374969482422  \n","Epoch:31/50     Step:6|6   loss:0.7246086597442627  \n","Epoch:31/50     Step:7|6   loss:0.8099750876426697  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:32/50     Step:1|6   loss:0.7554185390472412  \n","Epoch:32/50     Step:2|6   loss:0.7628669142723083  \n","Epoch:32/50     Step:3|6   loss:0.7513103485107422  \n","Epoch:32/50     Step:4|6   loss:0.7882772088050842  \n","Epoch:32/50     Step:5|6   loss:0.7544127702713013  \n","Epoch:32/50     Step:6|6   loss:0.7485320568084717  \n","Epoch:32/50     Step:7|6   loss:0.7612404823303223  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:33/50     Step:1|6   loss:0.7438561916351318  \n","Epoch:33/50     Step:2|6   loss:0.8162639141082764  \n","Epoch:33/50     Step:3|6   loss:0.7770497798919678  \n","Epoch:33/50     Step:4|6   loss:0.7102627754211426  \n","Epoch:33/50     Step:5|6   loss:0.7957001328468323  \n","Epoch:33/50     Step:6|6   loss:0.8061366081237793  \n","Epoch:33/50     Step:7|6   loss:0.7738196849822998  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:34/50     Step:1|6   loss:0.7872066497802734  \n","Epoch:34/50     Step:2|6   loss:0.7764261364936829  \n","Epoch:34/50     Step:3|6   loss:0.732824444770813  \n","Epoch:34/50     Step:4|6   loss:0.7456395030021667  \n","Epoch:34/50     Step:5|6   loss:0.7672904133796692  \n","Epoch:34/50     Step:6|6   loss:0.7746350169181824  \n","Epoch:34/50     Step:7|6   loss:0.7924728393554688  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:35/50     Step:1|6   loss:0.7806823253631592  \n","Epoch:35/50     Step:2|6   loss:0.8074796199798584  \n","Epoch:35/50     Step:3|6   loss:0.784771203994751  \n","Epoch:35/50     Step:4|6   loss:0.7731119990348816  \n","Epoch:35/50     Step:5|6   loss:0.8028421401977539  \n","Epoch:35/50     Step:6|6   loss:0.7961556911468506  \n","Epoch:35/50     Step:7|6   loss:0.8016133308410645  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:36/50     Step:1|6   loss:0.7644973993301392  \n","Epoch:36/50     Step:2|6   loss:0.7684016227722168  \n","Epoch:36/50     Step:3|6   loss:0.7286863327026367  \n","Epoch:36/50     Step:4|6   loss:0.7594017386436462  \n","Epoch:36/50     Step:5|6   loss:0.7396016716957092  \n","Epoch:36/50     Step:6|6   loss:0.7340950965881348  \n","Epoch:36/50     Step:7|6   loss:0.7864022850990295  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:37/50     Step:1|6   loss:0.77457594871521  \n","Epoch:37/50     Step:2|6   loss:0.7852917313575745  \n","Epoch:37/50     Step:3|6   loss:0.7602132558822632  \n","Epoch:37/50     Step:4|6   loss:0.7837626338005066  \n","Epoch:37/50     Step:5|6   loss:0.7932952642440796  \n","Epoch:37/50     Step:6|6   loss:0.7921804189682007  \n","Epoch:37/50     Step:7|6   loss:0.7355640530586243  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:38/50     Step:1|6   loss:0.7225992679595947  \n","Epoch:38/50     Step:2|6   loss:0.734778881072998  \n","Epoch:38/50     Step:3|6   loss:0.7453576922416687  \n","Epoch:38/50     Step:4|6   loss:0.7758321762084961  \n","Epoch:38/50     Step:5|6   loss:0.7691265940666199  \n","Epoch:38/50     Step:6|6   loss:0.8061313629150391  \n","Epoch:38/50     Step:7|6   loss:0.7749977111816406  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:39/50     Step:1|6   loss:0.7699724435806274  \n","Epoch:39/50     Step:2|6   loss:0.7473588585853577  \n","Epoch:39/50     Step:3|6   loss:0.7628329992294312  \n","Epoch:39/50     Step:4|6   loss:0.7621400356292725  \n","Epoch:39/50     Step:5|6   loss:0.7651331424713135  \n","Epoch:39/50     Step:6|6   loss:0.708439826965332  \n","Epoch:39/50     Step:7|6   loss:0.8285932540893555  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:40/50     Step:1|6   loss:0.7935189008712769  \n","Epoch:40/50     Step:2|6   loss:0.7410067319869995  \n","Epoch:40/50     Step:3|6   loss:0.7772215604782104  \n","Epoch:40/50     Step:4|6   loss:0.7550256848335266  \n","Epoch:40/50     Step:5|6   loss:0.7428257465362549  \n","Epoch:40/50     Step:6|6   loss:0.7758846282958984  \n","Epoch:40/50     Step:7|6   loss:0.703870415687561  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:41/50     Step:1|6   loss:0.776085615158081  \n","Epoch:41/50     Step:2|6   loss:0.7559345960617065  \n","Epoch:41/50     Step:3|6   loss:0.6758756637573242  \n","Epoch:41/50     Step:4|6   loss:0.7833899259567261  \n","Epoch:41/50     Step:5|6   loss:0.7548824548721313  \n","Epoch:41/50     Step:6|6   loss:0.7436670064926147  \n","Epoch:41/50     Step:7|6   loss:0.7773367762565613  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:42/50     Step:1|6   loss:0.7531609535217285  \n","Epoch:42/50     Step:2|6   loss:0.7891502976417542  \n","Epoch:42/50     Step:3|6   loss:0.772219181060791  \n","Epoch:42/50     Step:4|6   loss:0.7657889127731323  \n","Epoch:42/50     Step:5|6   loss:0.7549318075180054  \n","Epoch:42/50     Step:6|6   loss:0.7890064716339111  \n","Epoch:42/50     Step:7|6   loss:0.7698420882225037  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:43/50     Step:1|6   loss:0.7760677337646484  \n","Epoch:43/50     Step:2|6   loss:0.7517379522323608  \n","Epoch:43/50     Step:3|6   loss:0.7441199421882629  \n","Epoch:43/50     Step:4|6   loss:0.7506234645843506  \n","Epoch:43/50     Step:5|6   loss:0.7497329115867615  \n","Epoch:43/50     Step:6|6   loss:0.7358263731002808  \n","Epoch:43/50     Step:7|6   loss:0.725074827671051  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:44/50     Step:1|6   loss:0.734143853187561  \n","Epoch:44/50     Step:2|6   loss:0.7057832479476929  \n","Epoch:44/50     Step:3|6   loss:0.7609508037567139  \n","Epoch:44/50     Step:4|6   loss:0.7647092342376709  \n","Epoch:44/50     Step:5|6   loss:0.7772194743156433  \n","Epoch:44/50     Step:6|6   loss:0.7655274868011475  \n","Epoch:44/50     Step:7|6   loss:0.7746100425720215  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:45/50     Step:1|6   loss:0.7874650359153748  \n","Epoch:45/50     Step:2|6   loss:0.7220891714096069  \n","Epoch:45/50     Step:3|6   loss:0.7547765970230103  \n","Epoch:45/50     Step:4|6   loss:0.7273901700973511  \n","Epoch:45/50     Step:5|6   loss:0.722649872303009  \n","Epoch:45/50     Step:6|6   loss:0.7375034093856812  \n","Epoch:45/50     Step:7|6   loss:0.7260195016860962  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:46/50     Step:1|6   loss:0.7677345275878906  \n","Epoch:46/50     Step:2|6   loss:0.7267769575119019  \n","Epoch:46/50     Step:3|6   loss:0.7588964700698853  \n","Epoch:46/50     Step:4|6   loss:0.6748230457305908  \n","Epoch:46/50     Step:5|6   loss:0.7476733922958374  \n","Epoch:46/50     Step:6|6   loss:0.7448174357414246  \n","Epoch:46/50     Step:7|6   loss:0.6847590208053589  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:47/50     Step:1|6   loss:0.7071121335029602  \n","Epoch:47/50     Step:2|6   loss:0.7727864384651184  \n","Epoch:47/50     Step:3|6   loss:0.7110074758529663  \n","Epoch:47/50     Step:4|6   loss:0.7799932956695557  \n","Epoch:47/50     Step:5|6   loss:0.7183061838150024  \n","Epoch:47/50     Step:6|6   loss:0.7501002550125122  \n","Epoch:47/50     Step:7|6   loss:0.8264378309249878  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:48/50     Step:1|6   loss:0.7279863357543945  \n","Epoch:48/50     Step:2|6   loss:0.7463028430938721  \n","Epoch:48/50     Step:3|6   loss:0.7187105417251587  \n","Epoch:48/50     Step:4|6   loss:0.7298239469528198  \n","Epoch:48/50     Step:5|6   loss:0.7242732048034668  \n","Epoch:48/50     Step:6|6   loss:0.7401185035705566  \n","Epoch:48/50     Step:7|6   loss:0.7305557727813721  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:49/50     Step:1|6   loss:0.7666136622428894  \n","Epoch:49/50     Step:2|6   loss:0.7139883637428284  \n","Epoch:49/50     Step:3|6   loss:0.7371324300765991  \n","Epoch:49/50     Step:4|6   loss:0.6771894693374634  \n","Epoch:49/50     Step:5|6   loss:0.745782196521759  \n","Epoch:49/50     Step:6|6   loss:0.8029574155807495  \n","Epoch:49/50     Step:7|6   loss:0.7775859832763672  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Epoch:50/50     Step:1|6   loss:0.7379584312438965  \n","Epoch:50/50     Step:2|6   loss:0.7475515007972717  \n","Epoch:50/50     Step:3|6   loss:0.762243390083313  \n","Epoch:50/50     Step:4|6   loss:0.7259413599967957  \n","Epoch:50/50     Step:5|6   loss:0.6973159313201904  \n","Epoch:50/50     Step:6|6   loss:0.8021133542060852  \n","Epoch:50/50     Step:7|6   loss:0.748622477054596  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:99.07%\t train set:97.89%\n","Accuracy on test_set: 95.33 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-3 --model Flame_one_stream --mode both --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":9,"id":"358d68ce","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_two_stream(\n","  (stream1): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (stream2): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=16, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.059500813484192  \n","Epoch:1/50     Step:2|6   loss:1.1002435684204102  \n","Epoch:1/50     Step:3|6   loss:1.07369065284729  \n","Epoch:1/50     Step:4|6   loss:1.0231040716171265  \n","Epoch:1/50     Step:5|6   loss:1.055749535560608  \n","Epoch:1/50     Step:6|6   loss:1.0301944017410278  \n","Epoch:1/50     Step:7|6   loss:1.0239990949630737  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:42.06%\t train set:49.41%\n","Epoch:2/50     Step:1|6   loss:1.0149831771850586  \n","Epoch:2/50     Step:2|6   loss:0.9724116325378418  \n","Epoch:2/50     Step:3|6   loss:1.0145888328552246  \n","Epoch:2/50     Step:4|6   loss:0.9967550039291382  \n","Epoch:2/50     Step:5|6   loss:0.9879549145698547  \n","Epoch:2/50     Step:6|6   loss:0.9920854568481445  \n","Epoch:2/50     Step:7|6   loss:0.9867257475852966  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:42.06%\t train set:49.41%\n","Epoch:3/50     Step:1|6   loss:0.9488347768783569  \n","Epoch:3/50     Step:2|6   loss:0.9647476673126221  \n","Epoch:3/50     Step:3|6   loss:0.9907709360122681  \n","Epoch:3/50     Step:4|6   loss:0.9761139154434204  \n","Epoch:3/50     Step:5|6   loss:0.961978554725647  \n","Epoch:3/50     Step:6|6   loss:0.9767534732818604  \n","Epoch:3/50     Step:7|6   loss:0.9570439457893372  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:42.06%\t train set:49.41%\n","Epoch:4/50     Step:1|6   loss:0.9556163549423218  \n","Epoch:4/50     Step:2|6   loss:0.9479020237922668  \n","Epoch:4/50     Step:3|6   loss:0.9518874287605286  \n","Epoch:4/50     Step:4|6   loss:0.9638816714286804  \n","Epoch:4/50     Step:5|6   loss:0.9147623777389526  \n","Epoch:4/50     Step:6|6   loss:0.9452788829803467  \n","Epoch:4/50     Step:7|6   loss:0.9438906908035278  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:42.06%\t train set:49.41%\n","Epoch:5/50     Step:1|6   loss:0.9235395193099976  \n","Epoch:5/50     Step:2|6   loss:0.9204537868499756  \n","Epoch:5/50     Step:3|6   loss:0.9124124646186829  \n","Epoch:5/50     Step:4|6   loss:0.9008796215057373  \n","Epoch:5/50     Step:5|6   loss:0.8783137798309326  \n","Epoch:5/50     Step:6|6   loss:0.8810009956359863  \n","Epoch:5/50     Step:7|6   loss:0.9099830389022827  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:42.06%\t train set:49.41%\n","Epoch:6/50     Step:1|6   loss:0.904543399810791  \n","Epoch:6/50     Step:2|6   loss:0.9026361107826233  \n","Epoch:6/50     Step:3|6   loss:0.8912463784217834  \n","Epoch:6/50     Step:4|6   loss:0.881183922290802  \n","Epoch:6/50     Step:5|6   loss:0.8936310410499573  \n","Epoch:6/50     Step:6|6   loss:0.8689149618148804  \n","Epoch:6/50     Step:7|6   loss:0.8923775553703308  \n","Accuracy on test_set: 48.60 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:48.6%\t train set:53.86%\n","Epoch:7/50     Step:1|6   loss:0.8810504078865051  \n","Epoch:7/50     Step:2|6   loss:0.9035051465034485  \n","Epoch:7/50     Step:3|6   loss:0.883471667766571  \n","Epoch:7/50     Step:4|6   loss:0.8445987701416016  \n","Epoch:7/50     Step:5|6   loss:0.8809018135070801  \n","Epoch:7/50     Step:6|6   loss:0.8776106834411621  \n","Epoch:7/50     Step:7|6   loss:0.8569228053092957  \n","Accuracy on test_set: 69.16 %\n","Accuracy on train_set: 75.88 %\n","current max accuracy\t test set:69.16%\t train set:75.88%\n","Epoch:8/50     Step:1|6   loss:0.8557029962539673  \n","Epoch:8/50     Step:2|6   loss:0.8347184062004089  \n","Epoch:8/50     Step:3|6   loss:0.8801923394203186  \n","Epoch:8/50     Step:4|6   loss:0.8240293264389038  \n","Epoch:8/50     Step:5|6   loss:0.8925610184669495  \n","Epoch:8/50     Step:6|6   loss:0.781555712223053  \n","Epoch:8/50     Step:7|6   loss:0.8239116668701172  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:81.31%\t train set:84.07%\n","Epoch:9/50     Step:1|6   loss:0.865768313407898  \n","Epoch:9/50     Step:2|6   loss:0.8708722591400146  \n","Epoch:9/50     Step:3|6   loss:0.8767449855804443  \n","Epoch:9/50     Step:4|6   loss:0.8125491142272949  \n","Epoch:9/50     Step:5|6   loss:0.7923769950866699  \n","Epoch:9/50     Step:6|6   loss:0.865161657333374  \n","Epoch:9/50     Step:7|6   loss:0.7919858694076538  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:85.98%\t train set:87.35%\n","Epoch:10/50     Step:1|6   loss:0.8069480657577515  \n","Epoch:10/50     Step:2|6   loss:0.8828331828117371  \n","Epoch:10/50     Step:3|6   loss:0.8454306125640869  \n","Epoch:10/50     Step:4|6   loss:0.8446207642555237  \n","Epoch:10/50     Step:5|6   loss:0.886080265045166  \n","Epoch:10/50     Step:6|6   loss:0.8478469252586365  \n","Epoch:10/50     Step:7|6   loss:0.8031588792800903  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:85.98%\t train set:87.35%\n","Epoch:11/50     Step:1|6   loss:0.8078086972236633  \n","Epoch:11/50     Step:2|6   loss:0.8578866720199585  \n","Epoch:11/50     Step:3|6   loss:0.8455788493156433  \n","Epoch:11/50     Step:4|6   loss:0.8301984071731567  \n","Epoch:11/50     Step:5|6   loss:0.7968969345092773  \n","Epoch:11/50     Step:6|6   loss:0.8316575288772583  \n","Epoch:11/50     Step:7|6   loss:0.8403900861740112  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:95.33%\t train set:94.61%\n","Epoch:12/50     Step:1|6   loss:0.8525093793869019  \n","Epoch:12/50     Step:2|6   loss:0.8262652158737183  \n","Epoch:12/50     Step:3|6   loss:0.7734280824661255  \n","Epoch:12/50     Step:4|6   loss:0.8335831761360168  \n","Epoch:12/50     Step:5|6   loss:0.8262064456939697  \n","Epoch:12/50     Step:6|6   loss:0.8436042070388794  \n","Epoch:12/50     Step:7|6   loss:0.8123970031738281  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:95.33%\t train set:94.61%\n","Epoch:13/50     Step:1|6   loss:0.8432489037513733  \n","Epoch:13/50     Step:2|6   loss:0.8112764954566956  \n","Epoch:13/50     Step:3|6   loss:0.7572290897369385  \n","Epoch:13/50     Step:4|6   loss:0.8141051530838013  \n","Epoch:13/50     Step:5|6   loss:0.7768442630767822  \n","Epoch:13/50     Step:6|6   loss:0.7925692796707153  \n","Epoch:13/50     Step:7|6   loss:0.8067212104797363  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:14/50     Step:1|6   loss:0.8356154561042786  \n","Epoch:14/50     Step:2|6   loss:0.7835878729820251  \n","Epoch:14/50     Step:3|6   loss:0.7878220081329346  \n","Epoch:14/50     Step:4|6   loss:0.7616037130355835  \n","Epoch:14/50     Step:5|6   loss:0.841234564781189  \n","Epoch:14/50     Step:6|6   loss:0.8175547122955322  \n","Epoch:14/50     Step:7|6   loss:0.7620858550071716  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:15/50     Step:1|6   loss:0.7945294976234436  \n","Epoch:15/50     Step:2|6   loss:0.7593016624450684  \n","Epoch:15/50     Step:3|6   loss:0.8180137276649475  \n","Epoch:15/50     Step:4|6   loss:0.8006033301353455  \n","Epoch:15/50     Step:5|6   loss:0.7555941343307495  \n","Epoch:15/50     Step:6|6   loss:0.7900803089141846  \n","Epoch:15/50     Step:7|6   loss:0.8261060118675232  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:16/50     Step:1|6   loss:0.8439081907272339  \n","Epoch:16/50     Step:2|6   loss:0.7836666703224182  \n","Epoch:16/50     Step:3|6   loss:0.7725227475166321  \n","Epoch:16/50     Step:4|6   loss:0.7679805755615234  \n","Epoch:16/50     Step:5|6   loss:0.7380872368812561  \n","Epoch:16/50     Step:6|6   loss:0.7595214247703552  \n","Epoch:16/50     Step:7|6   loss:0.8374729156494141  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:17/50     Step:1|6   loss:0.7837274074554443  \n","Epoch:17/50     Step:2|6   loss:0.7838549613952637  \n","Epoch:17/50     Step:3|6   loss:0.7919881343841553  \n","Epoch:17/50     Step:4|6   loss:0.766779363155365  \n","Epoch:17/50     Step:5|6   loss:0.7455579042434692  \n","Epoch:17/50     Step:6|6   loss:0.812865138053894  \n","Epoch:17/50     Step:7|6   loss:0.7191976308822632  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:18/50     Step:1|6   loss:0.7364016175270081  \n","Epoch:18/50     Step:2|6   loss:0.7647618651390076  \n","Epoch:18/50     Step:3|6   loss:0.7728704214096069  \n","Epoch:18/50     Step:4|6   loss:0.7884394526481628  \n","Epoch:18/50     Step:5|6   loss:0.7415027618408203  \n","Epoch:18/50     Step:6|6   loss:0.7839751839637756  \n","Epoch:18/50     Step:7|6   loss:0.7220903038978577  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:95.33%\t train set:96.49%\n","Epoch:19/50     Step:1|6   loss:0.7353057265281677  \n","Epoch:19/50     Step:2|6   loss:0.7452363967895508  \n","Epoch:19/50     Step:3|6   loss:0.8271821737289429  \n","Epoch:19/50     Step:4|6   loss:0.7968847155570984  \n","Epoch:19/50     Step:5|6   loss:0.7559629082679749  \n","Epoch:19/50     Step:6|6   loss:0.7254605293273926  \n","Epoch:19/50     Step:7|6   loss:0.7059639692306519  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:20/50     Step:1|6   loss:0.7122622728347778  \n","Epoch:20/50     Step:2|6   loss:0.7463724613189697  \n","Epoch:20/50     Step:3|6   loss:0.7377347350120544  \n","Epoch:20/50     Step:4|6   loss:0.7869659662246704  \n","Epoch:20/50     Step:5|6   loss:0.7418959140777588  \n","Epoch:20/50     Step:6|6   loss:0.7277960777282715  \n","Epoch:20/50     Step:7|6   loss:0.8132282495498657  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:21/50     Step:1|6   loss:0.7842992544174194  \n","Epoch:21/50     Step:2|6   loss:0.7462326288223267  \n","Epoch:21/50     Step:3|6   loss:0.7942413091659546  \n","Epoch:21/50     Step:4|6   loss:0.7988430261611938  \n","Epoch:21/50     Step:5|6   loss:0.7420493364334106  \n","Epoch:21/50     Step:6|6   loss:0.7852252721786499  \n","Epoch:21/50     Step:7|6   loss:0.7775304913520813  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:22/50     Step:1|6   loss:0.7179571390151978  \n","Epoch:22/50     Step:2|6   loss:0.7409347891807556  \n","Epoch:22/50     Step:3|6   loss:0.7773494720458984  \n","Epoch:22/50     Step:4|6   loss:0.7986012697219849  \n","Epoch:22/50     Step:5|6   loss:0.7316812872886658  \n","Epoch:22/50     Step:6|6   loss:0.7811810970306396  \n","Epoch:22/50     Step:7|6   loss:0.739454984664917  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:23/50     Step:1|6   loss:0.7565387487411499  \n","Epoch:23/50     Step:2|6   loss:0.6960070729255676  \n","Epoch:23/50     Step:3|6   loss:0.7530115842819214  \n","Epoch:23/50     Step:4|6   loss:0.7204641103744507  \n","Epoch:23/50     Step:5|6   loss:0.7349056005477905  \n","Epoch:23/50     Step:6|6   loss:0.7567153573036194  \n","Epoch:23/50     Step:7|6   loss:0.7217681407928467  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:24/50     Step:1|6   loss:0.7489107847213745  \n","Epoch:24/50     Step:2|6   loss:0.7160146832466125  \n","Epoch:24/50     Step:3|6   loss:0.7316945195198059  \n","Epoch:24/50     Step:4|6   loss:0.6994458436965942  \n","Epoch:24/50     Step:5|6   loss:0.731480598449707  \n","Epoch:24/50     Step:6|6   loss:0.7256220579147339  \n","Epoch:24/50     Step:7|6   loss:0.7800310254096985  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 89.46 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:25/50     Step:1|6   loss:0.7776445150375366  \n","Epoch:25/50     Step:2|6   loss:0.7692714929580688  \n","Epoch:25/50     Step:3|6   loss:0.7626309394836426  \n","Epoch:25/50     Step:4|6   loss:0.705834150314331  \n","Epoch:25/50     Step:5|6   loss:0.7292202115058899  \n","Epoch:25/50     Step:6|6   loss:0.7233422994613647  \n","Epoch:25/50     Step:7|6   loss:0.7298969030380249  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:97.2%\t train set:96.72%\n","Epoch:26/50     Step:1|6   loss:0.7534180879592896  \n","Epoch:26/50     Step:2|6   loss:0.7072609066963196  \n","Epoch:26/50     Step:3|6   loss:0.7508524656295776  \n","Epoch:26/50     Step:4|6   loss:0.7786141633987427  \n","Epoch:26/50     Step:5|6   loss:0.7734975814819336  \n","Epoch:26/50     Step:6|6   loss:0.7200345993041992  \n","Epoch:26/50     Step:7|6   loss:0.7428730726242065  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:27/50     Step:1|6   loss:0.786196231842041  \n","Epoch:27/50     Step:2|6   loss:0.6881346702575684  \n","Epoch:27/50     Step:3|6   loss:0.7413887977600098  \n","Epoch:27/50     Step:4|6   loss:0.6978838443756104  \n","Epoch:27/50     Step:5|6   loss:0.7480753064155579  \n","Epoch:27/50     Step:6|6   loss:0.7509464025497437  \n","Epoch:27/50     Step:7|6   loss:0.7547229528427124  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:28/50     Step:1|6   loss:0.7711584568023682  \n","Epoch:28/50     Step:2|6   loss:0.7304269671440125  \n","Epoch:28/50     Step:3|6   loss:0.7636679410934448  \n","Epoch:28/50     Step:4|6   loss:0.7111188173294067  \n","Epoch:28/50     Step:5|6   loss:0.7471422553062439  \n","Epoch:28/50     Step:6|6   loss:0.7957689166069031  \n","Epoch:28/50     Step:7|6   loss:0.7330940961837769  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:29/50     Step:1|6   loss:0.7159155607223511  \n","Epoch:29/50     Step:2|6   loss:0.6767326593399048  \n","Epoch:29/50     Step:3|6   loss:0.7582043409347534  \n","Epoch:29/50     Step:4|6   loss:0.6987096071243286  \n","Epoch:29/50     Step:5|6   loss:0.7431893348693848  \n","Epoch:29/50     Step:6|6   loss:0.7482231855392456  \n","Epoch:29/50     Step:7|6   loss:0.6915872097015381  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:30/50     Step:1|6   loss:0.7074971199035645  \n","Epoch:30/50     Step:2|6   loss:0.7320703268051147  \n","Epoch:30/50     Step:3|6   loss:0.7130205035209656  \n","Epoch:30/50     Step:4|6   loss:0.7795045971870422  \n","Epoch:30/50     Step:5|6   loss:0.7489422559738159  \n","Epoch:30/50     Step:6|6   loss:0.7582165002822876  \n","Epoch:30/50     Step:7|6   loss:0.7088738083839417  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:31/50     Step:1|6   loss:0.7221561074256897  \n","Epoch:31/50     Step:2|6   loss:0.7620578408241272  \n","Epoch:31/50     Step:3|6   loss:0.7625763416290283  \n","Epoch:31/50     Step:4|6   loss:0.685525119304657  \n","Epoch:31/50     Step:5|6   loss:0.7554761171340942  \n","Epoch:31/50     Step:6|6   loss:0.7410973906517029  \n","Epoch:31/50     Step:7|6   loss:0.7586696147918701  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:32/50     Step:1|6   loss:0.7899031639099121  \n","Epoch:32/50     Step:2|6   loss:0.783102810382843  \n","Epoch:32/50     Step:3|6   loss:0.7663453817367554  \n","Epoch:32/50     Step:4|6   loss:0.7619538307189941  \n","Epoch:32/50     Step:5|6   loss:0.7333244681358337  \n","Epoch:32/50     Step:6|6   loss:0.7786461710929871  \n","Epoch:32/50     Step:7|6   loss:0.7136622071266174  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:33/50     Step:1|6   loss:0.7002124190330505  \n","Epoch:33/50     Step:2|6   loss:0.7234938144683838  \n","Epoch:33/50     Step:3|6   loss:0.7619184255599976  \n","Epoch:33/50     Step:4|6   loss:0.7509027719497681  \n","Epoch:33/50     Step:5|6   loss:0.7024455070495605  \n","Epoch:33/50     Step:6|6   loss:0.7494797110557556  \n","Epoch:33/50     Step:7|6   loss:0.7262918949127197  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:34/50     Step:1|6   loss:0.7391469478607178  \n","Epoch:34/50     Step:2|6   loss:0.7529972791671753  \n","Epoch:34/50     Step:3|6   loss:0.7903847694396973  \n","Epoch:34/50     Step:4|6   loss:0.7635455131530762  \n","Epoch:34/50     Step:5|6   loss:0.8029680252075195  \n","Epoch:34/50     Step:6|6   loss:0.7849348187446594  \n","Epoch:34/50     Step:7|6   loss:0.7242880463600159  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:97.2%\t train set:97.19%\n","Epoch:35/50     Step:1|6   loss:0.7786471247673035  \n","Epoch:35/50     Step:2|6   loss:0.7334669828414917  \n","Epoch:35/50     Step:3|6   loss:0.7387690544128418  \n","Epoch:35/50     Step:4|6   loss:0.7433013916015625  \n","Epoch:35/50     Step:5|6   loss:0.7300145030021667  \n","Epoch:35/50     Step:6|6   loss:0.7740556001663208  \n","Epoch:35/50     Step:7|6   loss:0.7594307065010071  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:97.2%\t train set:98.13%\n","Epoch:36/50     Step:1|6   loss:0.7413812279701233  \n","Epoch:36/50     Step:2|6   loss:0.7506037950515747  \n","Epoch:36/50     Step:3|6   loss:0.779120922088623  \n","Epoch:36/50     Step:4|6   loss:0.6862869262695312  \n","Epoch:36/50     Step:5|6   loss:0.741254985332489  \n","Epoch:36/50     Step:6|6   loss:0.6923545002937317  \n","Epoch:36/50     Step:7|6   loss:0.7226784825325012  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:37/50     Step:1|6   loss:0.691005527973175  \n","Epoch:37/50     Step:2|6   loss:0.6986724138259888  \n","Epoch:37/50     Step:3|6   loss:0.7007099986076355  \n","Epoch:37/50     Step:4|6   loss:0.7329610586166382  \n","Epoch:37/50     Step:5|6   loss:0.7287954092025757  \n","Epoch:37/50     Step:6|6   loss:0.6858124732971191  \n","Epoch:37/50     Step:7|6   loss:0.7202343940734863  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:38/50     Step:1|6   loss:0.8338079452514648  \n","Epoch:38/50     Step:2|6   loss:0.6824548244476318  \n","Epoch:38/50     Step:3|6   loss:0.7526342272758484  \n","Epoch:38/50     Step:4|6   loss:0.7664438486099243  \n","Epoch:38/50     Step:5|6   loss:0.6849830746650696  \n","Epoch:38/50     Step:6|6   loss:0.7453188896179199  \n","Epoch:38/50     Step:7|6   loss:0.7003898024559021  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:39/50     Step:1|6   loss:0.7161152362823486  \n","Epoch:39/50     Step:2|6   loss:0.7130416631698608  \n","Epoch:39/50     Step:3|6   loss:0.7157300114631653  \n","Epoch:39/50     Step:4|6   loss:0.7101128101348877  \n","Epoch:39/50     Step:5|6   loss:0.7330984473228455  \n","Epoch:39/50     Step:6|6   loss:0.7717504501342773  \n","Epoch:39/50     Step:7|6   loss:0.7198885679244995  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:40/50     Step:1|6   loss:0.7424471378326416  \n","Epoch:40/50     Step:2|6   loss:0.7219308614730835  \n","Epoch:40/50     Step:3|6   loss:0.7199631929397583  \n","Epoch:40/50     Step:4|6   loss:0.7287670969963074  \n","Epoch:40/50     Step:5|6   loss:0.6861902475357056  \n","Epoch:40/50     Step:6|6   loss:0.7843996286392212  \n","Epoch:40/50     Step:7|6   loss:0.7447266578674316  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:41/50     Step:1|6   loss:0.7367808222770691  \n","Epoch:41/50     Step:2|6   loss:0.7235048413276672  \n","Epoch:41/50     Step:3|6   loss:0.757672131061554  \n","Epoch:41/50     Step:4|6   loss:0.7184025645256042  \n","Epoch:41/50     Step:5|6   loss:0.6948791146278381  \n","Epoch:41/50     Step:6|6   loss:0.7744823694229126  \n","Epoch:41/50     Step:7|6   loss:0.7107603549957275  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:42/50     Step:1|6   loss:0.7611631751060486  \n","Epoch:42/50     Step:2|6   loss:0.7577858567237854  \n","Epoch:42/50     Step:3|6   loss:0.7013819217681885  \n","Epoch:42/50     Step:4|6   loss:0.7170130610466003  \n","Epoch:42/50     Step:5|6   loss:0.7974513173103333  \n","Epoch:42/50     Step:6|6   loss:0.7558372020721436  \n","Epoch:42/50     Step:7|6   loss:0.7172670364379883  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:43/50     Step:1|6   loss:0.7538806200027466  \n","Epoch:43/50     Step:2|6   loss:0.7810041904449463  \n","Epoch:43/50     Step:3|6   loss:0.7124015688896179  \n","Epoch:43/50     Step:4|6   loss:0.7444750070571899  \n","Epoch:43/50     Step:5|6   loss:0.7396356463432312  \n","Epoch:43/50     Step:6|6   loss:0.7292360067367554  \n","Epoch:43/50     Step:7|6   loss:0.7424172163009644  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:44/50     Step:1|6   loss:0.7198394536972046  \n","Epoch:44/50     Step:2|6   loss:0.7212347388267517  \n","Epoch:44/50     Step:3|6   loss:0.7275798916816711  \n","Epoch:44/50     Step:4|6   loss:0.7456194162368774  \n","Epoch:44/50     Step:5|6   loss:0.7212847471237183  \n","Epoch:44/50     Step:6|6   loss:0.7245144248008728  \n","Epoch:44/50     Step:7|6   loss:0.6857556104660034  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:45/50     Step:1|6   loss:0.7389246225357056  \n","Epoch:45/50     Step:2|6   loss:0.6863808631896973  \n","Epoch:45/50     Step:3|6   loss:0.7095048427581787  \n","Epoch:45/50     Step:4|6   loss:0.7014907598495483  \n","Epoch:45/50     Step:5|6   loss:0.6805157661437988  \n","Epoch:45/50     Step:6|6   loss:0.7523860335350037  \n","Epoch:45/50     Step:7|6   loss:0.776902973651886  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:46/50     Step:1|6   loss:0.7791079878807068  \n","Epoch:46/50     Step:2|6   loss:0.7173284292221069  \n","Epoch:46/50     Step:3|6   loss:0.7192034721374512  \n","Epoch:46/50     Step:4|6   loss:0.7067307233810425  \n","Epoch:46/50     Step:5|6   loss:0.7434672713279724  \n","Epoch:46/50     Step:6|6   loss:0.7440127730369568  \n","Epoch:46/50     Step:7|6   loss:0.7749242186546326  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:47/50     Step:1|6   loss:0.8225818276405334  \n","Epoch:47/50     Step:2|6   loss:0.755262017250061  \n","Epoch:47/50     Step:3|6   loss:0.760297417640686  \n","Epoch:47/50     Step:4|6   loss:0.734791100025177  \n","Epoch:47/50     Step:5|6   loss:0.7843057513237  \n","Epoch:47/50     Step:6|6   loss:0.7270734310150146  \n","Epoch:47/50     Step:7|6   loss:0.7149365544319153  1\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:48/50     Step:1|6   loss:0.7529928684234619  \n","Epoch:48/50     Step:2|6   loss:0.7014101147651672  \n","Epoch:48/50     Step:3|6   loss:0.7456924319267273  \n","Epoch:48/50     Step:4|6   loss:0.7076115608215332  \n","Epoch:48/50     Step:5|6   loss:0.7417343854904175  \n","Epoch:48/50     Step:6|6   loss:0.7282220721244812  \n","Epoch:48/50     Step:7|6   loss:0.7429418563842773  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:49/50     Step:1|6   loss:0.7440037727355957  \n","Epoch:49/50     Step:2|6   loss:0.7185384035110474  \n","Epoch:49/50     Step:3|6   loss:0.7342478036880493  \n","Epoch:49/50     Step:4|6   loss:0.6376837491989136  \n","Epoch:49/50     Step:5|6   loss:0.7320609092712402  \n","Epoch:49/50     Step:6|6   loss:0.7442871332168579  \n","Epoch:49/50     Step:7|6   loss:0.7198604345321655  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:50/50     Step:1|6   loss:0.7312718629837036  \n","Epoch:50/50     Step:2|6   loss:0.72807377576828  \n","Epoch:50/50     Step:3|6   loss:0.7657008171081543  \n","Epoch:50/50     Step:4|6   loss:0.7572424411773682  \n","Epoch:50/50     Step:5|6   loss:0.7202611565589905  \n","Epoch:50/50     Step:6|6   loss:0.7265108823776245  \n","Epoch:50/50     Step:7|6   loss:0.7138134241104126  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Accuracy on test_set: 96.26 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_two_stream(\n","  (stream1): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (stream2): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=16, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1572494506835938  \n","Epoch:1/50     Step:2|6   loss:1.209395408630371  \n","Epoch:1/50     Step:3|6   loss:1.1718765497207642  \n","Epoch:1/50     Step:4|6   loss:1.1551960706710815  \n","Epoch:1/50     Step:5|6   loss:1.160413384437561  \n","Epoch:1/50     Step:6|6   loss:1.093192219734192  \n","Epoch:1/50     Step:7|6   loss:1.1028293371200562  \n","Accuracy on test_set: 29.91 %\n","Accuracy on train_set: 29.04 %\n","current max accuracy\t test set:29.91%\t train set:29.04%\n","Epoch:2/50     Step:1|6   loss:1.1097246408462524  \n","Epoch:2/50     Step:2|6   loss:1.1075408458709717  \n","Epoch:2/50     Step:3|6   loss:1.0701483488082886  \n","Epoch:2/50     Step:4|6   loss:1.0830434560775757  \n","Epoch:2/50     Step:5|6   loss:1.015065312385559  \n","Epoch:2/50     Step:6|6   loss:1.0063921213150024  \n","Epoch:2/50     Step:7|6   loss:1.0368670225143433  \n","Accuracy on test_set: 29.91 %\n","Accuracy on train_set: 29.04 %\n","current max accuracy\t test set:29.91%\t train set:29.04%\n","Epoch:3/50     Step:1|6   loss:1.0237282514572144  \n","Epoch:3/50     Step:2|6   loss:1.02262282371521  \n","Epoch:3/50     Step:3|6   loss:1.0051878690719604  \n","Epoch:3/50     Step:4|6   loss:1.038651466369629  \n","Epoch:3/50     Step:5|6   loss:1.0173813104629517  \n","Epoch:3/50     Step:6|6   loss:0.9694469571113586  \n","Epoch:3/50     Step:7|6   loss:0.9754038453102112  \n","Accuracy on test_set: 31.78 %\n","Accuracy on train_set: 29.98 %\n","current max accuracy\t test set:31.78%\t train set:29.98%\n","Epoch:4/50     Step:1|6   loss:1.0059418678283691  \n","Epoch:4/50     Step:2|6   loss:0.9512200355529785  \n","Epoch:4/50     Step:3|6   loss:0.9603857398033142  \n","Epoch:4/50     Step:4|6   loss:0.9969992637634277  \n","Epoch:4/50     Step:5|6   loss:0.9874621629714966  \n","Epoch:4/50     Step:6|6   loss:0.9132305383682251  \n","Epoch:4/50     Step:7|6   loss:0.9827674627304077  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 68.38 %\n","current max accuracy\t test set:68.22%\t train set:68.38%\n","Epoch:5/50     Step:1|6   loss:0.9421366453170776  \n","Epoch:5/50     Step:2|6   loss:0.9492487907409668  \n","Epoch:5/50     Step:3|6   loss:0.9093677401542664  \n","Epoch:5/50     Step:4|6   loss:1.0119184255599976  \n","Epoch:5/50     Step:5|6   loss:0.9118126034736633  \n","Epoch:5/50     Step:6|6   loss:0.9533640146255493  \n","Epoch:5/50     Step:7|6   loss:0.9005373120307922  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 71.19 %\n","current max accuracy\t test set:68.22%\t train set:71.19%\n","Epoch:6/50     Step:1|6   loss:0.9069948196411133  \n","Epoch:6/50     Step:2|6   loss:0.9679001569747925  \n","Epoch:6/50     Step:3|6   loss:0.8706623315811157  \n","Epoch:6/50     Step:4|6   loss:0.9313079118728638  \n","Epoch:6/50     Step:5|6   loss:0.9165914058685303  \n","Epoch:6/50     Step:6|6   loss:0.8873583674430847  \n","Epoch:6/50     Step:7|6   loss:0.8816049695014954  \n","Accuracy on test_set: 68.22 %\n","Accuracy on train_set: 71.66 %\n","current max accuracy\t test set:68.22%\t train set:71.66%\n","Epoch:7/50     Step:1|6   loss:0.9085355401039124  \n","Epoch:7/50     Step:2|6   loss:0.90358567237854  \n","Epoch:7/50     Step:3|6   loss:0.8796935677528381  \n","Epoch:7/50     Step:4|6   loss:0.8839242458343506  \n","Epoch:7/50     Step:5|6   loss:0.8698681592941284  \n","Epoch:7/50     Step:6|6   loss:0.8583765625953674  \n","Epoch:7/50     Step:7|6   loss:0.8623355031013489  \n","Accuracy on test_set: 71.03 %\n","Accuracy on train_set: 72.60 %\n","current max accuracy\t test set:71.03%\t train set:72.6%\n","Epoch:8/50     Step:1|6   loss:0.9010968208312988  \n","Epoch:8/50     Step:2|6   loss:0.8873066902160645  \n","Epoch:8/50     Step:3|6   loss:0.879374623298645  \n","Epoch:8/50     Step:4|6   loss:0.8479166030883789  \n","Epoch:8/50     Step:5|6   loss:0.8874074220657349  \n","Epoch:8/50     Step:6|6   loss:0.8777716755867004  \n","Epoch:8/50     Step:7|6   loss:0.8295589685440063  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:82.24%\t train set:84.07%\n","Epoch:9/50     Step:1|6   loss:0.8480177521705627  \n","Epoch:9/50     Step:2|6   loss:0.871333658695221  \n","Epoch:9/50     Step:3|6   loss:0.8634260892868042  \n","Epoch:9/50     Step:4|6   loss:0.8790032267570496  \n","Epoch:9/50     Step:5|6   loss:0.849384069442749  \n","Epoch:9/50     Step:6|6   loss:0.8840165138244629  \n","Epoch:9/50     Step:7|6   loss:0.8814914226531982  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:90.65%\t train set:92.74%\n","Epoch:10/50     Step:1|6   loss:0.8590984344482422  \n","Epoch:10/50     Step:2|6   loss:0.8122457265853882  \n","Epoch:10/50     Step:3|6   loss:0.811939537525177  \n","Epoch:10/50     Step:4|6   loss:0.8408816456794739  \n","Epoch:10/50     Step:5|6   loss:0.8268610239028931  \n","Epoch:10/50     Step:6|6   loss:0.8319149613380432  \n","Epoch:10/50     Step:7|6   loss:0.8724111914634705  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:96.26%\t train set:97.89%\n","Epoch:11/50     Step:1|6   loss:0.8232702612876892  \n","Epoch:11/50     Step:2|6   loss:0.8136343359947205  \n","Epoch:11/50     Step:3|6   loss:0.7936419248580933  \n","Epoch:11/50     Step:4|6   loss:0.8287854194641113  \n","Epoch:11/50     Step:5|6   loss:0.8099565505981445  \n","Epoch:11/50     Step:6|6   loss:0.8221458196640015  \n","Epoch:11/50     Step:7|6   loss:0.856701135635376  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:96.26%\t train set:97.89%\n","Epoch:12/50     Step:1|6   loss:0.815056324005127  \n","Epoch:12/50     Step:2|6   loss:0.8109046816825867  \n","Epoch:12/50     Step:3|6   loss:0.8330191969871521  \n","Epoch:12/50     Step:4|6   loss:0.8056654930114746  \n","Epoch:12/50     Step:5|6   loss:0.7668505907058716  \n","Epoch:12/50     Step:6|6   loss:0.8507622480392456  \n","Epoch:12/50     Step:7|6   loss:0.7832849025726318  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:13/50     Step:1|6   loss:0.8285022377967834  \n","Epoch:13/50     Step:2|6   loss:0.7915652394294739  \n","Epoch:13/50     Step:3|6   loss:0.8285720348358154  \n","Epoch:13/50     Step:4|6   loss:0.8424768447875977  \n","Epoch:13/50     Step:5|6   loss:0.8084942698478699  \n","Epoch:13/50     Step:6|6   loss:0.8130910992622375  \n","Epoch:13/50     Step:7|6   loss:0.7604696750640869  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:14/50     Step:1|6   loss:0.7897849082946777  \n","Epoch:14/50     Step:2|6   loss:0.7963675260543823  \n","Epoch:14/50     Step:3|6   loss:0.8055046796798706  \n","Epoch:14/50     Step:4|6   loss:0.7819757461547852  \n","Epoch:14/50     Step:5|6   loss:0.7865768671035767  \n","Epoch:14/50     Step:6|6   loss:0.7258310317993164  \n","Epoch:14/50     Step:7|6   loss:0.8407679200172424  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:15/50     Step:1|6   loss:0.8374663591384888  \n","Epoch:15/50     Step:2|6   loss:0.7603546380996704  \n","Epoch:15/50     Step:3|6   loss:0.809306263923645  \n","Epoch:15/50     Step:4|6   loss:0.7371305227279663  \n","Epoch:15/50     Step:5|6   loss:0.7503138780593872  \n","Epoch:15/50     Step:6|6   loss:0.7809311151504517  \n","Epoch:15/50     Step:7|6   loss:0.77037513256073  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:16/50     Step:1|6   loss:0.7955639362335205  \n","Epoch:16/50     Step:2|6   loss:0.7888127565383911  \n","Epoch:16/50     Step:3|6   loss:0.7980769276618958  \n","Epoch:16/50     Step:4|6   loss:0.7876322269439697  \n","Epoch:16/50     Step:5|6   loss:0.8190049529075623  \n","Epoch:16/50     Step:6|6   loss:0.7839828729629517  \n","Epoch:16/50     Step:7|6   loss:0.7684342861175537  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:17/50     Step:1|6   loss:0.7551624178886414  \n","Epoch:17/50     Step:2|6   loss:0.736595630645752  \n","Epoch:17/50     Step:3|6   loss:0.7430738806724548  \n","Epoch:17/50     Step:4|6   loss:0.7704445719718933  \n","Epoch:17/50     Step:5|6   loss:0.790480375289917  \n","Epoch:17/50     Step:6|6   loss:0.779734194278717  \n","Epoch:17/50     Step:7|6   loss:0.7410062551498413  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:18/50     Step:1|6   loss:0.724007248878479  \n","Epoch:18/50     Step:2|6   loss:0.7851395606994629  \n","Epoch:18/50     Step:3|6   loss:0.7275598645210266  \n","Epoch:18/50     Step:4|6   loss:0.7700212597846985  \n","Epoch:18/50     Step:5|6   loss:0.7534314393997192  \n","Epoch:18/50     Step:6|6   loss:0.7693909406661987  \n","Epoch:18/50     Step:7|6   loss:0.8284109830856323  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:19/50     Step:1|6   loss:0.7438249588012695  \n","Epoch:19/50     Step:2|6   loss:0.764799952507019  \n","Epoch:19/50     Step:3|6   loss:0.7476352453231812  \n","Epoch:19/50     Step:4|6   loss:0.7631497383117676  \n","Epoch:19/50     Step:5|6   loss:0.8036242127418518  \n","Epoch:19/50     Step:6|6   loss:0.7434431314468384  \n","Epoch:19/50     Step:7|6   loss:0.7872708439826965  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:20/50     Step:1|6   loss:0.7559975385665894  \n","Epoch:20/50     Step:2|6   loss:0.6970933079719543  \n","Epoch:20/50     Step:3|6   loss:0.7684462666511536  \n","Epoch:20/50     Step:4|6   loss:0.7700456380844116  \n","Epoch:20/50     Step:5|6   loss:0.7619872689247131  \n","Epoch:20/50     Step:6|6   loss:0.7053139209747314  \n","Epoch:20/50     Step:7|6   loss:0.7579300403594971  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:21/50     Step:1|6   loss:0.7392005324363708  \n","Epoch:21/50     Step:2|6   loss:0.7211216688156128  \n","Epoch:21/50     Step:3|6   loss:0.7179974317550659  \n","Epoch:21/50     Step:4|6   loss:0.7522938251495361  \n","Epoch:21/50     Step:5|6   loss:0.7764946222305298  \n","Epoch:21/50     Step:6|6   loss:0.7703709006309509  \n","Epoch:21/50     Step:7|6   loss:0.7501112818717957  \n","Accuracy on test_set: 95.33 %\n","2Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:22/50     Step:1|6   loss:0.7465355396270752  \n","Epoch:22/50     Step:2|6   loss:0.7423080801963806  \n","Epoch:22/50     Step:3|6   loss:0.783333420753479  \n","Epoch:22/50     Step:4|6   loss:0.7705594301223755  \n","Epoch:22/50     Step:5|6   loss:0.6970653533935547  \n","Epoch:22/50     Step:6|6   loss:0.7194501161575317  \n","Epoch:22/50     Step:7|6   loss:0.7773139476776123  \n","Accuracy on test_set: 100.00 %\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:23/50     Step:1|6   loss:0.7079362869262695  \n","Epoch:23/50     Step:2|6   loss:0.7589722275733948  \n","Epoch:23/50     Step:3|6   loss:0.7698255181312561  \n","Epoch:23/50     Step:4|6   loss:0.7538876533508301  \n","Epoch:23/50     Step:5|6   loss:0.7733868360519409  \n","Epoch:23/50     Step:6|6   loss:0.8024106025695801  \n","Epoch:23/50     Step:7|6   loss:0.712019681930542  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:24/50     Step:1|6   loss:0.7328876256942749  \n","Epoch:24/50     Step:2|6   loss:0.7717496752738953  \n","Epoch:24/50     Step:3|6   loss:0.7775442600250244  \n","Epoch:24/50     Step:4|6   loss:0.7671031355857849  \n","Epoch:24/50     Step:5|6   loss:0.7170242071151733  \n","Epoch:24/50     Step:6|6   loss:0.7400951385498047  \n","Epoch:24/50     Step:7|6   loss:0.7144856452941895  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:25/50     Step:1|6   loss:0.6854223608970642  \n","Epoch:25/50     Step:2|6   loss:0.6905509233474731  \n","Epoch:25/50     Step:3|6   loss:0.7478913068771362  \n","Epoch:25/50     Step:4|6   loss:0.7408818006515503  \n","Epoch:25/50     Step:5|6   loss:0.7527107000350952  \n","Epoch:25/50     Step:6|6   loss:0.7163850665092468  \n","Epoch:25/50     Step:7|6   loss:0.7450917959213257  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:26/50     Step:1|6   loss:0.7274014949798584  \n","Epoch:26/50     Step:2|6   loss:0.71842360496521  \n","Epoch:26/50     Step:3|6   loss:0.7103469371795654  \n","Epoch:26/50     Step:4|6   loss:0.7186183333396912  \n","Epoch:26/50     Step:5|6   loss:0.7135937809944153  \n","Epoch:26/50     Step:6|6   loss:0.7159143090248108  \n","Epoch:26/50     Step:7|6   loss:0.7411388754844666  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:27/50     Step:1|6   loss:0.763849139213562  \n","Epoch:27/50     Step:2|6   loss:0.740828275680542  \n","Epoch:27/50     Step:3|6   loss:0.7304526567459106  \n","Epoch:27/50     Step:4|6   loss:0.7525838613510132  \n","Epoch:27/50     Step:5|6   loss:0.6903512477874756  \n","Epoch:27/50     Step:6|6   loss:0.721893310546875  \n","Epoch:27/50     Step:7|6   loss:0.7332102656364441  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:28/50     Step:1|6   loss:0.7446513772010803  \n","Epoch:28/50     Step:2|6   loss:0.7265145182609558  \n","Epoch:28/50     Step:3|6   loss:0.7112208008766174  \n","Epoch:28/50     Step:4|6   loss:0.7208939790725708  \n","Epoch:28/50     Step:5|6   loss:0.7421659231185913  \n","Epoch:28/50     Step:6|6   loss:0.7978349924087524  \n","Epoch:28/50     Step:7|6   loss:0.7713019847869873  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:29/50     Step:1|6   loss:0.7555404305458069  \n","Epoch:29/50     Step:2|6   loss:0.7397022843360901  \n","Epoch:29/50     Step:3|6   loss:0.7497895956039429  \n","Epoch:29/50     Step:4|6   loss:0.7348326444625854  \n","Epoch:29/50     Step:5|6   loss:0.7332282066345215  \n","Epoch:29/50     Step:6|6   loss:0.6775889992713928  \n","Epoch:29/50     Step:7|6   loss:0.7134592533111572  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:30/50     Step:1|6   loss:0.7897545099258423  \n","Epoch:30/50     Step:2|6   loss:0.7408758997917175  \n","Epoch:30/50     Step:3|6   loss:0.7366573214530945  \n","Epoch:30/50     Step:4|6   loss:0.7894061803817749  \n","Epoch:30/50     Step:5|6   loss:0.7577449679374695  \n","Epoch:30/50     Step:6|6   loss:0.7704602479934692  \n","Epoch:30/50     Step:7|6   loss:0.7606646418571472  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:31/50     Step:1|6   loss:0.764978289604187  \n","Epoch:31/50     Step:2|6   loss:0.7273098826408386  \n","Epoch:31/50     Step:3|6   loss:0.760793924331665  \n","Epoch:31/50     Step:4|6   loss:0.7562661170959473  \n","Epoch:31/50     Step:5|6   loss:0.7261228561401367  \n","Epoch:31/50     Step:6|6   loss:0.7110509872436523  \n","Epoch:31/50     Step:7|6   loss:0.7806953191757202  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:32/50     Step:1|6   loss:0.7235580682754517  \n","Epoch:32/50     Step:2|6   loss:0.7237558364868164  \n","Epoch:32/50     Step:3|6   loss:0.728390097618103  \n","Epoch:32/50     Step:4|6   loss:0.733573853969574  \n","Epoch:32/50     Step:5|6   loss:0.7265284061431885  \n","Epoch:32/50     Step:6|6   loss:0.761893630027771  \n","Epoch:32/50     Step:7|6   loss:0.7515567541122437  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:33/50     Step:1|6   loss:0.748561441898346  \n","Epoch:33/50     Step:2|6   loss:0.714042067527771  \n","Epoch:33/50     Step:3|6   loss:0.7423385381698608  \n","Epoch:33/50     Step:4|6   loss:0.7535420656204224  \n","Epoch:33/50     Step:5|6   loss:0.7264575958251953  \n","Epoch:33/50     Step:6|6   loss:0.7122863531112671  \n","Epoch:33/50     Step:7|6   loss:0.7531899213790894  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:34/50     Step:1|6   loss:0.731100857257843  \n","Epoch:34/50     Step:2|6   loss:0.7437548637390137  \n","Epoch:34/50     Step:3|6   loss:0.7210739850997925  \n","Epoch:34/50     Step:4|6   loss:0.7446688413619995  \n","Epoch:34/50     Step:5|6   loss:0.7621955275535583  \n","Epoch:34/50     Step:6|6   loss:0.7669451236724854  \n","Epoch:34/50     Step:7|6   loss:0.7883860468864441  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:35/50     Step:1|6   loss:0.7571159601211548  \n","Epoch:35/50     Step:2|6   loss:0.7534480094909668  \n","Epoch:35/50     Step:3|6   loss:0.733843982219696  \n","Epoch:35/50     Step:4|6   loss:0.7483499646186829  \n","Epoch:35/50     Step:5|6   loss:0.6803673505783081  \n","Epoch:35/50     Step:6|6   loss:0.7322079539299011  \n","Epoch:35/50     Step:7|6   loss:0.7402139902114868  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:36/50     Step:1|6   loss:0.6876153349876404  \n","Epoch:36/50     Step:2|6   loss:0.7065790891647339  \n","Epoch:36/50     Step:3|6   loss:0.7305619716644287  \n","Epoch:36/50     Step:4|6   loss:0.7467590570449829  \n","Epoch:36/50     Step:5|6   loss:0.7810737490653992  \n","Epoch:36/50     Step:6|6   loss:0.7879503965377808  \n","Epoch:36/50     Step:7|6   loss:0.7234840989112854  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:37/50     Step:1|6   loss:0.7714799642562866  \n","Epoch:37/50     Step:2|6   loss:0.6889084577560425  \n","Epoch:37/50     Step:3|6   loss:0.6976059675216675  \n","Epoch:37/50     Step:4|6   loss:0.7629729509353638  \n","Epoch:37/50     Step:5|6   loss:0.7132135033607483  \n","Epoch:37/50     Step:6|6   loss:0.7114303112030029  \n","Epoch:37/50     Step:7|6   loss:0.7014104127883911  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:38/50     Step:1|6   loss:0.7464520931243896  \n","Epoch:38/50     Step:2|6   loss:0.7185668349266052  \n","Epoch:38/50     Step:3|6   loss:0.7452410459518433  \n","Epoch:38/50     Step:4|6   loss:0.7346569299697876  \n","Epoch:38/50     Step:5|6   loss:0.6953612565994263  \n","Epoch:38/50     Step:6|6   loss:0.7514604330062866  \n","Epoch:38/50     Step:7|6   loss:0.7057554721832275  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:39/50     Step:1|6   loss:0.7509986162185669  \n","Epoch:39/50     Step:2|6   loss:0.7296134233474731  \n","Epoch:39/50     Step:3|6   loss:0.7487574815750122  \n","Epoch:39/50     Step:4|6   loss:0.7271689176559448  \n","Epoch:39/50     Step:5|6   loss:0.7305151224136353  \n","Epoch:39/50     Step:6|6   loss:0.7117097973823547  \n","Epoch:39/50     Step:7|6   loss:0.7336013913154602  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:40/50     Step:1|6   loss:0.7629753351211548  \n","Epoch:40/50     Step:2|6   loss:0.738726794719696  \n","Epoch:40/50     Step:3|6   loss:0.7554321885108948  \n","Epoch:40/50     Step:4|6   loss:0.7374159693717957  \n","Epoch:40/50     Step:5|6   loss:0.6813603639602661  \n","Epoch:40/50     Step:6|6   loss:0.6925775408744812  \n","Epoch:40/50     Step:7|6   loss:0.7397661209106445  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:41/50     Step:1|6   loss:0.7072601318359375  \n","Epoch:41/50     Step:2|6   loss:0.7602860927581787  \n","Epoch:41/50     Step:3|6   loss:0.7127487659454346  \n","Epoch:41/50     Step:4|6   loss:0.7199313640594482  \n","Epoch:41/50     Step:5|6   loss:0.7053226232528687  \n","Epoch:41/50     Step:6|6   loss:0.7642195820808411  \n","Epoch:41/50     Step:7|6   loss:0.6876605749130249  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:42/50     Step:1|6   loss:0.7440419793128967  \n","Epoch:42/50     Step:2|6   loss:0.7129959464073181  \n","Epoch:42/50     Step:3|6   loss:0.7194781303405762  \n","Epoch:42/50     Step:4|6   loss:0.7421340942382812  \n","Epoch:42/50     Step:5|6   loss:0.750121533870697  \n","Epoch:42/50     Step:6|6   loss:0.7424629330635071  \n","Epoch:42/50     Step:7|6   loss:0.7198889255523682  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:43/50     Step:1|6   loss:0.7861626148223877  \n","Epoch:43/50     Step:2|6   loss:0.7336416840553284  \n","Epoch:43/50     Step:3|6   loss:0.6955803632736206  \n","Epoch:43/50     Step:4|6   loss:0.6994573473930359  \n","Epoch:43/50     Step:5|6   loss:0.6899890303611755  \n","Epoch:43/50     Step:6|6   loss:0.7421997785568237  \n","Epoch:43/50     Step:7|6   loss:0.7675034999847412  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:44/50     Step:1|6   loss:0.72376549243927  \n","Epoch:44/50     Step:2|6   loss:0.7765146493911743  \n","Epoch:44/50     Step:3|6   loss:0.7225133776664734  \n","Epoch:44/50     Step:4|6   loss:0.7476463317871094  \n","Epoch:44/50     Step:5|6   loss:0.7385098934173584  \n","Epoch:44/50     Step:6|6   loss:0.6655795574188232  \n","Epoch:44/50     Step:7|6   loss:0.7133435010910034  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:45/50     Step:1|6   loss:0.7124261260032654  \n","Epoch:45/50     Step:2|6   loss:0.732854962348938  \n","Epoch:45/50     Step:3|6   loss:0.7116013169288635  \n","Epoch:45/50     Step:4|6   loss:0.7173967957496643  \n","Epoch:45/50     Step:5|6   loss:0.7448693513870239  \n","Epoch:45/50     Step:6|6   loss:0.7250487804412842  \n","Epoch:45/50     Step:7|6   loss:0.7416011095046997  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:46/50     Step:1|6   loss:0.7315853238105774  \n","Epoch:46/50     Step:2|6   loss:0.7199451923370361  \n","Epoch:46/50     Step:3|6   loss:0.7926487922668457  \n","Epoch:46/50     Step:4|6   loss:0.7548037767410278  \n","Epoch:46/50     Step:5|6   loss:0.735539436340332  \n","Epoch:46/50     Step:6|6   loss:0.6979586482048035  \n","Epoch:46/50     Step:7|6   loss:0.6812923550605774  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:47/50     Step:1|6   loss:0.762236475944519  \n","Epoch:47/50     Step:2|6   loss:0.7106620073318481  \n","Epoch:47/50     Step:3|6   loss:0.681147575378418  \n","Epoch:47/50     Step:4|6   loss:0.7436743974685669  \n","Epoch:47/50     Step:5|6   loss:0.7066007852554321  \n","Epoch:47/50     Step:6|6   loss:0.7529721260070801  \n","Epoch:47/50     Step:7|6   loss:0.6534984111785889  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:48/50     Step:1|6   loss:0.7272318601608276  \n","Epoch:48/50     Step:2|6   loss:0.7491122484207153  \n","Epoch:48/50     Step:3|6   loss:0.7507809400558472  \n","Epoch:48/50     Step:4|6   loss:0.7030145525932312  \n","Epoch:48/50     Step:5|6   loss:0.7442018985748291  \n","Epoch:48/50     Step:6|6   loss:0.7016559839248657  \n","Epoch:48/50     Step:7|6   loss:0.7508114576339722  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:100.0%\t train set:99.06%\n","Epoch:49/50     Step:1|6   loss:0.7323311567306519  \n","Epoch:49/50     Step:2|6   loss:0.6677767038345337  \n","Epoch:49/50     Step:3|6   loss:0.6814365983009338  \n","Epoch:49/50     Step:4|6   loss:0.6905261278152466  \n","Epoch:49/50     Step:5|6   loss:0.6984126567840576  \n","Epoch:49/50     Step:6|6   loss:0.7526726722717285  \n","Epoch:49/50     Step:7|6   loss:0.7566211223602295  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:100.0%\t train set:99.3%\n","Epoch:50/50     Step:1|6   loss:0.710471510887146  \n","Epoch:50/50     Step:2|6   loss:0.7383824586868286  \n","Epoch:50/50     Step:3|6   loss:0.7469007968902588  \n","Epoch:50/50     Step:4|6   loss:0.7319272756576538  \n","Epoch:50/50     Step:5|6   loss:0.7334819436073303  \n","Epoch:50/50     Step:6|6   loss:0.7122746706008911  \n","Epoch:50/50     Step:7|6   loss:0.7338732481002808  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:100.0%\t train set:99.3%\n","Accuracy on test_set: 97.20 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_two_stream(\n","  (stream1): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (stream2): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=16, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1570184230804443  \n","Epoch:1/50     Step:2|6   loss:1.2047799825668335  \n","Epoch:1/50     Step:3|6   loss:1.1663492918014526  \n","Epoch:1/50     Step:4|6   loss:1.1507632732391357  \n","Epoch:1/50     Step:5|6   loss:1.14021635055542  \n","Epoch:1/50     Step:6|6   loss:1.1907429695129395  \n","Epoch:1/50     Step:7|6   loss:1.1135495901107788  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 25.29 %\n","current max accuracy\t test set:25.23%\t train set:25.29%\n","Epoch:2/50     Step:1|6   loss:1.1784709692001343  \n","Epoch:2/50     Step:2|6   loss:1.135399341583252  \n","Epoch:2/50     Step:3|6   loss:1.1309545040130615  \n","Epoch:2/50     Step:4|6   loss:1.1447675228118896  \n","Epoch:2/50     Step:5|6   loss:1.0717310905456543  \n","Epoch:2/50     Step:6|6   loss:1.0920161008834839  \n","Epoch:2/50     Step:7|6   loss:1.0677778720855713  \n","Accuracy on test_set: 26.17 %\n","Accuracy on train_set: 32.08 %\n","current max accuracy\t test set:26.17%\t train set:32.08%\n","Epoch:3/50     Step:1|6   loss:1.0691617727279663  \n","Epoch:3/50     Step:2|6   loss:1.0219320058822632  \n","Epoch:3/50     Step:3|6   loss:1.0801783800125122  \n","Epoch:3/50     Step:4|6   loss:1.0160117149353027  \n","Epoch:3/50     Step:5|6   loss:1.0887134075164795  \n","Epoch:3/50     Step:6|6   loss:1.086108684539795  \n","Epoch:3/50     Step:7|6   loss:1.0048338174819946  \n","Accuracy on test_set: 14.95 %\n","Accuracy on train_set: 21.31 %\n","current max accuracy\t test set:26.17%\t train set:32.08%\n","Epoch:4/50     Step:1|6   loss:1.0556453466415405  \n","Epoch:4/50     Step:2|6   loss:1.0350605249404907  \n","Epoch:4/50     Step:3|6   loss:1.0496834516525269  \n","Epoch:4/50     Step:4|6   loss:1.0346630811691284  \n","Epoch:4/50     Step:5|6   loss:1.0210388898849487  \n","Epoch:4/50     Step:6|6   loss:1.0077917575836182  \n","Epoch:4/50     Step:7|6   loss:0.96719890832901  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 25.53 %\n","current max accuracy\t test set:26.17%\t train set:32.08%\n","Epoch:5/50     Step:1|6   loss:1.0359516143798828  \n","Epoch:5/50     Step:2|6   loss:1.018148422241211  \n","Epoch:5/50     Step:3|6   loss:0.9926379919052124  \n","Epoch:5/50     Step:4|6   loss:0.9846781492233276  \n","Epoch:5/50     Step:5|6   loss:1.005637526512146  \n","Epoch:5/50     Step:6|6   loss:0.9716640114784241  \n","Epoch:5/50     Step:7|6   loss:0.9895930886268616  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 63.70 %\n","current max accuracy\t test set:64.49%\t train set:63.7%\n","Epoch:6/50     Step:1|6   loss:0.9712250232696533  \n","Epoch:6/50     Step:2|6   loss:0.9618847966194153  \n","Epoch:6/50     Step:3|6   loss:0.9708114862442017  \n","Epoch:6/50     Step:4|6   loss:0.980512797832489  \n","Epoch:6/50     Step:5|6   loss:1.0171024799346924  \n","Epoch:6/50     Step:6|6   loss:0.9653398990631104  \n","Epoch:6/50     Step:7|6   loss:0.9635354280471802  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 76.11 %\n","current max accuracy\t test set:73.83%\t train set:76.11%\n","Epoch:7/50     Step:1|6   loss:0.9661712646484375  \n","Epoch:7/50     Step:2|6   loss:0.9553461074829102  \n","Epoch:7/50     Step:3|6   loss:0.9697458744049072  \n","Epoch:7/50     Step:4|6   loss:0.93924880027771  \n","Epoch:7/50     Step:5|6   loss:0.9467434883117676  \n","Epoch:7/50     Step:6|6   loss:0.9374210238456726  \n","Epoch:7/50     Step:7|6   loss:0.9525118470191956  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 77.52 %\n","current max accuracy\t test set:74.77%\t train set:77.52%\n","Epoch:8/50     Step:1|6   loss:0.9324803352355957  \n","Epoch:8/50     Step:2|6   loss:0.9516478180885315  \n","Epoch:8/50     Step:3|6   loss:0.9397256970405579  \n","Epoch:8/50     Step:4|6   loss:0.9365598559379578  \n","Epoch:8/50     Step:5|6   loss:0.9437878727912903  \n","Epoch:8/50     Step:6|6   loss:0.9378731846809387  \n","Epoch:8/50     Step:7|6   loss:0.9141418933868408  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 73.30 %\n","current max accuracy\t test set:74.77%\t train set:77.52%\n","Epoch:9/50     Step:1|6   loss:0.910576581954956  \n","Epoch:9/50     Step:2|6   loss:0.8990093469619751  \n","Epoch:9/50     Step:3|6   loss:0.8974412083625793  \n","Epoch:9/50     Step:4|6   loss:0.9169058203697205  \n","Epoch:9/50     Step:5|6   loss:0.9124407172203064  \n","Epoch:9/50     Step:6|6   loss:0.8668053150177002  \n","Epoch:9/50     Step:7|6   loss:0.9393683075904846  \n","Accuracy on test_set: 71.96 %\n","Accuracy on train_set: 70.02 %\n","current max accuracy\t test set:74.77%\t train set:77.52%\n","Epoch:10/50     Step:1|6   loss:0.876284122467041  \n","Epoch:10/50     Step:2|6   loss:0.8578610420227051  \n","Epoch:10/50     Step:3|6   loss:0.896199107170105  \n","Epoch:10/50     Step:4|6   loss:0.8844014406204224  \n","Epoch:10/50     Step:5|6   loss:0.8921575546264648  \n","Epoch:10/50     Step:6|6   loss:0.9268505573272705  \n","Epoch:10/50     Step:7|6   loss:0.84670490026474  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:85.05%\t train set:86.18%\n","Epoch:11/50     Step:1|6   loss:0.8588412404060364  \n","Epoch:11/50     Step:2|6   loss:0.8900870084762573  \n","Epoch:11/50     Step:3|6   loss:0.8741812705993652  \n","Epoch:11/50     Step:4|6   loss:0.8615819811820984  \n","Epoch:11/50     Step:5|6   loss:0.8693863153457642  \n","Epoch:11/50     Step:6|6   loss:0.8306756019592285  \n","Epoch:11/50     Step:7|6   loss:0.8124097585678101  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:86.92%\t train set:88.52%\n","Epoch:12/50     Step:1|6   loss:0.8038427233695984  \n","Epoch:12/50     Step:2|6   loss:0.8332395553588867  \n","Epoch:12/50     Step:3|6   loss:0.8775013089179993  \n","Epoch:12/50     Step:4|6   loss:0.8348625302314758  \n","Epoch:12/50     Step:5|6   loss:0.8395678997039795  \n","Epoch:12/50     Step:6|6   loss:0.8461299538612366  \n","Epoch:12/50     Step:7|6   loss:0.7849016785621643  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:13/50     Step:1|6   loss:0.8374884128570557  \n","Epoch:13/50     Step:2|6   loss:0.8193354606628418  \n","Epoch:13/50     Step:3|6   loss:0.8254438638687134  \n","Epoch:13/50     Step:4|6   loss:0.80311119556427  \n","Epoch:13/50     Step:5|6   loss:0.843336284160614  \n","Epoch:13/50     Step:6|6   loss:0.7946712374687195  \n","Epoch:13/50     Step:7|6   loss:0.8045049905776978  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:14/50     Step:1|6   loss:0.7702060341835022  \n","Epoch:14/50     Step:2|6   loss:0.8364677429199219  \n","Epoch:14/50     Step:3|6   loss:0.8139160871505737  \n","Epoch:14/50     Step:4|6   loss:0.8212579488754272  \n","Epoch:14/50     Step:5|6   loss:0.7938324809074402  \n","Epoch:14/50     Step:6|6   loss:0.8209460973739624  \n","Epoch:14/50     Step:7|6   loss:0.804153561592102  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:91.59%\t train set:94.38%\n","Epoch:15/50     Step:1|6   loss:0.8417761325836182  \n","Epoch:15/50     Step:2|6   loss:0.8030195236206055  \n","Epoch:15/50     Step:3|6   loss:0.8132449388504028  \n","Epoch:15/50     Step:4|6   loss:0.8067026734352112  \n","Epoch:15/50     Step:5|6   loss:0.7893792390823364  \n","Epoch:15/50     Step:6|6   loss:0.7798581123352051  \n","Epoch:15/50     Step:7|6   loss:0.8243977427482605  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:97.2%\t train set:95.55%\n","Epoch:16/50     Step:1|6   loss:0.781901478767395  \n","Epoch:16/50     Step:2|6   loss:0.7799482345581055  \n","Epoch:16/50     Step:3|6   loss:0.790541410446167  \n","Epoch:16/50     Step:4|6   loss:0.7739548087120056  \n","Epoch:16/50     Step:5|6   loss:0.7898021936416626  \n","Epoch:16/50     Step:6|6   loss:0.8158658742904663  \n","Epoch:16/50     Step:7|6   loss:0.8471266031265259  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:17/50     Step:1|6   loss:0.7670234441757202  \n","Epoch:17/50     Step:2|6   loss:0.7695200443267822  \n","Epoch:17/50     Step:3|6   loss:0.8108453750610352  \n","Epoch:17/50     Step:4|6   loss:0.801543116569519  \n","Epoch:17/50     Step:5|6   loss:0.8069571852684021  \n","Epoch:17/50     Step:6|6   loss:0.7771555185317993  \n","Epoch:17/50     Step:7|6   loss:0.722058892250061  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:18/50     Step:1|6   loss:0.7819024920463562  \n","Epoch:18/50     Step:2|6   loss:0.746213436126709  \n","Epoch:18/50     Step:3|6   loss:0.7670139074325562  \n","Epoch:18/50     Step:4|6   loss:0.8135684132575989  \n","Epoch:18/50     Step:5|6   loss:0.7668357491493225  \n","Epoch:18/50     Step:6|6   loss:0.7614234685897827  \n","Epoch:18/50     Step:7|6   loss:0.7586130499839783  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:97.2%\t train set:95.78%\n","Epoch:19/50     Step:1|6   loss:0.7254468202590942  \n","Epoch:19/50     Step:2|6   loss:0.760546863079071  \n","Epoch:19/50     Step:3|6   loss:0.7790008783340454  \n","Epoch:19/50     Step:4|6   loss:0.765016496181488  \n","Epoch:19/50     Step:5|6   loss:0.7587343454360962  \n","Epoch:19/50     Step:6|6   loss:0.7750022411346436  \n","Epoch:19/50     Step:7|6   loss:0.8159099817276001  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:20/50     Step:1|6   loss:0.7737473249435425  \n","Epoch:20/50     Step:2|6   loss:0.789668083190918  \n","Epoch:20/50     Step:3|6   loss:0.7445846199989319  \n","Epoch:20/50     Step:4|6   loss:0.7209752798080444  \n","Epoch:20/50     Step:5|6   loss:0.769091010093689  \n","Epoch:20/50     Step:6|6   loss:0.7940582036972046  \n","Epoch:20/50     Step:7|6   loss:0.7588075399398804  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:21/50     Step:1|6   loss:0.7915934324264526  \n","Epoch:21/50     Step:2|6   loss:0.7462469339370728  \n","Epoch:21/50     Step:3|6   loss:0.7753303050994873  \n","Epoch:21/50     Step:4|6   loss:0.8105508089065552  \n","Epoch:21/50     Step:5|6   loss:0.7615581154823303  \n","Epoch:21/50     Step:6|6   loss:0.7714354991912842  \n","Epoch:21/50     Step:7|6   loss:0.7884816527366638  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:98.13%\t train set:96.02%\n","Epoch:22/50     Step:1|6   loss:0.7520161271095276  \n","Epoch:22/50     Step:2|6   loss:0.7536357045173645  \n","Epoch:22/50     Step:3|6   loss:0.7675350904464722  \n","Epoch:22/50     Step:4|6   loss:0.743131697177887  \n","Epoch:22/50     Step:5|6   loss:0.7637070417404175  \n","Epoch:22/50     Step:6|6   loss:0.7873109579086304  \n","Epoch:22/50     Step:7|6   loss:0.7195137739181519  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:23/50     Step:1|6   loss:0.7221463918685913  \n","Epoch:23/50     Step:2|6   loss:0.769060492515564  \n","Epoch:23/50     Step:3|6   loss:0.7825863361358643  \n","Epoch:23/50     Step:4|6   loss:0.7379148006439209  \n","Epoch:23/50     Step:5|6   loss:0.7517043948173523  \n","Epoch:23/50     Step:6|6   loss:0.7787466049194336  \n","Epoch:23/50     Step:7|6   loss:0.7611987590789795  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:24/50     Step:1|6   loss:0.7714188098907471  \n","Epoch:24/50     Step:2|6   loss:0.8010284900665283  \n","Epoch:24/50     Step:3|6   loss:0.7556585073471069  \n","Epoch:24/50     Step:4|6   loss:0.7132675051689148  \n","Epoch:24/50     Step:5|6   loss:0.7528499364852905  \n","Epoch:24/50     Step:6|6   loss:0.7601211071014404  \n","Epoch:24/50     Step:7|6   loss:0.7362517714500427  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:25/50     Step:1|6   loss:0.709206223487854  \n","Epoch:25/50     Step:2|6   loss:0.76728355884552  \n","Epoch:25/50     Step:3|6   loss:0.760415256023407  \n","Epoch:25/50     Step:4|6   loss:0.7221736907958984  \n","Epoch:25/50     Step:5|6   loss:0.7676233053207397  \n","Epoch:25/50     Step:6|6   loss:0.7513262033462524  \n","Epoch:25/50     Step:7|6   loss:0.7956643104553223  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:26/50     Step:1|6   loss:0.7343906164169312  \n","Epoch:26/50     Step:2|6   loss:0.7446198463439941  \n","Epoch:26/50     Step:3|6   loss:0.7313795685768127  \n","Epoch:26/50     Step:4|6   loss:0.7414460182189941  \n","Epoch:26/50     Step:5|6   loss:0.7414165735244751  \n","Epoch:26/50     Step:6|6   loss:0.7634516358375549  \n","Epoch:26/50     Step:7|6   loss:0.8047083020210266  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:27/50     Step:1|6   loss:0.7547593712806702  \n","Epoch:27/50     Step:2|6   loss:0.7260891795158386  \n","Epoch:27/50     Step:3|6   loss:0.7386114001274109  \n","Epoch:27/50     Step:4|6   loss:0.7933911085128784  \n","Epoch:27/50     Step:5|6   loss:0.707760214805603  \n","Epoch:27/50     Step:6|6   loss:0.7365036010742188  \n","Epoch:27/50     Step:7|6   loss:0.7901846170425415  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:28/50     Step:1|6   loss:0.7499551773071289  \n","Epoch:28/50     Step:2|6   loss:0.7704719305038452  \n","Epoch:28/50     Step:3|6   loss:0.7665897607803345  \n","Epoch:28/50     Step:4|6   loss:0.740310788154602  \n","Epoch:28/50     Step:5|6   loss:0.7673192024230957  \n","Epoch:28/50     Step:6|6   loss:0.7060748338699341  \n","Epoch:28/50     Step:7|6   loss:0.8298131823539734  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:29/50     Step:1|6   loss:0.7821969985961914  \n","Epoch:29/50     Step:2|6   loss:0.7551150321960449  \n","Epoch:29/50     Step:3|6   loss:0.772519052028656  \n","Epoch:29/50     Step:4|6   loss:0.7708542346954346  \n","Epoch:29/50     Step:5|6   loss:0.7512747049331665  \n","Epoch:29/50     Step:6|6   loss:0.7166751623153687  \n","Epoch:29/50     Step:7|6   loss:0.77467942237854  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","3Epoch:30/50     Step:1|6   loss:0.7672381401062012  \n","Epoch:30/50     Step:2|6   loss:0.7590675950050354  \n","Epoch:30/50     Step:3|6   loss:0.7593915462493896  \n","Epoch:30/50     Step:4|6   loss:0.7579035758972168  \n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:30/50     Step:5|6   loss:0.7579248547554016  \n","Epoch:30/50     Step:6|6   loss:0.7366268634796143  \n","Epoch:30/50     Step:7|6   loss:0.7650353908538818  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:31/50     Step:1|6   loss:0.7247921228408813  \n","Epoch:31/50     Step:2|6   loss:0.7312098741531372  \n","Epoch:31/50     Step:3|6   loss:0.7683289051055908  \n","Epoch:31/50     Step:4|6   loss:0.7676550149917603  \n","Epoch:31/50     Step:5|6   loss:0.7713707089424133  \n","Epoch:31/50     Step:6|6   loss:0.7033676505088806  \n","Epoch:31/50     Step:7|6   loss:0.7605105638504028  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:32/50     Step:1|6   loss:0.7626099586486816  \n","Epoch:32/50     Step:2|6   loss:0.7363113164901733  \n","Epoch:32/50     Step:3|6   loss:0.7524495124816895  \n","Epoch:32/50     Step:4|6   loss:0.7443579435348511  \n","Epoch:32/50     Step:5|6   loss:0.7155216932296753  \n","Epoch:32/50     Step:6|6   loss:0.707166314125061  \n","Epoch:32/50     Step:7|6   loss:0.7752021551132202  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:33/50     Step:1|6   loss:0.6977382898330688  \n","Epoch:33/50     Step:2|6   loss:0.7620525360107422  \n","Epoch:33/50     Step:3|6   loss:0.7930519580841064  \n","Epoch:33/50     Step:4|6   loss:0.7511482238769531  \n","Epoch:33/50     Step:5|6   loss:0.7827520966529846  \n","Epoch:33/50     Step:6|6   loss:0.7048552632331848  \n","Epoch:33/50     Step:7|6   loss:0.7076818943023682  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 75.64 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:34/50     Step:1|6   loss:0.7141216993331909  \n","Epoch:34/50     Step:2|6   loss:0.7226290702819824  \n","Epoch:34/50     Step:3|6   loss:0.7153110504150391  \n","Epoch:34/50     Step:4|6   loss:0.7631603479385376  \n","Epoch:34/50     Step:5|6   loss:0.7764468193054199  \n","Epoch:34/50     Step:6|6   loss:0.7272287607192993  \n","Epoch:34/50     Step:7|6   loss:0.7570343613624573  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:35/50     Step:1|6   loss:0.7312594652175903  \n","Epoch:35/50     Step:2|6   loss:0.7638370990753174  \n","Epoch:35/50     Step:3|6   loss:0.8437876105308533  \n","Epoch:35/50     Step:4|6   loss:0.7562470436096191  \n","Epoch:35/50     Step:5|6   loss:0.7615399956703186  \n","Epoch:35/50     Step:6|6   loss:0.7826137542724609  \n","Epoch:35/50     Step:7|6   loss:0.6847084760665894  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:36/50     Step:1|6   loss:0.7627571225166321  \n","Epoch:36/50     Step:2|6   loss:0.7134920358657837  \n","Epoch:36/50     Step:3|6   loss:0.7614635229110718  \n","Epoch:36/50     Step:4|6   loss:0.797014594078064  \n","Epoch:36/50     Step:5|6   loss:0.7657172679901123  \n","Epoch:36/50     Step:6|6   loss:0.7364340424537659  \n","Epoch:36/50     Step:7|6   loss:0.778484582901001  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:37/50     Step:1|6   loss:0.7674403190612793  \n","Epoch:37/50     Step:2|6   loss:0.7757854461669922  \n","Epoch:37/50     Step:3|6   loss:0.7206284999847412  \n","Epoch:37/50     Step:4|6   loss:0.7999114394187927  \n","Epoch:37/50     Step:5|6   loss:0.710940957069397  \n","Epoch:37/50     Step:6|6   loss:0.7167513966560364  \n","Epoch:37/50     Step:7|6   loss:0.7006024122238159  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:38/50     Step:1|6   loss:0.7474253177642822  \n","Epoch:38/50     Step:2|6   loss:0.7526364326477051  \n","Epoch:38/50     Step:3|6   loss:0.6994914412498474  \n","Epoch:38/50     Step:4|6   loss:0.8008830547332764  \n","Epoch:38/50     Step:5|6   loss:0.725784420967102  \n","Epoch:38/50     Step:6|6   loss:0.7419167757034302  \n","Epoch:38/50     Step:7|6   loss:0.775383472442627  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:39/50     Step:1|6   loss:0.7346225380897522  \n","Epoch:39/50     Step:2|6   loss:0.7257657647132874  \n","Epoch:39/50     Step:3|6   loss:0.7299990653991699  \n","Epoch:39/50     Step:4|6   loss:0.7329128384590149  \n","Epoch:39/50     Step:5|6   loss:0.6918668746948242  \n","Epoch:39/50     Step:6|6   loss:0.7781217098236084  \n","Epoch:39/50     Step:7|6   loss:0.7427340745925903  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:40/50     Step:1|6   loss:0.7619454860687256  \n","Epoch:40/50     Step:2|6   loss:0.7095175981521606  \n","Epoch:40/50     Step:3|6   loss:0.7245277166366577  \n","Epoch:40/50     Step:4|6   loss:0.7551933526992798  \n","Epoch:40/50     Step:5|6   loss:0.7630581855773926  \n","Epoch:40/50     Step:6|6   loss:0.7324920892715454  \n","Epoch:40/50     Step:7|6   loss:0.7386126518249512  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:41/50     Step:1|6   loss:0.7769970297813416  \n","Epoch:41/50     Step:2|6   loss:0.7309004068374634  \n","Epoch:41/50     Step:3|6   loss:0.7003399133682251  \n","Epoch:41/50     Step:4|6   loss:0.7036391496658325  \n","Epoch:41/50     Step:5|6   loss:0.7332431077957153  \n","Epoch:41/50     Step:6|6   loss:0.7462748289108276  \n","Epoch:41/50     Step:7|6   loss:0.6949046850204468  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:42/50     Step:1|6   loss:0.720621645450592  \n","Epoch:42/50     Step:2|6   loss:0.7201019525527954  \n","Epoch:42/50     Step:3|6   loss:0.77314293384552  \n","Epoch:42/50     Step:4|6   loss:0.7006741762161255  \n","Epoch:42/50     Step:5|6   loss:0.7451616525650024  \n","Epoch:42/50     Step:6|6   loss:0.7860586643218994  \n","Epoch:42/50     Step:7|6   loss:0.6932936310768127  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:43/50     Step:1|6   loss:0.730642557144165  \n","Epoch:43/50     Step:2|6   loss:0.7391666173934937  \n","Epoch:43/50     Step:3|6   loss:0.7903512716293335  \n","Epoch:43/50     Step:4|6   loss:0.6960690021514893  \n","Epoch:43/50     Step:5|6   loss:0.7808298468589783  \n","Epoch:43/50     Step:6|6   loss:0.7225250005722046  \n","Epoch:43/50     Step:7|6   loss:0.7256604433059692  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:44/50     Step:1|6   loss:0.7540021538734436  \n","Epoch:44/50     Step:2|6   loss:0.7123165130615234  \n","Epoch:44/50     Step:3|6   loss:0.7526022791862488  \n","Epoch:44/50     Step:4|6   loss:0.7614675760269165  \n","Epoch:44/50     Step:5|6   loss:0.7228509187698364  \n","Epoch:44/50     Step:6|6   loss:0.729461669921875  \n","Epoch:44/50     Step:7|6   loss:0.7938649654388428  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:45/50     Step:1|6   loss:0.7240422964096069  \n","Epoch:45/50     Step:2|6   loss:0.7731397151947021  \n","Epoch:45/50     Step:3|6   loss:0.7257851362228394  \n","Epoch:45/50     Step:4|6   loss:0.7274718880653381  \n","Epoch:45/50     Step:5|6   loss:0.7385041117668152  \n","Epoch:45/50     Step:6|6   loss:0.7098180055618286  \n","Epoch:45/50     Step:7|6   loss:0.7318216562271118  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:46/50     Step:1|6   loss:0.7370681762695312  \n","Epoch:46/50     Step:2|6   loss:0.7002320289611816  \n","Epoch:46/50     Step:3|6   loss:0.7193043231964111  \n","Epoch:46/50     Step:4|6   loss:0.7725231647491455  \n","Epoch:46/50     Step:5|6   loss:0.6781258583068848  \n","Epoch:46/50     Step:6|6   loss:0.7342180013656616  \n","Epoch:46/50     Step:7|6   loss:0.6921234130859375  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 75.41 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:47/50     Step:1|6   loss:0.7036228179931641  \n","Epoch:47/50     Step:2|6   loss:0.779254674911499  \n","Epoch:47/50     Step:3|6   loss:0.7809442281723022  \n","Epoch:47/50     Step:4|6   loss:0.7480021715164185  \n","Epoch:47/50     Step:5|6   loss:0.7402053475379944  \n","Epoch:47/50     Step:6|6   loss:0.7671763896942139  \n","Epoch:47/50     Step:7|6   loss:0.6667871475219727  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:48/50     Step:1|6   loss:0.7065192461013794  \n","Epoch:48/50     Step:2|6   loss:0.7586137056350708  \n","Epoch:48/50     Step:3|6   loss:0.7065232992172241  \n","Epoch:48/50     Step:4|6   loss:0.6766488552093506  \n","Epoch:48/50     Step:5|6   loss:0.755548357963562  \n","Epoch:48/50     Step:6|6   loss:0.7203853130340576  \n","Epoch:48/50     Step:7|6   loss:0.7249428629875183  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:49/50     Step:1|6   loss:0.724871814250946  \n","Epoch:49/50     Step:2|6   loss:0.7362672090530396  \n","Epoch:49/50     Step:3|6   loss:0.7429428100585938  \n","Epoch:49/50     Step:4|6   loss:0.7751219272613525  \n","Epoch:49/50     Step:5|6   loss:0.6799832582473755  \n","Epoch:49/50     Step:6|6   loss:0.7266018390655518  \n","Epoch:49/50     Step:7|6   loss:0.7929263114929199  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:50/50     Step:1|6   loss:0.73787522315979  \n","Epoch:50/50     Step:2|6   loss:0.7168803215026855  \n","Epoch:50/50     Step:3|6   loss:0.722326397895813  \n","Epoch:50/50     Step:4|6   loss:0.7332363128662109  \n","Epoch:50/50     Step:5|6   loss:0.7348393201828003  \n","Epoch:50/50     Step:6|6   loss:0.7291476726531982  \n","Epoch:50/50     Step:7|6   loss:0.7192296981811523  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Accuracy on test_set: 97.20 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_two_stream(\n","  (stream1): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (stream2): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=16, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.2027884721755981  \n","Epoch:1/50     Step:2|6   loss:1.1401880979537964  \n","Epoch:1/50     Step:3|6   loss:1.179048776626587  \n","Epoch:1/50     Step:4|6   loss:1.0819683074951172  \n","Epoch:1/50     Step:5|6   loss:1.1331321001052856  \n","Epoch:1/50     Step:6|6   loss:1.1050753593444824  \n","Epoch:1/50     Step:7|6   loss:1.0429317951202393  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 45.67 %\n","current max accuracy\t test set:50.47%\t train set:45.67%\n","Epoch:2/50     Step:1|6   loss:1.0567177534103394  \n","Epoch:2/50     Step:2|6   loss:1.0728018283843994  \n","Epoch:2/50     Step:3|6   loss:1.0471620559692383  \n","Epoch:2/50     Step:4|6   loss:1.071276307106018  \n","Epoch:2/50     Step:5|6   loss:1.0863635540008545  \n","Epoch:2/50     Step:6|6   loss:1.0774970054626465  \n","Epoch:2/50     Step:7|6   loss:1.0615770816802979  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 45.67 %\n","current max accuracy\t test set:50.47%\t train set:45.67%\n","Epoch:3/50     Step:1|6   loss:1.01162588596344  \n","Epoch:3/50     Step:2|6   loss:1.0257773399353027  \n","Epoch:3/50     Step:3|6   loss:0.9488111734390259  \n","Epoch:3/50     Step:4|6   loss:1.0127407312393188  \n","Epoch:3/50     Step:5|6   loss:1.0054879188537598  \n","Epoch:3/50     Step:6|6   loss:1.0530585050582886  \n","Epoch:3/50     Step:7|6   loss:0.9830251932144165  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 45.67 %\n","current max accuracy\t test set:50.47%\t train set:45.67%\n","Epoch:4/50     Step:1|6   loss:1.0216951370239258  \n","Epoch:4/50     Step:2|6   loss:1.0096304416656494  \n","Epoch:4/50     Step:3|6   loss:0.9837856888771057  \n","Epoch:4/50     Step:4|6   loss:0.9719064831733704  \n","Epoch:4/50     Step:5|6   loss:0.9944339394569397  \n","Epoch:4/50     Step:6|6   loss:0.9832981824874878  \n","Epoch:4/50     Step:7|6   loss:0.9720906615257263  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 45.67 %\n","current max accuracy\t test set:50.47%\t train set:45.67%\n","Epoch:5/50     Step:1|6   loss:0.9630709886550903  \n","Epoch:5/50     Step:2|6   loss:0.9701945185661316  \n","Epoch:5/50     Step:3|6   loss:0.9437538385391235  \n","Epoch:5/50     Step:4|6   loss:0.996338427066803  \n","Epoch:5/50     Step:5|6   loss:0.9643611907958984  \n","Epoch:5/50     Step:6|6   loss:0.9564218521118164  \n","Epoch:5/50     Step:7|6   loss:0.9376349449157715  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 45.67 %\n","current max accuracy\t test set:50.47%\t train set:45.67%\n","Epoch:6/50     Step:1|6   loss:0.9309736490249634  \n","Epoch:6/50     Step:2|6   loss:0.9694743752479553  \n","Epoch:6/50     Step:3|6   loss:0.9598596096038818  \n","Epoch:6/50     Step:4|6   loss:0.9252266883850098  \n","Epoch:6/50     Step:5|6   loss:0.9294350743293762  \n","Epoch:6/50     Step:6|6   loss:0.9304230213165283  \n","Epoch:6/50     Step:7|6   loss:0.9829149842262268  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 45.67 %\n","current max accuracy\t test set:50.47%\t train set:45.67%\n","Epoch:7/50     Step:1|6   loss:0.9046218991279602  \n","Epoch:7/50     Step:2|6   loss:0.9144334197044373  \n","Epoch:7/50     Step:3|6   loss:0.8729621767997742  \n","Epoch:7/50     Step:4|6   loss:0.9194105863571167  \n","Epoch:7/50     Step:5|6   loss:0.8929505348205566  \n","Epoch:7/50     Step:6|6   loss:0.8935201168060303  \n","Epoch:7/50     Step:7|6   loss:0.9001320600509644  \n","Accuracy on test_set: 56.07 %\n","Accuracy on train_set: 51.52 %\n","current max accuracy\t test set:56.07%\t train set:51.52%\n","Epoch:8/50     Step:1|6   loss:0.9241695404052734  \n","Epoch:8/50     Step:2|6   loss:0.9217015504837036  \n","Epoch:8/50     Step:3|6   loss:0.8606277704238892  \n","Epoch:8/50     Step:4|6   loss:0.8547878861427307  \n","Epoch:8/50     Step:5|6   loss:0.8870395421981812  \n","Epoch:8/50     Step:6|6   loss:0.8715081214904785  \n","Epoch:8/50     Step:7|6   loss:0.8751105666160583  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:89.72%\t train set:88.99%\n","Epoch:9/50     Step:1|6   loss:0.8427390456199646  \n","Epoch:9/50     Step:2|6   loss:0.9031782150268555  \n","Epoch:9/50     Step:3|6   loss:0.8830392360687256  \n","Epoch:9/50     Step:4|6   loss:0.8785085678100586  \n","Epoch:9/50     Step:5|6   loss:0.9149346351623535  \n","Epoch:9/50     Step:6|6   loss:0.8570858240127563  \n","Epoch:9/50     Step:7|6   loss:0.8372738361358643  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:90.65%\t train set:90.16%\n","Epoch:10/50     Step:1|6   loss:0.8965493440628052  \n","Epoch:10/50     Step:2|6   loss:0.8891918063163757  \n","Epoch:10/50     Step:3|6   loss:0.8695994019508362  \n","Epoch:10/50     Step:4|6   loss:0.8497402667999268  \n","Epoch:10/50     Step:5|6   loss:0.8761913776397705  \n","Epoch:10/50     Step:6|6   loss:0.8689308166503906  \n","Epoch:10/50     Step:7|6   loss:0.8756917715072632  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:90.65%\t train set:91.8%\n","Epoch:11/50     Step:1|6   loss:0.8383774161338806  \n","Epoch:11/50     Step:2|6   loss:0.8292187452316284  \n","Epoch:11/50     Step:3|6   loss:0.8437701463699341  \n","Epoch:11/50     Step:4|6   loss:0.8638003468513489  \n","Epoch:11/50     Step:5|6   loss:0.8270667791366577  \n","Epoch:11/50     Step:6|6   loss:0.8468413949012756  \n","Epoch:11/50     Step:7|6   loss:0.8659536242485046  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:92.52%\t train set:95.32%\n","Epoch:12/50     Step:1|6   loss:0.8287925720214844  \n","Epoch:12/50     Step:2|6   loss:0.8469983339309692  \n","Epoch:12/50     Step:3|6   loss:0.8665387630462646  \n","Epoch:12/50     Step:4|6   loss:0.8281590342521667  \n","Epoch:12/50     Step:5|6   loss:0.76542729139328  \n","Epoch:12/50     Step:6|6   loss:0.8261926174163818  \n","Epoch:12/50     Step:7|6   loss:0.8683231472969055  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:96.26%\t train set:96.49%\n","Epoch:13/50     Step:1|6   loss:0.7949349880218506  \n","Epoch:13/50     Step:2|6   loss:0.7808557748794556  \n","Epoch:13/50     Step:3|6   loss:0.7753316760063171  \n","Epoch:13/50     Step:4|6   loss:0.8368052840232849  \n","Epoch:13/50     Step:5|6   loss:0.8221957683563232  \n","Epoch:13/50     Step:6|6   loss:0.7907048463821411  \n","Epoch:13/50     Step:7|6   loss:0.8067773580551147  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:96.26%\t train set:96.49%\n","Epoch:14/50     Step:1|6   loss:0.8071639537811279  \n","Epoch:14/50     Step:2|6   loss:0.8065319657325745  \n","Epoch:14/50     Step:3|6   loss:0.8354506492614746  \n","Epoch:14/50     Step:4|6   loss:0.7287549376487732  \n","Epoch:14/50     Step:5|6   loss:0.8509621620178223  \n","Epoch:14/50     Step:6|6   loss:0.7793757915496826  \n","Epoch:14/50     Step:7|6   loss:0.7710531949996948  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:96.26%\t train set:96.49%\n","Epoch:15/50     Step:1|6   loss:0.8316364288330078  \n","Epoch:15/50     Step:2|6   loss:0.836288571357727  \n","Epoch:15/50     Step:3|6   loss:0.8215848207473755  \n","Epoch:15/50     Step:4|6   loss:0.8294651508331299  \n","Epoch:15/50     Step:5|6   loss:0.8733580112457275  \n","Epoch:15/50     Step:6|6   loss:0.8565000891685486  \n","Epoch:15/50     Step:7|6   loss:0.7988343834877014  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:16/50     Step:1|6   loss:0.7954879999160767  \n","Epoch:16/50     Step:2|6   loss:0.7424737215042114  \n","Epoch:16/50     Step:3|6   loss:0.8415130376815796  \n","Epoch:16/50     Step:4|6   loss:0.8003149628639221  \n","Epoch:16/50     Step:5|6   loss:0.7346565127372742  \n","Epoch:16/50     Step:6|6   loss:0.797751247882843  \n","Epoch:16/50     Step:7|6   loss:0.742853045463562  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:96.26%\t train set:96.72%\n","Epoch:17/50     Step:1|6   loss:0.822827160358429  \n","Epoch:17/50     Step:2|6   loss:0.7757452726364136  \n","Epoch:17/50     Step:3|6   loss:0.7853142619132996  \n","Epoch:17/50     Step:4|6   loss:0.7712748646736145  \n","Epoch:17/50     Step:5|6   loss:0.7374613285064697  \n","Epoch:17/50     Step:6|6   loss:0.7928720712661743  \n","Epoch:17/50     Step:7|6   loss:0.8049284815788269  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:18/50     Step:1|6   loss:0.7624965906143188  \n","Epoch:18/50     Step:2|6   loss:0.8216792345046997  \n","Epoch:18/50     Step:3|6   loss:0.817470908164978  \n","Epoch:18/50     Step:4|6   loss:0.8122923374176025  \n","Epoch:18/50     Step:5|6   loss:0.8264673352241516  \n","Epoch:18/50     Step:6|6   loss:0.7742518186569214  \n","Epoch:18/50     Step:7|6   loss:0.7539422512054443  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:19/50     Step:1|6   loss:0.784076988697052  \n","Epoch:19/50     Step:2|6   loss:0.7806743383407593  \n","Epoch:19/50     Step:3|6   loss:0.735843300819397  \n","Epoch:19/50     Step:4|6   loss:0.8216183185577393  \n","Epoch:19/50     Step:5|6   loss:0.7779909372329712  \n","Epoch:19/50     Step:6|6   loss:0.765691876411438  \n","Epoch:19/50     Step:7|6   loss:0.738706111907959  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:20/50     Step:1|6   loss:0.7601362466812134  \n","Epoch:20/50     Step:2|6   loss:0.7655915021896362  \n","Epoch:20/50     Step:3|6   loss:0.7924562692642212  \n","Epoch:20/50     Step:4|6   loss:0.7448149919509888  \n","Epoch:20/50     Step:5|6   loss:0.8101552724838257  \n","Epoch:20/50     Step:6|6   loss:0.8196092247962952  \n","Epoch:20/50     Step:7|6   loss:0.7504209280014038  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:97.2%\t train set:97.42%\n","Epoch:21/50     Step:1|6   loss:0.8073403239250183  \n","Epoch:21/50     Step:2|6   loss:0.7733167409896851  \n","Epoch:21/50     Step:3|6   loss:0.7636731863021851  \n","Epoch:21/50     Step:4|6   loss:0.7884271144866943  \n","Epoch:21/50     Step:5|6   loss:0.7872166037559509  \n","Epoch:21/50     Step:6|6   loss:0.7807444930076599  \n","Epoch:21/50     Step:7|6   loss:0.8184173703193665  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:97.2%\t train set:97.42%\n","Epoch:22/50     Step:1|6   loss:0.77006995677948  \n","Epoch:22/50     Step:2|6   loss:0.7584089040756226  \n","Epoch:22/50     Step:3|6   loss:0.7847902774810791  \n","Epoch:22/50     Step:4|6   loss:0.7978383898735046  \n","Epoch:22/50     Step:5|6   loss:0.8068671226501465  \n","Epoch:22/50     Step:6|6   loss:0.7538252472877502  \n","Epoch:22/50     Step:7|6   loss:0.7335450649261475  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:97.2%\t train set:97.42%\n","Epoch:23/50     Step:1|6   loss:0.7881259918212891  \n","Epoch:23/50     Step:2|6   loss:0.781340479850769  \n","Epoch:23/50     Step:3|6   loss:0.8097041249275208  \n","Epoch:23/50     Step:4|6   loss:0.7656964063644409  \n","Epoch:23/50     Step:5|6   loss:0.7538575530052185  \n","Epoch:23/50     Step:6|6   loss:0.7639726996421814  \n","Epoch:23/50     Step:7|6   loss:0.7079648971557617  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:97.2%\t train set:97.42%\n","Epoch:24/50     Step:1|6   loss:0.8315869569778442  \n","Epoch:24/50     Step:2|6   loss:0.7308764457702637  \n","Epoch:24/50     Step:3|6   loss:0.7619277834892273  \n","Epoch:24/50     Step:4|6   loss:0.7617545127868652  \n","Epoch:24/50     Step:5|6   loss:0.7627830505371094  \n","Epoch:24/50     Step:6|6   loss:0.7595242261886597  \n","Epoch:24/50     Step:7|6   loss:0.8036249876022339  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:97.2%\t train set:97.42%\n","Epoch:25/50     Step:1|6   loss:0.7901800870895386  \n","Epoch:25/50     Step:2|6   loss:0.7470389008522034  \n","Epoch:25/50     Step:3|6   loss:0.7463016510009766  \n","Epoch:25/50     Step:4|6   loss:0.7389196753501892  \n","Epoch:25/50     Step:5|6   loss:0.7184392809867859  \n","Epoch:25/50     Step:6|6   loss:0.7263175249099731  \n","Epoch:25/50     Step:7|6   loss:0.7071777582168579  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:26/50     Step:1|6   loss:0.7709891200065613  \n","Epoch:26/50     Step:2|6   loss:0.7544025778770447  \n","Epoch:26/50     Step:3|6   loss:0.7148543000221252  \n","Epoch:26/50     Step:4|6   loss:0.7459567785263062  \n","Epoch:26/50     Step:5|6   loss:0.7825266122817993  \n","Epoch:26/50     Step:6|6   loss:0.7462928295135498  \n","Epoch:26/50     Step:7|6   loss:0.7275535464286804  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:27/50     Step:1|6   loss:0.742027997970581  \n","Epoch:27/50     Step:2|6   loss:0.7157684564590454  \n","Epoch:27/50     Step:3|6   loss:0.7854650020599365  \n","Epoch:27/50     Step:4|6   loss:0.7477415800094604  \n","Epoch:27/50     Step:5|6   loss:0.7330111265182495  \n","Epoch:27/50     Step:6|6   loss:0.7201610803604126  \n","Epoch:27/50     Step:7|6   loss:0.754240870475769  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:28/50     Step:1|6   loss:0.729006290435791  \n","Epoch:28/50     Step:2|6   loss:0.7572953701019287  \n","Epoch:28/50     Step:3|6   loss:0.7900403738021851  \n","Epoch:28/50     Step:4|6   loss:0.7807544469833374  \n","Epoch:28/50     Step:5|6   loss:0.7492562532424927  \n","Epoch:28/50     Step:6|6   loss:0.7518123388290405  \n","Epoch:28/50     Step:7|6   loss:0.7996100783348083  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:29/50     Step:1|6   loss:0.7655922174453735  \n","Epoch:29/50     Step:2|6   loss:0.7533743381500244  \n","Epoch:29/50     Step:3|6   loss:0.7875272035598755  \n","Epoch:29/50     Step:4|6   loss:0.6732693910598755  \n","Epoch:29/50     Step:5|6   loss:0.7837786078453064  \n","Epoch:29/50     Step:6|6   loss:0.7683769464492798  \n","Epoch:29/50     Step:7|6   loss:0.6880416870117188  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:30/50     Step:1|6   loss:0.6993836164474487  \n","Epoch:30/50     Step:2|6   loss:0.725867748260498  \n","Epoch:30/50     Step:3|6   loss:0.768435001373291  \n","Epoch:30/50     Step:4|6   loss:0.763237714767456  \n","Epoch:30/50     Step:5|6   loss:0.7888286709785461  \n","Epoch:30/50     Step:6|6   loss:0.7510685324668884  \n","Epoch:30/50     Step:7|6   loss:0.7332453727722168  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:31/50     Step:1|6   loss:0.7740825414657593  \n","Epoch:31/50     Step:2|6   loss:0.733593225479126  \n","Epoch:31/50     Step:3|6   loss:0.7066426277160645  \n","Epoch:31/50     Step:4|6   loss:0.7810503244400024  \n","Epoch:31/50     Step:5|6   loss:0.7638078927993774  \n","Epoch:31/50     Step:6|6   loss:0.74498450756073  \n","Epoch:31/50     Step:7|6   loss:0.736447811126709  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:98.13%\t train set:97.66%\n","Epoch:32/50     Step:1|6   loss:0.7751240730285645  \n","Epoch:32/50     Step:2|6   loss:0.7721953392028809  \n","Epoch:32/50     Step:3|6   loss:0.760475218296051  \n","Epoch:32/50     Step:4|6   loss:0.7748076915740967  \n","Epoch:32/50     Step:5|6   loss:0.760626494884491  \n","Epoch:32/50     Step:6|6   loss:0.7448889017105103  \n","Epoch:32/50     Step:7|6   loss:0.7155232429504395  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:33/50     Step:1|6   loss:0.727706789970398  \n","Epoch:33/50     Step:2|6   loss:0.760586142539978  \n","Epoch:33/50     Step:3|6   loss:0.7644426226615906  \n","Epoch:33/50     Step:4|6   loss:0.6837679147720337  \n","Epoch:33/50     Step:5|6   loss:0.7202668190002441  \n","Epoch:33/50     Step:6|6   loss:0.710915207862854  \n","Epoch:33/50     Step:7|6   loss:0.7788386344909668  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:34/50     Step:1|6   loss:0.7319188117980957  \n","Epoch:34/50     Step:2|6   loss:0.757901668548584  \n","Epoch:34/50     Step:3|6   loss:0.7287272214889526  \n","Epoch:34/50     Step:4|6   loss:0.7599942684173584  \n","Epoch:34/50     Step:5|6   loss:0.7128134369850159  \n","Epoch:34/50     Step:6|6   loss:0.7738349437713623  \n","Epoch:34/50     Step:7|6   loss:0.7755576372146606  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:35/50     Step:1|6   loss:0.7605800032615662  \n","Epoch:35/50     Step:2|6   loss:0.7200459241867065  \n","Epoch:35/50     Step:3|6   loss:0.7699205875396729  \n","Epoch:35/50     Step:4|6   loss:0.7201581001281738  \n","Epoch:35/50     Step:5|6   loss:0.7374840974807739  \n","Epoch:35/50     Step:6|6   loss:0.6997184753417969  \n","Epoch:35/50     Step:7|6   loss:0.7778996229171753  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:36/50     Step:1|6   loss:0.7191344499588013  \n","Epoch:36/50     Step:2|6   loss:0.7852510213851929  \n","Epoch:36/50     Step:3|6   loss:0.7801063060760498  \n","Epoch:36/50     Step:4|6   loss:0.7502983808517456  \n","Epoch:36/50     Step:5|6   loss:0.7740210294723511  \n","Epoch:36/50     Step:6|6   loss:0.7504823207855225  \n","Epoch:36/50     Step:7|6   loss:0.7010511159896851  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:37/50     Step:1|6   loss:0.6959025859832764  \n","Epoch:37/50     Step:2|6   loss:0.7740774154663086  \n","Epoch:37/50     Step:3|6   loss:0.7364943623542786  \n","Epoch:37/50     Step:4|6   loss:0.6928044557571411  \n","Epoch:37/50     Step:5|6   loss:0.7530637979507446  \n","Epoch:37/50     Step:6|6   loss:0.7397336959838867  \n","Epoch:37/50     Step:7|6   loss:0.7549439072608948  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:38/50     Step:1|6   loss:0.7567422986030579  \n","Epoch:38/50     Step:2|6   loss:0.7770794630050659  \n","Epoch:38/50     Step:3|6   loss:0.7279360890388489  \n","Epoch:38/50     Step:4|6   loss:0.7331513166427612  \n","Epoch:38/50     Step:5|6   loss:0.7533142566680908  \n","Epoch:38/50     Step:6|6   loss:0.7926418781280518  \n","Epoch:38/50     Step:7|6   loss:0.7966386079788208  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:39/50     Step:1|6   loss:0.7326184511184692  \n","Epoch:39/50     Step:2|6   loss:0.7660781145095825  \n","Epoch:39/50     Step:3|6   loss:0.7428449988365173  \n","Epoch:39/50     Step:4|6   loss:0.7601633071899414  \n","Epoch:39/50     Step:5|6   loss:0.7261199951171875  \n","Epoch:39/50     Step:6|6   loss:0.7457746267318726  \n","Epoch:39/50     Step:7|6   loss:0.7525987029075623  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:40/50     Step:1|6   loss:0.696634829044342  \n","Epoch:40/50     Step:2|6   loss:0.7858161926269531  \n","Epoch:40/50     Step:3|6   loss:0.7187268733978271  \n","Epoch:40/50     Step:4|6   loss:0.7157043218612671  \n","Epoch:40/50     Step:5|6   loss:0.7564737796783447  \n","Epoch:40/50     Step:6|6   loss:0.6977089643478394  \n","Epoch:40/50     Step:7|6   loss:0.7574756741523743  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:41/50     Step:1|6   loss:0.7582786083221436  \n","Epoch:41/50     Step:2|6   loss:0.643293023109436  \n","Epoch:41/50     Step:3|6   loss:0.7356038093566895  \n","Epoch:41/50     Step:4|6   loss:0.7446273565292358  \n","Epoch:41/50     Step:5|6   loss:0.75783371925354  \n","Epoch:41/50     Step:6|6   loss:0.7499014139175415  \n","Epoch:41/50     Step:7|6   loss:0.7163350582122803  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:42/50     Step:1|6   loss:0.7328798770904541  \n","Epoch:42/50     Step:2|6   loss:0.7165005207061768  \n","Epoch:42/50     Step:3|6   loss:0.7585974931716919  \n","Epoch:42/50     Step:4|6   loss:0.7615268230438232  \n","Epoch:42/50     Step:5|6   loss:0.7204704284667969  \n","Epoch:42/50     Step:6|6   loss:0.7570719122886658  \n","Epoch:42/50     Step:7|6   loss:0.7337415814399719  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:43/50     Step:1|6   loss:0.7359974384307861  \n","Epoch:43/50     Step:2|6   loss:0.7676628828048706  \n","Epoch:43/50     Step:3|6   loss:0.727853536605835  \n","Epoch:43/50     Step:4|6   loss:0.7713136672973633  \n","Epoch:43/50     Step:5|6   loss:0.7260776162147522  \n","Epoch:43/50     Step:6|6   loss:0.7820035219192505  \n","Epoch:43/50     Step:7|6   loss:0.7250493764877319  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:44/50     Step:1|6   loss:0.7638877630233765  \n","Epoch:44/50     Step:2|6   loss:0.7256479859352112  \n","Epoch:44/50     Step:3|6   loss:0.7286794781684875  \n","Epoch:44/50     Step:4|6   loss:0.759227454662323  \n","Epoch:44/50     Step:5|6   loss:0.6660708785057068  \n","Epoch:44/50     Step:6|6   loss:0.7326482534408569  \n","Epoch:44/50     Step:7|6   loss:0.7461932897567749  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:45/50     Step:1|6   loss:0.7116153240203857  \n","Epoch:45/50     Step:2|6   loss:0.6993836164474487  \n","Epoch:45/50     Step:3|6   loss:0.7432218790054321  \n","Epoch:45/50     Step:4|6   loss:0.7007735371589661  \n","Epoch:45/50     Step:5|6   loss:0.7701869010925293  \n","Epoch:45/50     Step:6|6   loss:0.7312651872634888  \n","Epoch:45/50     Step:7|6   loss:0.7409212589263916  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:46/50     Step:1|6   loss:0.7003437280654907  \n","Epoch:46/50     Step:2|6   loss:0.7665141820907593  \n","Epoch:46/50     Step:3|6   loss:0.719176709651947  \n","Epoch:46/50     Step:4|6   loss:0.7519080638885498  \n","Epoch:46/50     Step:5|6   loss:0.7571098804473877  \n","Epoch:46/50     Step:6|6   loss:0.732655942440033  \n","Epoch:46/50     Step:7|6   loss:0.764941930770874  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:47/50     Step:1|6   loss:0.7051210403442383  \n","Epoch:47/50     Step:2|6   loss:0.7527718544006348  \n","Epoch:47/50     Step:3|6   loss:0.670436441898346  \n","4Epoch:47/50     Step:4|6   loss:0.7198009490966797  \n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:47/50     Step:5|6   loss:0.759896993637085  \n","Epoch:47/50     Step:6|6   loss:0.756432056427002  \n","Epoch:47/50     Step:7|6   loss:0.7483088970184326  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:48/50     Step:1|6   loss:0.7803483009338379  \n","Epoch:48/50     Step:2|6   loss:0.7253292798995972  \n","Epoch:48/50     Step:3|6   loss:0.7599301338195801  \n","Epoch:48/50     Step:4|6   loss:0.7390023469924927  \n","Epoch:48/50     Step:5|6   loss:0.7561122179031372  \n","Epoch:48/50     Step:6|6   loss:0.7223982810974121  \n","Epoch:48/50     Step:7|6   loss:0.7694631814956665  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:49/50     Step:1|6   loss:0.7298868894577026  \n","Epoch:49/50     Step:2|6   loss:0.7453672885894775  \n","Epoch:49/50     Step:3|6   loss:0.7352755069732666  \n","Epoch:49/50     Step:4|6   loss:0.7635995149612427  \n","Epoch:49/50     Step:5|6   loss:0.6954028606414795  \n","Epoch:49/50     Step:6|6   loss:0.7553473114967346  \n","Epoch:49/50     Step:7|6   loss:0.7582089900970459  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Epoch:50/50     Step:1|6   loss:0.7610312104225159  \n","Epoch:50/50     Step:2|6   loss:0.7566989660263062  \n","Epoch:50/50     Step:3|6   loss:0.7458010911941528  \n","Epoch:50/50     Step:4|6   loss:0.8121867179870605  \n","Epoch:50/50     Step:5|6   loss:0.7398998737335205  \n","Epoch:50/50     Step:6|6   loss:0.7695433497428894  \n","Epoch:50/50     Step:7|6   loss:0.7406916618347168  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:99.07%\t train set:97.66%\n","Accuracy on test_set: 97.20 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.001, mode='both', model='Flame_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Flame_two_stream(\n","  (stream1): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (stream2): Flame(\n","    (IN): Sequential(\n","      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (IN_both): Sequential(\n","      (0): Conv2d(6, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (residual): Conv2d(8, 8, kernel_size=(1, 1), stride=(2, 2))\n","    (block): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU()\n","      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (block2): Sequential(\n","      (0): SeparableConv2d(\n","        (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n","        (pointwise): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=16, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0831729173660278  \n","Epoch:1/50     Step:2|6   loss:1.0573740005493164  \n","Epoch:1/50     Step:3|6   loss:1.0820609331130981  \n","Epoch:1/50     Step:4|6   loss:1.06299889087677  \n","Epoch:1/50     Step:5|6   loss:1.0619546175003052  \n","Epoch:1/50     Step:6|6   loss:1.056219458580017  \n","Epoch:1/50     Step:7|6   loss:1.052477478981018  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 28.57 %\n","current max accuracy\t test set:25.23%\t train set:28.57%\n","Epoch:2/50     Step:1|6   loss:1.0393327474594116  \n","Epoch:2/50     Step:2|6   loss:1.0649962425231934  \n","Epoch:2/50     Step:3|6   loss:1.0386734008789062  \n","Epoch:2/50     Step:4|6   loss:1.0230562686920166  \n","Epoch:2/50     Step:5|6   loss:0.9905774593353271  \n","Epoch:2/50     Step:6|6   loss:1.0154422521591187  \n","Epoch:2/50     Step:7|6   loss:0.9604074954986572  \n","Accuracy on test_set: 25.23 %\n","Accuracy on train_set: 28.57 %\n","current max accuracy\t test set:25.23%\t train set:28.57%\n","Epoch:3/50     Step:1|6   loss:0.9847395420074463  \n","Epoch:3/50     Step:2|6   loss:0.9804193377494812  \n","Epoch:3/50     Step:3|6   loss:1.0023136138916016  \n","Epoch:3/50     Step:4|6   loss:0.9693357348442078  \n","Epoch:3/50     Step:5|6   loss:0.9724217653274536  \n","Epoch:3/50     Step:6|6   loss:0.9980975389480591  \n","Epoch:3/50     Step:7|6   loss:0.9494906663894653  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 52.22 %\n","current max accuracy\t test set:44.86%\t train set:52.22%\n","Epoch:4/50     Step:1|6   loss:0.9772448539733887  \n","Epoch:4/50     Step:2|6   loss:0.9469536542892456  \n","Epoch:4/50     Step:3|6   loss:0.9540567994117737  \n","Epoch:4/50     Step:4|6   loss:0.9261264204978943  \n","Epoch:4/50     Step:5|6   loss:0.9329867362976074  \n","Epoch:4/50     Step:6|6   loss:0.9316461682319641  \n","Epoch:4/50     Step:7|6   loss:0.9831516146659851  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 51.05 %\n","current max accuracy\t test set:44.86%\t train set:52.22%\n","Epoch:5/50     Step:1|6   loss:0.9259555339813232  \n","Epoch:5/50     Step:2|6   loss:0.9029042720794678  \n","Epoch:5/50     Step:3|6   loss:0.882205605506897  \n","Epoch:5/50     Step:4|6   loss:0.9078198671340942  \n","Epoch:5/50     Step:5|6   loss:0.9574159979820251  \n","Epoch:5/50     Step:6|6   loss:0.8934838175773621  \n","Epoch:5/50     Step:7|6   loss:0.9097834229469299  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 51.05 %\n","current max accuracy\t test set:44.86%\t train set:52.22%\n","Epoch:6/50     Step:1|6   loss:0.9111184477806091  \n","Epoch:6/50     Step:2|6   loss:0.9072275161743164  \n","Epoch:6/50     Step:3|6   loss:0.8936149477958679  \n","Epoch:6/50     Step:4|6   loss:0.8805448412895203  \n","Epoch:6/50     Step:5|6   loss:0.8993334770202637  \n","Epoch:6/50     Step:6|6   loss:0.9020344614982605  \n","Epoch:6/50     Step:7|6   loss:0.8649740219116211  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 51.99 %\n","current max accuracy\t test set:44.86%\t train set:52.22%\n","Epoch:7/50     Step:1|6   loss:0.9112554788589478  \n","Epoch:7/50     Step:2|6   loss:0.9026159048080444  \n","Epoch:7/50     Step:3|6   loss:0.8794678449630737  \n","Epoch:7/50     Step:4|6   loss:0.8907931447029114  \n","Epoch:7/50     Step:5|6   loss:0.8924278020858765  \n","Epoch:7/50     Step:6|6   loss:0.8457009792327881  \n","Epoch:7/50     Step:7|6   loss:0.8297708630561829  \n","Accuracy on test_set: 60.75 %\n","Accuracy on train_set: 61.59 %\n","current max accuracy\t test set:60.75%\t train set:61.59%\n","Epoch:8/50     Step:1|6   loss:0.8824750185012817  \n","Epoch:8/50     Step:2|6   loss:0.8437151312828064  \n","Epoch:8/50     Step:3|6   loss:0.8788635730743408  \n","Epoch:8/50     Step:4|6   loss:0.8562159538269043  \n","Epoch:8/50     Step:5|6   loss:0.8943678736686707  \n","Epoch:8/50     Step:6|6   loss:0.8886934518814087  \n","Epoch:8/50     Step:7|6   loss:0.8782200813293457  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 80.33 %\n","current max accuracy\t test set:82.24%\t train set:80.33%\n","Epoch:9/50     Step:1|6   loss:0.8596301674842834  \n","Epoch:9/50     Step:2|6   loss:0.8275953531265259  \n","Epoch:9/50     Step:3|6   loss:0.8541312217712402  \n","Epoch:9/50     Step:4|6   loss:0.8615268468856812  \n","Epoch:9/50     Step:5|6   loss:0.8334468007087708  \n","Epoch:9/50     Step:6|6   loss:0.8460994958877563  \n","Epoch:9/50     Step:7|6   loss:0.8467333316802979  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 81.97 %\n","current max accuracy\t test set:82.24%\t train set:81.97%\n","Epoch:10/50     Step:1|6   loss:0.8349061608314514  \n","Epoch:10/50     Step:2|6   loss:0.8403540253639221  \n","Epoch:10/50     Step:3|6   loss:0.8239856362342834  \n","Epoch:10/50     Step:4|6   loss:0.8100121021270752  \n","Epoch:10/50     Step:5|6   loss:0.863472044467926  \n","Epoch:10/50     Step:6|6   loss:0.8034228682518005  \n","Epoch:10/50     Step:7|6   loss:0.8472987413406372  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 80.56 %\n","current max accuracy\t test set:82.24%\t train set:81.97%\n","Epoch:11/50     Step:1|6   loss:0.759388267993927  \n","Epoch:11/50     Step:2|6   loss:0.856605052947998  \n","Epoch:11/50     Step:3|6   loss:0.8148132562637329  \n","Epoch:11/50     Step:4|6   loss:0.8188492059707642  \n","Epoch:11/50     Step:5|6   loss:0.8198856115341187  \n","Epoch:11/50     Step:6|6   loss:0.7897505760192871  \n","Epoch:11/50     Step:7|6   loss:0.8592356443405151  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:93.46%\t train set:92.97%\n","Epoch:12/50     Step:1|6   loss:0.8647176027297974  \n","Epoch:12/50     Step:2|6   loss:0.8466182947158813  \n","Epoch:12/50     Step:3|6   loss:0.8208420276641846  \n","Epoch:12/50     Step:4|6   loss:0.7979320883750916  \n","Epoch:12/50     Step:5|6   loss:0.8216562271118164  \n","Epoch:12/50     Step:6|6   loss:0.8466184139251709  \n","Epoch:12/50     Step:7|6   loss:0.7986465096473694  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:98.13%\t train set:93.44%\n","Epoch:13/50     Step:1|6   loss:0.8782504796981812  \n","Epoch:13/50     Step:2|6   loss:0.7752881050109863  \n","Epoch:13/50     Step:3|6   loss:0.815345048904419  \n","Epoch:13/50     Step:4|6   loss:0.8034014701843262  \n","Epoch:13/50     Step:5|6   loss:0.7845478057861328  \n","Epoch:13/50     Step:6|6   loss:0.7600768208503723  \n","Epoch:13/50     Step:7|6   loss:0.8377258777618408  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:14/50     Step:1|6   loss:0.8276859521865845  \n","Epoch:14/50     Step:2|6   loss:0.786490797996521  \n","Epoch:14/50     Step:3|6   loss:0.7871196866035461  \n","Epoch:14/50     Step:4|6   loss:0.7879337072372437  \n","Epoch:14/50     Step:5|6   loss:0.8192547559738159  \n","Epoch:14/50     Step:6|6   loss:0.8031947612762451  \n","Epoch:14/50     Step:7|6   loss:0.7858976125717163  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:15/50     Step:1|6   loss:0.7810139060020447  \n","Epoch:15/50     Step:2|6   loss:0.77991783618927  \n","Epoch:15/50     Step:3|6   loss:0.8162115812301636  \n","Epoch:15/50     Step:4|6   loss:0.7928045392036438  \n","Epoch:15/50     Step:5|6   loss:0.7783265113830566  \n","Epoch:15/50     Step:6|6   loss:0.8014601469039917  \n","Epoch:15/50     Step:7|6   loss:0.7455021739006042  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:16/50     Step:1|6   loss:0.8126170635223389  \n","Epoch:16/50     Step:2|6   loss:0.7617789506912231  \n","Epoch:16/50     Step:3|6   loss:0.8359463214874268  \n","Epoch:16/50     Step:4|6   loss:0.8126124143600464  \n","Epoch:16/50     Step:5|6   loss:0.7820850014686584  \n","Epoch:16/50     Step:6|6   loss:0.7837249040603638  \n","Epoch:16/50     Step:7|6   loss:0.815070629119873  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:17/50     Step:1|6   loss:0.7814866304397583  \n","Epoch:17/50     Step:2|6   loss:0.8012868165969849  \n","Epoch:17/50     Step:3|6   loss:0.7503498196601868  \n","Epoch:17/50     Step:4|6   loss:0.8082202672958374  \n","Epoch:17/50     Step:5|6   loss:0.751093864440918  \n","Epoch:17/50     Step:6|6   loss:0.8290387392044067  \n","Epoch:17/50     Step:7|6   loss:0.8251371383666992  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 89.46 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:18/50     Step:1|6   loss:0.7355029582977295  \n","Epoch:18/50     Step:2|6   loss:0.8268221020698547  \n","Epoch:18/50     Step:3|6   loss:0.7887794971466064  \n","Epoch:18/50     Step:4|6   loss:0.7697659134864807  \n","Epoch:18/50     Step:5|6   loss:0.7489421367645264  \n","Epoch:18/50     Step:6|6   loss:0.7175731658935547  \n","Epoch:18/50     Step:7|6   loss:0.8303048014640808  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:19/50     Step:1|6   loss:0.7234910726547241  \n","Epoch:19/50     Step:2|6   loss:0.8131380081176758  \n","Epoch:19/50     Step:3|6   loss:0.7516692876815796  \n","Epoch:19/50     Step:4|6   loss:0.7954524755477905  \n","Epoch:19/50     Step:5|6   loss:0.7960799932479858  \n","Epoch:19/50     Step:6|6   loss:0.7858601808547974  \n","Epoch:19/50     Step:7|6   loss:0.7863318920135498  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:20/50     Step:1|6   loss:0.7134006023406982  \n","Epoch:20/50     Step:2|6   loss:0.7751336097717285  \n","Epoch:20/50     Step:3|6   loss:0.7266783118247986  \n","Epoch:20/50     Step:4|6   loss:0.7832583785057068  \n","Epoch:20/50     Step:5|6   loss:0.7934377789497375  \n","Epoch:20/50     Step:6|6   loss:0.7599866390228271  \n","Epoch:20/50     Step:7|6   loss:0.7994136810302734  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:21/50     Step:1|6   loss:0.7789404392242432  \n","Epoch:21/50     Step:2|6   loss:0.7970474362373352  \n","Epoch:21/50     Step:3|6   loss:0.7984102368354797  \n","Epoch:21/50     Step:4|6   loss:0.755423903465271  \n","Epoch:21/50     Step:5|6   loss:0.7990552186965942  \n","Epoch:21/50     Step:6|6   loss:0.7464605569839478  \n","Epoch:21/50     Step:7|6   loss:0.7504031658172607  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:22/50     Step:1|6   loss:0.8018395900726318  \n","Epoch:22/50     Step:2|6   loss:0.7952941060066223  \n","Epoch:22/50     Step:3|6   loss:0.749697208404541  \n","Epoch:22/50     Step:4|6   loss:0.772261917591095  \n","Epoch:22/50     Step:5|6   loss:0.7231187224388123  \n","Epoch:22/50     Step:6|6   loss:0.719014585018158  \n","Epoch:22/50     Step:7|6   loss:0.7511763572692871  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:100.0%\t train set:96.02%\n","Epoch:23/50     Step:1|6   loss:0.7781660556793213  \n","Epoch:23/50     Step:2|6   loss:0.7529306411743164  \n","Epoch:23/50     Step:3|6   loss:0.7799589037895203  \n","Epoch:23/50     Step:4|6   loss:0.7531896829605103  \n","Epoch:23/50     Step:5|6   loss:0.7375274896621704  \n","Epoch:23/50     Step:6|6   loss:0.7501175403594971  \n","Epoch:23/50     Step:7|6   loss:0.8030033111572266  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:24/50     Step:1|6   loss:0.7500810623168945  \n","Epoch:24/50     Step:2|6   loss:0.7665915489196777  \n","Epoch:24/50     Step:3|6   loss:0.7405889630317688  \n","Epoch:24/50     Step:4|6   loss:0.762182891368866  \n","Epoch:24/50     Step:5|6   loss:0.7457587122917175  \n","Epoch:24/50     Step:6|6   loss:0.8059501647949219  \n","Epoch:24/50     Step:7|6   loss:0.7951929569244385  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:25/50     Step:1|6   loss:0.7477442026138306  \n","Epoch:25/50     Step:2|6   loss:0.7606149911880493  \n","Epoch:25/50     Step:3|6   loss:0.7678201198577881  \n","Epoch:25/50     Step:4|6   loss:0.7952969074249268  \n","Epoch:25/50     Step:5|6   loss:0.7437578439712524  \n","Epoch:25/50     Step:6|6   loss:0.779260516166687  \n","Epoch:25/50     Step:7|6   loss:0.7624166011810303  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:26/50     Step:1|6   loss:0.7448479533195496  \n","Epoch:26/50     Step:2|6   loss:0.7501146793365479  \n","Epoch:26/50     Step:3|6   loss:0.7423825860023499  \n","Epoch:26/50     Step:4|6   loss:0.8095906972885132  \n","Epoch:26/50     Step:5|6   loss:0.809977650642395  \n","Epoch:26/50     Step:6|6   loss:0.7181910872459412  \n","Epoch:26/50     Step:7|6   loss:0.810877799987793  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:27/50     Step:1|6   loss:0.7630246877670288  \n","Epoch:27/50     Step:2|6   loss:0.7438278794288635  \n","Epoch:27/50     Step:3|6   loss:0.7221384048461914  \n","Epoch:27/50     Step:4|6   loss:0.8024481534957886  \n","Epoch:27/50     Step:5|6   loss:0.7526205778121948  \n","Epoch:27/50     Step:6|6   loss:0.7394402027130127  \n","Epoch:27/50     Step:7|6   loss:0.7911390066146851  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:28/50     Step:1|6   loss:0.7113395929336548  \n","Epoch:28/50     Step:2|6   loss:0.6933462619781494  \n","Epoch:28/50     Step:3|6   loss:0.7572799921035767  \n","Epoch:28/50     Step:4|6   loss:0.7312147617340088  \n","Epoch:28/50     Step:5|6   loss:0.7579180002212524  \n","Epoch:28/50     Step:6|6   loss:0.7446500062942505  \n","Epoch:28/50     Step:7|6   loss:0.8373070359230042  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:29/50     Step:1|6   loss:0.7427345514297485  \n","Epoch:29/50     Step:2|6   loss:0.7986358404159546  \n","Epoch:29/50     Step:3|6   loss:0.7909183502197266  \n","Epoch:29/50     Step:4|6   loss:0.7852134704589844  \n","Epoch:29/50     Step:5|6   loss:0.7263820171356201  \n","Epoch:29/50     Step:6|6   loss:0.7907032370567322  \n","Epoch:29/50     Step:7|6   loss:0.8704702854156494  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:30/50     Step:1|6   loss:0.75985187292099  \n","Epoch:30/50     Step:2|6   loss:0.7406452894210815  \n","Epoch:30/50     Step:3|6   loss:0.7817537188529968  \n","Epoch:30/50     Step:4|6   loss:0.7319315075874329  \n","Epoch:30/50     Step:5|6   loss:0.7252702713012695  \n","Epoch:30/50     Step:6|6   loss:0.7794312238693237  \n","Epoch:30/50     Step:7|6   loss:0.7202073931694031  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:31/50     Step:1|6   loss:0.7269941568374634  \n","Epoch:31/50     Step:2|6   loss:0.7485259175300598  \n","Epoch:31/50     Step:3|6   loss:0.7355302572250366  \n","Epoch:31/50     Step:4|6   loss:0.719936728477478  \n","Epoch:31/50     Step:5|6   loss:0.7302266359329224  \n","Epoch:31/50     Step:6|6   loss:0.7309826612472534  \n","Epoch:31/50     Step:7|6   loss:0.7421040534973145  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:32/50     Step:1|6   loss:0.7554069757461548  \n","Epoch:32/50     Step:2|6   loss:0.7848539352416992  \n","Epoch:32/50     Step:3|6   loss:0.7680462598800659  \n","Epoch:32/50     Step:4|6   loss:0.7531591057777405  \n","Epoch:32/50     Step:5|6   loss:0.7434777021408081  \n","Epoch:32/50     Step:6|6   loss:0.7119686603546143  \n","Epoch:32/50     Step:7|6   loss:0.7335984706878662  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:33/50     Step:1|6   loss:0.7614719867706299  \n","Epoch:33/50     Step:2|6   loss:0.6964279413223267  \n","Epoch:33/50     Step:3|6   loss:0.7433586716651917  \n","Epoch:33/50     Step:4|6   loss:0.7389963865280151  \n","Epoch:33/50     Step:5|6   loss:0.7532855868339539  \n","Epoch:33/50     Step:6|6   loss:0.7584114074707031  \n","Epoch:33/50     Step:7|6   loss:0.756925106048584  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:34/50     Step:1|6   loss:0.7093322277069092  \n","Epoch:34/50     Step:2|6   loss:0.778512716293335  \n","Epoch:34/50     Step:3|6   loss:0.7765388488769531  \n","Epoch:34/50     Step:4|6   loss:0.7336207032203674  \n","Epoch:34/50     Step:5|6   loss:0.7276018261909485  \n","Epoch:34/50     Step:6|6   loss:0.807172417640686  \n","Epoch:34/50     Step:7|6   loss:0.7946187257766724  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:35/50     Step:1|6   loss:0.8118118047714233  \n","Epoch:35/50     Step:2|6   loss:0.7894625663757324  \n","Epoch:35/50     Step:3|6   loss:0.7408633232116699  \n","Epoch:35/50     Step:4|6   loss:0.7036157846450806  \n","Epoch:35/50     Step:5|6   loss:0.6999362707138062  \n","Epoch:35/50     Step:6|6   loss:0.7292884588241577  \n","Epoch:35/50     Step:7|6   loss:0.7397345304489136  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:36/50     Step:1|6   loss:0.7185389995574951  \n","Epoch:36/50     Step:2|6   loss:0.7345864176750183  \n","Epoch:36/50     Step:3|6   loss:0.7302820682525635  \n","Epoch:36/50     Step:4|6   loss:0.7138601541519165  \n","Epoch:36/50     Step:5|6   loss:0.7022631764411926  \n","Epoch:36/50     Step:6|6   loss:0.7332932949066162  \n","Epoch:36/50     Step:7|6   loss:0.7411035895347595  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:37/50     Step:1|6   loss:0.7547444105148315  \n","Epoch:37/50     Step:2|6   loss:0.7236290574073792  \n","Epoch:37/50     Step:3|6   loss:0.7307734489440918  \n","Epoch:37/50     Step:4|6   loss:0.7766335010528564  \n","Epoch:37/50     Step:5|6   loss:0.7164794206619263  \n","Epoch:37/50     Step:6|6   loss:0.7545410990715027  \n","Epoch:37/50     Step:7|6   loss:0.7764921188354492  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:100.0%\t train set:96.25%\n","Epoch:38/50     Step:1|6   loss:0.7027130126953125  \n","Epoch:38/50     Step:2|6   loss:0.7509986162185669  \n","Epoch:38/50     Step:3|6   loss:0.7273513674736023  \n","Epoch:38/50     Step:4|6   loss:0.7230086326599121  \n","Epoch:38/50     Step:5|6   loss:0.7796032428741455  \n","Epoch:38/50     Step:6|6   loss:0.7159419059753418  \n","Epoch:38/50     Step:7|6   loss:0.7454636693000793  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:100.0%\t train set:96.72%\n","Epoch:39/50     Step:1|6   loss:0.7657241821289062  \n","Epoch:39/50     Step:2|6   loss:0.7212002277374268  \n","Epoch:39/50     Step:3|6   loss:0.7652027010917664  \n","Epoch:39/50     Step:4|6   loss:0.7773802280426025  \n","Epoch:39/50     Step:5|6   loss:0.7546489238739014  \n","Epoch:39/50     Step:6|6   loss:0.745059609413147  \n","Epoch:39/50     Step:7|6   loss:0.7517319917678833  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:100.0%\t train set:96.72%\n","Epoch:40/50     Step:1|6   loss:0.7550918459892273  \n","Epoch:40/50     Step:2|6   loss:0.7383348941802979  \n","Epoch:40/50     Step:3|6   loss:0.7387157678604126  \n","Epoch:40/50     Step:4|6   loss:0.7765374779701233  \n","Epoch:40/50     Step:5|6   loss:0.739648699760437  \n","Epoch:40/50     Step:6|6   loss:0.8247503042221069  \n","Epoch:40/50     Step:7|6   loss:0.7652814388275146  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:100.0%\t train set:96.72%\n","Epoch:41/50     Step:1|6   loss:0.7540489435195923  \n","Epoch:41/50     Step:2|6   loss:0.7761354446411133  \n","Epoch:41/50     Step:3|6   loss:0.7624320983886719  \n","Epoch:41/50     Step:4|6   loss:0.8093447685241699  \n","Epoch:41/50     Step:5|6   loss:0.7671008110046387  \n","Epoch:41/50     Step:6|6   loss:0.7429341077804565  \n","Epoch:41/50     Step:7|6   loss:0.7198278903961182  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:100.0%\t train set:96.72%\n","Epoch:42/50     Step:1|6   loss:0.7150353193283081  \n","Epoch:42/50     Step:2|6   loss:0.7510350942611694  \n","Epoch:42/50     Step:3|6   loss:0.7598646879196167  \n","Epoch:42/50     Step:4|6   loss:0.6968283653259277  \n","Epoch:42/50     Step:5|6   loss:0.7440645694732666  \n","Epoch:42/50     Step:6|6   loss:0.732082724571228  \n","Epoch:42/50     Step:7|6   loss:0.7450751066207886  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:100.0%\t train set:96.72%\n","Epoch:43/50     Step:1|6   loss:0.7397879362106323  \n","Epoch:43/50     Step:2|6   loss:0.6875369548797607  \n","Epoch:43/50     Step:3|6   loss:0.7575781941413879  \n","Epoch:43/50     Step:4|6   loss:0.7450591325759888  \n","Epoch:43/50     Step:5|6   loss:0.7165529727935791  \n","Epoch:43/50     Step:6|6   loss:0.7514476180076599  \n","Epoch:43/50     Step:7|6   loss:0.823150634765625  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:100.0%\t train set:96.72%\n","Epoch:44/50     Step:1|6   loss:0.7623350024223328  \n","Epoch:44/50     Step:2|6   loss:0.7757505178451538  \n","Epoch:44/50     Step:3|6   loss:0.7861499786376953  \n","Epoch:44/50     Step:4|6   loss:0.750969409942627  \n","Epoch:44/50     Step:5|6   loss:0.7056934237480164  \n","Epoch:44/50     Step:6|6   loss:0.7801511287689209  \n","Epoch:44/50     Step:7|6   loss:0.7838407158851624  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Epoch:45/50     Step:1|6   loss:0.7852591872215271  \n","Epoch:45/50     Step:2|6   loss:0.7680981755256653  \n","Epoch:45/50     Step:3|6   loss:0.7464331388473511  \n","Epoch:45/50     Step:4|6   loss:0.711383581161499  \n","Epoch:45/50     Step:5|6   loss:0.7099509835243225  \n","Epoch:45/50     Step:6|6   loss:0.7044600248336792  \n","Epoch:45/50     Step:7|6   loss:0.6835436820983887  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Epoch:46/50     Step:1|6   loss:0.7983511686325073  \n","Epoch:46/50     Step:2|6   loss:0.7242683172225952  \n","Epoch:46/50     Step:3|6   loss:0.7992581129074097  \n","Epoch:46/50     Step:4|6   loss:0.771977961063385  \n","Epoch:46/50     Step:5|6   loss:0.7284399271011353  \n","Epoch:46/50     Step:6|6   loss:0.7381699085235596  \n","Epoch:46/50     Step:7|6   loss:0.7395555973052979  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Epoch:47/50     Step:1|6   loss:0.7599433660507202  \n","Epoch:47/50     Step:2|6   loss:0.724311113357544  \n","Epoch:47/50     Step:3|6   loss:0.7707012891769409  \n","Epoch:47/50     Step:4|6   loss:0.7581257224082947  \n","Epoch:47/50     Step:5|6   loss:0.6993996500968933  \n","Epoch:47/50     Step:6|6   loss:0.7174237966537476  \n","Epoch:47/50     Step:7|6   loss:0.744623064994812  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Epoch:48/50     Step:1|6   loss:0.743153989315033  \n","Epoch:48/50     Step:2|6   loss:0.7146526575088501  \n","Epoch:48/50     Step:3|6   loss:0.7467536926269531  \n","Epoch:48/50     Step:4|6   loss:0.7897753715515137  \n","Epoch:48/50     Step:5|6   loss:0.7337938547134399  \n","Epoch:48/50     Step:6|6   loss:0.7403693795204163  \n","Epoch:48/50     Step:7|6   loss:0.7188822031021118  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Epoch:49/50     Step:1|6   loss:0.7161626815795898  \n","Epoch:49/50     Step:2|6   loss:0.72645503282547  \n","Epoch:49/50     Step:3|6   loss:0.7308943271636963  \n","Epoch:49/50     Step:4|6   loss:0.8171998262405396  \n","Epoch:49/50     Step:5|6   loss:0.7187228202819824  \n","Epoch:49/50     Step:6|6   loss:0.7519956827163696  \n","Epoch:49/50     Step:7|6   loss:0.752265214920044  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Epoch:50/50     Step:1|6   loss:0.7248936891555786  \n","Epoch:50/50     Step:2|6   loss:0.7585346698760986  \n","Epoch:50/50     Step:3|6   loss:0.7560732960700989  \n","Epoch:50/50     Step:4|6   loss:0.7606545686721802  \n","Epoch:50/50     Step:5|6   loss:0.748252272605896  \n","Epoch:50/50     Step:6|6   loss:0.7501565217971802  \n","Epoch:50/50     Step:7|6   loss:0.73534095287323  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:100.0%\t train set:97.42%\n","Accuracy on test_set: 95.33 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-3 --model Flame_two_stream --mode both --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":10,"id":"8cbe3050","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.0887038707733154  \n","Epoch:1/30     Step:2|6   loss:0.9074952006340027  \n","Epoch:1/30     Step:3|6   loss:0.714767336845398  \n","Epoch:1/30     Step:4|6   loss:0.8477770090103149  \n","Epoch:1/30     Step:5|6   loss:0.6074768900871277  \n","Epoch:1/30     Step:6|6   loss:0.6817680597305298  \n","Epoch:1/30     Step:7|6   loss:0.6788150668144226  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:2/30     Step:1|6   loss:0.6099686026573181  \n","Epoch:2/30     Step:2|6   loss:0.5914003849029541  \n","Epoch:2/30     Step:3|6   loss:0.5953953862190247  \n","Epoch:2/30     Step:4|6   loss:0.6555799841880798  \n","Epoch:2/30     Step:5|6   loss:0.5553523302078247  \n","Epoch:2/30     Step:6|6   loss:0.5709897875785828  \n","Epoch:2/30     Step:7|6   loss:0.5830436944961548  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:95.33%\t train set:97.42%\n","Epoch:3/30     Step:1|6   loss:0.603704035282135  \n","Epoch:3/30     Step:2|6   loss:0.5177701711654663  \n","Epoch:3/30     Step:3|6   loss:0.5301230549812317  \n","Epoch:3/30     Step:4|6   loss:0.5656377673149109  \n","Epoch:3/30     Step:5|6   loss:0.5448676347732544  \n","Epoch:3/30     Step:6|6   loss:0.5227265357971191  \n","Epoch:3/30     Step:7|6   loss:0.528840959072113  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5115032196044922  \n","Epoch:4/30     Step:2|6   loss:0.5052130818367004  \n","Epoch:4/30     Step:3|6   loss:0.511017382144928  \n","Epoch:4/30     Step:4|6   loss:0.5319709181785583  \n","Epoch:4/30     Step:5|6   loss:0.5073072910308838  \n","Epoch:4/30     Step:6|6   loss:0.5038762092590332  \n","Epoch:4/30     Step:7|6   loss:0.5333718061447144  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:5/30     Step:1|6   loss:0.5067490339279175  \n","Epoch:5/30     Step:2|6   loss:0.5020780563354492  \n","Epoch:5/30     Step:3|6   loss:0.5035877823829651  \n","Epoch:5/30     Step:4|6   loss:0.4980863332748413  \n","Epoch:5/30     Step:5|6   loss:0.502535343170166  \n","Epoch:5/30     Step:6|6   loss:0.4966312646865845  \n","Epoch:5/30     Step:7|6   loss:0.49613499641418457  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49505946040153503  \n","Epoch:6/30     Step:2|6   loss:0.5043472647666931  \n","Epoch:6/30     Step:3|6   loss:0.4978783428668976  \n","Epoch:6/30     Step:4|6   loss:0.493705689907074  \n","Epoch:6/30     Step:5|6   loss:0.4929855763912201  \n","Epoch:6/30     Step:6|6   loss:0.49622082710266113  \n","Epoch:6/30     Step:7|6   loss:0.4941907525062561  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4955081343650818  \n","Epoch:7/30     Step:2|6   loss:0.4927382469177246  \n","Epoch:7/30     Step:3|6   loss:0.4941467046737671  \n","Epoch:7/30     Step:4|6   loss:0.49131229519844055  \n","Epoch:7/30     Step:5|6   loss:0.4899756610393524  \n","Epoch:7/30     Step:6|6   loss:0.4912084639072418  \n","Epoch:7/30     Step:7|6   loss:0.4939965307712555  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49239978194236755  \n","Epoch:8/30     Step:2|6   loss:0.491238534450531  \n","Epoch:8/30     Step:3|6   loss:0.489077091217041  \n","Epoch:8/30     Step:4|6   loss:0.48987430334091187  \n","Epoch:8/30     Step:5|6   loss:0.49056583642959595  \n","Epoch:8/30     Step:6|6   loss:0.49102628231048584  \n","Epoch:8/30     Step:7|6   loss:0.49101629853248596  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4900711178779602  \n","Epoch:9/30     Step:2|6   loss:0.4888421297073364  \n","Epoch:9/30     Step:3|6   loss:0.4902135133743286  \n","Epoch:9/30     Step:4|6   loss:0.4894447922706604  \n","Epoch:9/30     Step:5|6   loss:0.48903608322143555  \n","Epoch:9/30     Step:6|6   loss:0.4899423122406006  \n","Epoch:9/30     Step:7|6   loss:0.49003875255584717  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4888538420200348  \n","Epoch:10/30     Step:2|6   loss:0.4886682331562042  \n","Epoch:10/30     Step:3|6   loss:0.48882171511650085  \n","Epoch:10/30     Step:4|6   loss:0.48855555057525635  \n","Epoch:10/30     Step:5|6   loss:0.4891551733016968  \n","Epoch:10/30     Step:6|6   loss:0.4885171949863434  \n","Epoch:10/30     Step:7|6   loss:0.48923221230506897  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.487937331199646  \n","Epoch:11/30     Step:2|6   loss:0.488864541053772  \n","Epoch:11/30     Step:3|6   loss:0.488687664270401  \n","Epoch:11/30     Step:4|6   loss:0.48983365297317505  \n","Epoch:11/30     Step:5|6   loss:0.4881036579608917  \n","Epoch:11/30     Step:6|6   loss:0.48852500319480896  \n","Epoch:11/30     Step:7|6   loss:0.4878476858139038  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48919975757598877  \n","Epoch:12/30     Step:2|6   loss:0.4882594347000122  \n","Epoch:12/30     Step:3|6   loss:0.4889608323574066  \n","Epoch:12/30     Step:4|6   loss:0.4883544445037842  \n","Epoch:12/30     Step:5|6   loss:0.4876917600631714  \n","Epoch:12/30     Step:6|6   loss:0.4885949492454529  \n","Epoch:12/30     Step:7|6   loss:0.4894789457321167  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.48845362663269043  \n","Epoch:13/30     Step:2|6   loss:0.48780354857444763  \n","Epoch:13/30     Step:3|6   loss:0.48800790309906006  \n","Epoch:13/30     Step:4|6   loss:0.48833873867988586  \n","Epoch:13/30     Step:5|6   loss:0.48858803510665894  \n","Epoch:13/30     Step:6|6   loss:0.48812851309776306  \n","Epoch:13/30     Step:7|6   loss:0.48785507678985596  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48830491304397583  \n","Epoch:14/30     Step:2|6   loss:0.48753929138183594  \n","Epoch:14/30     Step:3|6   loss:0.4879074692726135  \n","Epoch:14/30     Step:4|6   loss:0.48796889185905457  \n","Epoch:14/30     Step:5|6   loss:0.4876965284347534  \n","Epoch:14/30     Step:6|6   loss:0.48845627903938293  \n","Epoch:14/30     Step:7|6   loss:0.488105446100235  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4875550866127014  \n","Epoch:15/30     Step:2|6   loss:0.48799872398376465  \n","Epoch:15/30     Step:3|6   loss:0.48817503452301025  \n","Epoch:15/30     Step:4|6   loss:0.48900106549263  \n","Epoch:15/30     Step:5|6   loss:0.4881238043308258  \n","Epoch:15/30     Step:6|6   loss:0.4878876805305481  \n","Epoch:15/30     Step:7|6   loss:0.48812973499298096  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4874737858772278  \n","Epoch:16/30     Step:2|6   loss:0.48791372776031494  \n","Epoch:16/30     Step:3|6   loss:0.48721495270729065  \n","Epoch:16/30     Step:4|6   loss:0.48830175399780273  \n","Epoch:16/30     Step:5|6   loss:0.4880480170249939  \n","Epoch:16/30     Step:6|6   loss:0.4881187677383423  \n","Epoch:16/30     Step:7|6   loss:0.4889608323574066  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48708927631378174  \n","Epoch:17/30     Step:2|6   loss:0.48815447092056274  \n","Epoch:17/30     Step:3|6   loss:0.48731669783592224  \n","Epoch:17/30     Step:4|6   loss:0.4875538945198059  \n","Epoch:17/30     Step:5|6   loss:0.4871695935726166  \n","Epoch:17/30     Step:6|6   loss:0.4876343607902527  \n","Epoch:17/30     Step:7|6   loss:0.486989825963974  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48759186267852783  \n","Epoch:18/30     Step:2|6   loss:0.4880581796169281  \n","Epoch:18/30     Step:3|6   loss:0.4889916777610779  \n","Epoch:18/30     Step:4|6   loss:0.4875994622707367  \n","Epoch:18/30     Step:5|6   loss:0.4878321886062622  \n","Epoch:18/30     Step:6|6   loss:0.4880872666835785  \n","Epoch:18/30     Step:7|6   loss:0.4884905517101288  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4872625768184662  \n","Epoch:19/30     Step:2|6   loss:0.48736733198165894  \n","Epoch:19/30     Step:3|6   loss:0.48784592747688293  \n","Epoch:19/30     Step:4|6   loss:0.487393856048584  \n","Epoch:19/30     Step:5|6   loss:0.48775431513786316  \n","Epoch:19/30     Step:6|6   loss:0.4875171482563019  \n","Epoch:19/30     Step:7|6   loss:0.4879917502403259  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48768410086631775  \n","Epoch:20/30     Step:2|6   loss:0.4876369535923004  \n","Epoch:20/30     Step:3|6   loss:0.4872421622276306  \n","Epoch:20/30     Step:4|6   loss:0.48750877380371094  \n","Epoch:20/30     Step:5|6   loss:0.48785507678985596  \n","Epoch:20/30     Step:6|6   loss:0.48760128021240234  \n","Epoch:20/30     Step:7|6   loss:0.4874316155910492  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4880150854587555  \n","Epoch:21/30     Step:2|6   loss:0.4887559413909912  \n","Epoch:21/30     Step:3|6   loss:0.4886707663536072  \n","Epoch:21/30     Step:4|6   loss:0.4876295030117035  \n","Epoch:21/30     Step:5|6   loss:0.4873616099357605  \n","Epoch:21/30     Step:6|6   loss:0.487406462430954  \n","Epoch:21/30     Step:7|6   loss:0.4871175289154053  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48815402388572693  \n","Epoch:22/30     Step:2|6   loss:0.48758721351623535  \n","Epoch:22/30     Step:3|6   loss:0.4878508448600769  \n","Epoch:22/30     Step:4|6   loss:0.48761454224586487  \n","Epoch:22/30     Step:5|6   loss:0.48754242062568665  \n","Epoch:22/30     Step:6|6   loss:0.4873919188976288  \n","Epoch:22/30     Step:7|6   loss:0.4889463782310486  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4873726963996887  \n","Epoch:23/30     Step:2|6   loss:0.48798054456710815  \n","Epoch:23/30     Step:3|6   loss:0.487411767244339  \n","Epoch:23/30     Step:4|6   loss:0.4877830445766449  \n","Epoch:23/30     Step:5|6   loss:0.48767411708831787  \n","Epoch:23/30     Step:6|6   loss:0.4872298538684845  \n","Epoch:23/30     Step:7|6   loss:0.48755764961242676  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48787403106689453  \n","Epoch:24/30     Step:2|6   loss:0.48743465542793274  \n","Epoch:24/30     Step:3|6   loss:0.48819106817245483  \n","Epoch:24/30     Step:4|6   loss:0.48728516697883606  \n","Epoch:24/30     Step:5|6   loss:0.48800626397132874  \n","Epoch:24/30     Step:6|6   loss:0.4875965118408203  \n","Epoch:24/30     Step:7|6   loss:0.48743170499801636  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4877176880836487  \n","Epoch:25/30     Step:2|6   loss:0.48701292276382446  \n","Epoch:25/30     Step:3|6   loss:0.487756609916687  \n","Epoch:25/30     Step:4|6   loss:0.48742982745170593  \n","Epoch:25/30     Step:5|6   loss:0.487139493227005  \n","Epoch:25/30     Step:6|6   loss:0.48800140619277954  \n","Epoch:25/30     Step:7|6   loss:0.4870263934135437  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4879503846168518  \n","Epoch:26/30     Step:2|6   loss:0.48693734407424927  \n","Epoch:26/30     Step:3|6   loss:0.48757773637771606  \n","Epoch:26/30     Step:4|6   loss:0.4874267876148224  \n","Epoch:26/30     Step:5|6   loss:0.4878116846084595  \n","Epoch:26/30     Step:6|6   loss:0.4880007803440094  \n","Epoch:26/30     Step:7|6   loss:0.48777586221694946  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48740154504776  \n","Epoch:27/30     Step:2|6   loss:0.4873383343219757  \n","Epoch:27/30     Step:3|6   loss:0.48730769753456116  \n","Epoch:27/30     Step:4|6   loss:0.48809707164764404  \n","Epoch:27/30     Step:5|6   loss:0.4878251254558563  \n","Epoch:27/30     Step:6|6   loss:0.4873044788837433  \n","Epoch:27/30     Step:7|6   loss:0.48717230558395386  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4871535301208496  \n","Epoch:28/30     Step:2|6   loss:0.4869309067726135  \n","Epoch:28/30     Step:3|6   loss:0.4870927929878235  \n","Epoch:28/30     Step:4|6   loss:0.48743462562561035  \n","Epoch:28/30     Step:5|6   loss:0.4876566529273987  \n","Epoch:28/30     Step:6|6   loss:0.4875141382217407  \n","Epoch:28/30     Step:7|6   loss:0.48731809854507446  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4884611666202545  \n","Epoch:29/30     Step:2|6   loss:0.48747795820236206  \n","Epoch:29/30     Step:3|6   loss:0.48711878061294556  \n","Epoch:29/30     Step:4|6   loss:0.48774030804634094  \n","Epoch:29/30     Step:5|6   loss:0.487589031457901  \n","Epoch:29/30     Step:6|6   loss:0.48751771450042725  \n","Epoch:29/30     Step:7|6   loss:0.4874131381511688  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4875072240829468  \n","Epoch:30/30     Step:2|6   loss:0.4872261881828308  \n","Epoch:30/30     Step:3|6   loss:0.48766347765922546  \n","Epoch:30/30     Step:4|6   loss:0.48765015602111816  \n","Epoch:30/30     Step:5|6   loss:0.4880947470664978  \n","Epoch:30/30     Step:6|6   loss:0.48796403408050537  \n","Epoch:30/30     Step:7|6   loss:0.48746877908706665  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n","1\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1000522375106812  \n","Epoch:1/30     Step:2|6   loss:0.8143215179443359  \n","Epoch:1/30     Step:3|6   loss:1.034346103668213  \n","Epoch:1/30     Step:4|6   loss:0.6663525104522705  \n","Epoch:1/30     Step:5|6   loss:0.7416484355926514  \n","Epoch:1/30     Step:6|6   loss:0.6380841732025146  \n","Epoch:1/30     Step:7|6   loss:0.6112829446792603  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:90.65%\t train set:93.91%\n","Epoch:2/30     Step:1|6   loss:0.5768847465515137  \n","Epoch:2/30     Step:2|6   loss:0.5628745555877686  \n","Epoch:2/30     Step:3|6   loss:0.5760924816131592  \n","Epoch:2/30     Step:4|6   loss:0.543725848197937  \n","Epoch:2/30     Step:5|6   loss:0.5819998979568481  \n","Epoch:2/30     Step:6|6   loss:0.543646514415741  \n","Epoch:2/30     Step:7|6   loss:0.5444419980049133  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:96.26%\t train set:98.83%\n","Epoch:3/30     Step:1|6   loss:0.545925498008728  \n","Epoch:3/30     Step:2|6   loss:0.5315670967102051  \n","Epoch:3/30     Step:3|6   loss:0.5177440643310547  \n","Epoch:3/30     Step:4|6   loss:0.5057677030563354  \n","Epoch:3/30     Step:5|6   loss:0.5218757390975952  \n","Epoch:3/30     Step:6|6   loss:0.5264179110527039  \n","Epoch:3/30     Step:7|6   loss:0.5173384547233582  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5076934695243835  \n","Epoch:4/30     Step:2|6   loss:0.501653254032135  \n","Epoch:4/30     Step:3|6   loss:0.5009699463844299  \n","Epoch:4/30     Step:4|6   loss:0.5070303678512573  \n","Epoch:4/30     Step:5|6   loss:0.5009588599205017  \n","Epoch:4/30     Step:6|6   loss:0.5127246379852295  \n","Epoch:4/30     Step:7|6   loss:0.5065737962722778  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49659132957458496  \n","Epoch:5/30     Step:2|6   loss:0.49765080213546753  \n","Epoch:5/30     Step:3|6   loss:0.4927513599395752  \n","Epoch:5/30     Step:4|6   loss:0.5006455183029175  \n","Epoch:5/30     Step:5|6   loss:0.5034018158912659  \n","Epoch:5/30     Step:6|6   loss:0.4975079894065857  \n","Epoch:5/30     Step:7|6   loss:0.49617981910705566  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49430155754089355  \n","Epoch:6/30     Step:2|6   loss:0.49331092834472656  \n","Epoch:6/30     Step:3|6   loss:0.4952186942100525  \n","Epoch:6/30     Step:4|6   loss:0.4916330873966217  \n","Epoch:6/30     Step:5|6   loss:0.4924946427345276  \n","Epoch:6/30     Step:6|6   loss:0.4914688467979431  \n","Epoch:6/30     Step:7|6   loss:0.49204421043395996  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49085235595703125  \n","Epoch:7/30     Step:2|6   loss:0.49164724349975586  \n","Epoch:7/30     Step:3|6   loss:0.48866814374923706  \n","Epoch:7/30     Step:4|6   loss:0.48961520195007324  \n","Epoch:7/30     Step:5|6   loss:0.4924349784851074  \n","Epoch:7/30     Step:6|6   loss:0.4899193048477173  \n","Epoch:7/30     Step:7|6   loss:0.4919196367263794  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.48934656381607056  \n","Epoch:8/30     Step:2|6   loss:0.48915743827819824  \n","Epoch:8/30     Step:3|6   loss:0.4904222786426544  \n","Epoch:8/30     Step:4|6   loss:0.49058565497398376  \n","Epoch:8/30     Step:5|6   loss:0.48982760310173035  \n","Epoch:8/30     Step:6|6   loss:0.4896508455276489  \n","Epoch:8/30     Step:7|6   loss:0.4878303110599518  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4892571270465851  \n","Epoch:9/30     Step:2|6   loss:0.4897460341453552  \n","Epoch:9/30     Step:3|6   loss:0.48912644386291504  \n","Epoch:9/30     Step:4|6   loss:0.48896676301956177  \n","Epoch:9/30     Step:5|6   loss:0.48929157853126526  \n","Epoch:9/30     Step:6|6   loss:0.4890652298927307  \n","Epoch:9/30     Step:7|6   loss:0.48880892992019653  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4888605773448944  \n","Epoch:10/30     Step:2|6   loss:0.48784327507019043  \n","Epoch:10/30     Step:3|6   loss:0.4879997670650482  \n","Epoch:10/30     Step:4|6   loss:0.4882116913795471  \n","Epoch:10/30     Step:5|6   loss:0.4890286326408386  \n","Epoch:10/30     Step:6|6   loss:0.4889496862888336  \n","Epoch:10/30     Step:7|6   loss:0.48905688524246216  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4879583418369293  \n","Epoch:11/30     Step:2|6   loss:0.48852115869522095  \n","Epoch:11/30     Step:3|6   loss:0.48780351877212524  \n","Epoch:11/30     Step:4|6   loss:0.4880656898021698  \n","Epoch:11/30     Step:5|6   loss:0.48872122168540955  \n","Epoch:11/30     Step:6|6   loss:0.48792755603790283  \n","Epoch:11/30     Step:7|6   loss:0.48784494400024414  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48837339878082275  \n","Epoch:12/30     Step:2|6   loss:0.4890425503253937  \n","Epoch:12/30     Step:3|6   loss:0.48789018392562866  \n","Epoch:12/30     Step:4|6   loss:0.48825910687446594  \n","Epoch:12/30     Step:5|6   loss:0.48787420988082886  \n","Epoch:12/30     Step:6|6   loss:0.48798513412475586  \n","Epoch:12/30     Step:7|6   loss:0.4884833097457886  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.48840293288230896  \n","Epoch:13/30     Step:2|6   loss:0.48887667059898376  \n","Epoch:13/30     Step:3|6   loss:0.48807257413864136  \n","Epoch:13/30     Step:4|6   loss:0.48848897218704224  \n","Epoch:13/30     Step:5|6   loss:0.48822394013404846  \n","Epoch:13/30     Step:6|6   loss:0.48776182532310486  \n","Epoch:13/30     Step:7|6   loss:0.48744478821754456  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.487700492143631  \n","Epoch:14/30     Step:2|6   loss:0.4869910478591919  \n","Epoch:14/30     Step:3|6   loss:0.48788559436798096  \n","Epoch:14/30     Step:4|6   loss:0.48787614703178406  \n","Epoch:14/30     Step:5|6   loss:0.4876120090484619  \n","Epoch:14/30     Step:6|6   loss:0.48790615797042847  \n","Epoch:14/30     Step:7|6   loss:0.4881848990917206  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4886368215084076  \n","Epoch:15/30     Step:2|6   loss:0.486946165561676  \n","Epoch:15/30     Step:3|6   loss:0.4883083999156952  \n","Epoch:15/30     Step:4|6   loss:0.4877346158027649  \n","Epoch:15/30     Step:5|6   loss:0.4884547293186188  \n","Epoch:15/30     Step:6|6   loss:0.4872076213359833  \n","Epoch:15/30     Step:7|6   loss:0.48804256319999695  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48804956674575806  \n","Epoch:16/30     Step:2|6   loss:0.4877042770385742  \n","Epoch:16/30     Step:3|6   loss:0.48800724744796753  \n","Epoch:16/30     Step:4|6   loss:0.48787081241607666  \n","Epoch:16/30     Step:5|6   loss:0.48739632964134216  \n","Epoch:16/30     Step:6|6   loss:0.48805171251296997  \n","Epoch:16/30     Step:7|6   loss:0.4886719584465027  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4871101677417755  \n","Epoch:17/30     Step:2|6   loss:0.48713579773902893  \n","Epoch:17/30     Step:3|6   loss:0.48746615648269653  \n","Epoch:17/30     Step:4|6   loss:0.4873886704444885  \n","Epoch:17/30     Step:5|6   loss:0.4888405203819275  \n","Epoch:17/30     Step:6|6   loss:0.4879421889781952  \n","Epoch:17/30     Step:7|6   loss:0.486862450838089  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48792019486427307  \n","Epoch:18/30     Step:2|6   loss:0.4872816801071167  \n","Epoch:18/30     Step:3|6   loss:0.4872687757015228  \n","Epoch:18/30     Step:4|6   loss:0.4877759516239166  \n","Epoch:18/30     Step:5|6   loss:0.4877839982509613  \n","Epoch:18/30     Step:6|6   loss:0.4868449866771698  \n","Epoch:18/30     Step:7|6   loss:0.48774453997612  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4886651337146759  \n","Epoch:19/30     Step:2|6   loss:0.48822253942489624  \n","Epoch:19/30     Step:3|6   loss:0.48773565888404846  \n","Epoch:19/30     Step:4|6   loss:0.4879313111305237  \n","Epoch:19/30     Step:5|6   loss:0.48783841729164124  \n","Epoch:19/30     Step:6|6   loss:0.4875592887401581  \n","Epoch:19/30     Step:7|6   loss:0.4884106516838074  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48777449131011963  \n","Epoch:20/30     Step:2|6   loss:0.4875146150588989  \n","Epoch:20/30     Step:3|6   loss:0.48784711956977844  \n","Epoch:20/30     Step:4|6   loss:0.48710116744041443  \n","Epoch:20/30     Step:5|6   loss:0.4867987036705017  \n","Epoch:20/30     Step:6|6   loss:0.48730191588401794  \n","Epoch:20/30     Step:7|6   loss:0.4874040186405182  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48801007866859436  \n","Epoch:21/30     Step:2|6   loss:0.48696330189704895  \n","Epoch:21/30     Step:3|6   loss:0.48756447434425354  \n","Epoch:21/30     Step:4|6   loss:0.488711416721344  \n","Epoch:21/30     Step:5|6   loss:0.487989217042923  \n","Epoch:21/30     Step:6|6   loss:0.48751357197761536  \n","Epoch:21/30     Step:7|6   loss:0.4874613881111145  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48710888624191284  \n","Epoch:22/30     Step:2|6   loss:0.48690229654312134  \n","Epoch:22/30     Step:3|6   loss:0.48770368099212646  \n","Epoch:22/30     Step:4|6   loss:0.4870806336402893  \n","Epoch:22/30     Step:5|6   loss:0.4877243638038635  \n","Epoch:22/30     Step:6|6   loss:0.48755383491516113  \n","Epoch:22/30     Step:7|6   loss:0.4872904121875763  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48732855916023254  \n","Epoch:23/30     Step:2|6   loss:0.4872695505619049  \n","Epoch:23/30     Step:3|6   loss:0.4867716133594513  \n","Epoch:23/30     Step:4|6   loss:0.4875677824020386  \n","Epoch:23/30     Step:5|6   loss:0.48727428913116455  \n","Epoch:23/30     Step:6|6   loss:0.48734501004219055  \n","Epoch:23/30     Step:7|6   loss:0.4876655638217926  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48753857612609863  \n","Epoch:24/30     Step:2|6   loss:0.487135648727417  \n","Epoch:24/30     Step:3|6   loss:0.4873819649219513  \n","Epoch:24/30     Step:4|6   loss:0.48732346296310425  \n","Epoch:24/30     Step:5|6   loss:0.48684874176979065  \n","Epoch:24/30     Step:6|6   loss:0.4867973327636719  \n","Epoch:24/30     Step:7|6   loss:0.48722314834594727  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4870452880859375  \n","Epoch:25/30     Step:2|6   loss:0.4875856041908264  \n","Epoch:25/30     Step:3|6   loss:0.48728299140930176  \n","Epoch:25/30     Step:4|6   loss:0.48738545179367065  \n","Epoch:25/30     Step:5|6   loss:0.487366259098053  \n","Epoch:25/30     Step:6|6   loss:0.48727211356163025  \n","Epoch:25/30     Step:7|6   loss:0.4872487783432007  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.487102210521698  \n","Epoch:26/30     Step:2|6   loss:0.4869435727596283  \n","Epoch:26/30     Step:3|6   loss:0.48762595653533936  \n","Epoch:26/30     Step:4|6   loss:0.48750239610671997  \n","Epoch:26/30     Step:5|6   loss:0.4875437617301941  \n","Epoch:26/30     Step:6|6   loss:0.4868413507938385  \n","Epoch:26/30     Step:7|6   loss:0.48733949661254883  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4869893193244934  \n","Epoch:27/30     Step:2|6   loss:0.48713448643684387  \n","Epoch:27/30     Step:3|6   loss:0.48782557249069214  \n","Epoch:27/30     Step:4|6   loss:0.4871654808521271  \n","Epoch:27/30     Step:5|6   loss:0.48790740966796875  \n","Epoch:27/30     Step:6|6   loss:0.48649436235427856  \n","Epoch:27/30     Step:7|6   loss:0.48722395300865173  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.48780491948127747  \n","Epoch:28/30     Step:2|6   loss:0.4870074987411499  \n","Epoch:28/30     Step:3|6   loss:0.4868066608905792  \n","Epoch:28/30     Step:4|6   loss:0.4873661696910858  \n","Epoch:28/30     Step:5|6   loss:0.48763349652290344  \n","Epoch:28/30     Step:6|6   loss:0.48760727047920227  \n","Epoch:28/30     Step:7|6   loss:0.48765847086906433  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.48711496591567993  \n","Epoch:29/30     Step:2|6   loss:0.4866860508918762  \n","Epoch:29/30     Step:3|6   loss:0.4875465929508209  \n","Epoch:29/30     Step:4|6   loss:0.48722654581069946  \n","Epoch:29/30     Step:5|6   loss:0.48725706338882446  \n","Epoch:29/30     Step:6|6   loss:0.4876617193222046  \n","Epoch:29/30     Step:7|6   loss:0.4889157712459564  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4872681498527527  \n","Epoch:30/30     Step:2|6   loss:0.4870491027832031  \n","Epoch:30/30     Step:3|6   loss:0.4875009059906006  \n","Epoch:30/30     Step:4|6   loss:0.4879734516143799  \n","Epoch:30/30     Step:5|6   loss:0.4873100221157074  \n","Epoch:30/30     Step:6|6   loss:0.48695045709609985  \n","Epoch:30/30     Step:7|6   loss:0.48742491006851196  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n","2\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1000920534133911  \n","Epoch:1/30     Step:2|6   loss:0.8483539819717407  \n","Epoch:1/30     Step:3|6   loss:0.9421314001083374  \n","Epoch:1/30     Step:4|6   loss:0.7438926696777344  \n","Epoch:1/30     Step:5|6   loss:0.6440330147743225  \n","Epoch:1/30     Step:6|6   loss:0.633392333984375  \n","Epoch:1/30     Step:7|6   loss:0.6619209051132202  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:93.46%\t train set:92.27%\n","Epoch:2/30     Step:1|6   loss:0.6339219808578491  \n","Epoch:2/30     Step:2|6   loss:0.5580256581306458  \n","Epoch:2/30     Step:3|6   loss:0.5838373899459839  \n","Epoch:2/30     Step:4|6   loss:0.5256742835044861  \n","Epoch:2/30     Step:5|6   loss:0.5574565529823303  \n","Epoch:2/30     Step:6|6   loss:0.5598154067993164  \n","Epoch:2/30     Step:7|6   loss:0.5466748476028442  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:98.36%\n","Epoch:3/30     Step:1|6   loss:0.5539875030517578  \n","Epoch:3/30     Step:2|6   loss:0.534546434879303  \n","Epoch:3/30     Step:3|6   loss:0.5285112261772156  \n","Epoch:3/30     Step:4|6   loss:0.512718677520752  \n","Epoch:3/30     Step:5|6   loss:0.5237494111061096  \n","Epoch:3/30     Step:6|6   loss:0.5090064406394958  \n","Epoch:3/30     Step:7|6   loss:0.5125923156738281  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:100.0%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5074228048324585  \n","Epoch:4/30     Step:2|6   loss:0.5017513036727905  \n","Epoch:4/30     Step:3|6   loss:0.5027803182601929  \n","Epoch:4/30     Step:4|6   loss:0.5036740303039551  \n","Epoch:4/30     Step:5|6   loss:0.501706063747406  \n","Epoch:4/30     Step:6|6   loss:0.50311279296875  \n","Epoch:4/30     Step:7|6   loss:0.5151320695877075  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49291345477104187  \n","Epoch:5/30     Step:2|6   loss:0.49808329343795776  \n","Epoch:5/30     Step:3|6   loss:0.5003646612167358  \n","Epoch:5/30     Step:4|6   loss:0.4935859441757202  \n","Epoch:5/30     Step:5|6   loss:0.4978845715522766  \n","Epoch:5/30     Step:6|6   loss:0.4997158646583557  \n","Epoch:5/30     Step:7|6   loss:0.4993284344673157  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4981463551521301  \n","Epoch:6/30     Step:2|6   loss:0.49750658869743347  \n","Epoch:6/30     Step:3|6   loss:0.4941204786300659  \n","Epoch:6/30     Step:4|6   loss:0.4927712380886078  \n","Epoch:6/30     Step:5|6   loss:0.49482059478759766  \n","Epoch:6/30     Step:6|6   loss:0.4975737929344177  \n","Epoch:6/30     Step:7|6   loss:0.49425646662712097  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49234047532081604  \n","Epoch:7/30     Step:2|6   loss:0.4947347640991211  \n","Epoch:7/30     Step:3|6   loss:0.4920370578765869  \n","Epoch:7/30     Step:4|6   loss:0.4922795295715332  \n","Epoch:7/30     Step:5|6   loss:0.4931487441062927  \n","Epoch:7/30     Step:6|6   loss:0.493283212184906  \n","Epoch:7/30     Step:7|6   loss:0.4941801428794861  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49216777086257935  \n","Epoch:8/30     Step:2|6   loss:0.4923386573791504  \n","Epoch:8/30     Step:3|6   loss:0.4945259988307953  \n","Epoch:8/30     Step:4|6   loss:0.4917390048503876  \n","Epoch:8/30     Step:5|6   loss:0.49194955825805664  \n","Epoch:8/30     Step:6|6   loss:0.49108296632766724  \n","Epoch:8/30     Step:7|6   loss:0.49302566051483154  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4910901188850403  \n","Epoch:9/30     Step:2|6   loss:0.4900531768798828  \n","Epoch:9/30     Step:3|6   loss:0.4888265132904053  \n","Epoch:9/30     Step:4|6   loss:0.4900417625904083  \n","Epoch:9/30     Step:5|6   loss:0.4912685453891754  \n","Epoch:9/30     Step:6|6   loss:0.4892627000808716  \n","Epoch:9/30     Step:7|6   loss:0.4899325966835022  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48905670642852783  \n","Epoch:10/30     Step:2|6   loss:0.48846235871315  \n","Epoch:10/30     Step:3|6   loss:0.48893460631370544  \n","Epoch:10/30     Step:4|6   loss:0.4892348051071167  \n","Epoch:10/30     Step:5|6   loss:0.4883109927177429  \n","Epoch:10/30     Step:6|6   loss:0.48813360929489136  \n","Epoch:10/30     Step:7|6   loss:0.48821088671684265  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4879150390625  \n","Epoch:11/30     Step:2|6   loss:0.4889841079711914  \n","Epoch:11/30     Step:3|6   loss:0.48840194940567017  \n","Epoch:11/30     Step:4|6   loss:0.48832815885543823  \n","Epoch:11/30     Step:5|6   loss:0.4886377155780792  \n","Epoch:11/30     Step:6|6   loss:0.4888361096382141  \n","Epoch:11/30     Step:7|6   loss:0.48983079195022583  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4877684414386749  \n","Epoch:12/30     Step:2|6   loss:0.48765745759010315  \n","Epoch:12/30     Step:3|6   loss:0.4889831840991974  \n","Epoch:12/30     Step:4|6   loss:0.4887949824333191  \n","Epoch:12/30     Step:5|6   loss:0.4883038103580475  \n","Epoch:12/30     Step:6|6   loss:0.48767074942588806  \n","Epoch:12/30     Step:7|6   loss:0.4880633056163788  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4878690242767334  \n","Epoch:13/30     Step:2|6   loss:0.48791244626045227  \n","Epoch:13/30     Step:3|6   loss:0.48845964670181274  \n","Epoch:13/30     Step:4|6   loss:0.4875239431858063  \n","Epoch:13/30     Step:5|6   loss:0.488990843296051  \n","Epoch:13/30     Step:6|6   loss:0.48816579580307007  \n","Epoch:13/30     Step:7|6   loss:0.48809128999710083  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4880281984806061  \n","Epoch:14/30     Step:2|6   loss:0.48745784163475037  \n","Epoch:14/30     Step:3|6   loss:0.4877176582813263  \n","Epoch:14/30     Step:4|6   loss:0.48853403329849243  \n","Epoch:14/30     Step:5|6   loss:0.4880632162094116  \n","Epoch:14/30     Step:6|6   loss:0.48795372247695923  \n","Epoch:14/30     Step:7|6   loss:0.48756685853004456  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4877820909023285  \n","Epoch:15/30     Step:2|6   loss:0.4881044626235962  \n","Epoch:15/30     Step:3|6   loss:0.4874909520149231  \n","Epoch:15/30     Step:4|6   loss:0.48791027069091797  \n","Epoch:15/30     Step:5|6   loss:0.4889017641544342  \n","Epoch:15/30     Step:6|6   loss:0.4876989722251892  \n","Epoch:15/30     Step:7|6   loss:0.4876795709133148  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48793476819992065  \n","Epoch:16/30     Step:2|6   loss:0.487793505191803  \n","Epoch:16/30     Step:3|6   loss:0.4880603849887848  \n","Epoch:16/30     Step:4|6   loss:0.4879988729953766  \n","Epoch:16/30     Step:5|6   loss:0.4880468249320984  \n","Epoch:16/30     Step:6|6   loss:0.48754212260246277  \n","Epoch:16/30     Step:7|6   loss:0.48788923025131226  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4877678453922272  \n","Epoch:17/30     Step:2|6   loss:0.48675888776779175  \n","Epoch:17/30     Step:3|6   loss:0.4878244996070862  \n","Epoch:17/30     Step:4|6   loss:0.48757240176200867  \n","Epoch:17/30     Step:5|6   loss:0.4876158833503723  \n","Epoch:17/30     Step:6|6   loss:0.48792344331741333  \n","Epoch:17/30     Step:7|6   loss:0.4873623251914978  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4876781105995178  \n","Epoch:18/30     Step:2|6   loss:0.487504243850708  \n","Epoch:18/30     Step:3|6   loss:0.4877498745918274  \n","Epoch:18/30     Step:4|6   loss:0.4883882999420166  \n","Epoch:18/30     Step:5|6   loss:0.48785364627838135  \n","Epoch:18/30     Step:6|6   loss:0.4872409403324127  \n","Epoch:18/30     Step:7|6   loss:0.48835232853889465  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.488128662109375  \n","Epoch:19/30     Step:2|6   loss:0.4880252480506897  \n","Epoch:19/30     Step:3|6   loss:0.4875936508178711  \n","Epoch:19/30     Step:4|6   loss:0.4876157343387604  \n","Epoch:19/30     Step:5|6   loss:0.48823636770248413  \n","Epoch:19/30     Step:6|6   loss:0.48727700114250183  \n","Epoch:19/30     Step:7|6   loss:0.4882121682167053  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48789435625076294  \n","Epoch:20/30     Step:2|6   loss:0.48824796080589294  \n","Epoch:20/30     Step:3|6   loss:0.4874071180820465  \n","Epoch:20/30     Step:4|6   loss:0.48725426197052  \n","Epoch:20/30     Step:5|6   loss:0.48799920082092285  \n","Epoch:20/30     Step:6|6   loss:0.48721104860305786  \n","Epoch:20/30     Step:7|6   loss:0.4872004985809326  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4881305694580078  \n","Epoch:21/30     Step:2|6   loss:0.4880125820636749  \n","Epoch:21/30     Step:3|6   loss:0.48787111043930054  \n","Epoch:21/30     Step:4|6   loss:0.48751112818717957  \n","Epoch:21/30     Step:5|6   loss:0.48797643184661865  \n","Epoch:21/30     Step:6|6   loss:0.48894262313842773  \n","Epoch:21/30     Step:7|6   loss:0.4881647229194641  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48783397674560547  \n","Epoch:22/30     Step:2|6   loss:0.48750221729278564  \n","Epoch:22/30     Step:3|6   loss:0.487704336643219  \n","Epoch:22/30     Step:4|6   loss:0.48734408617019653  \n","Epoch:22/30     Step:5|6   loss:0.4872300624847412  \n","Epoch:22/30     Step:6|6   loss:0.4875829815864563  \n","Epoch:22/30     Step:7|6   loss:0.48791563510894775  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48742401599884033  \n","Epoch:23/30     Step:2|6   loss:0.4877150058746338  \n","Epoch:23/30     Step:3|6   loss:0.48748844861984253  \n","Epoch:23/30     Step:4|6   loss:0.48829686641693115  \n","Epoch:23/30     Step:5|6   loss:0.4871068298816681  \n","Epoch:23/30     Step:6|6   loss:0.48828956484794617  \n","Epoch:23/30     Step:7|6   loss:0.48765772581100464  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4877764880657196  \n","Epoch:24/30     Step:2|6   loss:0.4878438711166382  \n","Epoch:24/30     Step:3|6   loss:0.487568199634552  \n","Epoch:24/30     Step:4|6   loss:0.48701778054237366  \n","Epoch:24/30     Step:5|6   loss:0.48736336827278137  \n","Epoch:24/30     Step:6|6   loss:0.48849374055862427  \n","Epoch:24/30     Step:7|6   loss:0.48905086517333984  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4873904287815094  \n","Epoch:25/30     Step:2|6   loss:0.48715877532958984  \n","Epoch:25/30     Step:3|6   loss:0.4873792827129364  \n","Epoch:25/30     Step:4|6   loss:0.48720112442970276  \n","Epoch:25/30     Step:5|6   loss:0.48702365159988403  \n","Epoch:25/30     Step:6|6   loss:0.487342894077301  \n","Epoch:25/30     Step:7|6   loss:0.4882875084877014  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.48737093806266785  \n","Epoch:26/30     Step:2|6   loss:0.48749279975891113  \n","Epoch:26/30     Step:3|6   loss:0.48741090297698975  \n","Epoch:26/30     Step:4|6   loss:0.4875663220882416  \n","Epoch:26/30     Step:5|6   loss:0.48838678002357483  \n","Epoch:26/30     Step:6|6   loss:0.48773330450057983  \n","Epoch:26/30     Step:7|6   loss:0.48718053102493286  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48787498474121094  \n","Epoch:27/30     Step:2|6   loss:0.48744577169418335  \n","Epoch:27/30     Step:3|6   loss:0.48814448714256287  \n","Epoch:27/30     Step:4|6   loss:0.48711007833480835  \n","Epoch:27/30     Step:5|6   loss:0.48739373683929443  \n","Epoch:27/30     Step:6|6   loss:0.48797744512557983  \n","Epoch:27/30     Step:7|6   loss:0.4878164529800415  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4877201020717621  \n","3Epoch:28/30     Step:2|6   loss:0.4875146746635437  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:28/30     Step:3|6   loss:0.48724085092544556  \n","Epoch:28/30     Step:4|6   loss:0.48742547631263733  \n","Epoch:28/30     Step:5|6   loss:0.488111674785614  \n","Epoch:28/30     Step:6|6   loss:0.48700594902038574  \n","Epoch:28/30     Step:7|6   loss:0.4888785481452942  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.48800814151763916  \n","Epoch:29/30     Step:2|6   loss:0.4871710538864136  \n","Epoch:29/30     Step:3|6   loss:0.4883609116077423  \n","Epoch:29/30     Step:4|6   loss:0.4868912100791931  \n","Epoch:29/30     Step:5|6   loss:0.487369567155838  \n","Epoch:29/30     Step:6|6   loss:0.48835262656211853  \n","Epoch:29/30     Step:7|6   loss:0.48846131563186646  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4872363209724426  \n","Epoch:30/30     Step:2|6   loss:0.4892198145389557  \n","Epoch:30/30     Step:3|6   loss:0.4890194833278656  \n","Epoch:30/30     Step:4|6   loss:0.4872710406780243  \n","Epoch:30/30     Step:5|6   loss:0.48854345083236694  \n","Epoch:30/30     Step:6|6   loss:0.48823750019073486  \n","Epoch:30/30     Step:7|6   loss:0.4874569773674011  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1261693239212036  \n","Epoch:1/30     Step:2|6   loss:0.9372708201408386  \n","Epoch:1/30     Step:3|6   loss:0.8330482244491577  \n","Epoch:1/30     Step:4|6   loss:0.6794896125793457  \n","Epoch:1/30     Step:5|6   loss:0.6256524324417114  \n","Epoch:1/30     Step:6|6   loss:0.7965719699859619  \n","Epoch:1/30     Step:7|6   loss:0.5623634457588196  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:89.72%\t train set:92.51%\n","Epoch:2/30     Step:1|6   loss:0.6440068483352661  \n","Epoch:2/30     Step:2|6   loss:0.5877277255058289  \n","Epoch:2/30     Step:3|6   loss:0.579637885093689  \n","Epoch:2/30     Step:4|6   loss:0.5723447203636169  \n","Epoch:2/30     Step:5|6   loss:0.5564038753509521  \n","Epoch:2/30     Step:6|6   loss:0.5394749641418457  \n","Epoch:2/30     Step:7|6   loss:0.5448111295700073  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:97.2%\t train set:98.36%\n","Epoch:3/30     Step:1|6   loss:0.5377849340438843  \n","Epoch:3/30     Step:2|6   loss:0.5445689558982849  \n","Epoch:3/30     Step:3|6   loss:0.5215703845024109  \n","Epoch:3/30     Step:4|6   loss:0.5271681547164917  \n","Epoch:3/30     Step:5|6   loss:0.5077606439590454  \n","Epoch:3/30     Step:6|6   loss:0.518856406211853  \n","Epoch:3/30     Step:7|6   loss:0.5197896361351013  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.511709988117218  \n","Epoch:4/30     Step:2|6   loss:0.5057523250579834  \n","Epoch:4/30     Step:3|6   loss:0.5038848519325256  \n","Epoch:4/30     Step:4|6   loss:0.5002283453941345  \n","Epoch:4/30     Step:5|6   loss:0.49959874153137207  \n","Epoch:4/30     Step:6|6   loss:0.506874144077301  \n","Epoch:4/30     Step:7|6   loss:0.5060257911682129  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49829763174057007  \n","Epoch:5/30     Step:2|6   loss:0.5070888996124268  \n","Epoch:5/30     Step:3|6   loss:0.4959779381752014  \n","Epoch:5/30     Step:4|6   loss:0.49168288707733154  \n","Epoch:5/30     Step:5|6   loss:0.49287497997283936  \n","Epoch:5/30     Step:6|6   loss:0.4959436058998108  \n","Epoch:5/30     Step:7|6   loss:0.4982093572616577  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4939197301864624  \n","Epoch:6/30     Step:2|6   loss:0.49189886450767517  \n","Epoch:6/30     Step:3|6   loss:0.4918021261692047  \n","Epoch:6/30     Step:4|6   loss:0.4929225444793701  \n","Epoch:6/30     Step:5|6   loss:0.49082452058792114  \n","Epoch:6/30     Step:6|6   loss:0.4908890128135681  \n","Epoch:6/30     Step:7|6   loss:0.4915948510169983  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4918578565120697  \n","Epoch:7/30     Step:2|6   loss:0.4917107820510864  \n","Epoch:7/30     Step:3|6   loss:0.49188539385795593  \n","Epoch:7/30     Step:4|6   loss:0.49023011326789856  \n","Epoch:7/30     Step:5|6   loss:0.4893580377101898  \n","Epoch:7/30     Step:6|6   loss:0.4897213280200958  \n","Epoch:7/30     Step:7|6   loss:0.490170419216156  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49025753140449524  \n","Epoch:8/30     Step:2|6   loss:0.4898499846458435  \n","Epoch:8/30     Step:3|6   loss:0.48934802412986755  \n","Epoch:8/30     Step:4|6   loss:0.4886253774166107  \n","Epoch:8/30     Step:5|6   loss:0.48875272274017334  \n","Epoch:8/30     Step:6|6   loss:0.4886598587036133  \n","Epoch:8/30     Step:7|6   loss:0.4907118082046509  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4895906150341034  \n","Epoch:9/30     Step:2|6   loss:0.48877111077308655  \n","Epoch:9/30     Step:3|6   loss:0.4882020652294159  \n","Epoch:9/30     Step:4|6   loss:0.48956188559532166  \n","Epoch:9/30     Step:5|6   loss:0.4886513948440552  \n","Epoch:9/30     Step:6|6   loss:0.48892539739608765  \n","Epoch:9/30     Step:7|6   loss:0.48909223079681396  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49027395248413086  \n","Epoch:10/30     Step:2|6   loss:0.48859959840774536  \n","Epoch:10/30     Step:3|6   loss:0.48792764544487  \n","Epoch:10/30     Step:4|6   loss:0.4892001152038574  \n","Epoch:10/30     Step:5|6   loss:0.48854321241378784  \n","Epoch:10/30     Step:6|6   loss:0.4877609312534332  \n","Epoch:10/30     Step:7|6   loss:0.48960819840431213  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.488125205039978  \n","Epoch:11/30     Step:2|6   loss:0.4896518290042877  \n","Epoch:11/30     Step:3|6   loss:0.4883577823638916  \n","Epoch:11/30     Step:4|6   loss:0.4888697862625122  \n","Epoch:11/30     Step:5|6   loss:0.48780688643455505  \n","Epoch:11/30     Step:6|6   loss:0.48808908462524414  \n","Epoch:11/30     Step:7|6   loss:0.4885786175727844  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4880251884460449  \n","Epoch:12/30     Step:2|6   loss:0.48863181471824646  \n","Epoch:12/30     Step:3|6   loss:0.4881557822227478  \n","Epoch:12/30     Step:4|6   loss:0.4885631799697876  \n","Epoch:12/30     Step:5|6   loss:0.48808956146240234  \n","Epoch:12/30     Step:6|6   loss:0.4889127016067505  \n","Epoch:12/30     Step:7|6   loss:0.4875189960002899  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4876348376274109  \n","Epoch:13/30     Step:2|6   loss:0.4876633882522583  \n","Epoch:13/30     Step:3|6   loss:0.4891358017921448  \n","Epoch:13/30     Step:4|6   loss:0.48793458938598633  \n","Epoch:13/30     Step:5|6   loss:0.4881588816642761  \n","Epoch:13/30     Step:6|6   loss:0.4885118305683136  \n","Epoch:13/30     Step:7|6   loss:0.48881518840789795  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48865923285484314  \n","Epoch:14/30     Step:2|6   loss:0.48790428042411804  \n","Epoch:14/30     Step:3|6   loss:0.4880909323692322  \n","Epoch:14/30     Step:4|6   loss:0.48783546686172485  \n","Epoch:14/30     Step:5|6   loss:0.4884980618953705  \n","Epoch:14/30     Step:6|6   loss:0.48831450939178467  \n","Epoch:14/30     Step:7|6   loss:0.48743736743927  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4876691997051239  \n","Epoch:15/30     Step:2|6   loss:0.4882689416408539  \n","Epoch:15/30     Step:3|6   loss:0.4890567660331726  \n","Epoch:15/30     Step:4|6   loss:0.48705095052719116  \n","Epoch:15/30     Step:5|6   loss:0.487377405166626  \n","Epoch:15/30     Step:6|6   loss:0.4877226650714874  \n","Epoch:15/30     Step:7|6   loss:0.48916178941726685  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48770302534103394  \n","Epoch:16/30     Step:2|6   loss:0.48830342292785645  \n","Epoch:16/30     Step:3|6   loss:0.48834654688835144  \n","Epoch:16/30     Step:4|6   loss:0.48827069997787476  \n","Epoch:16/30     Step:5|6   loss:0.48736506700515747  \n","Epoch:16/30     Step:6|6   loss:0.48776668310165405  \n","Epoch:16/30     Step:7|6   loss:0.4884425401687622  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48901641368865967  \n","Epoch:17/30     Step:2|6   loss:0.48806896805763245  \n","Epoch:17/30     Step:3|6   loss:0.48771578073501587  \n","Epoch:17/30     Step:4|6   loss:0.4876942038536072  \n","Epoch:17/30     Step:5|6   loss:0.4876331686973572  \n","Epoch:17/30     Step:6|6   loss:0.48800432682037354  \n","Epoch:17/30     Step:7|6   loss:0.4879390299320221  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4885040819644928  \n","Epoch:18/30     Step:2|6   loss:0.48806434869766235  \n","Epoch:18/30     Step:3|6   loss:0.48747920989990234  \n","Epoch:18/30     Step:4|6   loss:0.4878370761871338  \n","Epoch:18/30     Step:5|6   loss:0.48792827129364014  \n","Epoch:18/30     Step:6|6   loss:0.48829013109207153  \n","Epoch:18/30     Step:7|6   loss:0.48885059356689453  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.488575279712677  \n","Epoch:19/30     Step:2|6   loss:0.4884970188140869  \n","Epoch:19/30     Step:3|6   loss:0.48799800872802734  \n","Epoch:19/30     Step:4|6   loss:0.48760339617729187  \n","Epoch:19/30     Step:5|6   loss:0.4885942339897156  \n","Epoch:19/30     Step:6|6   loss:0.4875391125679016  \n","Epoch:19/30     Step:7|6   loss:0.48857778310775757  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48827651143074036  \n","Epoch:20/30     Step:2|6   loss:0.48756882548332214  \n","Epoch:20/30     Step:3|6   loss:0.4873601794242859  \n","Epoch:20/30     Step:4|6   loss:0.48797303438186646  \n","Epoch:20/30     Step:5|6   loss:0.4890730082988739  \n","Epoch:20/30     Step:6|6   loss:0.4875542223453522  \n","Epoch:20/30     Step:7|6   loss:0.48744329810142517  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4884112775325775  \n","Epoch:21/30     Step:2|6   loss:0.48766446113586426  \n","Epoch:21/30     Step:3|6   loss:0.48749521374702454  \n","Epoch:21/30     Step:4|6   loss:0.48855113983154297  \n","Epoch:21/30     Step:5|6   loss:0.48808425664901733  \n","Epoch:21/30     Step:6|6   loss:0.4884204864501953  \n","Epoch:21/30     Step:7|6   loss:0.4885599613189697  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4879470467567444  \n","Epoch:22/30     Step:2|6   loss:0.48787760734558105  \n","Epoch:22/30     Step:3|6   loss:0.48829761147499084  \n","Epoch:22/30     Step:4|6   loss:0.48786893486976624  \n","Epoch:22/30     Step:5|6   loss:0.48763418197631836  \n","Epoch:22/30     Step:6|6   loss:0.4875444173812866  \n","Epoch:22/30     Step:7|6   loss:0.48775413632392883  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4875394403934479  \n","Epoch:23/30     Step:2|6   loss:0.48800504207611084  \n","Epoch:23/30     Step:3|6   loss:0.4870701730251312  \n","Epoch:23/30     Step:4|6   loss:0.48677682876586914  \n","Epoch:23/30     Step:5|6   loss:0.4871551990509033  \n","Epoch:23/30     Step:6|6   loss:0.48792633414268494  \n","Epoch:23/30     Step:7|6   loss:0.4879691004753113  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48777371644973755  \n","Epoch:24/30     Step:2|6   loss:0.4874436557292938  \n","Epoch:24/30     Step:3|6   loss:0.4874470829963684  \n","Epoch:24/30     Step:4|6   loss:0.48750394582748413  \n","Epoch:24/30     Step:5|6   loss:0.4873284101486206  \n","Epoch:24/30     Step:6|6   loss:0.4881371259689331  \n","Epoch:24/30     Step:7|6   loss:0.4868253469467163  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4875807464122772  \n","Epoch:25/30     Step:2|6   loss:0.4873838722705841  \n","Epoch:25/30     Step:3|6   loss:0.4873690605163574  \n","Epoch:25/30     Step:4|6   loss:0.48747551441192627  \n","Epoch:25/30     Step:5|6   loss:0.48770368099212646  \n","Epoch:25/30     Step:6|6   loss:0.48792076110839844  \n","Epoch:25/30     Step:7|6   loss:0.4875548779964447  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.487567663192749  \n","Epoch:26/30     Step:2|6   loss:0.4884974956512451  \n","Epoch:26/30     Step:3|6   loss:0.48840823769569397  \n","Epoch:26/30     Step:4|6   loss:0.4876292049884796  \n","Epoch:26/30     Step:5|6   loss:0.487771213054657  \n","Epoch:26/30     Step:6|6   loss:0.48725950717926025  \n","Epoch:26/30     Step:7|6   loss:0.4874560534954071  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4869632124900818  \n","Epoch:27/30     Step:2|6   loss:0.48769819736480713  \n","Epoch:27/30     Step:3|6   loss:0.4900780916213989  \n","Epoch:27/30     Step:4|6   loss:0.48766565322875977  \n","Epoch:27/30     Step:5|6   loss:0.48759743571281433  \n","Epoch:27/30     Step:6|6   loss:0.4884556233882904  \n","Epoch:27/30     Step:7|6   loss:0.4879058301448822  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.488058477640152  \n","Epoch:28/30     Step:2|6   loss:0.4880812168121338  \n","Epoch:28/30     Step:3|6   loss:0.4880744218826294  \n","Epoch:28/30     Step:4|6   loss:0.4877825677394867  \n","Epoch:28/30     Step:5|6   loss:0.48780542612075806  \n","Epoch:28/30     Step:6|6   loss:0.4885976016521454  \n","Epoch:28/30     Step:7|6   loss:0.48714959621429443  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4870721399784088  \n","Epoch:29/30     Step:2|6   loss:0.4875227212905884  \n","Epoch:29/30     Step:3|6   loss:0.4875999093055725  \n","Epoch:29/30     Step:4|6   loss:0.48770731687545776  \n","Epoch:29/30     Step:5|6   loss:0.4876773953437805  \n","Epoch:29/30     Step:6|6   loss:0.48797494173049927  \n","Epoch:29/30     Step:7|6   loss:0.488360196352005  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4889650344848633  \n","Epoch:30/30     Step:2|6   loss:0.4877207279205322  \n","Epoch:30/30     Step:3|6   loss:0.4876942038536072  \n","Epoch:30/30     Step:4|6   loss:0.488084614276886  \n","Epoch:30/30     Step:5|6   loss:0.48711034655570984  \n","Epoch:30/30     Step:6|6   loss:0.4874252676963806  \n","Epoch:30/30     Step:7|6   loss:0.48734158277511597  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","4\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.0954270362854004  \n","Epoch:1/30     Step:2|6   loss:0.8716211318969727  \n","Epoch:1/30     Step:3|6   loss:0.6484692692756653  \n","Epoch:1/30     Step:4|6   loss:0.6472518444061279  \n","Epoch:1/30     Step:5|6   loss:0.6508657932281494  \n","Epoch:1/30     Step:6|6   loss:0.5563238263130188  \n","Epoch:1/30     Step:7|6   loss:0.5601828098297119  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 86.65 %\n","current max accuracy\t test set:88.79%\t train set:86.65%\n","Epoch:2/30     Step:1|6   loss:0.631544828414917  \n","Epoch:2/30     Step:2|6   loss:0.5485695600509644  \n","Epoch:2/30     Step:3|6   loss:0.6126080751419067  \n","Epoch:2/30     Step:4|6   loss:0.5433998107910156  \n","Epoch:2/30     Step:5|6   loss:0.542269766330719  \n","Epoch:2/30     Step:6|6   loss:0.5744332075119019  \n","Epoch:2/30     Step:7|6   loss:0.5101468563079834  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:95.33%\t train set:99.53%\n","Epoch:3/30     Step:1|6   loss:0.5235931873321533  \n","Epoch:3/30     Step:2|6   loss:0.5419003963470459  \n","Epoch:3/30     Step:3|6   loss:0.5129714608192444  \n","Epoch:3/30     Step:4|6   loss:0.5179831981658936  \n","Epoch:3/30     Step:5|6   loss:0.5093920826911926  \n","Epoch:3/30     Step:6|6   loss:0.5055996775627136  \n","Epoch:3/30     Step:7|6   loss:0.4998627305030823  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5021643042564392  \n","Epoch:4/30     Step:2|6   loss:0.5039575695991516  \n","Epoch:4/30     Step:3|6   loss:0.5086839199066162  \n","Epoch:4/30     Step:4|6   loss:0.49902960658073425  \n","Epoch:4/30     Step:5|6   loss:0.4986491799354553  \n","Epoch:4/30     Step:6|6   loss:0.495144784450531  \n","Epoch:4/30     Step:7|6   loss:0.5039660930633545  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5025249123573303  \n","Epoch:5/30     Step:2|6   loss:0.495177686214447  \n","Epoch:5/30     Step:3|6   loss:0.49357369542121887  \n","Epoch:5/30     Step:4|6   loss:0.49518638849258423  \n","Epoch:5/30     Step:5|6   loss:0.49777042865753174  \n","Epoch:5/30     Step:6|6   loss:0.49477118253707886  \n","Epoch:5/30     Step:7|6   loss:0.4942200183868408  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49139270186424255  \n","Epoch:6/30     Step:2|6   loss:0.4923053979873657  \n","Epoch:6/30     Step:3|6   loss:0.49362820386886597  \n","Epoch:6/30     Step:4|6   loss:0.4899289608001709  \n","Epoch:6/30     Step:5|6   loss:0.4977301061153412  \n","Epoch:6/30     Step:6|6   loss:0.49592700600624084  \n","Epoch:6/30     Step:7|6   loss:0.490863174200058  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49037081003189087  \n","Epoch:7/30     Step:2|6   loss:0.48960450291633606  \n","Epoch:7/30     Step:3|6   loss:0.4888429641723633  \n","Epoch:7/30     Step:4|6   loss:0.4931752681732178  \n","Epoch:7/30     Step:5|6   loss:0.49045825004577637  \n","Epoch:7/30     Step:6|6   loss:0.48934629559516907  \n","Epoch:7/30     Step:7|6   loss:0.4921901822090149  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49031269550323486  \n","Epoch:8/30     Step:2|6   loss:0.4894562065601349  \n","Epoch:8/30     Step:3|6   loss:0.49045509099960327  \n","Epoch:8/30     Step:4|6   loss:0.48959600925445557  \n","Epoch:8/30     Step:5|6   loss:0.49011892080307007  \n","Epoch:8/30     Step:6|6   loss:0.48977458477020264  \n","Epoch:8/30     Step:7|6   loss:0.4888720214366913  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4918377101421356  \n","Epoch:9/30     Step:2|6   loss:0.49061840772628784  \n","Epoch:9/30     Step:3|6   loss:0.48978227376937866  \n","Epoch:9/30     Step:4|6   loss:0.4883021414279938  \n","Epoch:9/30     Step:5|6   loss:0.4901871383190155  \n","Epoch:9/30     Step:6|6   loss:0.48971372842788696  \n","Epoch:9/30     Step:7|6   loss:0.4901650547981262  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48814213275909424  \n","Epoch:10/30     Step:2|6   loss:0.4896252155303955  \n","Epoch:10/30     Step:3|6   loss:0.48947256803512573  \n","Epoch:10/30     Step:4|6   loss:0.49053484201431274  \n","Epoch:10/30     Step:5|6   loss:0.4886094331741333  \n","Epoch:10/30     Step:6|6   loss:0.4892699718475342  \n","Epoch:10/30     Step:7|6   loss:0.4882117509841919  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4890369176864624  \n","Epoch:11/30     Step:2|6   loss:0.4892769157886505  \n","Epoch:11/30     Step:3|6   loss:0.4885532855987549  \n","Epoch:11/30     Step:4|6   loss:0.48799827694892883  \n","Epoch:11/30     Step:5|6   loss:0.4887147843837738  \n","Epoch:11/30     Step:6|6   loss:0.48967841267585754  \n","Epoch:11/30     Step:7|6   loss:0.4902823567390442  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4880753755569458  \n","Epoch:12/30     Step:2|6   loss:0.4887261986732483  \n","Epoch:12/30     Step:3|6   loss:0.48994460701942444  \n","Epoch:12/30     Step:4|6   loss:0.4887511730194092  \n","Epoch:12/30     Step:5|6   loss:0.48864153027534485  \n","Epoch:12/30     Step:6|6   loss:0.48926183581352234  \n","Epoch:12/30     Step:7|6   loss:0.48949816823005676  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4887898862361908  \n","Epoch:13/30     Step:2|6   loss:0.48915013670921326  \n","Epoch:13/30     Step:3|6   loss:0.4891769289970398  \n","Epoch:13/30     Step:4|6   loss:0.48827534914016724  \n","Epoch:13/30     Step:5|6   loss:0.4889620244503021  \n","Epoch:13/30     Step:6|6   loss:0.4893413782119751  \n","Epoch:13/30     Step:7|6   loss:0.48880061507225037  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48895782232284546  \n","Epoch:14/30     Step:2|6   loss:0.4895530641078949  \n","Epoch:14/30     Step:3|6   loss:0.48954641819000244  \n","Epoch:14/30     Step:4|6   loss:0.48851025104522705  \n","Epoch:14/30     Step:5|6   loss:0.48900720477104187  \n","Epoch:14/30     Step:6|6   loss:0.48966866731643677  \n","Epoch:14/30     Step:7|6   loss:0.48986050486564636  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48853960633277893  \n","Epoch:15/30     Step:2|6   loss:0.48760509490966797  \n","Epoch:15/30     Step:3|6   loss:0.4879474341869354  \n","Epoch:15/30     Step:4|6   loss:0.4884950816631317  \n","Epoch:15/30     Step:5|6   loss:0.48884686827659607  \n","Epoch:15/30     Step:6|6   loss:0.4888247549533844  \n","Epoch:15/30     Step:7|6   loss:0.48690539598464966  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4887663722038269  \n","Epoch:16/30     Step:2|6   loss:0.4893379807472229  \n","Epoch:16/30     Step:3|6   loss:0.4884023070335388  \n","Epoch:16/30     Step:4|6   loss:0.4895879924297333  \n","Epoch:16/30     Step:5|6   loss:0.4889049530029297  \n","Epoch:16/30     Step:6|6   loss:0.48928093910217285  \n","Epoch:16/30     Step:7|6   loss:0.4887728691101074  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48800086975097656  \n","Epoch:17/30     Step:2|6   loss:0.48859912157058716  \n","Epoch:17/30     Step:3|6   loss:0.4897008538246155  \n","Epoch:17/30     Step:4|6   loss:0.4884459674358368  \n","Epoch:17/30     Step:5|6   loss:0.48921215534210205  \n","Epoch:17/30     Step:6|6   loss:0.48839738965034485  \n","Epoch:17/30     Step:7|6   loss:0.4882427752017975  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48807135224342346  \n","Epoch:18/30     Step:2|6   loss:0.4896062910556793  \n","Epoch:18/30     Step:3|6   loss:0.48837822675704956  \n","Epoch:18/30     Step:4|6   loss:0.487739622592926  \n","Epoch:18/30     Step:5|6   loss:0.48933321237564087  \n","Epoch:18/30     Step:6|6   loss:0.4889054000377655  \n","Epoch:18/30     Step:7|6   loss:0.4876561164855957  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4878213405609131  \n","Epoch:19/30     Step:2|6   loss:0.4876905083656311  \n","Epoch:19/30     Step:3|6   loss:0.48936375975608826  \n","Epoch:19/30     Step:4|6   loss:0.488211452960968  \n","Epoch:19/30     Step:5|6   loss:0.48707741498947144  \n","Epoch:19/30     Step:6|6   loss:0.48824456334114075  \n","Epoch:19/30     Step:7|6   loss:0.48747575283050537  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48705166578292847  \n","Epoch:20/30     Step:2|6   loss:0.4877094030380249  \n","Epoch:20/30     Step:3|6   loss:0.4876193106174469  \n","Epoch:20/30     Step:4|6   loss:0.4885483980178833  \n","Epoch:20/30     Step:5|6   loss:0.48793232440948486  \n","Epoch:20/30     Step:6|6   loss:0.48756349086761475  \n","Epoch:20/30     Step:7|6   loss:0.48759326338768005  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48847314715385437  \n","Epoch:21/30     Step:2|6   loss:0.48732390999794006  \n","Epoch:21/30     Step:3|6   loss:0.4876477122306824  \n","Epoch:21/30     Step:4|6   loss:0.48716580867767334  \n","Epoch:21/30     Step:5|6   loss:0.4879847466945648  \n","Epoch:21/30     Step:6|6   loss:0.4876216650009155  \n","Epoch:21/30     Step:7|6   loss:0.48760560154914856  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4883778393268585  \n","Epoch:22/30     Step:2|6   loss:0.48729828000068665  \n","Epoch:22/30     Step:3|6   loss:0.48799824714660645  \n","Epoch:22/30     Step:4|6   loss:0.48779433965682983  \n","Epoch:22/30     Step:5|6   loss:0.4873446524143219  \n","Epoch:22/30     Step:6|6   loss:0.4872705638408661  \n","Epoch:22/30     Step:7|6   loss:0.48757749795913696  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4876112937927246  \n","Epoch:23/30     Step:2|6   loss:0.48750683665275574  \n","Epoch:23/30     Step:3|6   loss:0.4869222939014435  \n","Epoch:23/30     Step:4|6   loss:0.48791685700416565  \n","Epoch:23/30     Step:5|6   loss:0.4874931275844574  \n","Epoch:23/30     Step:6|6   loss:0.488585889339447  \n","Epoch:23/30     Step:7|6   loss:0.48714587092399597  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48766112327575684  \n","Epoch:24/30     Step:2|6   loss:0.4871385097503662  \n","Epoch:24/30     Step:3|6   loss:0.4873453974723816  \n","Epoch:24/30     Step:4|6   loss:0.4877079427242279  \n","Epoch:24/30     Step:5|6   loss:0.4878162741661072  \n","Epoch:24/30     Step:6|6   loss:0.4878188669681549  \n","Epoch:24/30     Step:7|6   loss:0.4874425232410431  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48703402280807495  \n","Epoch:25/30     Step:2|6   loss:0.4879319369792938  \n","Epoch:25/30     Step:3|6   loss:0.4887276291847229  \n","Epoch:25/30     Step:4|6   loss:0.48820316791534424  \n","Epoch:25/30     Step:5|6   loss:0.48768216371536255  \n","Epoch:25/30     Step:6|6   loss:0.4886775314807892  \n","Epoch:25/30     Step:7|6   loss:0.4875483810901642  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.48785868287086487  \n","Epoch:26/30     Step:2|6   loss:0.48781687021255493  \n","Epoch:26/30     Step:3|6   loss:0.4877452850341797  \n","Epoch:26/30     Step:4|6   loss:0.4879853427410126  \n","Epoch:26/30     Step:5|6   loss:0.4875125586986542  \n","Epoch:26/30     Step:6|6   loss:0.4868672490119934  \n","Epoch:26/30     Step:7|6   loss:0.4873981177806854  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4876171052455902  \n","Epoch:27/30     Step:2|6   loss:0.4878593385219574  \n","Epoch:27/30     Step:3|6   loss:0.48744913935661316  \n","Epoch:27/30     Step:4|6   loss:0.4872916042804718  \n","Epoch:27/30     Step:5|6   loss:0.4876950681209564  \n","Epoch:27/30     Step:6|6   loss:0.4881589412689209  \n","Epoch:27/30     Step:7|6   loss:0.48721960186958313  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4868376851081848  \n","Epoch:28/30     Step:2|6   loss:0.4866035282611847  \n","Epoch:28/30     Step:3|6   loss:0.4876462519168854  \n","Epoch:28/30     Step:4|6   loss:0.4880908131599426  \n","Epoch:28/30     Step:5|6   loss:0.4867430031299591  \n","Epoch:28/30     Step:6|6   loss:0.48803281784057617  \n","Epoch:28/30     Step:7|6   loss:0.48728474974632263  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.48789799213409424  \n","Epoch:29/30     Step:2|6   loss:0.4872499406337738  \n","Epoch:29/30     Step:3|6   loss:0.48773393034935  \n","Epoch:29/30     Step:4|6   loss:0.48718732595443726  \n","Epoch:29/30     Step:5|6   loss:0.4873063862323761  \n","Epoch:29/30     Step:6|6   loss:0.4879162907600403  \n","Epoch:29/30     Step:7|6   loss:0.4877697229385376  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4876887798309326  \n","Epoch:30/30     Step:2|6   loss:0.4873608350753784  \n","Epoch:30/30     Step:3|6   loss:0.4875849485397339  \n","Epoch:30/30     Step:4|6   loss:0.4873790144920349  \n","Epoch:30/30     Step:5|6   loss:0.48703068494796753  \n","Epoch:30/30     Step:6|6   loss:0.4872260093688965  \n","Epoch:30/30     Step:7|6   loss:0.4876910448074341  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model VGG16 --mode rgb --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":11,"id":"5ac0898c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1085789203643799  \n","Epoch:1/30     Step:2|6   loss:0.8767662644386292  \n","Epoch:1/30     Step:3|6   loss:0.7352397441864014  \n","Epoch:1/30     Step:4|6   loss:0.8947265148162842  \n","Epoch:1/30     Step:5|6   loss:0.8565703630447388  \n","Epoch:1/30     Step:6|6   loss:0.7143499255180359  \n","Epoch:1/30     Step:7|6   loss:0.7602040767669678  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:87.85%\t train set:91.1%\n","Epoch:2/30     Step:1|6   loss:0.7187626361846924  \n","Epoch:2/30     Step:2|6   loss:0.6406081914901733  \n","Epoch:2/30     Step:3|6   loss:0.6246955394744873  \n","Epoch:2/30     Step:4|6   loss:0.6484163403511047  \n","Epoch:2/30     Step:5|6   loss:0.6184674501419067  \n","Epoch:2/30     Step:6|6   loss:0.6072248220443726  \n","Epoch:2/30     Step:7|6   loss:0.6385135054588318  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:88.79%\t train set:93.21%\n","Epoch:3/30     Step:1|6   loss:0.5519824028015137  \n","Epoch:3/30     Step:2|6   loss:0.5986683368682861  \n","Epoch:3/30     Step:3|6   loss:0.5969358682632446  \n","Epoch:3/30     Step:4|6   loss:0.6025068759918213  \n","Epoch:3/30     Step:5|6   loss:0.562736988067627  \n","Epoch:3/30     Step:6|6   loss:0.5620693564414978  \n","Epoch:3/30     Step:7|6   loss:0.5628275871276855  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:95.33%\t train set:98.59%\n","Epoch:4/30     Step:1|6   loss:0.5361965298652649  \n","Epoch:4/30     Step:2|6   loss:0.5436367392539978  \n","Epoch:4/30     Step:3|6   loss:0.5352574586868286  \n","Epoch:4/30     Step:4|6   loss:0.5349372029304504  \n","Epoch:4/30     Step:5|6   loss:0.5081589221954346  \n","Epoch:4/30     Step:6|6   loss:0.5132914781570435  \n","Epoch:4/30     Step:7|6   loss:0.5322067737579346  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:96.26%\t train set:99.77%\n","Epoch:5/30     Step:1|6   loss:0.5133828520774841  \n","Epoch:5/30     Step:2|6   loss:0.5190240144729614  \n","Epoch:5/30     Step:3|6   loss:0.5228158831596375  \n","Epoch:5/30     Step:4|6   loss:0.5065571069717407  \n","Epoch:5/30     Step:5|6   loss:0.5020642876625061  \n","Epoch:5/30     Step:6|6   loss:0.5069162845611572  \n","Epoch:5/30     Step:7|6   loss:0.5010296106338501  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:6/30     Step:1|6   loss:0.49986350536346436  \n","Epoch:6/30     Step:2|6   loss:0.49615490436553955  \n","Epoch:6/30     Step:3|6   loss:0.496005117893219  \n","Epoch:6/30     Step:4|6   loss:0.4988400936126709  \n","Epoch:6/30     Step:5|6   loss:0.4990183115005493  \n","Epoch:6/30     Step:6|6   loss:0.49246135354042053  \n","Epoch:6/30     Step:7|6   loss:0.4935586452484131  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49861037731170654  \n","Epoch:7/30     Step:2|6   loss:0.4958818852901459  \n","Epoch:7/30     Step:3|6   loss:0.4930844306945801  \n","Epoch:7/30     Step:4|6   loss:0.49536585807800293  \n","Epoch:7/30     Step:5|6   loss:0.49192148447036743  \n","Epoch:7/30     Step:6|6   loss:0.4932604432106018  \n","Epoch:7/30     Step:7|6   loss:0.4983811378479004  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49300599098205566  \n","Epoch:8/30     Step:2|6   loss:0.49355679750442505  \n","Epoch:8/30     Step:3|6   loss:0.49081969261169434  \n","Epoch:8/30     Step:4|6   loss:0.49173450469970703  \n","Epoch:8/30     Step:5|6   loss:0.491876482963562  \n","Epoch:8/30     Step:6|6   loss:0.4921337366104126  \n","Epoch:8/30     Step:7|6   loss:0.4932210445404053  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4922185242176056  \n","Epoch:9/30     Step:2|6   loss:0.4913156032562256  \n","Epoch:9/30     Step:3|6   loss:0.4894586205482483  \n","Epoch:9/30     Step:4|6   loss:0.4911211133003235  \n","Epoch:9/30     Step:5|6   loss:0.49043333530426025  \n","Epoch:9/30     Step:6|6   loss:0.49038439989089966  \n","1Epoch:9/30     Step:7|6   loss:0.489901602268219  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48981761932373047  \n","Epoch:10/30     Step:2|6   loss:0.48903223872184753  \n","Epoch:10/30     Step:3|6   loss:0.4902653098106384  \n","Epoch:10/30     Step:4|6   loss:0.4893283545970917  \n","Epoch:10/30     Step:5|6   loss:0.491501122713089  \n","Epoch:10/30     Step:6|6   loss:0.49064961075782776  \n","Epoch:10/30     Step:7|6   loss:0.4909272789955139  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4889499843120575  \n","\n","Epoch:11/30     Step:2|6   loss:0.48930197954177856  \n","Epoch:11/30     Step:3|6   loss:0.4886125922203064  \n","Epoch:11/30     Step:4|6   loss:0.488374799489975  \n","Epoch:11/30     Step:5|6   loss:0.48894166946411133  \n","Epoch:11/30     Step:6|6   loss:0.4899684488773346  \n","Epoch:11/30     Step:7|6   loss:0.49107834696769714  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4888486862182617  \n","Epoch:12/30     Step:2|6   loss:0.4879548251628876  \n","Epoch:12/30     Step:3|6   loss:0.49023377895355225  \n","Epoch:12/30     Step:4|6   loss:0.48909464478492737  \n","Epoch:12/30     Step:5|6   loss:0.48941096663475037  \n","Epoch:12/30     Step:6|6   loss:0.48877811431884766  \n","Epoch:12/30     Step:7|6   loss:0.4883807897567749  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4884829521179199  \n","Epoch:13/30     Step:2|6   loss:0.48921146988868713  \n","Epoch:13/30     Step:3|6   loss:0.48823657631874084  \n","Epoch:13/30     Step:4|6   loss:0.48789167404174805  \n","Epoch:13/30     Step:5|6   loss:0.48864248394966125  \n","Epoch:13/30     Step:6|6   loss:0.4888494312763214  \n","Epoch:13/30     Step:7|6   loss:0.48990896344184875  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48827144503593445  \n","Epoch:14/30     Step:2|6   loss:0.4886385202407837  \n","Epoch:14/30     Step:3|6   loss:0.4882560074329376  \n","Epoch:14/30     Step:4|6   loss:0.48927509784698486  \n","Epoch:14/30     Step:5|6   loss:0.48836657404899597  \n","Epoch:14/30     Step:6|6   loss:0.48907554149627686  \n","Epoch:14/30     Step:7|6   loss:0.4881943166255951  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48942530155181885  \n","Epoch:15/30     Step:2|6   loss:0.48879706859588623  \n","Epoch:15/30     Step:3|6   loss:0.48865219950675964  \n","Epoch:15/30     Step:4|6   loss:0.4887692928314209  \n","Epoch:15/30     Step:5|6   loss:0.4893674850463867  \n","Epoch:15/30     Step:6|6   loss:0.4887840747833252  \n","Epoch:15/30     Step:7|6   loss:0.48867174983024597  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4883670210838318  \n","Epoch:16/30     Step:2|6   loss:0.488000750541687  \n","Epoch:16/30     Step:3|6   loss:0.48853418231010437  \n","Epoch:16/30     Step:4|6   loss:0.4889972507953644  \n","Epoch:16/30     Step:5|6   loss:0.4875805974006653  \n","Epoch:16/30     Step:6|6   loss:0.48814284801483154  \n","Epoch:16/30     Step:7|6   loss:0.48830902576446533  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4891991913318634  \n","Epoch:17/30     Step:2|6   loss:0.48819682002067566  \n","Epoch:17/30     Step:3|6   loss:0.48766112327575684  \n","Epoch:17/30     Step:4|6   loss:0.4886528551578522  \n","Epoch:17/30     Step:5|6   loss:0.48831906914711  \n","Epoch:17/30     Step:6|6   loss:0.48817354440689087  \n","Epoch:17/30     Step:7|6   loss:0.4875011742115021  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.488602876663208  \n","Epoch:18/30     Step:2|6   loss:0.4884629249572754  \n","Epoch:18/30     Step:3|6   loss:0.4882490336894989  \n","Epoch:18/30     Step:4|6   loss:0.48806294798851013  \n","Epoch:18/30     Step:5|6   loss:0.48788902163505554  \n","Epoch:18/30     Step:6|6   loss:0.48915234208106995  \n","Epoch:18/30     Step:7|6   loss:0.4885222911834717  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4878426492214203  \n","Epoch:19/30     Step:2|6   loss:0.4872434437274933  \n","Epoch:19/30     Step:3|6   loss:0.48815613985061646  \n","Epoch:19/30     Step:4|6   loss:0.488910049200058  \n","Epoch:19/30     Step:5|6   loss:0.4876733422279358  \n","Epoch:19/30     Step:6|6   loss:0.48798543214797974  \n","Epoch:19/30     Step:7|6   loss:0.4887213110923767  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48850223422050476  \n","Epoch:20/30     Step:2|6   loss:0.487444132566452  \n","Epoch:20/30     Step:3|6   loss:0.48760026693344116  \n","Epoch:20/30     Step:4|6   loss:0.48822021484375  \n","Epoch:20/30     Step:5|6   loss:0.489059716463089  \n","Epoch:20/30     Step:6|6   loss:0.48879098892211914  \n","Epoch:20/30     Step:7|6   loss:0.4879394769668579  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48723798990249634  \n","Epoch:21/30     Step:2|6   loss:0.48819488286972046  \n","Epoch:21/30     Step:3|6   loss:0.48894715309143066  \n","Epoch:21/30     Step:4|6   loss:0.4881862998008728  \n","Epoch:21/30     Step:5|6   loss:0.4875587224960327  \n","Epoch:21/30     Step:6|6   loss:0.4877784848213196  \n","Epoch:21/30     Step:7|6   loss:0.48784369230270386  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48783743381500244  \n","Epoch:22/30     Step:2|6   loss:0.48803117871284485  \n","Epoch:22/30     Step:3|6   loss:0.4879978895187378  \n","Epoch:22/30     Step:4|6   loss:0.4877395033836365  \n","Epoch:22/30     Step:5|6   loss:0.48927414417266846  \n","Epoch:22/30     Step:6|6   loss:0.488374799489975  \n","Epoch:22/30     Step:7|6   loss:0.48807916045188904  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48802828788757324  \n","Epoch:23/30     Step:2|6   loss:0.4888383746147156  \n","Epoch:23/30     Step:3|6   loss:0.48701468110084534  \n","Epoch:23/30     Step:4|6   loss:0.4883114993572235  \n","Epoch:23/30     Step:5|6   loss:0.4881657660007477  \n","Epoch:23/30     Step:6|6   loss:0.4878663420677185  \n","Epoch:23/30     Step:7|6   loss:0.48832935094833374  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.487966924905777  \n","Epoch:24/30     Step:2|6   loss:0.48760801553726196  \n","Epoch:24/30     Step:3|6   loss:0.48831307888031006  \n","Epoch:24/30     Step:4|6   loss:0.48888489603996277  \n","Epoch:24/30     Step:5|6   loss:0.4880123436450958  \n","Epoch:24/30     Step:6|6   loss:0.4877642095088959  \n","Epoch:24/30     Step:7|6   loss:0.488987535238266  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4878069758415222  \n","Epoch:25/30     Step:2|6   loss:0.48831069469451904  \n","Epoch:25/30     Step:3|6   loss:0.4874621331691742  \n","Epoch:25/30     Step:4|6   loss:0.487907350063324  \n","Epoch:25/30     Step:5|6   loss:0.4881277084350586  \n","Epoch:25/30     Step:6|6   loss:0.4885312020778656  \n","Epoch:25/30     Step:7|6   loss:0.48745837807655334  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.48812592029571533  \n","Epoch:26/30     Step:2|6   loss:0.48733896017074585  \n","Epoch:26/30     Step:3|6   loss:0.4875764846801758  \n","Epoch:26/30     Step:4|6   loss:0.48758408427238464  \n","Epoch:26/30     Step:5|6   loss:0.488878458738327  \n","Epoch:26/30     Step:6|6   loss:0.48862388730049133  \n","Epoch:26/30     Step:7|6   loss:0.4873313307762146  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48741960525512695  \n","Epoch:27/30     Step:2|6   loss:0.48800110816955566  \n","Epoch:27/30     Step:3|6   loss:0.4874841570854187  \n","Epoch:27/30     Step:4|6   loss:0.4872561991214752  \n","Epoch:27/30     Step:5|6   loss:0.48766982555389404  \n","Epoch:27/30     Step:6|6   loss:0.48824647068977356  \n","Epoch:27/30     Step:7|6   loss:0.488165020942688  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4875786006450653  \n","Epoch:28/30     Step:2|6   loss:0.48757630586624146  \n","Epoch:28/30     Step:3|6   loss:0.48775917291641235  \n","Epoch:28/30     Step:4|6   loss:0.48782339692115784  \n","Epoch:28/30     Step:5|6   loss:0.48746833205223083  \n","Epoch:28/30     Step:6|6   loss:0.4876343309879303  \n","Epoch:28/30     Step:7|6   loss:0.4871780276298523  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4881535470485687  \n","Epoch:29/30     Step:2|6   loss:0.4883011281490326  \n","Epoch:29/30     Step:3|6   loss:0.4875850975513458  \n","Epoch:29/30     Step:4|6   loss:0.4874707758426666  \n","Epoch:29/30     Step:5|6   loss:0.4877634048461914  \n","Epoch:29/30     Step:6|6   loss:0.48707160353660583  \n","Epoch:29/30     Step:7|6   loss:0.4875267446041107  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4880253076553345  \n","Epoch:30/30     Step:2|6   loss:0.4875543415546417  \n","Epoch:30/30     Step:3|6   loss:0.4874672591686249  \n","Epoch:30/30     Step:4|6   loss:0.48827362060546875  \n","Epoch:30/30     Step:5|6   loss:0.488517165184021  \n","Epoch:30/30     Step:6|6   loss:0.4871829152107239  \n","Epoch:30/30     Step:7|6   loss:0.48814162611961365  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1002681255340576  \n","Epoch:1/30     Step:2|6   loss:0.8889096975326538  \n","Epoch:1/30     Step:3|6   loss:0.7725638151168823  \n","Epoch:1/30     Step:4|6   loss:0.6593449115753174  \n","Epoch:1/30     Step:5|6   loss:0.650119423866272  \n","Epoch:1/30     Step:6|6   loss:0.6498652100563049  \n","Epoch:1/30     Step:7|6   loss:0.7349398732185364  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:87.85%\t train set:90.63%\n","Epoch:2/30     Step:1|6   loss:0.6497923135757446  \n","Epoch:2/30     Step:2|6   loss:0.581963300704956  \n","Epoch:2/30     Step:3|6   loss:0.6326439380645752  \n","Epoch:2/30     Step:4|6   loss:0.5879960656166077  \n","Epoch:2/30     Step:5|6   loss:0.5419933795928955  \n","Epoch:2/30     Step:6|6   loss:0.6249157786369324  \n","Epoch:2/30     Step:7|6   loss:0.5365269184112549  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:94.39%\t train set:98.13%\n","Epoch:3/30     Step:1|6   loss:0.548297643661499  \n","Epoch:3/30     Step:2|6   loss:0.5154767036437988  \n","Epoch:3/30     Step:3|6   loss:0.5232056975364685  \n","Epoch:3/30     Step:4|6   loss:0.5484676957130432  \n","Epoch:3/30     Step:5|6   loss:0.5185844302177429  \n","Epoch:3/30     Step:6|6   loss:0.524591326713562  \n","Epoch:3/30     Step:7|6   loss:0.5137815475463867  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:96.26%\t train set:99.53%\n","Epoch:4/30     Step:1|6   loss:0.5165513753890991  \n","Epoch:4/30     Step:2|6   loss:0.5119869709014893  \n","Epoch:4/30     Step:3|6   loss:0.506476104259491  \n","Epoch:4/30     Step:4|6   loss:0.5116097927093506  \n","Epoch:4/30     Step:5|6   loss:0.5234827399253845  \n","Epoch:4/30     Step:6|6   loss:0.5161389112472534  \n","Epoch:4/30     Step:7|6   loss:0.5130728483200073  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5095081925392151  \n","Epoch:5/30     Step:2|6   loss:0.5071369409561157  \n","Epoch:5/30     Step:3|6   loss:0.5084959864616394  \n","Epoch:5/30     Step:4|6   loss:0.5063611268997192  \n","Epoch:5/30     Step:5|6   loss:0.5044906139373779  \n","Epoch:5/30     Step:6|6   loss:0.5049508213996887  \n","Epoch:5/30     Step:7|6   loss:0.508979320526123  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5024919509887695  \n","Epoch:6/30     Step:2|6   loss:0.5003926753997803  \n","Epoch:6/30     Step:3|6   loss:0.505882740020752  \n","Epoch:6/30     Step:4|6   loss:0.5042126774787903  \n","Epoch:6/30     Step:5|6   loss:0.5008512735366821  \n","Epoch:6/30     Step:6|6   loss:0.49510443210601807  \n","Epoch:6/30     Step:7|6   loss:0.5002117156982422  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.503877580165863  \n","Epoch:7/30     Step:2|6   loss:0.49698472023010254  \n","Epoch:7/30     Step:3|6   loss:0.4938846230506897  \n","Epoch:7/30     Step:4|6   loss:0.49160537123680115  \n","Epoch:7/30     Step:5|6   loss:0.4996548891067505  \n","Epoch:7/30     Step:6|6   loss:0.5003630518913269  \n","Epoch:7/30     Step:7|6   loss:0.5002182722091675  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.48998159170150757  \n","Epoch:8/30     Step:2|6   loss:0.4906727373600006  \n","Epoch:8/30     Step:3|6   loss:0.4946659505367279  \n","Epoch:8/30     Step:4|6   loss:0.4948965609073639  \n","Epoch:8/30     Step:5|6   loss:0.49168112874031067  \n","Epoch:8/30     Step:6|6   loss:0.4935385584831238  \n","Epoch:8/30     Step:7|6   loss:0.4901963174343109  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49151062965393066  \n","Epoch:9/30     Step:2|6   loss:0.4905397295951843  \n","Epoch:9/30     Step:3|6   loss:0.4912256598472595  \n","Epoch:9/30     Step:4|6   loss:0.491472452878952  \n","Epoch:9/30     Step:5|6   loss:0.4905131161212921  \n","Epoch:9/30     Step:6|6   loss:0.4929630160331726  \n","Epoch:9/30     Step:7|6   loss:0.4904598295688629  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49046480655670166  \n","Epoch:10/30     Step:2|6   loss:0.491970956325531  \n","Epoch:10/30     Step:3|6   loss:0.49119889736175537  \n","Epoch:10/30     Step:4|6   loss:0.48940402269363403  \n","Epoch:10/30     Step:5|6   loss:0.4895699620246887  \n","Epoch:10/30     Step:6|6   loss:0.4897508919239044  \n","Epoch:10/30     Step:7|6   loss:0.48917099833488464  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4884704053401947  \n","Epoch:11/30     Step:2|6   loss:0.4890952706336975  \n","Epoch:11/30     Step:3|6   loss:0.48985767364501953  \n","Epoch:11/30     Step:4|6   loss:0.4894911050796509  \n","Epoch:11/30     Step:5|6   loss:0.4886949062347412  \n","Epoch:11/30     Step:6|6   loss:0.48890620470046997  \n","Epoch:11/30     Step:7|6   loss:0.4877268970012665  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48796963691711426  \n","Epoch:12/30     Step:2|6   loss:0.4882967472076416  \n","Epoch:12/30     Step:3|6   loss:0.4884684085845947  \n","Epoch:12/30     Step:4|6   loss:0.4885476529598236  \n","Epoch:12/30     Step:5|6   loss:0.48842766880989075  \n","Epoch:12/30     Step:6|6   loss:0.4889475405216217  \n","Epoch:12/30     Step:7|6   loss:0.49087685346603394  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4899260401725769  \n","Epoch:13/30     Step:2|6   loss:0.48886680603027344  \n","Epoch:13/30     Step:3|6   loss:0.4890977442264557  \n","Epoch:13/30     Step:4|6   loss:0.4894615709781647  \n","Epoch:13/30     Step:5|6   loss:0.4885191023349762  \n","Epoch:13/30     Step:6|6   loss:0.4882231652736664  \n","Epoch:13/30     Step:7|6   loss:0.4888092279434204  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4894876778125763  \n","Epoch:14/30     Step:2|6   loss:0.48934105038642883  \n","Epoch:14/30     Step:3|6   loss:0.4880051016807556  \n","Epoch:14/30     Step:4|6   loss:0.48804521560668945  \n","Epoch:14/30     Step:5|6   loss:0.48805341124534607  \n","Epoch:14/30     Step:6|6   loss:0.48802101612091064  \n","Epoch:14/30     Step:7|6   loss:0.48902827501296997  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4884490370750427  \n","Epoch:15/30     Step:2|6   loss:0.48878148198127747  \n","Epoch:15/30     Step:3|6   loss:0.4887889623641968  \n","Epoch:15/30     Step:4|6   loss:0.48941320180892944  \n","Epoch:15/30     Step:5|6   loss:0.4889134466648102  \n","Epoch:15/30     Step:6|6   loss:0.4887172281742096  \n","Epoch:15/30     Step:7|6   loss:0.48740553855895996  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4891752600669861  \n","Epoch:16/30     Step:2|6   loss:0.48767274618148804  \n","Epoch:16/30     Step:3|6   loss:0.4883001446723938  \n","Epoch:16/30     Step:4|6   loss:0.48836931586265564  \n","Epoch:16/30     Step:5|6   loss:0.48732027411460876  \n","Epoch:16/30     Step:6|6   loss:0.48938530683517456  \n","Epoch:16/30     Step:7|6   loss:0.48802393674850464  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48834913969039917  \n","Epoch:17/30     Step:2|6   loss:0.48797011375427246  \n","Epoch:17/30     Step:3|6   loss:0.48758000135421753  \n","Epoch:17/30     Step:4|6   loss:0.4878282845020294  \n","Epoch:17/30     Step:5|6   loss:0.4886966347694397  \n","Epoch:17/30     Step:6|6   loss:0.48823678493499756  \n","Epoch:17/30     Step:7|6   loss:0.48837774991989136  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48823583126068115  \n","Epoch:18/30     Step:2|6   loss:0.48812851309776306  \n","Epoch:18/30     Step:3|6   loss:0.48749569058418274  \n","Epoch:18/30     Step:4|6   loss:0.48799818754196167  \n","Epoch:18/30     Step:5|6   loss:0.488137811422348  \n","Epoch:18/30     Step:6|6   loss:0.4880818724632263  \n","Epoch:18/30     Step:7|6   loss:0.48860815167427063  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","2\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:19/30     Step:1|6   loss:0.4878179728984833  \n","Epoch:19/30     Step:2|6   loss:0.48871833086013794  \n","Epoch:19/30     Step:3|6   loss:0.4878244400024414  \n","Epoch:19/30     Step:4|6   loss:0.4883803427219391  \n","Epoch:19/30     Step:5|6   loss:0.4887179136276245  \n","Epoch:19/30     Step:6|6   loss:0.4871184229850769  \n","Epoch:19/30     Step:7|6   loss:0.4883320927619934  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48862501978874207  \n","Epoch:20/30     Step:2|6   loss:0.4879276156425476  \n","Epoch:20/30     Step:3|6   loss:0.48775196075439453  \n","Epoch:20/30     Step:4|6   loss:0.48857420682907104  \n","Epoch:20/30     Step:5|6   loss:0.48820292949676514  \n","Epoch:20/30     Step:6|6   loss:0.4882562756538391  \n","Epoch:20/30     Step:7|6   loss:0.48754727840423584  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4882533550262451  \n","Epoch:21/30     Step:2|6   loss:0.4872915744781494  \n","Epoch:21/30     Step:3|6   loss:0.48762017488479614  \n","Epoch:21/30     Step:4|6   loss:0.4878219962120056  \n","Epoch:21/30     Step:5|6   loss:0.4872414767742157  \n","Epoch:21/30     Step:6|6   loss:0.48840776085853577  \n","Epoch:21/30     Step:7|6   loss:0.48813778162002563  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48836585879325867  \n","Epoch:22/30     Step:2|6   loss:0.4873354136943817  \n","Epoch:22/30     Step:3|6   loss:0.4878418445587158  \n","Epoch:22/30     Step:4|6   loss:0.4873526096343994  \n","Epoch:22/30     Step:5|6   loss:0.4869963526725769  \n","Epoch:22/30     Step:6|6   loss:0.4883369207382202  \n","Epoch:22/30     Step:7|6   loss:0.48768219351768494  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.487745463848114  \n","Epoch:23/30     Step:2|6   loss:0.4883166551589966  \n","Epoch:23/30     Step:3|6   loss:0.48723581433296204  \n","Epoch:23/30     Step:4|6   loss:0.4880272150039673  \n","Epoch:23/30     Step:5|6   loss:0.48788487911224365  \n","Epoch:23/30     Step:6|6   loss:0.4881034195423126  \n","Epoch:23/30     Step:7|6   loss:0.48710912466049194  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48758184909820557  \n","Epoch:24/30     Step:2|6   loss:0.48781999945640564  \n","Epoch:24/30     Step:3|6   loss:0.48770833015441895  \n","Epoch:24/30     Step:4|6   loss:0.4880187511444092  \n","Epoch:24/30     Step:5|6   loss:0.48954153060913086  \n","Epoch:24/30     Step:6|6   loss:0.48769909143447876  \n","Epoch:24/30     Step:7|6   loss:0.48741695284843445  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48788681626319885  \n","Epoch:25/30     Step:2|6   loss:0.4880615472793579  \n","Epoch:25/30     Step:3|6   loss:0.48828259110450745  \n","Epoch:25/30     Step:4|6   loss:0.48750099539756775  \n","Epoch:25/30     Step:5|6   loss:0.48829448223114014  \n","Epoch:25/30     Step:6|6   loss:0.4881032109260559  \n","Epoch:25/30     Step:7|6   loss:0.48845401406288147  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4882580637931824  \n","Epoch:26/30     Step:2|6   loss:0.4886065423488617  \n","Epoch:26/30     Step:3|6   loss:0.4875202178955078  \n","Epoch:26/30     Step:4|6   loss:0.4875911772251129  \n","Epoch:26/30     Step:5|6   loss:0.4872457683086395  \n","Epoch:26/30     Step:6|6   loss:0.48798227310180664  \n","Epoch:26/30     Step:7|6   loss:0.4889069199562073  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4880719780921936  \n","Epoch:27/30     Step:2|6   loss:0.48753616213798523  \n","Epoch:27/30     Step:3|6   loss:0.4877178370952606  \n","Epoch:27/30     Step:4|6   loss:0.4880845546722412  \n","Epoch:27/30     Step:5|6   loss:0.4884067177772522  \n","Epoch:27/30     Step:6|6   loss:0.48836079239845276  \n","Epoch:27/30     Step:7|6   loss:0.4886106550693512  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.487016886472702  \n","Epoch:28/30     Step:2|6   loss:0.4883604347705841  \n","Epoch:28/30     Step:3|6   loss:0.4876108169555664  \n","Epoch:28/30     Step:4|6   loss:0.48722150921821594  \n","Epoch:28/30     Step:5|6   loss:0.48867154121398926  \n","Epoch:28/30     Step:6|6   loss:0.48754194378852844  \n","Epoch:28/30     Step:7|6   loss:0.48729515075683594  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4884718656539917  \n","Epoch:29/30     Step:2|6   loss:0.4876628518104553  \n","Epoch:29/30     Step:3|6   loss:0.48803776502609253  \n","Epoch:29/30     Step:4|6   loss:0.4872637987136841  \n","Epoch:29/30     Step:5|6   loss:0.4885892868041992  \n","Epoch:29/30     Step:6|6   loss:0.4878617823123932  \n","Epoch:29/30     Step:7|6   loss:0.4882267415523529  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.48877623677253723  \n","Epoch:30/30     Step:2|6   loss:0.48700565099716187  \n","Epoch:30/30     Step:3|6   loss:0.487962543964386  \n","Epoch:30/30     Step:4|6   loss:0.4873397648334503  \n","Epoch:30/30     Step:5|6   loss:0.4879913032054901  \n","Epoch:30/30     Step:6|6   loss:0.4883585274219513  \n","Epoch:30/30     Step:7|6   loss:0.4885518550872803  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1362115144729614  \n","Epoch:1/30     Step:2|6   loss:0.9457935690879822  \n","Epoch:1/30     Step:3|6   loss:0.8887797594070435  \n","Epoch:1/30     Step:4|6   loss:0.7495875954627991  \n","Epoch:1/30     Step:5|6   loss:0.6604477763175964  \n","Epoch:1/30     Step:6|6   loss:0.695847749710083  \n","Epoch:1/30     Step:7|6   loss:0.6625924110412598  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:94.39%\t train set:93.44%\n","Epoch:2/30     Step:1|6   loss:0.6387538313865662  \n","Epoch:2/30     Step:2|6   loss:0.6078391075134277  \n","Epoch:2/30     Step:3|6   loss:0.6553379893302917  \n","Epoch:2/30     Step:4|6   loss:0.5894401669502258  \n","Epoch:2/30     Step:5|6   loss:0.5686757564544678  \n","Epoch:2/30     Step:6|6   loss:0.6010733842849731  \n","Epoch:2/30     Step:7|6   loss:0.5901148915290833  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:94.39%\t train set:96.72%\n","Epoch:3/30     Step:1|6   loss:0.5706676244735718  \n","Epoch:3/30     Step:2|6   loss:0.5533673763275146  \n","Epoch:3/30     Step:3|6   loss:0.5430974960327148  \n","Epoch:3/30     Step:4|6   loss:0.5598207116127014  \n","Epoch:3/30     Step:5|6   loss:0.5356690883636475  \n","Epoch:3/30     Step:6|6   loss:0.5149045586585999  \n","Epoch:3/30     Step:7|6   loss:0.5188668966293335  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5164197087287903  \n","Epoch:4/30     Step:2|6   loss:0.5157477855682373  \n","Epoch:4/30     Step:3|6   loss:0.5124667882919312  \n","Epoch:4/30     Step:4|6   loss:0.5061579942703247  \n","Epoch:4/30     Step:5|6   loss:0.5024491548538208  \n","Epoch:4/30     Step:6|6   loss:0.5079846978187561  \n","Epoch:4/30     Step:7|6   loss:0.5365714430809021  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5029982924461365  \n","Epoch:5/30     Step:2|6   loss:0.5035991668701172  \n","Epoch:5/30     Step:3|6   loss:0.5025990009307861  \n","Epoch:5/30     Step:4|6   loss:0.5009593963623047  \n","Epoch:5/30     Step:5|6   loss:0.4995119869709015  \n","Epoch:5/30     Step:6|6   loss:0.49713385105133057  \n","Epoch:5/30     Step:7|6   loss:0.5065420866012573  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4961426556110382  \n","Epoch:6/30     Step:2|6   loss:0.49287042021751404  \n","Epoch:6/30     Step:3|6   loss:0.4937977194786072  \n","Epoch:6/30     Step:4|6   loss:0.493191123008728  \n","Epoch:6/30     Step:5|6   loss:0.49933135509490967  \n","Epoch:6/30     Step:6|6   loss:0.4977695941925049  \n","Epoch:6/30     Step:7|6   loss:0.4945574700832367  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4930051267147064  \n","Epoch:7/30     Step:2|6   loss:0.49266311526298523  \n","Epoch:7/30     Step:3|6   loss:0.492545485496521  \n","Epoch:7/30     Step:4|6   loss:0.4928535223007202  \n","Epoch:7/30     Step:5|6   loss:0.4894865155220032  \n","Epoch:7/30     Step:6|6   loss:0.49031734466552734  \n","Epoch:7/30     Step:7|6   loss:0.4896172285079956  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4911639392375946  \n","Epoch:8/30     Step:2|6   loss:0.49133822321891785  \n","Epoch:8/30     Step:3|6   loss:0.4900810420513153  \n","Epoch:8/30     Step:4|6   loss:0.49076294898986816  \n","Epoch:8/30     Step:5|6   loss:0.4907561242580414  \n","Epoch:8/30     Step:6|6   loss:0.4899028539657593  \n","Epoch:8/30     Step:7|6   loss:0.49201545119285583  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.490028440952301  \n","Epoch:9/30     Step:2|6   loss:0.488837867975235  \n","Epoch:9/30     Step:3|6   loss:0.49116289615631104  \n","Epoch:9/30     Step:4|6   loss:0.490129292011261  \n","Epoch:9/30     Step:5|6   loss:0.493496835231781  \n","Epoch:9/30     Step:6|6   loss:0.488694429397583  \n","Epoch:9/30     Step:7|6   loss:0.490715354681015  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4894879460334778  \n","Epoch:10/30     Step:2|6   loss:0.490479439496994  \n","Epoch:10/30     Step:3|6   loss:0.48921775817871094  \n","Epoch:10/30     Step:4|6   loss:0.4898286461830139  \n","Epoch:10/30     Step:5|6   loss:0.489712655544281  \n","Epoch:10/30     Step:6|6   loss:0.4895934462547302  \n","Epoch:10/30     Step:7|6   loss:0.4891548454761505  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4902781546115875  \n","Epoch:11/30     Step:2|6   loss:0.4903337359428406  \n","Epoch:11/30     Step:3|6   loss:0.48872077465057373  \n","Epoch:11/30     Step:4|6   loss:0.4885762631893158  \n","Epoch:11/30     Step:5|6   loss:0.4896242618560791  \n","Epoch:11/30     Step:6|6   loss:0.48965132236480713  \n","Epoch:11/30     Step:7|6   loss:0.4898449182510376  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48920726776123047  \n","Epoch:12/30     Step:2|6   loss:0.49031323194503784  \n","Epoch:12/30     Step:3|6   loss:0.48845264315605164  \n","Epoch:12/30     Step:4|6   loss:0.49014127254486084  \n","Epoch:12/30     Step:5|6   loss:0.4905858039855957  \n","Epoch:12/30     Step:6|6   loss:0.48834964632987976  \n","Epoch:12/30     Step:7|6   loss:0.48939546942710876  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4890463948249817  \n","Epoch:13/30     Step:2|6   loss:0.4881928563117981  \n","Epoch:13/30     Step:3|6   loss:0.489183634519577  \n","Epoch:13/30     Step:4|6   loss:0.48890766501426697  \n","Epoch:13/30     Step:5|6   loss:0.4885184168815613  \n","Epoch:13/30     Step:6|6   loss:0.48812854290008545  \n","Epoch:13/30     Step:7|6   loss:0.48788461089134216  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48844534158706665  \n","Epoch:14/30     Step:2|6   loss:0.49071836471557617  \n","Epoch:14/30     Step:3|6   loss:0.4884302616119385  \n","Epoch:14/30     Step:4|6   loss:0.4893861413002014  \n","Epoch:14/30     Step:5|6   loss:0.4888460040092468  \n","Epoch:14/30     Step:6|6   loss:0.48803824186325073  \n","Epoch:14/30     Step:7|6   loss:0.48824870586395264  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4885786175727844  \n","Epoch:15/30     Step:2|6   loss:0.4882006049156189  \n","Epoch:15/30     Step:3|6   loss:0.4877796173095703  \n","Epoch:15/30     Step:4|6   loss:0.4889187514781952  \n","Epoch:15/30     Step:5|6   loss:0.4882040023803711  \n","Epoch:15/30     Step:6|6   loss:0.48751574754714966  \n","Epoch:15/30     Step:7|6   loss:0.48769742250442505  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.488659143447876  \n","Epoch:16/30     Step:2|6   loss:0.48877567052841187  \n","Epoch:16/30     Step:3|6   loss:0.4875427484512329  \n","Epoch:16/30     Step:4|6   loss:0.4880712330341339  \n","Epoch:16/30     Step:5|6   loss:0.4879753887653351  \n","Epoch:16/30     Step:6|6   loss:0.48851338028907776  \n","Epoch:16/30     Step:7|6   loss:0.4878423810005188  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4885851740837097  \n","Epoch:17/30     Step:2|6   loss:0.4883713722229004  \n","Epoch:17/30     Step:3|6   loss:0.48855000734329224  \n","Epoch:17/30     Step:4|6   loss:0.48799455165863037  \n","Epoch:17/30     Step:5|6   loss:0.487379252910614  \n","Epoch:17/30     Step:6|6   loss:0.48888203501701355  \n","Epoch:17/30     Step:7|6   loss:0.4877370595932007  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48851609230041504  \n","Epoch:18/30     Step:2|6   loss:0.4881840944290161  \n","Epoch:18/30     Step:3|6   loss:0.4892696738243103  \n","Epoch:18/30     Step:4|6   loss:0.48763206601142883  \n","Epoch:18/30     Step:5|6   loss:0.488311767578125  \n","Epoch:18/30     Step:6|6   loss:0.48807036876678467  \n","Epoch:18/30     Step:7|6   loss:0.48852860927581787  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.48868003487586975  \n","Epoch:19/30     Step:2|6   loss:0.48788130283355713  \n","Epoch:19/30     Step:3|6   loss:0.48859238624572754  \n","Epoch:19/30     Step:4|6   loss:0.48967140913009644  \n","Epoch:19/30     Step:5|6   loss:0.48807358741760254  \n","Epoch:19/30     Step:6|6   loss:0.48788100481033325  \n","Epoch:19/30     Step:7|6   loss:0.4881080687046051  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4883365035057068  \n","Epoch:20/30     Step:2|6   loss:0.48846670985221863  \n","Epoch:20/30     Step:3|6   loss:0.48695242404937744  \n","Epoch:20/30     Step:4|6   loss:0.48709583282470703  \n","Epoch:20/30     Step:5|6   loss:0.4882770776748657  \n","Epoch:20/30     Step:6|6   loss:0.48803770542144775  \n","Epoch:20/30     Step:7|6   loss:0.4873895049095154  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48731815814971924  \n","Epoch:21/30     Step:2|6   loss:0.487322062253952  \n","Epoch:21/30     Step:3|6   loss:0.48826533555984497  \n","Epoch:21/30     Step:4|6   loss:0.48860201239585876  \n","Epoch:21/30     Step:5|6   loss:0.4881598651409149  \n","Epoch:21/30     Step:6|6   loss:0.4878399670124054  \n","Epoch:21/30     Step:7|6   loss:0.4894092082977295  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48833924531936646  \n","Epoch:22/30     Step:2|6   loss:0.48733043670654297  \n","Epoch:22/30     Step:3|6   loss:0.48859840631484985  \n","Epoch:22/30     Step:4|6   loss:0.48777690529823303  \n","Epoch:22/30     Step:5|6   loss:0.48719415068626404  \n","Epoch:22/30     Step:6|6   loss:0.4872135818004608  \n","Epoch:22/30     Step:7|6   loss:0.48774629831314087  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48868730664253235  \n","Epoch:23/30     Step:2|6   loss:0.48748254776000977  \n","Epoch:23/30     Step:3|6   loss:0.4877323806285858  \n","Epoch:23/30     Step:4|6   loss:0.4877074956893921  \n","Epoch:23/30     Step:5|6   loss:0.489236980676651  \n","Epoch:23/30     Step:6|6   loss:0.4867015779018402  \n","Epoch:23/30     Step:7|6   loss:0.4872789978981018  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4874453544616699  \n","Epoch:24/30     Step:2|6   loss:0.4882797598838806  \n","Epoch:24/30     Step:3|6   loss:0.4881160259246826  \n","Epoch:24/30     Step:4|6   loss:0.4872146248817444  \n","Epoch:24/30     Step:5|6   loss:0.4873192012310028  \n","Epoch:24/30     Step:6|6   loss:0.48788556456565857  \n","Epoch:24/30     Step:7|6   loss:0.4883676767349243  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4871908128261566  \n","Epoch:25/30     Step:2|6   loss:0.4877534508705139  \n","Epoch:25/30     Step:3|6   loss:0.4882684051990509  \n","Epoch:25/30     Step:4|6   loss:0.48797306418418884  \n","Epoch:25/30     Step:5|6   loss:0.48781144618988037  \n","Epoch:25/30     Step:6|6   loss:0.4868483245372772  \n","Epoch:25/30     Step:7|6   loss:0.48936542868614197  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4889391362667084  \n","Epoch:26/30     Step:2|6   loss:0.48783591389656067  \n","Epoch:26/30     Step:3|6   loss:0.48751774430274963  \n","Epoch:26/30     Step:4|6   loss:0.488162636756897  \n","Epoch:26/30     Step:5|6   loss:0.48830851912498474  \n","Epoch:26/30     Step:6|6   loss:0.488399475812912  \n","Epoch:26/30     Step:7|6   loss:0.4877198338508606  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48705753684043884  \n","Epoch:27/30     Step:2|6   loss:0.48792874813079834  \n","Epoch:27/30     Step:3|6   loss:0.48783087730407715  \n","Epoch:27/30     Step:4|6   loss:0.4882873594760895  \n","Epoch:27/30     Step:5|6   loss:0.4874832034111023  \n","Epoch:27/30     Step:6|6   loss:0.4882332384586334  \n","Epoch:27/30     Step:7|6   loss:0.48947417736053467  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.487385094165802  \n","Epoch:28/30     Step:2|6   loss:0.48740246891975403  \n","Epoch:28/30     Step:3|6   loss:0.4878299832344055  \n","Epoch:28/30     Step:4|6   loss:0.48895180225372314  \n","Epoch:28/30     Step:5|6   loss:0.4871155619621277  \n","Epoch:28/30     Step:6|6   loss:0.4877394735813141  \n","Epoch:28/30     Step:7|6   loss:0.4890437126159668  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.48918864130973816  \n","Epoch:29/30     Step:2|6   loss:0.48722952604293823  \n","Epoch:29/30     Step:3|6   loss:0.4875132143497467  \n","Epoch:29/30     Step:4|6   loss:0.48787519335746765  \n","Epoch:29/30     Step:5|6   loss:0.48893967270851135  \n","Epoch:29/30     Step:6|6   loss:0.48775652050971985  \n","Epoch:29/30     Step:7|6   loss:0.4879520535469055  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4890660047531128  \n","Epoch:30/30     Step:2|6   loss:0.4877154231071472  \n","Epoch:30/30     Step:3|6   loss:0.4892324209213257  \n","Epoch:30/30     Step:4|6   loss:0.48792028427124023  \n","Epoch:30/30     Step:5|6   loss:0.48855024576187134  \n","Epoch:30/30     Step:6|6   loss:0.4893116354942322  \n","Epoch:30/30     Step:7|6   loss:0.48810702562332153  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","3\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.0847734212875366  \n","Epoch:1/30     Step:2|6   loss:0.8569612503051758  \n","Epoch:1/30     Step:3|6   loss:0.8397723436355591  \n","Epoch:1/30     Step:4|6   loss:0.6712250113487244  \n","Epoch:1/30     Step:5|6   loss:0.659358561038971  \n","Epoch:1/30     Step:6|6   loss:0.6447992324829102  \n","Epoch:1/30     Step:7|6   loss:0.6641026139259338  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:89.72%\t train set:91.57%\n","Epoch:2/30     Step:1|6   loss:0.6602175235748291  \n","Epoch:2/30     Step:2|6   loss:0.5926305055618286  \n","Epoch:2/30     Step:3|6   loss:0.5899017453193665  \n","Epoch:2/30     Step:4|6   loss:0.5714616775512695  \n","Epoch:2/30     Step:5|6   loss:0.5768412947654724  \n","Epoch:2/30     Step:6|6   loss:0.5621031522750854  \n","Epoch:2/30     Step:7|6   loss:0.5621808171272278  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:95.33%\t train set:98.83%\n","Epoch:3/30     Step:1|6   loss:0.5301473140716553  \n","Epoch:3/30     Step:2|6   loss:0.5442915558815002  \n","Epoch:3/30     Step:3|6   loss:0.5218684077262878  \n","Epoch:3/30     Step:4|6   loss:0.5070557594299316  \n","Epoch:3/30     Step:5|6   loss:0.5192040801048279  \n","Epoch:3/30     Step:6|6   loss:0.5307899713516235  \n","Epoch:3/30     Step:7|6   loss:0.5178163647651672  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5068919658660889  \n","Epoch:4/30     Step:2|6   loss:0.5078139305114746  \n","Epoch:4/30     Step:3|6   loss:0.5018789172172546  \n","Epoch:4/30     Step:4|6   loss:0.509279191493988  \n","Epoch:4/30     Step:5|6   loss:0.5148545503616333  \n","Epoch:4/30     Step:6|6   loss:0.5037301778793335  \n","Epoch:4/30     Step:7|6   loss:0.4986424446105957  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5010027289390564  \n","Epoch:5/30     Step:2|6   loss:0.5076063275337219  \n","Epoch:5/30     Step:3|6   loss:0.5008275508880615  \n","Epoch:5/30     Step:4|6   loss:0.49804067611694336  \n","Epoch:5/30     Step:5|6   loss:0.49637728929519653  \n","Epoch:5/30     Step:6|6   loss:0.5008670091629028  \n","Epoch:5/30     Step:7|6   loss:0.5035073161125183  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4970463514328003  \n","Epoch:6/30     Step:2|6   loss:0.494972288608551  \n","Epoch:6/30     Step:3|6   loss:0.4974272847175598  \n","Epoch:6/30     Step:4|6   loss:0.49477455019950867  \n","Epoch:6/30     Step:5|6   loss:0.4934588670730591  \n","Epoch:6/30     Step:6|6   loss:0.49257177114486694  \n","Epoch:6/30     Step:7|6   loss:0.4919719696044922  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4931104779243469  \n","Epoch:7/30     Step:2|6   loss:0.4926416277885437  \n","Epoch:7/30     Step:3|6   loss:0.4926217496395111  \n","Epoch:7/30     Step:4|6   loss:0.49315983057022095  \n","Epoch:7/30     Step:5|6   loss:0.49129408597946167  \n","Epoch:7/30     Step:6|6   loss:0.4903850555419922  \n","Epoch:7/30     Step:7|6   loss:0.4930320680141449  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4913673400878906  \n","Epoch:8/30     Step:2|6   loss:0.49241718649864197  \n","Epoch:8/30     Step:3|6   loss:0.4907899498939514  \n","Epoch:8/30     Step:4|6   loss:0.491299569606781  \n","Epoch:8/30     Step:5|6   loss:0.4945237934589386  \n","Epoch:8/30     Step:6|6   loss:0.4907156825065613  \n","Epoch:8/30     Step:7|6   loss:0.4891709089279175  \n","4Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4896027445793152  \n","Epoch:9/30     Step:2|6   loss:0.4908401072025299  \n","Epoch:9/30     Step:3|6   loss:0.4912295639514923  \n","Epoch:9/30     Step:4|6   loss:0.4905996322631836  \n","Epoch:9/30     Step:5|6   loss:0.4897274374961853  \n","Epoch:9/30     Step:6|6   loss:0.4910457730293274  \n","\n","Epoch:9/30     Step:7|6   loss:0.49057483673095703  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48941126465797424  \n","Epoch:10/30     Step:2|6   loss:0.4897855520248413  \n","Epoch:10/30     Step:3|6   loss:0.48941463232040405  \n","Epoch:10/30     Step:4|6   loss:0.4901312291622162  \n","Epoch:10/30     Step:5|6   loss:0.49176159501075745  \n","Epoch:10/30     Step:6|6   loss:0.4902957081794739  \n","Epoch:10/30     Step:7|6   loss:0.4884995222091675  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.48907768726348877  \n","Epoch:11/30     Step:2|6   loss:0.49033603072166443  \n","Epoch:11/30     Step:3|6   loss:0.48900601267814636  \n","Epoch:11/30     Step:4|6   loss:0.48861920833587646  \n","Epoch:11/30     Step:5|6   loss:0.4899323582649231  \n","Epoch:11/30     Step:6|6   loss:0.4890788197517395  \n","Epoch:11/30     Step:7|6   loss:0.4887148141860962  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48906058073043823  \n","Epoch:12/30     Step:2|6   loss:0.4897805154323578  \n","Epoch:12/30     Step:3|6   loss:0.48979392647743225  \n","Epoch:12/30     Step:4|6   loss:0.4891471266746521  \n","Epoch:12/30     Step:5|6   loss:0.4912644624710083  \n","Epoch:12/30     Step:6|6   loss:0.4890799820423126  \n","Epoch:12/30     Step:7|6   loss:0.4898473620414734  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4892404079437256  \n","Epoch:13/30     Step:2|6   loss:0.4885728061199188  \n","Epoch:13/30     Step:3|6   loss:0.4897865653038025  \n","Epoch:13/30     Step:4|6   loss:0.4885236918926239  \n","Epoch:13/30     Step:5|6   loss:0.4883076846599579  \n","Epoch:13/30     Step:6|6   loss:0.4884308874607086  \n","Epoch:13/30     Step:7|6   loss:0.4896191954612732  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48936963081359863  \n","Epoch:14/30     Step:2|6   loss:0.4879838824272156  \n","Epoch:14/30     Step:3|6   loss:0.4873886704444885  \n","Epoch:14/30     Step:4|6   loss:0.49024713039398193  \n","Epoch:14/30     Step:5|6   loss:0.4893314838409424  \n","Epoch:14/30     Step:6|6   loss:0.4900773763656616  \n","Epoch:14/30     Step:7|6   loss:0.4886716902256012  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4893333911895752  \n","Epoch:15/30     Step:2|6   loss:0.4894113838672638  \n","Epoch:15/30     Step:3|6   loss:0.48882871866226196  \n","Epoch:15/30     Step:4|6   loss:0.4897727370262146  \n","Epoch:15/30     Step:5|6   loss:0.48911774158477783  \n","Epoch:15/30     Step:6|6   loss:0.48880791664123535  \n","Epoch:15/30     Step:7|6   loss:0.4882689118385315  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48920249938964844  \n","Epoch:16/30     Step:2|6   loss:0.48838353157043457  \n","Epoch:16/30     Step:3|6   loss:0.48824891448020935  \n","Epoch:16/30     Step:4|6   loss:0.489346981048584  \n","Epoch:16/30     Step:5|6   loss:0.4895092844963074  \n","Epoch:16/30     Step:6|6   loss:0.48882436752319336  \n","Epoch:16/30     Step:7|6   loss:0.4891960024833679  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48922592401504517  \n","Epoch:17/30     Step:2|6   loss:0.48827382922172546  \n","Epoch:17/30     Step:3|6   loss:0.4882963299751282  \n","Epoch:17/30     Step:4|6   loss:0.4887924790382385  \n","Epoch:17/30     Step:5|6   loss:0.4904998242855072  \n","Epoch:17/30     Step:6|6   loss:0.4886102080345154  \n","Epoch:17/30     Step:7|6   loss:0.48755931854248047  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4889506697654724  \n","Epoch:18/30     Step:2|6   loss:0.4890613257884979  \n","Epoch:18/30     Step:3|6   loss:0.4883674085140228  \n","Epoch:18/30     Step:4|6   loss:0.4881437420845032  \n","Epoch:18/30     Step:5|6   loss:0.48898056149482727  \n","Epoch:18/30     Step:6|6   loss:0.48864880204200745  \n","Epoch:18/30     Step:7|6   loss:0.4868690073490143  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4883284568786621  \n","Epoch:19/30     Step:2|6   loss:0.4879901111125946  \n","Epoch:19/30     Step:3|6   loss:0.4880986511707306  \n","Epoch:19/30     Step:4|6   loss:0.4886022210121155  \n","Epoch:19/30     Step:5|6   loss:0.48830658197402954  \n","Epoch:19/30     Step:6|6   loss:0.4881267845630646  \n","Epoch:19/30     Step:7|6   loss:0.4885350465774536  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48876142501831055  \n","Epoch:20/30     Step:2|6   loss:0.4890696108341217  \n","Epoch:20/30     Step:3|6   loss:0.4877356290817261  \n","Epoch:20/30     Step:4|6   loss:0.4882528483867645  \n","Epoch:20/30     Step:5|6   loss:0.4885667860507965  \n","Epoch:20/30     Step:6|6   loss:0.4882102906703949  \n","Epoch:20/30     Step:7|6   loss:0.48843345046043396  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4879691004753113  \n","Epoch:21/30     Step:2|6   loss:0.4883904755115509  \n","Epoch:21/30     Step:3|6   loss:0.4875907301902771  \n","Epoch:21/30     Step:4|6   loss:0.48727133870124817  \n","Epoch:21/30     Step:5|6   loss:0.4877508282661438  \n","Epoch:21/30     Step:6|6   loss:0.4879511594772339  \n","Epoch:21/30     Step:7|6   loss:0.48747357726097107  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4880743622779846  \n","Epoch:22/30     Step:2|6   loss:0.4874646067619324  \n","Epoch:22/30     Step:3|6   loss:0.48753201961517334  \n","Epoch:22/30     Step:4|6   loss:0.48797816038131714  \n","Epoch:22/30     Step:5|6   loss:0.4882883131504059  \n","Epoch:22/30     Step:6|6   loss:0.4877699017524719  \n","Epoch:22/30     Step:7|6   loss:0.48742902278900146  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48734086751937866  \n","Epoch:23/30     Step:2|6   loss:0.48936334252357483  \n","Epoch:23/30     Step:3|6   loss:0.4869459271430969  \n","Epoch:23/30     Step:4|6   loss:0.48770588636398315  \n","Epoch:23/30     Step:5|6   loss:0.4879158139228821  \n","Epoch:23/30     Step:6|6   loss:0.48749861121177673  \n","Epoch:23/30     Step:7|6   loss:0.4887152910232544  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4876743257045746  \n","Epoch:24/30     Step:2|6   loss:0.4874628484249115  \n","Epoch:24/30     Step:3|6   loss:0.48842185735702515  \n","Epoch:24/30     Step:4|6   loss:0.4890177845954895  \n","Epoch:24/30     Step:5|6   loss:0.4874800145626068  \n","Epoch:24/30     Step:6|6   loss:0.4877287447452545  \n","Epoch:24/30     Step:7|6   loss:0.4876086711883545  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4887223243713379  \n","Epoch:25/30     Step:2|6   loss:0.4883483052253723  \n","Epoch:25/30     Step:3|6   loss:0.48738613724708557  \n","Epoch:25/30     Step:4|6   loss:0.48819878697395325  \n","Epoch:25/30     Step:5|6   loss:0.4886101186275482  \n","Epoch:25/30     Step:6|6   loss:0.4880460500717163  \n","Epoch:25/30     Step:7|6   loss:0.48711204528808594  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4872109889984131  \n","Epoch:26/30     Step:2|6   loss:0.4874494671821594  \n","Epoch:26/30     Step:3|6   loss:0.48715823888778687  \n","Epoch:26/30     Step:4|6   loss:0.48725584149360657  \n","Epoch:26/30     Step:5|6   loss:0.4872666597366333  \n","Epoch:26/30     Step:6|6   loss:0.4889053404331207  \n","Epoch:26/30     Step:7|6   loss:0.487690269947052  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48751306533813477  \n","Epoch:27/30     Step:2|6   loss:0.48747286200523376  \n","Epoch:27/30     Step:3|6   loss:0.48816487193107605  \n","Epoch:27/30     Step:4|6   loss:0.4878297448158264  \n","Epoch:27/30     Step:5|6   loss:0.4887407720088959  \n","Epoch:27/30     Step:6|6   loss:0.48791471123695374  \n","Epoch:27/30     Step:7|6   loss:0.4870094060897827  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.48778000473976135  \n","Epoch:28/30     Step:2|6   loss:0.48757779598236084  \n","Epoch:28/30     Step:3|6   loss:0.48712313175201416  \n","Epoch:28/30     Step:4|6   loss:0.48743927478790283  \n","Epoch:28/30     Step:5|6   loss:0.4879029393196106  \n","Epoch:28/30     Step:6|6   loss:0.4875571131706238  \n","Epoch:28/30     Step:7|6   loss:0.4876639246940613  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4876944422721863  \n","Epoch:29/30     Step:2|6   loss:0.4881584346294403  \n","Epoch:29/30     Step:3|6   loss:0.48784780502319336  \n","Epoch:29/30     Step:4|6   loss:0.48860228061676025  \n","Epoch:29/30     Step:5|6   loss:0.48753759264945984  \n","Epoch:29/30     Step:6|6   loss:0.48775169253349304  \n","Epoch:29/30     Step:7|6   loss:0.48747408390045166  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4879659414291382  \n","Epoch:30/30     Step:2|6   loss:0.48820966482162476  \n","Epoch:30/30     Step:3|6   loss:0.48807308077812195  \n","Epoch:30/30     Step:4|6   loss:0.4881938397884369  \n","Epoch:30/30     Step:5|6   loss:0.48714810609817505  \n","Epoch:30/30     Step:6|6   loss:0.4873712956905365  \n","Epoch:30/30     Step:7|6   loss:0.48707976937294006  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='VGG16', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1269199848175049  \n","Epoch:1/30     Step:2|6   loss:0.9587608575820923  \n","Epoch:1/30     Step:3|6   loss:0.7689017057418823  \n","Epoch:1/30     Step:4|6   loss:0.7726583480834961  \n","Epoch:1/30     Step:5|6   loss:1.1022130250930786  \n","Epoch:1/30     Step:6|6   loss:0.6980854272842407  \n","Epoch:1/30     Step:7|6   loss:0.7413325309753418  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 78.45 %\n","current max accuracy\t test set:79.44%\t train set:78.45%\n","Epoch:2/30     Step:1|6   loss:0.7777085900306702  \n","Epoch:2/30     Step:2|6   loss:0.721193790435791  \n","Epoch:2/30     Step:3|6   loss:0.6143355369567871  \n","Epoch:2/30     Step:4|6   loss:0.7341173887252808  \n","Epoch:2/30     Step:5|6   loss:0.6611779928207397  \n","Epoch:2/30     Step:6|6   loss:0.6422220468521118  \n","Epoch:2/30     Step:7|6   loss:0.649099588394165  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:95.33%\t train set:93.68%\n","Epoch:3/30     Step:1|6   loss:0.6334978342056274  \n","Epoch:3/30     Step:2|6   loss:0.5977699756622314  \n","Epoch:3/30     Step:3|6   loss:0.588762640953064  \n","Epoch:3/30     Step:4|6   loss:0.5886802673339844  \n","Epoch:3/30     Step:5|6   loss:0.5541287064552307  \n","Epoch:3/30     Step:6|6   loss:0.6061103343963623  \n","Epoch:3/30     Step:7|6   loss:0.54648756980896  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:97.2%\t train set:98.59%\n","Epoch:4/30     Step:1|6   loss:0.5382482409477234  \n","Epoch:4/30     Step:2|6   loss:0.5348297953605652  \n","Epoch:4/30     Step:3|6   loss:0.5344922542572021  \n","Epoch:4/30     Step:4|6   loss:0.5330777764320374  \n","Epoch:4/30     Step:5|6   loss:0.5306987166404724  \n","Epoch:4/30     Step:6|6   loss:0.5380405187606812  \n","Epoch:4/30     Step:7|6   loss:0.5138294100761414  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:5/30     Step:1|6   loss:0.5113332271575928  \n","Epoch:5/30     Step:2|6   loss:0.5000253915786743  \n","Epoch:5/30     Step:3|6   loss:0.503068745136261  \n","Epoch:5/30     Step:4|6   loss:0.50611412525177  \n","Epoch:5/30     Step:5|6   loss:0.5049366354942322  \n","Epoch:5/30     Step:6|6   loss:0.5016680955886841  \n","Epoch:5/30     Step:7|6   loss:0.5275838971138  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5015437602996826  \n","Epoch:6/30     Step:2|6   loss:0.5147902965545654  \n","Epoch:6/30     Step:3|6   loss:0.49981003999710083  \n","Epoch:6/30     Step:4|6   loss:0.496980220079422  \n","Epoch:6/30     Step:5|6   loss:0.4932355582714081  \n","Epoch:6/30     Step:6|6   loss:0.49703750014305115  \n","Epoch:6/30     Step:7|6   loss:0.4963756203651428  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4970279932022095  \n","Epoch:7/30     Step:2|6   loss:0.49854451417922974  \n","Epoch:7/30     Step:3|6   loss:0.49575838446617126  \n","Epoch:7/30     Step:4|6   loss:0.49530452489852905  \n","Epoch:7/30     Step:5|6   loss:0.49637192487716675  \n","Epoch:7/30     Step:6|6   loss:0.4946300685405731  \n","Epoch:7/30     Step:7|6   loss:0.49687817692756653  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4987078905105591  \n","Epoch:8/30     Step:2|6   loss:0.4928942918777466  \n","Epoch:8/30     Step:3|6   loss:0.49218523502349854  \n","Epoch:8/30     Step:4|6   loss:0.49371397495269775  \n","Epoch:8/30     Step:5|6   loss:0.493633508682251  \n","Epoch:8/30     Step:6|6   loss:0.49479591846466064  \n","Epoch:8/30     Step:7|6   loss:0.4898611903190613  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4904352128505707  \n","Epoch:9/30     Step:2|6   loss:0.49068307876586914  \n","Epoch:9/30     Step:3|6   loss:0.49306273460388184  \n","Epoch:9/30     Step:4|6   loss:0.4914129972457886  \n","Epoch:9/30     Step:5|6   loss:0.49110931158065796  \n","Epoch:9/30     Step:6|6   loss:0.48978790640830994  \n","Epoch:9/30     Step:7|6   loss:0.4912071228027344  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4919184446334839  \n","Epoch:10/30     Step:2|6   loss:0.4908885359764099  \n","Epoch:10/30     Step:3|6   loss:0.489705353975296  \n","Epoch:10/30     Step:4|6   loss:0.4894898235797882  \n","Epoch:10/30     Step:5|6   loss:0.4909422993659973  \n","Epoch:10/30     Step:6|6   loss:0.49136871099472046  \n","Epoch:10/30     Step:7|6   loss:0.49099284410476685  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.48903167247772217  \n","Epoch:11/30     Step:2|6   loss:0.48994746804237366  \n","Epoch:11/30     Step:3|6   loss:0.49073103070259094  \n","Epoch:11/30     Step:4|6   loss:0.4896256923675537  \n","Epoch:11/30     Step:5|6   loss:0.48947107791900635  \n","Epoch:11/30     Step:6|6   loss:0.48962175846099854  \n","Epoch:11/30     Step:7|6   loss:0.48933902382850647  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4905444383621216  \n","Epoch:12/30     Step:2|6   loss:0.4896818995475769  \n","Epoch:12/30     Step:3|6   loss:0.48923200368881226  \n","Epoch:12/30     Step:4|6   loss:0.4886195659637451  \n","Epoch:12/30     Step:5|6   loss:0.48901262879371643  \n","Epoch:12/30     Step:6|6   loss:0.4892697036266327  \n","Epoch:12/30     Step:7|6   loss:0.4892025589942932  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4887586832046509  \n","Epoch:13/30     Step:2|6   loss:0.48858290910720825  \n","Epoch:13/30     Step:3|6   loss:0.4885481297969818  \n","Epoch:13/30     Step:4|6   loss:0.4884255528450012  \n","Epoch:13/30     Step:5|6   loss:0.48864778876304626  \n","Epoch:13/30     Step:6|6   loss:0.4887372553348541  \n","Epoch:13/30     Step:7|6   loss:0.4882902204990387  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4883994460105896  \n","Epoch:14/30     Step:2|6   loss:0.4884006679058075  \n","Epoch:14/30     Step:3|6   loss:0.4883268177509308  \n","Epoch:14/30     Step:4|6   loss:0.4888765811920166  \n","Epoch:14/30     Step:5|6   loss:0.4882148504257202  \n","Epoch:14/30     Step:6|6   loss:0.4894981384277344  \n","Epoch:14/30     Step:7|6   loss:0.4882020950317383  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:15/30     Step:1|6   loss:0.49005138874053955  \n","Epoch:15/30     Step:2|6   loss:0.4880046546459198  \n","Epoch:15/30     Step:3|6   loss:0.48932674527168274  \n","Epoch:15/30     Step:4|6   loss:0.4890252351760864  \n","Epoch:15/30     Step:5|6   loss:0.48849785327911377  \n","Epoch:15/30     Step:6|6   loss:0.4890657067298889  \n","Epoch:15/30     Step:7|6   loss:0.4884209632873535  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48905614018440247  \n","Epoch:16/30     Step:2|6   loss:0.4891866147518158  \n","Epoch:16/30     Step:3|6   loss:0.4892693758010864  \n","Epoch:16/30     Step:4|6   loss:0.4889848232269287  \n","Epoch:16/30     Step:5|6   loss:0.48783424496650696  \n","Epoch:16/30     Step:6|6   loss:0.4880882501602173  \n","Epoch:16/30     Step:7|6   loss:0.48837095499038696  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4885633587837219  \n","Epoch:17/30     Step:2|6   loss:0.4890761375427246  \n","Epoch:17/30     Step:3|6   loss:0.48943138122558594  \n","Epoch:17/30     Step:4|6   loss:0.48777148127555847  \n","Epoch:17/30     Step:5|6   loss:0.4881832003593445  \n","Epoch:17/30     Step:6|6   loss:0.4885996878147125  \n","Epoch:17/30     Step:7|6   loss:0.48923271894454956  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48782357573509216  \n","Epoch:18/30     Step:2|6   loss:0.48768511414527893  \n","Epoch:18/30     Step:3|6   loss:0.4885365664958954  \n","Epoch:18/30     Step:4|6   loss:0.4880474805831909  \n","Epoch:18/30     Step:5|6   loss:0.4889630973339081  \n","Epoch:18/30     Step:6|6   loss:0.48791128396987915  \n","Epoch:18/30     Step:7|6   loss:0.4883222281932831  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.48784810304641724  \n","Epoch:19/30     Step:2|6   loss:0.48835670948028564  \n","Epoch:19/30     Step:3|6   loss:0.48886460065841675  \n","Epoch:19/30     Step:4|6   loss:0.488630473613739  \n","Epoch:19/30     Step:5|6   loss:0.48938217759132385  \n","Epoch:19/30     Step:6|6   loss:0.48838818073272705  \n","Epoch:19/30     Step:7|6   loss:0.4882688522338867  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48807984590530396  \n","Epoch:20/30     Step:2|6   loss:0.4881265461444855  \n","Epoch:20/30     Step:3|6   loss:0.48778286576271057  \n","Epoch:20/30     Step:4|6   loss:0.4878348112106323  \n","Epoch:20/30     Step:5|6   loss:0.4883856475353241  \n","Epoch:20/30     Step:6|6   loss:0.4885319769382477  \n","Epoch:20/30     Step:7|6   loss:0.48745274543762207  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4872584044933319  \n","Epoch:21/30     Step:2|6   loss:0.48847708106040955  \n","Epoch:21/30     Step:3|6   loss:0.4884767532348633  \n","Epoch:21/30     Step:4|6   loss:0.48944711685180664  \n","Epoch:21/30     Step:5|6   loss:0.48820701241493225  \n","Epoch:21/30     Step:6|6   loss:0.4878557324409485  \n","Epoch:21/30     Step:7|6   loss:0.48758095502853394  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4891207814216614  \n","Epoch:22/30     Step:2|6   loss:0.48742735385894775  \n","Epoch:22/30     Step:3|6   loss:0.488278865814209  \n","Epoch:22/30     Step:4|6   loss:0.48812994360923767  \n","Epoch:22/30     Step:5|6   loss:0.4889611005783081  \n","Epoch:22/30     Step:6|6   loss:0.48793187737464905  \n","Epoch:22/30     Step:7|6   loss:0.48847848176956177  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48744332790374756  \n","Epoch:23/30     Step:2|6   loss:0.4884914457798004  \n","Epoch:23/30     Step:3|6   loss:0.48817580938339233  \n","Epoch:23/30     Step:4|6   loss:0.48803475499153137  \n","Epoch:23/30     Step:5|6   loss:0.48801231384277344  \n","Epoch:23/30     Step:6|6   loss:0.48836082220077515  \n","Epoch:23/30     Step:7|6   loss:0.4882340729236603  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48795512318611145  \n","Epoch:24/30     Step:2|6   loss:0.4884357452392578  \n","Epoch:24/30     Step:3|6   loss:0.4883780777454376  \n","Epoch:24/30     Step:4|6   loss:0.4876514971256256  \n","Epoch:24/30     Step:5|6   loss:0.48795223236083984  \n","Epoch:24/30     Step:6|6   loss:0.4886171817779541  \n","Epoch:24/30     Step:7|6   loss:0.48772042989730835  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48773089051246643  \n","Epoch:25/30     Step:2|6   loss:0.4879714548587799  \n","Epoch:25/30     Step:3|6   loss:0.4876706898212433  \n","Epoch:25/30     Step:4|6   loss:0.48876696825027466  \n","Epoch:25/30     Step:5|6   loss:0.4884968400001526  \n","Epoch:25/30     Step:6|6   loss:0.48821407556533813  \n","Epoch:25/30     Step:7|6   loss:0.48858770728111267  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4876396059989929  \n","Epoch:26/30     Step:2|6   loss:0.4877067804336548  \n","Epoch:26/30     Step:3|6   loss:0.4883500039577484  \n","Epoch:26/30     Step:4|6   loss:0.4888877868652344  \n","Epoch:26/30     Step:5|6   loss:0.4887547492980957  \n","Epoch:26/30     Step:6|6   loss:0.4879305362701416  \n","Epoch:26/30     Step:7|6   loss:0.48851731419563293  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4880393147468567  \n","Epoch:27/30     Step:2|6   loss:0.48752036690711975  \n","Epoch:27/30     Step:3|6   loss:0.48869770765304565  \n","Epoch:27/30     Step:4|6   loss:0.48838239908218384  \n","Epoch:27/30     Step:5|6   loss:0.4881420135498047  \n","Epoch:27/30     Step:6|6   loss:0.4882141947746277  \n","Epoch:27/30     Step:7|6   loss:0.4877395033836365  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4890289306640625  \n","Epoch:28/30     Step:2|6   loss:0.4884483218193054  \n","Epoch:28/30     Step:3|6   loss:0.4886106252670288  \n","Epoch:28/30     Step:4|6   loss:0.48729413747787476  \n","Epoch:28/30     Step:5|6   loss:0.48802313208580017  \n","Epoch:28/30     Step:6|6   loss:0.4881696403026581  \n","Epoch:28/30     Step:7|6   loss:0.4873705506324768  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.48749685287475586  \n","Epoch:29/30     Step:2|6   loss:0.48818984627723694  \n","Epoch:29/30     Step:3|6   loss:0.4881976246833801  \n","Epoch:29/30     Step:4|6   loss:0.48774462938308716  \n","Epoch:29/30     Step:5|6   loss:0.48725542426109314  \n","Epoch:29/30     Step:6|6   loss:0.48837974667549133  \n","Epoch:29/30     Step:7|6   loss:0.48801887035369873  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4872950315475464  \n","Epoch:30/30     Step:2|6   loss:0.4875383973121643  \n","Epoch:30/30     Step:3|6   loss:0.4877951145172119  \n","Epoch:30/30     Step:4|6   loss:0.4876401722431183  \n","Epoch:30/30     Step:5|6   loss:0.488484263420105  \n","Epoch:30/30     Step:6|6   loss:0.4890028238296509  \n","Epoch:30/30     Step:7|6   loss:0.4881645739078522  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model VGG16 --mode ir --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":12,"id":"ad12960f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.0778772830963135  \n","Epoch:1/30     Step:2|6   loss:0.8736979961395264  \n","Epoch:1/30     Step:3|6   loss:0.7521004676818848  \n","Epoch:1/30     Step:4|6   loss:0.6243913769721985  \n","Epoch:1/30     Step:5|6   loss:0.5952329635620117  \n","Epoch:1/30     Step:6|6   loss:0.5832435488700867  \n","Epoch:1/30     Step:7|6   loss:0.5251345038414001  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:94.39%\t train set:96.72%\n","Epoch:2/30     Step:1|6   loss:0.5365237593650818  \n","Epoch:2/30     Step:2|6   loss:0.5644174814224243  \n","Epoch:2/30     Step:3|6   loss:0.5604666471481323  \n","Epoch:2/30     Step:4|6   loss:0.5523241758346558  \n","Epoch:2/30     Step:5|6   loss:0.5306947231292725  \n","Epoch:2/30     Step:6|6   loss:0.5392007231712341  \n","Epoch:2/30     Step:7|6   loss:0.5412012338638306  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.521346926689148  \n","Epoch:3/30     Step:2|6   loss:0.5183114409446716  \n","Epoch:3/30     Step:3|6   loss:0.5245434641838074  \n","Epoch:3/30     Step:4|6   loss:0.5164667963981628  \n","Epoch:3/30     Step:5|6   loss:0.5041223168373108  \n","Epoch:3/30     Step:6|6   loss:0.5065495371818542  \n","Epoch:3/30     Step:7|6   loss:0.5073667168617249  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5327030420303345  \n","Epoch:4/30     Step:2|6   loss:0.5044107437133789  \n","Epoch:4/30     Step:3|6   loss:0.5032787322998047  \n","Epoch:4/30     Step:4|6   loss:0.5035452246665955  \n","Epoch:4/30     Step:5|6   loss:0.5086995959281921  \n","Epoch:4/30     Step:6|6   loss:0.49736714363098145  \n","Epoch:4/30     Step:7|6   loss:0.5069835186004639  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5081459879875183  \n","Epoch:5/30     Step:2|6   loss:0.4985847473144531  \n","Epoch:5/30     Step:3|6   loss:0.49890628457069397  \n","Epoch:5/30     Step:4|6   loss:0.49676868319511414  \n","Epoch:5/30     Step:5|6   loss:0.5046476721763611  \n","Epoch:5/30     Step:6|6   loss:0.5061843395233154  \n","Epoch:5/30     Step:7|6   loss:0.5056344866752625  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5107917785644531  \n","Epoch:6/30     Step:2|6   loss:0.4964171051979065  \n","Epoch:6/30     Step:3|6   loss:0.5264795422554016  \n","Epoch:6/30     Step:4|6   loss:0.5117406249046326  \n","Epoch:6/30     Step:5|6   loss:0.5065617561340332  \n","Epoch:6/30     Step:6|6   loss:0.5129697322845459  \n","Epoch:6/30     Step:7|6   loss:0.5038778781890869  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.5007145404815674  \n","Epoch:7/30     Step:2|6   loss:0.5020769834518433  \n","Epoch:7/30     Step:3|6   loss:0.5014402270317078  \n","Epoch:7/30     Step:4|6   loss:0.4967889189720154  \n","Epoch:7/30     Step:5|6   loss:0.494314968585968  \n","Epoch:7/30     Step:6|6   loss:0.4995724558830261  \n","Epoch:7/30     Step:7|6   loss:0.49781396985054016  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4965957701206207  \n","Epoch:8/30     Step:2|6   loss:0.491669237613678  \n","Epoch:8/30     Step:3|6   loss:0.4941754937171936  \n","Epoch:8/30     Step:4|6   loss:0.4954710602760315  \n","Epoch:8/30     Step:5|6   loss:0.4930347204208374  \n","Epoch:8/30     Step:6|6   loss:0.4944571256637573  \n","Epoch:8/30     Step:7|6   loss:0.4929637908935547  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.5071719288825989  \n","Epoch:9/30     Step:2|6   loss:0.49872684478759766  \n","Epoch:9/30     Step:3|6   loss:0.4966125786304474  \n","Epoch:9/30     Step:4|6   loss:0.494248628616333  \n","Epoch:9/30     Step:5|6   loss:0.4904150664806366  \n","Epoch:9/30     Step:6|6   loss:0.5029720067977905  \n","Epoch:9/30     Step:7|6   loss:0.5100015997886658  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49250528216362  \n","Epoch:10/30     Step:2|6   loss:0.4942456781864166  \n","Epoch:10/30     Step:3|6   loss:0.4956108331680298  \n","Epoch:10/30     Step:4|6   loss:0.4960288107395172  \n","Epoch:10/30     Step:5|6   loss:0.4933058023452759  \n","Epoch:10/30     Step:6|6   loss:0.4939061403274536  \n","Epoch:10/30     Step:7|6   loss:0.5162613391876221  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49752265214920044  \n","Epoch:11/30     Step:2|6   loss:0.492910236120224  \n","Epoch:11/30     Step:3|6   loss:0.5131816267967224  \n","Epoch:11/30     Step:4|6   loss:0.49114990234375  \n","Epoch:11/30     Step:5|6   loss:0.4958494305610657  \n","Epoch:11/30     Step:6|6   loss:0.4913073778152466  \n","Epoch:11/30     Step:7|6   loss:0.4909507930278778  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.49454647302627563  \n","Epoch:12/30     Step:2|6   loss:0.49698406457901  \n","Epoch:12/30     Step:3|6   loss:0.4935356378555298  \n","Epoch:12/30     Step:4|6   loss:0.4926595389842987  \n","Epoch:12/30     Step:5|6   loss:0.4996820092201233  \n","Epoch:12/30     Step:6|6   loss:0.5041905045509338  \n","Epoch:12/30     Step:7|6   loss:0.4943241775035858  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4935262203216553  \n","Epoch:13/30     Step:2|6   loss:0.492495596408844  \n","Epoch:13/30     Step:3|6   loss:0.49407079815864563  \n","Epoch:13/30     Step:4|6   loss:0.49402090907096863  \n","Epoch:13/30     Step:5|6   loss:0.49202924966812134  \n","Epoch:13/30     Step:6|6   loss:0.49746835231781006  \n","Epoch:13/30     Step:7|6   loss:0.4956240653991699  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.49403083324432373  \n","Epoch:14/30     Step:2|6   loss:0.496471643447876  \n","Epoch:14/30     Step:3|6   loss:0.4942484498023987  \n","Epoch:14/30     Step:4|6   loss:0.49529334902763367  \n","Epoch:14/30     Step:5|6   loss:0.4961145520210266  \n","Epoch:14/30     Step:6|6   loss:0.49126970767974854  \n","Epoch:14/30     Step:7|6   loss:0.49230140447616577  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4982925057411194  \n","Epoch:15/30     Step:2|6   loss:0.49148985743522644  \n","Epoch:15/30     Step:3|6   loss:0.49329957365989685  \n","Epoch:15/30     Step:4|6   loss:0.49553215503692627  \n","Epoch:15/30     Step:5|6   loss:0.4922373294830322  \n","Epoch:15/30     Step:6|6   loss:0.4917689561843872  \n","Epoch:15/30     Step:7|6   loss:0.4951421022415161  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4948729872703552  \n","Epoch:16/30     Step:2|6   loss:0.49293479323387146  \n","Epoch:16/30     Step:3|6   loss:0.4950113296508789  \n","Epoch:16/30     Step:4|6   loss:0.4914816617965698  \n","Epoch:16/30     Step:5|6   loss:0.4951046109199524  \n","Epoch:16/30     Step:6|6   loss:0.4934190511703491  \n","Epoch:16/30     Step:7|6   loss:0.4919397830963135  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4947112202644348  \n","Epoch:17/30     Step:2|6   loss:0.49085116386413574  \n","Epoch:17/30     Step:3|6   loss:0.49213945865631104  \n","Epoch:17/30     Step:4|6   loss:0.49097058176994324  \n","Epoch:17/30     Step:5|6   loss:0.4992543160915375  \n","Epoch:17/30     Step:6|6   loss:0.493164598941803  \n","Epoch:17/30     Step:7|6   loss:0.49755430221557617  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.5015808343887329  \n","Epoch:18/30     Step:2|6   loss:0.4971699118614197  \n","Epoch:18/30     Step:3|6   loss:0.49541082978248596  \n","Epoch:18/30     Step:4|6   loss:0.4945999085903168  \n","Epoch:18/30     Step:5|6   loss:0.4979182481765747  \n","Epoch:18/30     Step:6|6   loss:0.49431413412094116  \n","Epoch:18/30     Step:7|6   loss:0.4935842752456665  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.49678805470466614  \n","Epoch:19/30     Step:2|6   loss:0.5019869208335876  \n","Epoch:19/30     Step:3|6   loss:0.49307775497436523  \n","Epoch:19/30     Step:4|6   loss:0.49216216802597046  \n","Epoch:19/30     Step:5|6   loss:0.49597465991973877  \n","Epoch:19/30     Step:6|6   loss:0.49581676721572876  \n","Epoch:19/30     Step:7|6   loss:0.49151942133903503  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4908401072025299  \n","Epoch:20/30     Step:2|6   loss:0.4948157072067261  \n","Epoch:20/30     Step:3|6   loss:0.49567127227783203  \n","Epoch:20/30     Step:4|6   loss:0.49673813581466675  \n","Epoch:20/30     Step:5|6   loss:0.49377113580703735  \n","Epoch:20/30     Step:6|6   loss:0.49689069390296936  \n","Epoch:20/30     Step:7|6   loss:0.5031268000602722  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.501280665397644  \n","Epoch:21/30     Step:2|6   loss:0.49325159192085266  \n","Epoch:21/30     Step:3|6   loss:0.49476248025894165  \n","Epoch:21/30     Step:4|6   loss:0.49459007382392883  \n","Epoch:21/30     Step:5|6   loss:0.49784570932388306  \n","Epoch:21/30     Step:6|6   loss:0.49997884035110474  \n","Epoch:21/30     Step:7|6   loss:0.49700772762298584  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4954473674297333  \n","Epoch:22/30     Step:2|6   loss:0.4936870336532593  \n","Epoch:22/30     Step:3|6   loss:0.5054458379745483  \n","Epoch:22/30     Step:4|6   loss:0.49194464087486267  \n","Epoch:22/30     Step:5|6   loss:0.4948430061340332  \n","Epoch:22/30     Step:6|6   loss:0.4923388361930847  \n","Epoch:22/30     Step:7|6   loss:0.4938933253288269  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4906551241874695  \n","Epoch:23/30     Step:2|6   loss:0.49383366107940674  \n","Epoch:23/30     Step:3|6   loss:0.4959067106246948  \n","Epoch:23/30     Step:4|6   loss:0.5028203129768372  \n","Epoch:23/30     Step:5|6   loss:0.493322491645813  \n","Epoch:23/30     Step:6|6   loss:0.4929336905479431  \n","Epoch:23/30     Step:7|6   loss:0.4933270812034607  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4938583970069885  \n","Epoch:24/30     Step:2|6   loss:0.49664515256881714  \n","Epoch:24/30     Step:3|6   loss:0.49296197295188904  \n","Epoch:24/30     Step:4|6   loss:0.4930097162723541  \n","Epoch:24/30     Step:5|6   loss:0.4912945330142975  \n","Epoch:24/30     Step:6|6   loss:0.4923415780067444  \n","Epoch:24/30     Step:7|6   loss:0.4927639663219452  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49430522322654724  \n","Epoch:25/30     Step:2|6   loss:0.4952599108219147  \n","Epoch:25/30     Step:3|6   loss:0.5005819201469421  \n","Epoch:25/30     Step:4|6   loss:0.4930804371833801  \n","Epoch:25/30     Step:5|6   loss:0.49446871876716614  \n","Epoch:25/30     Step:6|6   loss:0.4982917606830597  \n","Epoch:25/30     Step:7|6   loss:0.49235284328460693  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4930994510650635  \n","Epoch:26/30     Step:2|6   loss:0.4917237162590027  \n","Epoch:26/30     Step:3|6   loss:0.49054598808288574  \n","Epoch:26/30     Step:4|6   loss:0.4928908348083496  \n","Epoch:26/30     Step:5|6   loss:0.4927068054676056  \n","Epoch:26/30     Step:6|6   loss:0.4902357757091522  \n","Epoch:26/30     Step:7|6   loss:0.49112024903297424  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49330538511276245  \n","Epoch:27/30     Step:2|6   loss:0.5008047223091125  \n","Epoch:27/30     Step:3|6   loss:0.49317824840545654  \n","Epoch:27/30     Step:4|6   loss:0.4985092282295227  \n","Epoch:27/30     Step:5|6   loss:0.49167171120643616  \n","Epoch:27/30     Step:6|6   loss:0.4955710470676422  \n","Epoch:27/30     Step:7|6   loss:0.5093323588371277  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.499683141708374  \n","Epoch:28/30     Step:2|6   loss:0.493011474609375  \n","Epoch:28/30     Step:3|6   loss:0.49519866704940796  \n","Epoch:28/30     Step:4|6   loss:0.4938200116157532  \n","Epoch:28/30     Step:5|6   loss:0.4960947632789612  \n","Epoch:28/30     Step:6|6   loss:0.4963184595108032  \n","Epoch:28/30     Step:7|6   loss:0.4999651312828064  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49350348114967346  \n","Epoch:29/30     Step:2|6   loss:0.49949678778648376  \n","Epoch:29/30     Step:3|6   loss:0.49279576539993286  \n","Epoch:29/30     Step:4|6   loss:0.4945727288722992  \n","Epoch:29/30     Step:5|6   loss:0.4991351366043091  \n","Epoch:29/30     Step:6|6   loss:0.4977319836616516  \n","Epoch:29/30     Step:7|6   loss:0.49420246481895447  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4949527978897095  \n","Epoch:30/30     Step:2|6   loss:0.4930192828178406  \n","Epoch:30/30     Step:3|6   loss:0.4951588809490204  \n","Epoch:30/30     Step:4|6   loss:0.49350833892822266  \n","Epoch:30/30     Step:5|6   loss:0.49591535329818726  \n","Epoch:30/30     Step:6|6   loss:0.4994877576828003  \n","Epoch:30/30     Step:7|6   loss:0.4995811879634857  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","1\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","2        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1207369565963745  \n","Epoch:1/30     Step:2|6   loss:0.8832178711891174  \n","Epoch:1/30     Step:3|6   loss:0.7513165473937988  \n","Epoch:1/30     Step:4|6   loss:0.6356241703033447  \n","Epoch:1/30     Step:5|6   loss:0.6112828254699707  \n","Epoch:1/30     Step:6|6   loss:0.5719901323318481  \n","Epoch:1/30     Step:7|6   loss:0.5821032524108887  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:2/30     Step:1|6   loss:0.543677568435669  \n","Epoch:2/30     Step:2|6   loss:0.547156035900116  \n","Epoch:2/30     Step:3|6   loss:0.5453827381134033  \n","Epoch:2/30     Step:4|6   loss:0.5348827838897705  \n","Epoch:2/30     Step:5|6   loss:0.5475577712059021  \n","Epoch:2/30     Step:6|6   loss:0.5625595450401306  \n","Epoch:2/30     Step:7|6   loss:0.5392469167709351  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.5289806127548218  \n","Epoch:3/30     Step:2|6   loss:0.528110682964325  \n","Epoch:3/30     Step:3|6   loss:0.5374529957771301  \n","Epoch:3/30     Step:4|6   loss:0.511511504650116  \n","Epoch:3/30     Step:5|6   loss:0.537523090839386  \n","Epoch:3/30     Step:6|6   loss:0.5098903775215149  \n","Epoch:3/30     Step:7|6   loss:0.5179537534713745  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5128435492515564  \n","Epoch:4/30     Step:2|6   loss:0.5110812187194824  \n","Epoch:4/30     Step:3|6   loss:0.5251519680023193  \n","Epoch:4/30     Step:4|6   loss:0.5065702199935913  \n","Epoch:4/30     Step:5|6   loss:0.5196024775505066  \n","Epoch:4/30     Step:6|6   loss:0.5053341388702393  \n","Epoch:4/30     Step:7|6   loss:0.506291389465332  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.504853367805481  \n","Epoch:5/30     Step:2|6   loss:0.503135621547699  \n","Epoch:5/30     Step:3|6   loss:0.5009586215019226  \n","Epoch:5/30     Step:4|6   loss:0.504947304725647  \n","Epoch:5/30     Step:5|6   loss:0.5076624155044556  \n","Epoch:5/30     Step:6|6   loss:0.5002123117446899  \n","Epoch:5/30     Step:7|6   loss:0.5006860494613647  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49645745754241943  \n","Epoch:6/30     Step:2|6   loss:0.4951823949813843  \n","Epoch:6/30     Step:3|6   loss:0.5061190724372864  \n","Epoch:6/30     Step:4|6   loss:0.4985337257385254  \n","Epoch:6/30     Step:5|6   loss:0.4964822828769684  \n","Epoch:6/30     Step:6|6   loss:0.49382278323173523  \n","Epoch:6/30     Step:7|6   loss:0.49457722902297974  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49335813522338867  \n","Epoch:7/30     Step:2|6   loss:0.49725234508514404  \n","Epoch:7/30     Step:3|6   loss:0.4953460693359375  \n","Epoch:7/30     Step:4|6   loss:0.49512043595314026  \n","Epoch:7/30     Step:5|6   loss:0.5013786554336548  \n","Epoch:7/30     Step:6|6   loss:0.49534156918525696  \n","Epoch:7/30     Step:7|6   loss:0.5012578964233398  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4963694214820862  \n","Epoch:8/30     Step:2|6   loss:0.5147275924682617  \n","Epoch:8/30     Step:3|6   loss:0.4942803680896759  \n","Epoch:8/30     Step:4|6   loss:0.521609365940094  \n","Epoch:8/30     Step:5|6   loss:0.4993477463722229  \n","Epoch:8/30     Step:6|6   loss:0.517917275428772  \n","Epoch:8/30     Step:7|6   loss:0.5058649778366089  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4925432801246643  \n","Epoch:9/30     Step:2|6   loss:0.4950747489929199  \n","Epoch:9/30     Step:3|6   loss:0.4928107261657715  \n","Epoch:9/30     Step:4|6   loss:0.4965529441833496  \n","Epoch:9/30     Step:5|6   loss:0.49923175573349  \n","Epoch:9/30     Step:6|6   loss:0.49882838129997253  \n","Epoch:9/30     Step:7|6   loss:0.4979780316352844  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49956372380256653  \n","Epoch:10/30     Step:2|6   loss:0.4928569793701172  \n","Epoch:10/30     Step:3|6   loss:0.4975500702857971  \n","Epoch:10/30     Step:4|6   loss:0.4960719347000122  \n","Epoch:10/30     Step:5|6   loss:0.49530914425849915  \n","Epoch:10/30     Step:6|6   loss:0.49313777685165405  \n","Epoch:10/30     Step:7|6   loss:0.5099565982818604  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49444279074668884  \n","Epoch:11/30     Step:2|6   loss:0.4951443672180176  \n","Epoch:11/30     Step:3|6   loss:0.4972822666168213  \n","Epoch:11/30     Step:4|6   loss:0.49433475732803345  \n","Epoch:11/30     Step:5|6   loss:0.4950210750102997  \n","Epoch:11/30     Step:6|6   loss:0.5054453015327454  \n","Epoch:11/30     Step:7|6   loss:0.5079664587974548  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.49357736110687256  \n","Epoch:12/30     Step:2|6   loss:0.49346303939819336  \n","Epoch:12/30     Step:3|6   loss:0.49639132618904114  \n","Epoch:12/30     Step:4|6   loss:0.4961210787296295  \n","Epoch:12/30     Step:5|6   loss:0.49546462297439575  \n","Epoch:12/30     Step:6|6   loss:0.4943822920322418  \n","Epoch:12/30     Step:7|6   loss:0.5149306058883667  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.49598610401153564  \n","Epoch:13/30     Step:2|6   loss:0.49305927753448486  \n","Epoch:13/30     Step:3|6   loss:0.5095953941345215  \n","Epoch:13/30     Step:4|6   loss:0.5026915073394775  \n","Epoch:13/30     Step:5|6   loss:0.5118957757949829  \n","Epoch:13/30     Step:6|6   loss:0.4938913881778717  \n","Epoch:13/30     Step:7|6   loss:0.4933881163597107  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.5037838220596313  \n","Epoch:14/30     Step:2|6   loss:0.4954332709312439  \n","Epoch:14/30     Step:3|6   loss:0.4998672604560852  \n","Epoch:14/30     Step:4|6   loss:0.4977763593196869  \n","Epoch:14/30     Step:5|6   loss:0.49655357003211975  \n","Epoch:14/30     Step:6|6   loss:0.49381622672080994  \n","Epoch:14/30     Step:7|6   loss:0.5091307759284973  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4935557246208191  \n","Epoch:15/30     Step:2|6   loss:0.4935244917869568  \n","Epoch:15/30     Step:3|6   loss:0.49671638011932373  \n","Epoch:15/30     Step:4|6   loss:0.4940004348754883  \n","Epoch:15/30     Step:5|6   loss:0.4959172308444977  \n","Epoch:15/30     Step:6|6   loss:0.49493345618247986  \n","Epoch:15/30     Step:7|6   loss:0.49457356333732605  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.5042439699172974  \n","Epoch:16/30     Step:2|6   loss:0.49186843633651733  \n","Epoch:16/30     Step:3|6   loss:0.4985552728176117  \n","Epoch:16/30     Step:4|6   loss:0.49463552236557007  \n","Epoch:16/30     Step:5|6   loss:0.49383044242858887  \n","Epoch:16/30     Step:6|6   loss:0.49217289686203003  \n","Epoch:16/30     Step:7|6   loss:0.4958713948726654  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.49066394567489624  \n","Epoch:17/30     Step:2|6   loss:0.4932307004928589  \n","Epoch:17/30     Step:3|6   loss:0.4945563077926636  \n","Epoch:17/30     Step:4|6   loss:0.49613434076309204  \n","Epoch:17/30     Step:5|6   loss:0.49255234003067017  \n","Epoch:17/30     Step:6|6   loss:0.49216195940971375  \n","Epoch:17/30     Step:7|6   loss:0.49086758494377136  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4936641454696655  \n","Epoch:18/30     Step:2|6   loss:0.4982430040836334  \n","Epoch:18/30     Step:3|6   loss:0.49851715564727783  \n","Epoch:18/30     Step:4|6   loss:0.49739742279052734  \n","Epoch:18/30     Step:5|6   loss:0.4992995858192444  \n","Epoch:18/30     Step:6|6   loss:0.4964448809623718  \n","Epoch:18/30     Step:7|6   loss:0.49987804889678955  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.500678539276123  \n","Epoch:19/30     Step:2|6   loss:0.4944714605808258  \n","Epoch:19/30     Step:3|6   loss:0.49901947379112244  \n","Epoch:19/30     Step:4|6   loss:0.49664565920829773  \n","Epoch:19/30     Step:5|6   loss:0.5134249925613403  \n","Epoch:19/30     Step:6|6   loss:0.5182377099990845  \n","Epoch:19/30     Step:7|6   loss:0.49520716071128845  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.49345144629478455  \n","Epoch:20/30     Step:2|6   loss:0.4977487325668335  \n","Epoch:20/30     Step:3|6   loss:0.4938039779663086  \n","Epoch:20/30     Step:4|6   loss:0.4965483844280243  \n","Epoch:20/30     Step:5|6   loss:0.4956153631210327  \n","Epoch:20/30     Step:6|6   loss:0.4966663122177124  \n","Epoch:20/30     Step:7|6   loss:0.4949808120727539  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4989638030529022  \n","Epoch:21/30     Step:2|6   loss:0.4946919083595276  \n","Epoch:21/30     Step:3|6   loss:0.49376386404037476  \n","Epoch:21/30     Step:4|6   loss:0.5010217428207397  \n","Epoch:21/30     Step:5|6   loss:0.5026124119758606  \n","Epoch:21/30     Step:6|6   loss:0.4939287006855011  \n","Epoch:21/30     Step:7|6   loss:0.49541303515434265  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4942161738872528  \n","Epoch:22/30     Step:2|6   loss:0.49425408244132996  \n","Epoch:22/30     Step:3|6   loss:0.4962456226348877  \n","Epoch:22/30     Step:4|6   loss:0.49636104702949524  \n","Epoch:22/30     Step:5|6   loss:0.5011914968490601  \n","Epoch:22/30     Step:6|6   loss:0.49396201968193054  \n","Epoch:22/30     Step:7|6   loss:0.49460992217063904  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.49602559208869934  \n","Epoch:23/30     Step:2|6   loss:0.49596792459487915  \n","Epoch:23/30     Step:3|6   loss:0.4908970296382904  \n","Epoch:23/30     Step:4|6   loss:0.492412269115448  \n","Epoch:23/30     Step:5|6   loss:0.49400997161865234  \n","Epoch:23/30     Step:6|6   loss:0.49547088146209717  \n","Epoch:23/30     Step:7|6   loss:0.5124524831771851  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4983424246311188  \n","Epoch:24/30     Step:2|6   loss:0.495006263256073  \n","Epoch:24/30     Step:3|6   loss:0.4947882890701294  \n","Epoch:24/30     Step:4|6   loss:0.4937068223953247  \n","Epoch:24/30     Step:5|6   loss:0.4963681101799011  \n","Epoch:24/30     Step:6|6   loss:0.4963364899158478  \n","Epoch:24/30     Step:7|6   loss:0.49452081322669983  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4921415448188782  \n","Epoch:25/30     Step:2|6   loss:0.4943900406360626  \n","Epoch:25/30     Step:3|6   loss:0.4904782176017761  \n","Epoch:25/30     Step:4|6   loss:0.4909154772758484  \n","Epoch:25/30     Step:5|6   loss:0.4944162666797638  \n","Epoch:25/30     Step:6|6   loss:0.4900207817554474  \n","Epoch:25/30     Step:7|6   loss:0.4909977316856384  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4951569437980652  \n","Epoch:26/30     Step:2|6   loss:0.4960061013698578  \n","Epoch:26/30     Step:3|6   loss:0.491874635219574  \n","Epoch:26/30     Step:4|6   loss:0.5019521713256836  \n","Epoch:26/30     Step:5|6   loss:0.49394696950912476  \n","Epoch:26/30     Step:6|6   loss:0.4927334785461426  \n","Epoch:26/30     Step:7|6   loss:0.492607057094574  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49253377318382263  \n","Epoch:27/30     Step:2|6   loss:0.4946151673793793  \n","Epoch:27/30     Step:3|6   loss:0.49128004908561707  \n","Epoch:27/30     Step:4|6   loss:0.4923613369464874  \n","Epoch:27/30     Step:5|6   loss:0.4932946562767029  \n","Epoch:27/30     Step:6|6   loss:0.49207067489624023  \n","Epoch:27/30     Step:7|6   loss:0.5066366195678711  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4918537139892578  \n","Epoch:28/30     Step:2|6   loss:0.49051836133003235  \n","Epoch:28/30     Step:3|6   loss:0.4919149577617645  \n","Epoch:28/30     Step:4|6   loss:0.49874183535575867  \n","Epoch:28/30     Step:5|6   loss:0.4940534234046936  \n","Epoch:28/30     Step:6|6   loss:0.5022775530815125  \n","Epoch:28/30     Step:7|6   loss:0.4989188313484192  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4926198124885559  \n","Epoch:29/30     Step:2|6   loss:0.4906584918498993  \n","Epoch:29/30     Step:3|6   loss:0.49181970953941345  \n","Epoch:29/30     Step:4|6   loss:0.4974483847618103  \n","Epoch:29/30     Step:5|6   loss:0.49228158593177795  \n","Epoch:29/30     Step:6|6   loss:0.49123018980026245  \n","Epoch:29/30     Step:7|6   loss:0.500702440738678  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.49042263627052307  \n","Epoch:30/30     Step:2|6   loss:0.49350640177726746  \n","Epoch:30/30     Step:3|6   loss:0.4924567937850952  \n","Epoch:30/30     Step:4|6   loss:0.4907132685184479  \n","Epoch:30/30     Step:5|6   loss:0.5021712183952332  \n","Epoch:30/30     Step:6|6   loss:0.49849316477775574  \n","Epoch:30/30     Step:7|6   loss:0.5357946157455444  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.140499472618103  \n","Epoch:1/30     Step:2|6   loss:0.9679811596870422  \n","Epoch:1/30     Step:3|6   loss:0.8148289918899536  \n","Epoch:1/30     Step:4|6   loss:0.6651666164398193  \n","Epoch:1/30     Step:5|6   loss:0.6525431871414185  \n","Epoch:1/30     Step:6|6   loss:0.5877383947372437  \n","Epoch:1/30     Step:7|6   loss:0.6009545922279358  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:91.59%\t train set:95.32%\n","Epoch:2/30     Step:1|6   loss:0.5559998750686646  \n","Epoch:2/30     Step:2|6   loss:0.5464586019515991  \n","Epoch:2/30     Step:3|6   loss:0.5493147373199463  \n","Epoch:2/30     Step:4|6   loss:0.5912197232246399  \n","Epoch:2/30     Step:5|6   loss:0.55852872133255  \n","Epoch:2/30     Step:6|6   loss:0.5517227649688721  \n","Epoch:2/30     Step:7|6   loss:0.6713448762893677  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:96.26%\t train set:99.53%\n","Epoch:3/30     Step:1|6   loss:0.5417720079421997  \n","Epoch:3/30     Step:2|6   loss:0.5211533308029175  \n","Epoch:3/30     Step:3|6   loss:0.5174636244773865  \n","Epoch:3/30     Step:4|6   loss:0.5196342468261719  \n","Epoch:3/30     Step:5|6   loss:0.5156145095825195  \n","Epoch:3/30     Step:6|6   loss:0.5585408210754395  \n","Epoch:3/30     Step:7|6   loss:0.5406941175460815  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.52086341381073  \n","Epoch:4/30     Step:2|6   loss:0.5118292570114136  \n","Epoch:4/30     Step:3|6   loss:0.5196487307548523  \n","Epoch:4/30     Step:4|6   loss:0.5000078678131104  \n","Epoch:4/30     Step:5|6   loss:0.5058343410491943  \n","Epoch:4/30     Step:6|6   loss:0.5030486583709717  \n","Epoch:4/30     Step:7|6   loss:0.5078310370445251  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49839410185813904  \n","Epoch:5/30     Step:2|6   loss:0.5011879801750183  \n","Epoch:5/30     Step:3|6   loss:0.5103569626808167  \n","Epoch:5/30     Step:4|6   loss:0.4978886842727661  \n","Epoch:5/30     Step:5|6   loss:0.5021564364433289  \n","Epoch:5/30     Step:6|6   loss:0.5007762908935547  \n","Epoch:5/30     Step:7|6   loss:0.5017005801200867  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49519121646881104  \n","Epoch:6/30     Step:2|6   loss:0.5004823207855225  \n","Epoch:6/30     Step:3|6   loss:0.4953046143054962  \n","Epoch:6/30     Step:4|6   loss:0.49645254015922546  \n","Epoch:6/30     Step:5|6   loss:0.5004935264587402  \n","Epoch:6/30     Step:6|6   loss:0.49624398350715637  \n","Epoch:6/30     Step:7|6   loss:0.4957004189491272  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49833303689956665  \n","Epoch:7/30     Step:2|6   loss:0.4926930069923401  \n","Epoch:7/30     Step:3|6   loss:0.5046390295028687  \n","Epoch:7/30     Step:4|6   loss:0.497599333524704  \n","Epoch:7/30     Step:5|6   loss:0.4927438199520111  \n","Epoch:7/30     Step:6|6   loss:0.5067136883735657  \n","Epoch:7/30     Step:7|6   loss:0.49115440249443054  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49510034918785095  \n","Epoch:8/30     Step:2|6   loss:0.49536818265914917  \n","Epoch:8/30     Step:3|6   loss:0.4917547106742859  \n","Epoch:8/30     Step:4|6   loss:0.49728909134864807  \n","Epoch:8/30     Step:5|6   loss:0.4938855767250061  \n","Epoch:8/30     Step:6|6   loss:0.49665695428848267  \n","Epoch:8/30     Step:7|6   loss:0.4950740337371826  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4931876063346863  \n","Epoch:9/30     Step:2|6   loss:0.4930560886859894  \n","Epoch:9/30     Step:3|6   loss:0.5011865496635437  \n","Epoch:9/30     Step:4|6   loss:0.4934481978416443  \n","Epoch:9/30     Step:5|6   loss:0.511583685874939  \n","Epoch:9/30     Step:6|6   loss:0.49145615100860596  \n","Epoch:9/30     Step:7|6   loss:0.49450385570526123  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49475133419036865  \n","Epoch:10/30     Step:2|6   loss:0.49500972032546997  \n","Epoch:10/30     Step:3|6   loss:0.49155256152153015  \n","Epoch:10/30     Step:4|6   loss:0.49253663420677185  \n","Epoch:10/30     Step:5|6   loss:0.4936753213405609  \n","Epoch:10/30     Step:6|6   loss:0.4948626458644867  \n","Epoch:10/30     Step:7|6   loss:0.5091554522514343  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.495088666677475  \n","Epoch:11/30     Step:2|6   loss:0.49230682849884033  \n","Epoch:11/30     Step:3|6   loss:0.49593034386634827  \n","Epoch:11/30     Step:4|6   loss:0.49381521344184875  \n","Epoch:11/30     Step:5|6   loss:0.49377062916755676  \n","Epoch:11/30     Step:6|6   loss:0.4978106617927551  \n","Epoch:11/30     Step:7|6   loss:0.4978398084640503  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4939854145050049  \n","Epoch:12/30     Step:2|6   loss:0.4998205006122589  \n","Epoch:12/30     Step:3|6   loss:0.4962031841278076  \n","Epoch:12/30     Step:4|6   loss:0.49481919407844543  \n","Epoch:12/30     Step:5|6   loss:0.4950256049633026  \n","Epoch:12/30     Step:6|6   loss:0.4999082088470459  \n","Epoch:12/30     Step:7|6   loss:0.5047455430030823  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.49209150671958923  \n","Epoch:13/30     Step:2|6   loss:0.4959925413131714  \n","Epoch:13/30     Step:3|6   loss:0.4959771931171417  \n","Epoch:13/30     Step:4|6   loss:0.5105890035629272  \n","Epoch:13/30     Step:5|6   loss:0.49439382553100586  \n","Epoch:13/30     Step:6|6   loss:0.4947018623352051  \n","Epoch:13/30     Step:7|6   loss:0.5035173296928406  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.500314474105835  \n","Epoch:14/30     Step:2|6   loss:0.5036593079566956  \n","Epoch:14/30     Step:3|6   loss:0.4948027729988098  \n","Epoch:14/30     Step:4|6   loss:0.4978361129760742  \n","Epoch:14/30     Step:5|6   loss:0.49373000860214233  \n","Epoch:14/30     Step:6|6   loss:0.49324169754981995  \n","Epoch:14/30     Step:7|6   loss:0.5196604132652283  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.5152402520179749  \n","Epoch:15/30     Step:2|6   loss:0.4951269328594208  \n","Epoch:15/30     Step:3|6   loss:0.4939535856246948  \n","Epoch:15/30     Step:4|6   loss:0.49766895174980164  \n","Epoch:15/30     Step:5|6   loss:0.49622413516044617  \n","Epoch:15/30     Step:6|6   loss:0.49622467160224915  \n","Epoch:15/30     Step:7|6   loss:0.5066321492195129  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.49282169342041016  \n","Epoch:16/30     Step:2|6   loss:0.4922107458114624  \n","Epoch:16/30     Step:3|6   loss:0.4929772913455963  \n","Epoch:16/30     Step:4|6   loss:0.495080828666687  \n","Epoch:16/30     Step:5|6   loss:0.5015897750854492  \n","Epoch:16/30     Step:6|6   loss:0.49744439125061035  \n","Epoch:16/30     Step:7|6   loss:0.4933016896247864  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.5024837255477905  \n","Epoch:17/30     Step:2|6   loss:0.5064268708229065  \n","Epoch:17/30     Step:3|6   loss:0.49535223841667175  \n","Epoch:17/30     Step:4|6   loss:0.495411217212677  \n","Epoch:17/30     Step:5|6   loss:0.4954304099082947  \n","Epoch:17/30     Step:6|6   loss:0.4965783953666687  \n","Epoch:17/30     Step:7|6   loss:0.49973398447036743  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4948651194572449  \n","Epoch:18/30     Step:2|6   loss:0.4973227083683014  \n","Epoch:18/30     Step:3|6   loss:0.4943482279777527  \n","Epoch:18/30     Step:4|6   loss:0.503542959690094  \n","Epoch:18/30     Step:5|6   loss:0.49681705236434937  \n","Epoch:18/30     Step:6|6   loss:0.4923701286315918  \n","Epoch:18/30     Step:7|6   loss:0.5047846436500549  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4947962462902069  \n","Epoch:19/30     Step:2|6   loss:0.49190670251846313  \n","Epoch:19/30     Step:3|6   loss:0.4936527609825134  \n","Epoch:19/30     Step:4|6   loss:0.495370477437973  \n","Epoch:19/30     Step:5|6   loss:0.49976906180381775  \n","Epoch:19/30     Step:6|6   loss:0.4935827851295471  \n","Epoch:19/30     Step:7|6   loss:0.5029441118240356  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.49282553791999817  \n","Epoch:20/30     Step:2|6   loss:0.49142518639564514  \n","Epoch:20/30     Step:3|6   loss:0.4977959394454956  \n","Epoch:20/30     Step:4|6   loss:0.49338671565055847  \n","Epoch:20/30     Step:5|6   loss:0.4942314624786377  \n","Epoch:20/30     Step:6|6   loss:0.49389344453811646  \n","Epoch:20/30     Step:7|6   loss:0.5216383934020996  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.49586015939712524  \n","Epoch:21/30     Step:2|6   loss:0.5084229707717896  \n","Epoch:21/30     Step:3|6   loss:0.4959597587585449  \n","Epoch:21/30     Step:4|6   loss:0.4945468008518219  \n","Epoch:21/30     Step:5|6   loss:0.49899759888648987  \n","Epoch:21/30     Step:6|6   loss:0.49416428804397583  \n","Epoch:21/30     Step:7|6   loss:0.4961065351963043  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.49258679151535034  \n","Epoch:22/30     Step:2|6   loss:0.4935522973537445  \n","Epoch:22/30     Step:3|6   loss:0.4936310648918152  \n","Epoch:22/30     Step:4|6   loss:0.49810361862182617  \n","Epoch:22/30     Step:5|6   loss:0.4913466274738312  \n","Epoch:22/30     Step:6|6   loss:0.4972192049026489  \n","Epoch:22/30     Step:7|6   loss:0.5003468990325928  3\n","\n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4918985664844513  \n","Epoch:23/30     Step:2|6   loss:0.501444399356842  \n","Epoch:23/30     Step:3|6   loss:0.49566352367401123  \n","Epoch:23/30     Step:4|6   loss:0.49467337131500244  \n","Epoch:23/30     Step:5|6   loss:0.492238849401474  \n","Epoch:23/30     Step:6|6   loss:0.49885451793670654  \n","Epoch:23/30     Step:7|6   loss:0.4983178675174713  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4923779368400574  \n","Epoch:24/30     Step:2|6   loss:0.4908941090106964  \n","Epoch:24/30     Step:3|6   loss:0.49129927158355713  \n","Epoch:24/30     Step:4|6   loss:0.49203333258628845  \n","Epoch:24/30     Step:5|6   loss:0.4942963123321533  \n","Epoch:24/30     Step:6|6   loss:0.49530962109565735  \n","Epoch:24/30     Step:7|6   loss:0.5039681792259216  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49593937397003174  \n","Epoch:25/30     Step:2|6   loss:0.4904625713825226  \n","Epoch:25/30     Step:3|6   loss:0.4937116503715515  \n","Epoch:25/30     Step:4|6   loss:0.495236873626709  \n","Epoch:25/30     Step:5|6   loss:0.4901988208293915  \n","Epoch:25/30     Step:6|6   loss:0.49247634410858154  \n","Epoch:25/30     Step:7|6   loss:0.49302130937576294  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4919864237308502  \n","Epoch:26/30     Step:2|6   loss:0.4931783974170685  \n","Epoch:26/30     Step:3|6   loss:0.4896230399608612  \n","Epoch:26/30     Step:4|6   loss:0.49362510442733765  \n","Epoch:26/30     Step:5|6   loss:0.4908806085586548  \n","Epoch:26/30     Step:6|6   loss:0.4927150011062622  \n","Epoch:26/30     Step:7|6   loss:0.500937819480896  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49826228618621826  \n","Epoch:27/30     Step:2|6   loss:0.4970065951347351  \n","Epoch:27/30     Step:3|6   loss:0.49214082956314087  \n","Epoch:27/30     Step:4|6   loss:0.49242860078811646  \n","Epoch:27/30     Step:5|6   loss:0.4974682331085205  \n","Epoch:27/30     Step:6|6   loss:0.4951642155647278  \n","Epoch:27/30     Step:7|6   loss:0.49728071689605713  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.49019578099250793  \n","Epoch:28/30     Step:2|6   loss:0.49215325713157654  \n","Epoch:28/30     Step:3|6   loss:0.49412772059440613  \n","Epoch:28/30     Step:4|6   loss:0.4924153685569763  \n","Epoch:28/30     Step:5|6   loss:0.49067074060440063  \n","Epoch:28/30     Step:6|6   loss:0.4940812587738037  \n","Epoch:28/30     Step:7|6   loss:0.49574029445648193  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49205154180526733  \n","Epoch:29/30     Step:2|6   loss:0.49591994285583496  \n","Epoch:29/30     Step:3|6   loss:0.4992571175098419  \n","Epoch:29/30     Step:4|6   loss:0.49651038646698  \n","Epoch:29/30     Step:5|6   loss:0.49993062019348145  \n","Epoch:29/30     Step:6|6   loss:0.5022383332252502  \n","Epoch:29/30     Step:7|6   loss:0.4906737208366394  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.495894193649292  \n","Epoch:30/30     Step:2|6   loss:0.5029828548431396  \n","Epoch:30/30     Step:3|6   loss:0.49277937412261963  \n","Epoch:30/30     Step:4|6   loss:0.5041459798812866  \n","Epoch:30/30     Step:5|6   loss:0.4922732412815094  \n","Epoch:30/30     Step:6|6   loss:0.49252286553382874  \n","Epoch:30/30     Step:7|6   loss:0.49470391869544983  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Accuracy on test_set: 97.20 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","4\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.2688177824020386  \n","Epoch:1/30     Step:2|6   loss:0.942987322807312  \n","Epoch:1/30     Step:3|6   loss:0.7847306728363037  \n","Epoch:1/30     Step:4|6   loss:0.6691247224807739  \n","Epoch:1/30     Step:5|6   loss:0.6601393818855286  \n","Epoch:1/30     Step:6|6   loss:0.5999725461006165  \n","Epoch:1/30     Step:7|6   loss:0.5757333040237427  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:95.33%\t train set:97.42%\n","Epoch:2/30     Step:1|6   loss:0.5442419052124023  \n","Epoch:2/30     Step:2|6   loss:0.5525363683700562  \n","Epoch:2/30     Step:3|6   loss:0.5774052739143372  \n","Epoch:2/30     Step:4|6   loss:0.5719982385635376  \n","Epoch:2/30     Step:5|6   loss:0.5640850067138672  \n","Epoch:2/30     Step:6|6   loss:0.5580422878265381  \n","Epoch:2/30     Step:7|6   loss:0.534033477306366  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:3/30     Step:1|6   loss:0.5384901165962219  \n","Epoch:3/30     Step:2|6   loss:0.5378164052963257  \n","Epoch:3/30     Step:3|6   loss:0.5128047466278076  \n","Epoch:3/30     Step:4|6   loss:0.5179793834686279  \n","Epoch:3/30     Step:5|6   loss:0.5034515261650085  \n","Epoch:3/30     Step:6|6   loss:0.5114770531654358  \n","Epoch:3/30     Step:7|6   loss:0.5202555656433105  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5007846355438232  \n","Epoch:4/30     Step:2|6   loss:0.5244579315185547  \n","Epoch:4/30     Step:3|6   loss:0.5359771847724915  \n","Epoch:4/30     Step:4|6   loss:0.5118977427482605  \n","Epoch:4/30     Step:5|6   loss:0.5011548399925232  \n","Epoch:4/30     Step:6|6   loss:0.513429582118988  \n","Epoch:4/30     Step:7|6   loss:0.5817840695381165  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5030365586280823  \n","Epoch:5/30     Step:2|6   loss:0.5031203627586365  \n","Epoch:5/30     Step:3|6   loss:0.5062706470489502  \n","Epoch:5/30     Step:4|6   loss:0.5000789165496826  \n","Epoch:5/30     Step:5|6   loss:0.5040659308433533  \n","Epoch:5/30     Step:6|6   loss:0.530886709690094  \n","Epoch:5/30     Step:7|6   loss:0.5132957696914673  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5004353523254395  \n","Epoch:6/30     Step:2|6   loss:0.5115607976913452  \n","Epoch:6/30     Step:3|6   loss:0.5039277076721191  \n","Epoch:6/30     Step:4|6   loss:0.5009297728538513  \n","Epoch:6/30     Step:5|6   loss:0.516551673412323  \n","Epoch:6/30     Step:6|6   loss:0.5024516582489014  \n","Epoch:6/30     Step:7|6   loss:0.4943977892398834  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49651557207107544  \n","Epoch:7/30     Step:2|6   loss:0.49621933698654175  \n","Epoch:7/30     Step:3|6   loss:0.4981924891471863  \n","Epoch:7/30     Step:4|6   loss:0.49795037508010864  \n","Epoch:7/30     Step:5|6   loss:0.49728479981422424  \n","Epoch:7/30     Step:6|6   loss:0.49531495571136475  \n","Epoch:7/30     Step:7|6   loss:0.4975762963294983  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49588537216186523  \n","Epoch:8/30     Step:2|6   loss:0.4969250559806824  \n","Epoch:8/30     Step:3|6   loss:0.49496158957481384  \n","Epoch:8/30     Step:4|6   loss:0.4936055839061737  \n","Epoch:8/30     Step:5|6   loss:0.49965977668762207  \n","Epoch:8/30     Step:6|6   loss:0.49777135252952576  \n","Epoch:8/30     Step:7|6   loss:0.5051741600036621  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4993394613265991  \n","Epoch:9/30     Step:2|6   loss:0.49396079778671265  \n","Epoch:9/30     Step:3|6   loss:0.4977492094039917  \n","Epoch:9/30     Step:4|6   loss:0.49933376908302307  \n","Epoch:9/30     Step:5|6   loss:0.49529147148132324  \n","Epoch:9/30     Step:6|6   loss:0.49360591173171997  \n","Epoch:9/30     Step:7|6   loss:0.50358647108078  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.502750039100647  \n","Epoch:10/30     Step:2|6   loss:0.495090514421463  \n","Epoch:10/30     Step:3|6   loss:0.4941960275173187  \n","Epoch:10/30     Step:4|6   loss:0.49412012100219727  \n","Epoch:10/30     Step:5|6   loss:0.4976223111152649  \n","Epoch:10/30     Step:6|6   loss:0.4952389597892761  \n","Epoch:10/30     Step:7|6   loss:0.49514061212539673  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4930700361728668  \n","Epoch:11/30     Step:2|6   loss:0.4937998950481415  \n","Epoch:11/30     Step:3|6   loss:0.4960605204105377  \n","Epoch:11/30     Step:4|6   loss:0.4938335418701172  \n","Epoch:11/30     Step:5|6   loss:0.49382221698760986  \n","Epoch:11/30     Step:6|6   loss:0.49584251642227173  \n","Epoch:11/30     Step:7|6   loss:0.4922756850719452  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4936012625694275  \n","Epoch:12/30     Step:2|6   loss:0.49949315190315247  \n","Epoch:12/30     Step:3|6   loss:0.49639415740966797  \n","Epoch:12/30     Step:4|6   loss:0.495509535074234  \n","Epoch:12/30     Step:5|6   loss:0.5007729530334473  \n","Epoch:12/30     Step:6|6   loss:0.511009931564331  \n","Epoch:12/30     Step:7|6   loss:0.4951937198638916  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.495386004447937  \n","Epoch:13/30     Step:2|6   loss:0.4932416081428528  \n","Epoch:13/30     Step:3|6   loss:0.49275001883506775  \n","Epoch:13/30     Step:4|6   loss:0.4923369884490967  \n","Epoch:13/30     Step:5|6   loss:0.4905765652656555  \n","Epoch:13/30     Step:6|6   loss:0.49894195795059204  \n","Epoch:13/30     Step:7|6   loss:0.4927460551261902  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.49898892641067505  \n","Epoch:14/30     Step:2|6   loss:0.5115758180618286  \n","Epoch:14/30     Step:3|6   loss:0.49054622650146484  \n","Epoch:14/30     Step:4|6   loss:0.5018957853317261  \n","Epoch:14/30     Step:5|6   loss:0.49371349811553955  \n","Epoch:14/30     Step:6|6   loss:0.49476101994514465  \n","Epoch:14/30     Step:7|6   loss:0.4914250373840332  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.49415600299835205  \n","Epoch:15/30     Step:2|6   loss:0.4932589530944824  \n","Epoch:15/30     Step:3|6   loss:0.4919937252998352  \n","Epoch:15/30     Step:4|6   loss:0.49315112829208374  \n","Epoch:15/30     Step:5|6   loss:0.4999232888221741  \n","Epoch:15/30     Step:6|6   loss:0.503371000289917  \n","Epoch:15/30     Step:7|6   loss:0.5017358660697937  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.5063765048980713  \n","Epoch:16/30     Step:2|6   loss:0.4915132224559784  \n","Epoch:16/30     Step:3|6   loss:0.5024885535240173  \n","Epoch:16/30     Step:4|6   loss:0.4951845705509186  \n","Epoch:16/30     Step:5|6   loss:0.510558545589447  \n","Epoch:16/30     Step:6|6   loss:0.49358153343200684  \n","Epoch:16/30     Step:7|6   loss:0.5019880533218384  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4923262596130371  \n","Epoch:17/30     Step:2|6   loss:0.4913754165172577  \n","Epoch:17/30     Step:3|6   loss:0.49403437972068787  \n","Epoch:17/30     Step:4|6   loss:0.49884140491485596  \n","Epoch:17/30     Step:5|6   loss:0.4920928180217743  \n","Epoch:17/30     Step:6|6   loss:0.4925394058227539  \n","Epoch:17/30     Step:7|6   loss:0.4996771216392517  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4953223764896393  \n","Epoch:18/30     Step:2|6   loss:0.4941869378089905  \n","Epoch:18/30     Step:3|6   loss:0.49724239110946655  \n","Epoch:18/30     Step:4|6   loss:0.49190235137939453  \n","Epoch:18/30     Step:5|6   loss:0.5090524554252625  \n","Epoch:18/30     Step:6|6   loss:0.4939212501049042  \n","Epoch:18/30     Step:7|6   loss:0.4949362874031067  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4928939938545227  \n","Epoch:19/30     Step:2|6   loss:0.492278128862381  \n","Epoch:19/30     Step:3|6   loss:0.4938460886478424  \n","Epoch:19/30     Step:4|6   loss:0.4929227828979492  \n","Epoch:19/30     Step:5|6   loss:0.49724361300468445  \n","Epoch:19/30     Step:6|6   loss:0.49521055817604065  \n","Epoch:19/30     Step:7|6   loss:0.4941268861293793  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4948480427265167  \n","Epoch:20/30     Step:2|6   loss:0.4959157705307007  \n","Epoch:20/30     Step:3|6   loss:0.5115766525268555  \n","Epoch:20/30     Step:4|6   loss:0.4946651756763458  \n","Epoch:20/30     Step:5|6   loss:0.49358516931533813  \n","Epoch:20/30     Step:6|6   loss:0.4911115765571594  \n","Epoch:20/30     Step:7|6   loss:0.5001952052116394  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4953708350658417  \n","Epoch:21/30     Step:2|6   loss:0.4923759400844574  \n","Epoch:21/30     Step:3|6   loss:0.49339523911476135  \n","Epoch:21/30     Step:4|6   loss:0.4912742078304291  \n","Epoch:21/30     Step:5|6   loss:0.49187660217285156  \n","Epoch:21/30     Step:6|6   loss:0.5095402598381042  \n","Epoch:21/30     Step:7|6   loss:0.5057602524757385  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4917147159576416  \n","Epoch:22/30     Step:2|6   loss:0.4958663582801819  \n","Epoch:22/30     Step:3|6   loss:0.49587422609329224  \n","Epoch:22/30     Step:4|6   loss:0.494505375623703  \n","Epoch:22/30     Step:5|6   loss:0.5110999941825867  \n","Epoch:22/30     Step:6|6   loss:0.494107723236084  \n","Epoch:22/30     Step:7|6   loss:0.4959148168563843  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4938526749610901  \n","Epoch:23/30     Step:2|6   loss:0.4936859607696533  \n","Epoch:23/30     Step:3|6   loss:0.5012086629867554  \n","Epoch:23/30     Step:4|6   loss:0.4924495816230774  \n","Epoch:23/30     Step:5|6   loss:0.49480482935905457  \n","Epoch:23/30     Step:6|6   loss:0.497050404548645  \n","Epoch:23/30     Step:7|6   loss:0.4981715679168701  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49424922466278076  \n","Epoch:24/30     Step:2|6   loss:0.4932018220424652  \n","Epoch:24/30     Step:3|6   loss:0.4974415600299835  \n","Epoch:24/30     Step:4|6   loss:0.4951022267341614  \n","Epoch:24/30     Step:5|6   loss:0.4914419651031494  \n","Epoch:24/30     Step:6|6   loss:0.49230054020881653  \n","Epoch:24/30     Step:7|6   loss:0.4956835210323334  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49630245566368103  \n","Epoch:25/30     Step:2|6   loss:0.4929220676422119  \n","Epoch:25/30     Step:3|6   loss:0.4927281141281128  \n","Epoch:25/30     Step:4|6   loss:0.49615201354026794  \n","Epoch:25/30     Step:5|6   loss:0.492933452129364  \n","Epoch:25/30     Step:6|6   loss:0.49302566051483154  \n","Epoch:25/30     Step:7|6   loss:0.4960257411003113  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4912091791629791  \n","Epoch:26/30     Step:2|6   loss:0.4917314052581787  \n","Epoch:26/30     Step:3|6   loss:0.498695433139801  \n","Epoch:26/30     Step:4|6   loss:0.4946129322052002  \n","Epoch:26/30     Step:5|6   loss:0.4947980046272278  \n","Epoch:26/30     Step:6|6   loss:0.49553483724594116  \n","Epoch:26/30     Step:7|6   loss:0.49142342805862427  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49129319190979004  \n","Epoch:27/30     Step:2|6   loss:0.49279075860977173  \n","Epoch:27/30     Step:3|6   loss:0.4939025044441223  \n","Epoch:27/30     Step:4|6   loss:0.4970851540565491  \n","Epoch:27/30     Step:5|6   loss:0.49260079860687256  \n","Epoch:27/30     Step:6|6   loss:0.49312523007392883  \n","Epoch:27/30     Step:7|6   loss:0.49351391196250916  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.5074931383132935  \n","Epoch:28/30     Step:2|6   loss:0.4936485290527344  \n","Epoch:28/30     Step:3|6   loss:0.4956817030906677  \n","Epoch:28/30     Step:4|6   loss:0.4964436888694763  \n","Epoch:28/30     Step:5|6   loss:0.49497097730636597  \n","Epoch:28/30     Step:6|6   loss:0.5102047324180603  \n","Epoch:28/30     Step:7|6   loss:0.5020451545715332  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4927586615085602  \n","Epoch:29/30     Step:2|6   loss:0.4927483797073364  \n","Epoch:29/30     Step:3|6   loss:0.49297428131103516  \n","Epoch:29/30     Step:4|6   loss:0.4944213628768921  \n","Epoch:29/30     Step:5|6   loss:0.4956498444080353  \n","Epoch:29/30     Step:6|6   loss:0.4964543581008911  \n","Epoch:29/30     Step:7|6   loss:0.4937608242034912  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.5056927800178528  \n","Epoch:30/30     Step:2|6   loss:0.49203234910964966  \n","Epoch:30/30     Step:3|6   loss:0.4954359531402588  \n","Epoch:30/30     Step:4|6   loss:0.4955308437347412  \n","Epoch:30/30     Step:5|6   loss:0.5007100105285645  \n","Epoch:30/30     Step:6|6   loss:0.4964507818222046  \n","Epoch:30/30     Step:7|6   loss:0.49325454235076904  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.2239660024642944  \n","Epoch:1/30     Step:2|6   loss:0.9800851941108704  \n","Epoch:1/30     Step:3|6   loss:0.752561628818512  \n","Epoch:1/30     Step:4|6   loss:0.6911936402320862  \n","Epoch:1/30     Step:5|6   loss:0.635877251625061  \n","Epoch:1/30     Step:6|6   loss:0.59996497631073  \n","Epoch:1/30     Step:7|6   loss:0.5379763245582581  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:97.2%\t train set:97.89%\n","Epoch:2/30     Step:1|6   loss:0.5527673959732056  \n","Epoch:2/30     Step:2|6   loss:0.573185384273529  \n","Epoch:2/30     Step:3|6   loss:0.5670282244682312  \n","Epoch:2/30     Step:4|6   loss:0.5580111145973206  \n","Epoch:2/30     Step:5|6   loss:0.5647743940353394  \n","Epoch:2/30     Step:6|6   loss:0.5318078994750977  \n","Epoch:2/30     Step:7|6   loss:0.5284715890884399  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.5316414833068848  \n","Epoch:3/30     Step:2|6   loss:0.523896336555481  \n","Epoch:3/30     Step:3|6   loss:0.5116621255874634  \n","Epoch:3/30     Step:4|6   loss:0.5305362343788147  \n","Epoch:3/30     Step:5|6   loss:0.5134387016296387  \n","Epoch:3/30     Step:6|6   loss:0.511748194694519  \n","Epoch:3/30     Step:7|6   loss:0.5410363078117371  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5174223184585571  \n","Epoch:4/30     Step:2|6   loss:0.5081674456596375  \n","Epoch:4/30     Step:3|6   loss:0.5263674259185791  \n","Epoch:4/30     Step:4|6   loss:0.5238950848579407  \n","Epoch:4/30     Step:5|6   loss:0.507028341293335  \n","Epoch:4/30     Step:6|6   loss:0.5000529289245605  \n","Epoch:4/30     Step:7|6   loss:0.5097106099128723  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5034549236297607  \n","Epoch:5/30     Step:2|6   loss:0.4991791844367981  \n","Epoch:5/30     Step:3|6   loss:0.5096220970153809  \n","Epoch:5/30     Step:4|6   loss:0.49828219413757324  \n","Epoch:5/30     Step:5|6   loss:0.5025520324707031  \n","Epoch:5/30     Step:6|6   loss:0.5003288388252258  \n","Epoch:5/30     Step:7|6   loss:0.4979914426803589  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5035054683685303  \n","Epoch:6/30     Step:2|6   loss:0.5075066089630127  \n","Epoch:6/30     Step:3|6   loss:0.4995195269584656  \n","Epoch:6/30     Step:4|6   loss:0.4961584806442261  \n","Epoch:6/30     Step:5|6   loss:0.49508604407310486  \n","Epoch:6/30     Step:6|6   loss:0.4982830286026001  \n","Epoch:6/30     Step:7|6   loss:0.49573057889938354  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49999064207077026  \n","Epoch:7/30     Step:2|6   loss:0.5041211247444153  \n","Epoch:7/30     Step:3|6   loss:0.4955120086669922  \n","Epoch:7/30     Step:4|6   loss:0.4995875954627991  \n","Epoch:7/30     Step:5|6   loss:0.49952489137649536  \n","Epoch:7/30     Step:6|6   loss:0.49705031514167786  \n","Epoch:7/30     Step:7|6   loss:0.49665194749832153  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4948892593383789  \n","Epoch:8/30     Step:2|6   loss:0.49874863028526306  \n","Epoch:8/30     Step:3|6   loss:0.5104140043258667  \n","Epoch:8/30     Step:4|6   loss:0.4962965250015259  \n","Epoch:8/30     Step:5|6   loss:0.4931153655052185  \n","Epoch:8/30     Step:6|6   loss:0.5045742988586426  \n","Epoch:8/30     Step:7|6   loss:0.5009759068489075  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.5057071447372437  \n","Epoch:9/30     Step:2|6   loss:0.4976077079772949  \n","Epoch:9/30     Step:3|6   loss:0.5112254619598389  \n","Epoch:9/30     Step:4|6   loss:0.4931398928165436  \n","Epoch:9/30     Step:5|6   loss:0.5017218589782715  \n","Epoch:9/30     Step:6|6   loss:0.5039880871772766  \n","Epoch:9/30     Step:7|6   loss:0.4994851350784302  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.5028876066207886  \n","Epoch:10/30     Step:2|6   loss:0.5010653138160706  \n","Epoch:10/30     Step:3|6   loss:0.49842017889022827  \n","Epoch:10/30     Step:4|6   loss:0.49474483728408813  \n","Epoch:10/30     Step:5|6   loss:0.49438291788101196  \n","Epoch:10/30     Step:6|6   loss:0.5095553398132324  \n","Epoch:10/30     Step:7|6   loss:0.4974256157875061  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49813783168792725  \n","Epoch:11/30     Step:2|6   loss:0.49591735005378723  \n","Epoch:11/30     Step:3|6   loss:0.5035425424575806  \n","Epoch:11/30     Step:4|6   loss:0.514117956161499  \n","Epoch:11/30     Step:5|6   loss:0.49948543310165405  \n","Epoch:11/30     Step:6|6   loss:0.4927480220794678  \n","Epoch:11/30     Step:7|6   loss:0.5041424036026001  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.5006604194641113  \n","Epoch:12/30     Step:2|6   loss:0.49611836671829224  \n","Epoch:12/30     Step:3|6   loss:0.4991297721862793  \n","Epoch:12/30     Step:4|6   loss:0.4938717484474182  \n","Epoch:12/30     Step:5|6   loss:0.4980940520763397  \n","Epoch:12/30     Step:6|6   loss:0.5044896602630615  \n","Epoch:12/30     Step:7|6   loss:0.49645161628723145  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.49801886081695557  \n","Epoch:13/30     Step:2|6   loss:0.49856171011924744  \n","Epoch:13/30     Step:3|6   loss:0.4925523102283478  \n","Epoch:13/30     Step:4|6   loss:0.49838921427726746  \n","Epoch:13/30     Step:5|6   loss:0.4951833486557007  \n","Epoch:13/30     Step:6|6   loss:0.49646201729774475  \n","Epoch:13/30     Step:7|6   loss:0.5543588399887085  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4938649535179138  \n","Epoch:14/30     Step:2|6   loss:0.49479684233665466  \n","Epoch:14/30     Step:3|6   loss:0.49432888627052307  \n","Epoch:14/30     Step:4|6   loss:0.5075075626373291  \n","Epoch:14/30     Step:5|6   loss:0.5163671970367432  \n","Epoch:14/30     Step:6|6   loss:0.4913797378540039  \n","Epoch:14/30     Step:7|6   loss:0.5095231533050537  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.495615154504776  \n","Epoch:15/30     Step:2|6   loss:0.4996834397315979  \n","Epoch:15/30     Step:3|6   loss:0.5050977468490601  \n","Epoch:15/30     Step:4|6   loss:0.49497950077056885  \n","Epoch:15/30     Step:5|6   loss:0.4947965443134308  \n","Epoch:15/30     Step:6|6   loss:0.4977326989173889  \n","Epoch:15/30     Step:7|6   loss:0.5014976263046265  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4969102442264557  \n","Epoch:16/30     Step:2|6   loss:0.49471142888069153  \n","Epoch:16/30     Step:3|6   loss:0.4936662018299103  \n","Epoch:16/30     Step:4|6   loss:0.4998294413089752  \n","Epoch:16/30     Step:5|6   loss:0.49316591024398804  \n","Epoch:16/30     Step:6|6   loss:0.49330517649650574  \n","Epoch:16/30     Step:7|6   loss:0.4951252043247223  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.518168032169342  \n","Epoch:17/30     Step:2|6   loss:0.4925135672092438  \n","Epoch:17/30     Step:3|6   loss:0.4947662651538849  \n","Epoch:17/30     Step:4|6   loss:0.4942615032196045  \n","Epoch:17/30     Step:5|6   loss:0.4951780140399933  \n","Epoch:17/30     Step:6|6   loss:0.49557727575302124  \n","Epoch:17/30     Step:7|6   loss:0.5161583423614502  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.49500465393066406  \n","Epoch:18/30     Step:2|6   loss:0.4952391982078552  \n","Epoch:18/30     Step:3|6   loss:0.4932483732700348  \n","Epoch:18/30     Step:4|6   loss:0.4938693344593048  \n","Epoch:18/30     Step:5|6   loss:0.4936215579509735  \n","Epoch:18/30     Step:6|6   loss:0.502826452255249  \n","Epoch:18/30     Step:7|6   loss:0.501335620880127  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.49728649854660034  \n","Epoch:19/30     Step:2|6   loss:0.5056442022323608  \n","Epoch:19/30     Step:3|6   loss:0.4926578104496002  \n","Epoch:19/30     Step:4|6   loss:0.4954712986946106  \n","Epoch:19/30     Step:5|6   loss:0.4929150342941284  \n","Epoch:19/30     Step:6|6   loss:0.49452218413352966  \n","Epoch:19/30     Step:7|6   loss:0.49268639087677  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.49331170320510864  \n","Epoch:20/30     Step:2|6   loss:0.4936150312423706  \n","Epoch:20/30     Step:3|6   loss:0.49350059032440186  \n","Epoch:20/30     Step:4|6   loss:0.49279093742370605  \n","Epoch:20/30     Step:5|6   loss:0.49298715591430664  \n","Epoch:20/30     Step:6|6   loss:0.4940367043018341  \n","Epoch:20/30     Step:7|6   loss:0.4954388737678528  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4952915906906128  \n","Epoch:21/30     Step:2|6   loss:0.4950375556945801  \n","Epoch:21/30     Step:3|6   loss:0.49298956990242004  \n","Epoch:21/30     Step:4|6   loss:0.4925161302089691  \n","Epoch:21/30     Step:5|6   loss:0.4911099970340729  \n","Epoch:21/30     Step:6|6   loss:0.5005104541778564  \n","Epoch:21/30     Step:7|6   loss:0.5082805156707764  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.49205201864242554  \n","Epoch:22/30     Step:2|6   loss:0.49433594942092896  \n","Epoch:22/30     Step:3|6   loss:0.4940417408943176  \n","Epoch:22/30     Step:4|6   loss:0.4942663311958313  \n","Epoch:22/30     Step:5|6   loss:0.49173372983932495  \n","Epoch:22/30     Step:6|6   loss:0.5002492070198059  \n","Epoch:22/30     Step:7|6   loss:0.491262286901474  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.49449849128723145  \n","Epoch:23/30     Step:2|6   loss:0.49209555983543396  \n","Epoch:23/30     Step:3|6   loss:0.4964332580566406  \n","Epoch:23/30     Step:4|6   loss:0.4904656708240509  \n","Epoch:23/30     Step:5|6   loss:0.49142467975616455  \n","Epoch:23/30     Step:6|6   loss:0.5094076991081238  \n","Epoch:23/30     Step:7|6   loss:0.49938297271728516  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49080199003219604  \n","Epoch:24/30     Step:2|6   loss:0.4963570237159729  \n","Epoch:24/30     Step:3|6   loss:0.4991223216056824  \n","Epoch:24/30     Step:4|6   loss:0.4912651777267456  \n","Epoch:24/30     Step:5|6   loss:0.4953228831291199  \n","Epoch:24/30     Step:6|6   loss:0.5076870918273926  \n","Epoch:24/30     Step:7|6   loss:0.4913853108882904  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49179595708847046  \n","Epoch:25/30     Step:2|6   loss:0.4925864338874817  \n","Epoch:25/30     Step:3|6   loss:0.4915558695793152  \n","Epoch:25/30     Step:4|6   loss:0.49342721700668335  \n","Epoch:25/30     Step:5|6   loss:0.493102490901947  \n","Epoch:25/30     Step:6|6   loss:0.5039185881614685  \n","Epoch:25/30     Step:7|6   loss:0.4954427480697632  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.49369707703590393  \n","Epoch:26/30     Step:2|6   loss:0.49301859736442566  \n","Epoch:26/30     Step:3|6   loss:0.4954274892807007  \n","Epoch:26/30     Step:4|6   loss:0.49711817502975464  \n","Epoch:26/30     Step:5|6   loss:0.4978134036064148  \n","Epoch:26/30     Step:6|6   loss:0.49377575516700745  \n","Epoch:26/30     Step:7|6   loss:0.4938139319419861  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49183836579322815  \n","Epoch:27/30     Step:2|6   loss:0.4929264485836029  \n","Epoch:27/30     Step:3|6   loss:0.494430273771286  \n","Epoch:27/30     Step:4|6   loss:0.4923846125602722  \n","Epoch:27/30     Step:5|6   loss:0.49394088983535767  \n","Epoch:27/30     Step:6|6   loss:0.49214091897010803  \n","Epoch:27/30     Step:7|6   loss:0.4940950870513916  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.49060142040252686  \n","Epoch:28/30     Step:2|6   loss:0.49135783314704895  \n","Epoch:28/30     Step:3|6   loss:0.490790992975235  \n","Epoch:28/30     Step:4|6   loss:0.4973462224006653  \n","Epoch:28/30     Step:5|6   loss:0.4948621690273285  \n","Epoch:28/30     Step:6|6   loss:0.4962539076805115  \n","Epoch:28/30     Step:7|6   loss:0.49097195267677307  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4944954216480255  \n","Epoch:29/30     Step:2|6   loss:0.49416521191596985  \n","Epoch:29/30     Step:3|6   loss:0.4936476945877075  \n","Epoch:29/30     Step:4|6   loss:0.4952443242073059  \n","Epoch:29/30     Step:5|6   loss:0.5015668869018555  \n","Epoch:29/30     Step:6|6   loss:0.49093398451805115  \n","Epoch:29/30     Step:7|6   loss:0.49458959698677063  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4924078583717346  \n","Epoch:30/30     Step:2|6   loss:0.4970453679561615  \n","Epoch:30/30     Step:3|6   loss:0.49391311407089233  \n","Epoch:30/30     Step:4|6   loss:0.5001359581947327  \n","Epoch:30/30     Step:5|6   loss:0.4967364966869354  \n","Epoch:30/30     Step:6|6   loss:0.49331167340278625  \n","Epoch:30/30     Step:7|6   loss:0.49793076515197754  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 100.00 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model Mobilenetv2 --mode rgb --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":13,"id":"b27570bf","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1825473308563232  \n","Epoch:1/30     Step:2|6   loss:1.0683693885803223  \n","Epoch:1/30     Step:3|6   loss:0.8480161428451538  \n","Epoch:1/30     Step:4|6   loss:0.7680370807647705  \n","Epoch:1/30     Step:5|6   loss:0.7106571197509766  \n","Epoch:1/30     Step:6|6   loss:0.6698383092880249  \n","Epoch:1/30     Step:7|6   loss:0.6476912498474121  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 85.25 %\n","current max accuracy\t test set:84.11%\t train set:85.25%\n","Epoch:2/30     Step:1|6   loss:0.6116799116134644  \n","Epoch:2/30     Step:2|6   loss:0.6438634395599365  \n","Epoch:2/30     Step:3|6   loss:0.5566295981407166  \n","Epoch:2/30     Step:4|6   loss:0.5888584852218628  \n","Epoch:2/30     Step:5|6   loss:0.5967320203781128  \n","Epoch:2/30     Step:6|6   loss:0.6206344366073608  \n","Epoch:2/30     Step:7|6   loss:0.5928407311439514  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:96.26%\t train set:96.25%\n","Epoch:3/30     Step:1|6   loss:0.5364350080490112  \n","Epoch:3/30     Step:2|6   loss:0.5231539011001587  \n","Epoch:3/30     Step:3|6   loss:0.5520269870758057  \n","Epoch:3/30     Step:4|6   loss:0.5247504115104675  \n","Epoch:3/30     Step:5|6   loss:0.5419988036155701  \n","Epoch:3/30     Step:6|6   loss:0.5225130319595337  \n","Epoch:3/30     Step:7|6   loss:0.5303153395652771  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5276898145675659  \n","Epoch:4/30     Step:2|6   loss:0.5292739868164062  \n","Epoch:4/30     Step:3|6   loss:0.5172248482704163  \n","Epoch:4/30     Step:4|6   loss:0.5178321003913879  \n","Epoch:4/30     Step:5|6   loss:0.5120954513549805  \n","Epoch:4/30     Step:6|6   loss:0.5203601121902466  \n","Epoch:4/30     Step:7|6   loss:0.5124053359031677  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5048249959945679  \n","Epoch:5/30     Step:2|6   loss:0.5157045722007751  \n","Epoch:5/30     Step:3|6   loss:0.5162397027015686  \n","Epoch:5/30     Step:4|6   loss:0.5051858425140381  \n","Epoch:5/30     Step:5|6   loss:0.5035566687583923  \n","Epoch:5/30     Step:6|6   loss:0.5029978156089783  \n","Epoch:5/30     Step:7|6   loss:0.5060622692108154  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49805742502212524  \n","Epoch:6/30     Step:2|6   loss:0.5031707882881165  \n","Epoch:6/30     Step:3|6   loss:0.5097433924674988  \n","Epoch:6/30     Step:4|6   loss:0.5157790184020996  \n","Epoch:6/30     Step:5|6   loss:0.500565767288208  \n","Epoch:6/30     Step:6|6   loss:0.5251200199127197  \n","Epoch:6/30     Step:7|6   loss:0.5007379055023193  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4957038164138794  \n","Epoch:7/30     Step:2|6   loss:0.5074409246444702  \n","Epoch:7/30     Step:3|6   loss:0.49816200137138367  \n","Epoch:7/30     Step:4|6   loss:0.4996185898780823  \n","Epoch:7/30     Step:5|6   loss:0.49675577878952026  \n","Epoch:7/30     Step:6|6   loss:0.4943183958530426  \n","Epoch:7/30     Step:7|6   loss:0.5379645824432373  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4978237748146057  \n","Epoch:8/30     Step:2|6   loss:0.49672606587409973  \n","Epoch:8/30     Step:3|6   loss:0.4945084750652313  \n","Epoch:8/30     Step:4|6   loss:0.5080550312995911  \n","Epoch:8/30     Step:5|6   loss:0.5029692053794861  \n","Epoch:8/30     Step:6|6   loss:0.5039938688278198  \n","Epoch:8/30     Step:7|6   loss:0.49347051978111267  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4938778281211853  \n","Epoch:9/30     Step:2|6   loss:0.507847785949707  \n","Epoch:9/30     Step:3|6   loss:0.5067175030708313  \n","Epoch:9/30     Step:4|6   loss:0.4992160201072693  \n","Epoch:9/30     Step:5|6   loss:0.4949963092803955  \n","Epoch:9/30     Step:6|6   loss:0.5006746649742126  \n","Epoch:9/30     Step:7|6   loss:0.5049537420272827  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4972374439239502  \n","Epoch:10/30     Step:2|6   loss:0.4925753176212311  \n","Epoch:10/30     Step:3|6   loss:0.49289780855178833  \n","Epoch:10/30     Step:4|6   loss:0.494797945022583  \n","Epoch:10/30     Step:5|6   loss:0.4927259087562561  \n","Epoch:10/30     Step:6|6   loss:0.49651485681533813  \n","Epoch:10/30     Step:7|6   loss:0.49420082569122314  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.5047882199287415  \n","Epoch:11/30     Step:2|6   loss:0.49222037196159363  \n","Epoch:11/30     Step:3|6   loss:0.5038042068481445  \n","Epoch:11/30     Step:4|6   loss:0.5127296447753906  \n","Epoch:11/30     Step:5|6   loss:0.49363934993743896  \n","Epoch:11/30     Step:6|6   loss:0.5004764199256897  \n","Epoch:11/30     Step:7|6   loss:0.49700483679771423  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4949035048484802  \n","Epoch:12/30     Step:2|6   loss:0.49915561079978943  \n","Epoch:12/30     Step:3|6   loss:0.4995163381099701  \n","Epoch:12/30     Step:4|6   loss:0.49882620573043823  \n","Epoch:12/30     Step:5|6   loss:0.4973585307598114  \n","Epoch:12/30     Step:6|6   loss:0.4982295036315918  \n","Epoch:12/30     Step:7|6   loss:0.5035493969917297  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.49323421716690063  \n","Epoch:13/30     Step:2|6   loss:0.49792513251304626  \n","Epoch:13/30     Step:3|6   loss:0.5001069903373718  \n","Epoch:13/30     Step:4|6   loss:0.5018281936645508  \n","Epoch:13/30     Step:5|6   loss:0.5002814531326294  \n","Epoch:13/30     Step:6|6   loss:0.49218642711639404  \n","Epoch:13/30     Step:7|6   loss:0.4926116168498993  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.5027399659156799  \n","Epoch:14/30     Step:2|6   loss:0.4920005202293396  \n","Epoch:14/30     Step:3|6   loss:0.49802523851394653  \n","Epoch:14/30     Step:4|6   loss:0.49320781230926514  \n","Epoch:14/30     Step:5|6   loss:0.4944974184036255  \n","Epoch:14/30     Step:6|6   loss:0.5047272443771362  \n","Epoch:14/30     Step:7|6   loss:0.49552977085113525  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.49863067269325256  \n","Epoch:15/30     Step:2|6   loss:0.4963949918746948  \n","Epoch:15/30     Step:3|6   loss:0.49158430099487305  \n","Epoch:15/30     Step:4|6   loss:0.5081689357757568  \n","Epoch:15/30     Step:5|6   loss:0.4944254457950592  \n","Epoch:15/30     Step:6|6   loss:0.4937984049320221  \n","Epoch:15/30     Step:7|6   loss:0.523038923740387  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4953558146953583  \n","Epoch:16/30     Step:2|6   loss:0.4985811710357666  \n","Epoch:16/30     Step:3|6   loss:0.49933749437332153  \n","Epoch:16/30     Step:4|6   loss:0.4949064254760742  \n","Epoch:16/30     Step:5|6   loss:0.5043793320655823  \n","Epoch:16/30     Step:6|6   loss:0.49398332834243774  \n","Epoch:16/30     Step:7|6   loss:0.49565884470939636  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4956388473510742  \n","Epoch:17/30     Step:2|6   loss:0.4945402145385742  \n","Epoch:17/30     Step:3|6   loss:0.49476078152656555  \n","Epoch:17/30     Step:4|6   loss:0.49320894479751587  \n","Epoch:17/30     Step:5|6   loss:0.4972207546234131  \n","Epoch:17/30     Step:6|6   loss:0.49668920040130615  \n","Epoch:17/30     Step:7|6   loss:0.4948433041572571  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.49613896012306213  \n","Epoch:18/30     Step:2|6   loss:0.4942423701286316  \n","Epoch:18/30     Step:3|6   loss:0.5004513263702393  \n","Epoch:18/30     Step:4|6   loss:0.4978998899459839  \n","Epoch:18/30     Step:5|6   loss:0.49815016984939575  \n","Epoch:18/30     Step:6|6   loss:0.4952428638935089  \n","Epoch:18/30     Step:7|6   loss:0.49543094635009766  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4955105185508728  \n","Epoch:19/30     Step:2|6   loss:0.4944758415222168  \n","Epoch:19/30     Step:3|6   loss:0.5053662061691284  \n","Epoch:19/30     Step:4|6   loss:0.49929675459861755  \n","Epoch:19/30     Step:5|6   loss:0.49250975251197815  \n","Epoch:19/30     Step:6|6   loss:0.4921060800552368  \n","Epoch:19/30     Step:7|6   loss:0.5235927104949951  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.492276132106781  \n","Epoch:20/30     Step:2|6   loss:0.4961964190006256  \n","Epoch:20/30     Step:3|6   loss:0.4938199520111084  \n","Epoch:20/30     Step:4|6   loss:0.49255281686782837  \n","Epoch:20/30     Step:5|6   loss:0.4961588382720947  \n","Epoch:20/30     Step:6|6   loss:0.49444717168807983  \n","Epoch:20/30     Step:7|6   loss:0.4933699369430542  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.5138182044029236  \n","Epoch:21/30     Step:2|6   loss:0.4961138665676117  \n","Epoch:21/30     Step:3|6   loss:0.4915410876274109  \n","Epoch:21/30     Step:4|6   loss:0.4967038035392761  \n","Epoch:21/30     Step:5|6   loss:0.499966561794281  \n","Epoch:21/30     Step:6|6   loss:0.4928340017795563  \n","Epoch:21/30     Step:7|6   loss:0.4983474016189575  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.492633193731308  \n","Epoch:22/30     Step:2|6   loss:0.4957205057144165  \n","Epoch:22/30     Step:3|6   loss:0.49189627170562744  \n","Epoch:22/30     Step:4|6   loss:0.4927034378051758  \n","Epoch:22/30     Step:5|6   loss:0.49653807282447815  \n","Epoch:22/30     Step:6|6   loss:0.49201685190200806  \n","Epoch:22/30     Step:7|6   loss:0.5044293403625488  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4970744252204895  \n","Epoch:23/30     Step:2|6   loss:0.49512651562690735  \n","Epoch:23/30     Step:3|6   loss:0.49338817596435547  \n","Epoch:23/30     Step:4|6   loss:0.4979989528656006  \n","Epoch:23/30     Step:5|6   loss:0.4972628951072693  \n","1Epoch:23/30     Step:6|6   loss:0.49785733222961426  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:23/30     Step:7|6   loss:0.5002897381782532  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.494254469871521  \n","Epoch:24/30     Step:2|6   loss:0.5168997645378113  \n","Epoch:24/30     Step:3|6   loss:0.4971710443496704  \n","Epoch:24/30     Step:4|6   loss:0.504406213760376  \n","Epoch:24/30     Step:5|6   loss:0.512787938117981  \n","Epoch:24/30     Step:6|6   loss:0.5065003633499146  \n","Epoch:24/30     Step:7|6   loss:0.4982239007949829  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4938327670097351  \n","Epoch:25/30     Step:2|6   loss:0.5018714666366577  \n","Epoch:25/30     Step:3|6   loss:0.4977494180202484  \n","Epoch:25/30     Step:4|6   loss:0.4934338927268982  \n","Epoch:25/30     Step:5|6   loss:0.5037792921066284  \n","Epoch:25/30     Step:6|6   loss:0.4933573305606842  \n","Epoch:25/30     Step:7|6   loss:0.49564793705940247  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4966081976890564  \n","Epoch:26/30     Step:2|6   loss:0.49205633997917175  \n","Epoch:26/30     Step:3|6   loss:0.4957798719406128  \n","Epoch:26/30     Step:4|6   loss:0.49602389335632324  \n","Epoch:26/30     Step:5|6   loss:0.49741944670677185  \n","Epoch:26/30     Step:6|6   loss:0.4971158802509308  \n","Epoch:26/30     Step:7|6   loss:0.49849367141723633  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4956129193305969  \n","Epoch:27/30     Step:2|6   loss:0.4991704821586609  \n","Epoch:27/30     Step:3|6   loss:0.49302196502685547  \n","Epoch:27/30     Step:4|6   loss:0.4938232898712158  \n","Epoch:27/30     Step:5|6   loss:0.49183300137519836  \n","Epoch:27/30     Step:6|6   loss:0.5004192590713501  \n","Epoch:27/30     Step:7|6   loss:0.4965655207633972  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.5016030073165894  \n","Epoch:28/30     Step:2|6   loss:0.49426019191741943  \n","Epoch:28/30     Step:3|6   loss:0.4897216260433197  \n","Epoch:28/30     Step:4|6   loss:0.4942377209663391  \n","Epoch:28/30     Step:5|6   loss:0.4974104166030884  \n","Epoch:28/30     Step:6|6   loss:0.49216362833976746  \n","Epoch:28/30     Step:7|6   loss:0.495270311832428  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.492390900850296  \n","Epoch:29/30     Step:2|6   loss:0.4978155493736267  \n","Epoch:29/30     Step:3|6   loss:0.49232015013694763  \n","Epoch:29/30     Step:4|6   loss:0.49118104577064514  \n","Epoch:29/30     Step:5|6   loss:0.5035080909729004  \n","Epoch:29/30     Step:6|6   loss:0.49209266901016235  \n","Epoch:29/30     Step:7|6   loss:0.4944469928741455  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.49111515283584595  \n","Epoch:30/30     Step:2|6   loss:0.5006363391876221  \n","Epoch:30/30     Step:3|6   loss:0.4974554181098938  \n","Epoch:30/30     Step:4|6   loss:0.49393224716186523  \n","Epoch:30/30     Step:5|6   loss:0.49741095304489136  \n","Epoch:30/30     Step:6|6   loss:0.4974329173564911  \n","Epoch:30/30     Step:7|6   loss:0.49546754360198975  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.0349576473236084  \n","Epoch:1/30     Step:2|6   loss:0.8784356117248535  \n","Epoch:1/30     Step:3|6   loss:0.7373563051223755  \n","Epoch:1/30     Step:4|6   loss:0.7393733263015747  \n","Epoch:1/30     Step:5|6   loss:0.654579758644104  \n","Epoch:1/30     Step:6|6   loss:0.6052327156066895  \n","Epoch:1/30     Step:7|6   loss:0.5788912177085876  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:91.59%\t train set:91.57%\n","Epoch:2/30     Step:1|6   loss:0.5894133448600769  \n","Epoch:2/30     Step:2|6   loss:0.5948777198791504  \n","Epoch:2/30     Step:3|6   loss:0.5528993606567383  \n","Epoch:2/30     Step:4|6   loss:0.5569788813591003  \n","Epoch:2/30     Step:5|6   loss:0.5608648657798767  \n","Epoch:2/30     Step:6|6   loss:0.6268861889839172  \n","Epoch:2/30     Step:7|6   loss:0.5763370394706726  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:97.2%\t train set:98.59%\n","Epoch:3/30     Step:1|6   loss:0.5594930648803711  \n","Epoch:3/30     Step:2|6   loss:0.5359803438186646  \n","Epoch:3/30     Step:3|6   loss:0.5282874703407288  \n","Epoch:3/30     Step:4|6   loss:0.518994927406311  \n","Epoch:3/30     Step:5|6   loss:0.5139487981796265  \n","Epoch:3/30     Step:6|6   loss:0.5420159101486206  \n","Epoch:3/30     Step:7|6   loss:0.5466445088386536  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:4/30     Step:1|6   loss:0.5197916030883789  \n","Epoch:4/30     Step:2|6   loss:0.5155160427093506  \n","Epoch:4/30     Step:3|6   loss:0.5171226263046265  \n","Epoch:4/30     Step:4|6   loss:0.5174654722213745  \n","Epoch:4/30     Step:5|6   loss:0.5064366459846497  \n","Epoch:4/30     Step:6|6   loss:0.5126950144767761  \n","Epoch:4/30     Step:7|6   loss:0.5142804384231567  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5035088658332825  \n","Epoch:5/30     Step:2|6   loss:0.4981773793697357  \n","Epoch:5/30     Step:3|6   loss:0.5029750466346741  \n","Epoch:5/30     Step:4|6   loss:0.5002066493034363  \n","Epoch:5/30     Step:5|6   loss:0.4975612163543701  \n","Epoch:5/30     Step:6|6   loss:0.5004344582557678  \n","Epoch:5/30     Step:7|6   loss:0.5045002698898315  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4989180266857147  \n","Epoch:6/30     Step:2|6   loss:0.5026087164878845  \n","Epoch:6/30     Step:3|6   loss:0.49492767453193665  \n","Epoch:6/30     Step:4|6   loss:0.4991193413734436  \n","Epoch:6/30     Step:5|6   loss:0.5023980140686035  \n","Epoch:6/30     Step:6|6   loss:0.5042120218276978  \n","Epoch:6/30     Step:7|6   loss:0.5191034078598022  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","2Epoch:7/30     Step:1|6   loss:0.5046401023864746  \n","Epoch:7/30     Step:2|6   loss:0.4951167106628418  \n","Epoch:7/30     Step:3|6   loss:0.4989369511604309  \n","Epoch:7/30     Step:4|6   loss:0.4968884289264679  \n","Epoch:7/30     Step:5|6   loss:0.4965009093284607  \n","Epoch:7/30     Step:6|6   loss:0.5064263343811035  \n","Epoch:7/30     Step:7|6   loss:0.5007203221321106  \n","Accuracy on test_set: 99.07 %\n","\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4950759708881378  \n","Epoch:8/30     Step:2|6   loss:0.5014267563819885  \n","Epoch:8/30     Step:3|6   loss:0.5003631711006165  \n","Epoch:8/30     Step:4|6   loss:0.5030139088630676  \n","Epoch:8/30     Step:5|6   loss:0.4994393587112427  \n","Epoch:8/30     Step:6|6   loss:0.49779754877090454  \n","Epoch:8/30     Step:7|6   loss:0.4956226944923401  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4948368966579437  \n","Epoch:9/30     Step:2|6   loss:0.5009484887123108  \n","Epoch:9/30     Step:3|6   loss:0.4963260889053345  \n","Epoch:9/30     Step:4|6   loss:0.4947059154510498  \n","Epoch:9/30     Step:5|6   loss:0.4956537187099457  \n","Epoch:9/30     Step:6|6   loss:0.49609899520874023  \n","Epoch:9/30     Step:7|6   loss:0.49775537848472595  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49283367395401  \n","Epoch:10/30     Step:2|6   loss:0.5018250942230225  \n","Epoch:10/30     Step:3|6   loss:0.4967549741268158  \n","Epoch:10/30     Step:4|6   loss:0.5010905265808105  \n","Epoch:10/30     Step:5|6   loss:0.496624618768692  \n","Epoch:10/30     Step:6|6   loss:0.4933980703353882  \n","Epoch:10/30     Step:7|6   loss:0.5024309754371643  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49905186891555786  \n","Epoch:11/30     Step:2|6   loss:0.49447691440582275  \n","Epoch:11/30     Step:3|6   loss:0.49942976236343384  \n","Epoch:11/30     Step:4|6   loss:0.5004416704177856  \n","Epoch:11/30     Step:5|6   loss:0.49403080344200134  \n","Epoch:11/30     Step:6|6   loss:0.4975854158401489  \n","Epoch:11/30     Step:7|6   loss:0.4995967745780945  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.5043342113494873  \n","Epoch:12/30     Step:2|6   loss:0.4952043890953064  \n","Epoch:12/30     Step:3|6   loss:0.4938306212425232  \n","Epoch:12/30     Step:4|6   loss:0.5055865049362183  \n","Epoch:12/30     Step:5|6   loss:0.49874797463417053  \n","Epoch:12/30     Step:6|6   loss:0.5002242922782898  \n","Epoch:12/30     Step:7|6   loss:0.519390344619751  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4947924017906189  \n","Epoch:13/30     Step:2|6   loss:0.49390673637390137  \n","Epoch:13/30     Step:3|6   loss:0.4980715811252594  \n","Epoch:13/30     Step:4|6   loss:0.49785393476486206  \n","Epoch:13/30     Step:5|6   loss:0.4936525523662567  \n","Epoch:13/30     Step:6|6   loss:0.4998543858528137  \n","Epoch:13/30     Step:7|6   loss:0.4957776367664337  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4908662736415863  \n","Epoch:14/30     Step:2|6   loss:0.49483898282051086  \n","Epoch:14/30     Step:3|6   loss:0.4959488809108734  \n","Epoch:14/30     Step:4|6   loss:0.49590855836868286  \n","Epoch:14/30     Step:5|6   loss:0.4927825331687927  \n","Epoch:14/30     Step:6|6   loss:0.49381959438323975  \n","Epoch:14/30     Step:7|6   loss:0.4928916096687317  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4957600235939026  \n","Epoch:15/30     Step:2|6   loss:0.4943917989730835  \n","Epoch:15/30     Step:3|6   loss:0.4935963749885559  \n","Epoch:15/30     Step:4|6   loss:0.4932674169540405  \n","Epoch:15/30     Step:5|6   loss:0.49178022146224976  \n","Epoch:15/30     Step:6|6   loss:0.4920283555984497  \n","Epoch:15/30     Step:7|6   loss:0.4973962903022766  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4934713840484619  \n","Epoch:16/30     Step:2|6   loss:0.4989011883735657  \n","Epoch:16/30     Step:3|6   loss:0.4922819435596466  \n","Epoch:16/30     Step:4|6   loss:0.498024582862854  \n","Epoch:16/30     Step:5|6   loss:0.5048231482505798  \n","Epoch:16/30     Step:6|6   loss:0.49938711524009705  \n","Epoch:16/30     Step:7|6   loss:0.49520912766456604  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4976876378059387  \n","Epoch:17/30     Step:2|6   loss:0.49343061447143555  \n","Epoch:17/30     Step:3|6   loss:0.4936256408691406  \n","Epoch:17/30     Step:4|6   loss:0.4929366409778595  \n","Epoch:17/30     Step:5|6   loss:0.4923866093158722  \n","Epoch:17/30     Step:6|6   loss:0.49202635884284973  \n","Epoch:17/30     Step:7|6   loss:0.5055310130119324  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.49998849630355835  \n","Epoch:18/30     Step:2|6   loss:0.49216464161872864  \n","Epoch:18/30     Step:3|6   loss:0.49163520336151123  \n","Epoch:18/30     Step:4|6   loss:0.4935283660888672  \n","Epoch:18/30     Step:5|6   loss:0.4971769452095032  \n","Epoch:18/30     Step:6|6   loss:0.501288115978241  \n","Epoch:18/30     Step:7|6   loss:0.4934755861759186  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4927994906902313  \n","Epoch:19/30     Step:2|6   loss:0.4967374801635742  \n","Epoch:19/30     Step:3|6   loss:0.49182984232902527  \n","Epoch:19/30     Step:4|6   loss:0.4941452741622925  \n","Epoch:19/30     Step:5|6   loss:0.4936414957046509  \n","Epoch:19/30     Step:6|6   loss:0.5104203224182129  \n","Epoch:19/30     Step:7|6   loss:0.4970487952232361  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.49610474705696106  \n","Epoch:20/30     Step:2|6   loss:0.4967919588088989  \n","Epoch:20/30     Step:3|6   loss:0.496046781539917  \n","Epoch:20/30     Step:4|6   loss:0.4938424825668335  \n","Epoch:20/30     Step:5|6   loss:0.4965342879295349  \n","Epoch:20/30     Step:6|6   loss:0.49580511450767517  \n","Epoch:20/30     Step:7|6   loss:0.5059794783592224  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4922471046447754  \n","Epoch:21/30     Step:2|6   loss:0.49275481700897217  \n","Epoch:21/30     Step:3|6   loss:0.4933343529701233  \n","Epoch:21/30     Step:4|6   loss:0.49209946393966675  \n","Epoch:21/30     Step:5|6   loss:0.4953804612159729  \n","Epoch:21/30     Step:6|6   loss:0.5019155144691467  \n","Epoch:21/30     Step:7|6   loss:0.49996456503868103  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4930722713470459  \n","Epoch:22/30     Step:2|6   loss:0.49110057950019836  \n","Epoch:22/30     Step:3|6   loss:0.4918327331542969  \n","Epoch:22/30     Step:4|6   loss:0.49360013008117676  \n","Epoch:22/30     Step:5|6   loss:0.4936366379261017  \n","Epoch:22/30     Step:6|6   loss:0.5034142136573792  \n","Epoch:22/30     Step:7|6   loss:0.5041856169700623  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4974912106990814  \n","Epoch:23/30     Step:2|6   loss:0.49330687522888184  \n","Epoch:23/30     Step:3|6   loss:0.49753084778785706  \n","Epoch:23/30     Step:4|6   loss:0.49025958776474  \n","Epoch:23/30     Step:5|6   loss:0.5070279836654663  \n","Epoch:23/30     Step:6|6   loss:0.49304336309432983  \n","Epoch:23/30     Step:7|6   loss:0.49458053708076477  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49562951922416687  \n","Epoch:24/30     Step:2|6   loss:0.4919591248035431  \n","Epoch:24/30     Step:3|6   loss:0.49211469292640686  \n","Epoch:24/30     Step:4|6   loss:0.4972403347492218  \n","Epoch:24/30     Step:5|6   loss:0.49178948998451233  \n","Epoch:24/30     Step:6|6   loss:0.4974023401737213  \n","Epoch:24/30     Step:7|6   loss:0.5024250149726868  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4910277724266052  \n","Epoch:25/30     Step:2|6   loss:0.4923774302005768  \n","Epoch:25/30     Step:3|6   loss:0.49686992168426514  \n","Epoch:25/30     Step:4|6   loss:0.5051166415214539  \n","Epoch:25/30     Step:5|6   loss:0.4904925525188446  \n","Epoch:25/30     Step:6|6   loss:0.499015212059021  \n","Epoch:25/30     Step:7|6   loss:0.5040215849876404  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.49131321907043457  \n","Epoch:26/30     Step:2|6   loss:0.495747834444046  \n","Epoch:26/30     Step:3|6   loss:0.49592888355255127  \n","Epoch:26/30     Step:4|6   loss:0.4924998879432678  \n","Epoch:26/30     Step:5|6   loss:0.5086569786071777  \n","Epoch:26/30     Step:6|6   loss:0.49331873655319214  \n","Epoch:26/30     Step:7|6   loss:0.4971957206726074  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49638253450393677  \n","Epoch:27/30     Step:2|6   loss:0.49261534214019775  \n","Epoch:27/30     Step:3|6   loss:0.492082417011261  \n","Epoch:27/30     Step:4|6   loss:0.5013841390609741  \n","Epoch:27/30     Step:5|6   loss:0.4905543029308319  \n","Epoch:27/30     Step:6|6   loss:0.4915209412574768  \n","Epoch:27/30     Step:7|6   loss:0.5109294056892395  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4930795133113861  \n","Epoch:28/30     Step:2|6   loss:0.494225412607193  \n","Epoch:28/30     Step:3|6   loss:0.4935479164123535  \n","Epoch:28/30     Step:4|6   loss:0.4925612807273865  \n","Epoch:28/30     Step:5|6   loss:0.493821918964386  \n","Epoch:28/30     Step:6|6   loss:0.4906283915042877  \n","Epoch:28/30     Step:7|6   loss:0.4954007565975189  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49587482213974  \n","Epoch:29/30     Step:2|6   loss:0.49864059686660767  \n","Epoch:29/30     Step:3|6   loss:0.49068090319633484  \n","Epoch:29/30     Step:4|6   loss:0.4924764633178711  \n","Epoch:29/30     Step:5|6   loss:0.4927023649215698  \n","Epoch:29/30     Step:6|6   loss:0.4922710061073303  \n","Epoch:29/30     Step:7|6   loss:0.5082980990409851  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.493058443069458  \n","Epoch:30/30     Step:2|6   loss:0.49168574810028076  \n","Epoch:30/30     Step:3|6   loss:0.4926730692386627  \n","Epoch:30/30     Step:4|6   loss:0.48957616090774536  \n","Epoch:30/30     Step:5|6   loss:0.49763888120651245  \n","Epoch:30/30     Step:6|6   loss:0.49260133504867554  \n","Epoch:30/30     Step:7|6   loss:0.4952104091644287  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(3\n"]},{"name":"stdout","output_type":"stream","text":["\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.089147686958313  \n","Epoch:1/30     Step:2|6   loss:0.9315573573112488  \n","Epoch:1/30     Step:3|6   loss:0.7920370101928711  \n","Epoch:1/30     Step:4|6   loss:0.7192363739013672  \n","Epoch:1/30     Step:5|6   loss:0.6976374387741089  \n","Epoch:1/30     Step:6|6   loss:0.5719237327575684  \n","Epoch:1/30     Step:7|6   loss:0.6588555574417114  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 89.23 %\n","current max accuracy\t test set:91.59%\t train set:89.23%\n","Epoch:2/30     Step:1|6   loss:0.6112506985664368  \n","Epoch:2/30     Step:2|6   loss:0.572144091129303  \n","Epoch:2/30     Step:3|6   loss:0.6233200430870056  \n","Epoch:2/30     Step:4|6   loss:0.576119065284729  \n","Epoch:2/30     Step:5|6   loss:0.5645102858543396  \n","Epoch:2/30     Step:6|6   loss:0.5924156904220581  \n","Epoch:2/30     Step:7|6   loss:0.5565210580825806  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:100.0%\t train set:98.13%\n","Epoch:3/30     Step:1|6   loss:0.5687506794929504  \n","Epoch:3/30     Step:2|6   loss:0.5685179829597473  \n","Epoch:3/30     Step:3|6   loss:0.5316989421844482  \n","Epoch:3/30     Step:4|6   loss:0.5278436541557312  \n","Epoch:3/30     Step:5|6   loss:0.5221518278121948  \n","Epoch:3/30     Step:6|6   loss:0.5202059745788574  \n","Epoch:3/30     Step:7|6   loss:0.527407705783844  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:100.0%\t train set:99.3%\n","Epoch:4/30     Step:1|6   loss:0.5185616612434387  \n","Epoch:4/30     Step:2|6   loss:0.5077541470527649  \n","Epoch:4/30     Step:3|6   loss:0.5058771371841431  \n","Epoch:4/30     Step:4|6   loss:0.5090129971504211  \n","Epoch:4/30     Step:5|6   loss:0.5106338262557983  \n","Epoch:4/30     Step:6|6   loss:0.5173286199569702  \n","Epoch:4/30     Step:7|6   loss:0.5073436498641968  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5051116347312927  \n","Epoch:5/30     Step:2|6   loss:0.5010436177253723  \n","Epoch:5/30     Step:3|6   loss:0.5057474374771118  \n","Epoch:5/30     Step:4|6   loss:0.5197497606277466  \n","Epoch:5/30     Step:5|6   loss:0.4975464344024658  \n","Epoch:5/30     Step:6|6   loss:0.50624680519104  \n","Epoch:5/30     Step:7|6   loss:0.5026754140853882  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4967345595359802  \n","Epoch:6/30     Step:2|6   loss:0.5007004737854004  \n","Epoch:6/30     Step:3|6   loss:0.49995362758636475  \n","Epoch:6/30     Step:4|6   loss:0.5042046904563904  \n","Epoch:6/30     Step:5|6   loss:0.5003039240837097  \n","Epoch:6/30     Step:6|6   loss:0.5102541446685791  \n","Epoch:6/30     Step:7|6   loss:0.5089567303657532  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49787062406539917  \n","Epoch:7/30     Step:2|6   loss:0.49773290753364563  \n","Epoch:7/30     Step:3|6   loss:0.5004703998565674  \n","Epoch:7/30     Step:4|6   loss:0.5043492913246155  \n","Epoch:7/30     Step:5|6   loss:0.4959909915924072  \n","Epoch:7/30     Step:6|6   loss:0.5067396759986877  \n","Epoch:7/30     Step:7|6   loss:0.4957805871963501  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4955565333366394  \n","Epoch:8/30     Step:2|6   loss:0.49688947200775146  \n","Epoch:8/30     Step:3|6   loss:0.49908140301704407  \n","Epoch:8/30     Step:4|6   loss:0.49977463483810425  \n","Epoch:8/30     Step:5|6   loss:0.49226146936416626  \n","Epoch:8/30     Step:6|6   loss:0.49548059701919556  \n","Epoch:8/30     Step:7|6   loss:0.5070601105690002  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49401727318763733  \n","Epoch:9/30     Step:2|6   loss:0.5005069971084595  \n","Epoch:9/30     Step:3|6   loss:0.493865430355072  \n","Epoch:9/30     Step:4|6   loss:0.499850869178772  \n","Epoch:9/30     Step:5|6   loss:0.4912418723106384  \n","Epoch:9/30     Step:6|6   loss:0.4929945766925812  \n","Epoch:9/30     Step:7|6   loss:0.5014229416847229  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.5049659609794617  \n","Epoch:10/30     Step:2|6   loss:0.5100294351577759  \n","Epoch:10/30     Step:3|6   loss:0.49343493580818176  \n","Epoch:10/30     Step:4|6   loss:0.4965359568595886  \n","Epoch:10/30     Step:5|6   loss:0.5076636075973511  \n","Epoch:10/30     Step:6|6   loss:0.49866509437561035  \n","Epoch:10/30     Step:7|6   loss:0.4931282103061676  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49457529187202454  \n","Epoch:11/30     Step:2|6   loss:0.5058610439300537  \n","Epoch:11/30     Step:3|6   loss:0.4990367591381073  \n","Epoch:11/30     Step:4|6   loss:0.49405789375305176  \n","Epoch:11/30     Step:5|6   loss:0.4962311089038849  \n","Epoch:11/30     Step:6|6   loss:0.49371522665023804  \n","Epoch:11/30     Step:7|6   loss:0.49982306361198425  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4957001805305481  \n","Epoch:12/30     Step:2|6   loss:0.4937003254890442  \n","Epoch:12/30     Step:3|6   loss:0.49137067794799805  \n","Epoch:12/30     Step:4|6   loss:0.49604329466819763  \n","Epoch:12/30     Step:5|6   loss:0.4999069273471832  \n","Epoch:12/30     Step:6|6   loss:0.4981902241706848  \n","Epoch:12/30     Step:7|6   loss:0.5058311223983765  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4926757216453552  \n","Epoch:13/30     Step:2|6   loss:0.4958198368549347  \n","Epoch:13/30     Step:3|6   loss:0.4949050843715668  \n","Epoch:13/30     Step:4|6   loss:0.4968200623989105  \n","Epoch:13/30     Step:5|6   loss:0.4952731132507324  \n","Epoch:13/30     Step:6|6   loss:0.49381738901138306  \n","Epoch:13/30     Step:7|6   loss:0.49226969480514526  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4913400411605835  \n","Epoch:14/30     Step:2|6   loss:0.49173101782798767  \n","Epoch:14/30     Step:3|6   loss:0.4971887469291687  \n","Epoch:14/30     Step:4|6   loss:0.4932025671005249  \n","Epoch:14/30     Step:5|6   loss:0.4944306015968323  \n","Epoch:14/30     Step:6|6   loss:0.4942808747291565  \n","Epoch:14/30     Step:7|6   loss:0.49497729539871216  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4921620190143585  \n","Epoch:15/30     Step:2|6   loss:0.4954241216182709  \n","Epoch:15/30     Step:3|6   loss:0.4953385591506958  \n","Epoch:15/30     Step:4|6   loss:0.4929129183292389  \n","Epoch:15/30     Step:5|6   loss:0.4916222393512726  \n","Epoch:15/30     Step:6|6   loss:0.4944404661655426  \n","Epoch:15/30     Step:7|6   loss:0.5385967493057251  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4926793873310089  \n","Epoch:16/30     Step:2|6   loss:0.49370846152305603  \n","Epoch:16/30     Step:3|6   loss:0.4960837662220001  \n","Epoch:16/30     Step:4|6   loss:0.4930289089679718  \n","Epoch:16/30     Step:5|6   loss:0.49903756380081177  \n","Epoch:16/30     Step:6|6   loss:0.5036939382553101  \n","Epoch:16/30     Step:7|6   loss:0.495944619178772  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.49309778213500977  \n","Epoch:17/30     Step:2|6   loss:0.4947316646575928  \n","Epoch:17/30     Step:3|6   loss:0.4918283224105835  \n","Epoch:17/30     Step:4|6   loss:0.49449488520622253  \n","Epoch:17/30     Step:5|6   loss:0.49067002534866333  \n","Epoch:17/30     Step:6|6   loss:0.4920387268066406  \n","Epoch:17/30     Step:7|6   loss:0.49676698446273804  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.5085947513580322  \n","Epoch:18/30     Step:2|6   loss:0.5124554634094238  \n","Epoch:18/30     Step:3|6   loss:0.492252379655838  \n","Epoch:18/30     Step:4|6   loss:0.4945627748966217  \n","Epoch:18/30     Step:5|6   loss:0.49267056584358215  \n","Epoch:18/30     Step:6|6   loss:0.49714183807373047  \n","Epoch:18/30     Step:7|6   loss:0.4922659397125244  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4937862455844879  \n","Epoch:19/30     Step:2|6   loss:0.49666157364845276  \n","Epoch:19/30     Step:3|6   loss:0.4962608814239502  \n","Epoch:19/30     Step:4|6   loss:0.4905501902103424  \n","Epoch:19/30     Step:5|6   loss:0.493264764547348  \n","Epoch:19/30     Step:6|6   loss:0.4943511486053467  \n","Epoch:19/30     Step:7|6   loss:0.4955229163169861  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.49151352047920227  \n","Epoch:20/30     Step:2|6   loss:0.4952598512172699  \n","Epoch:20/30     Step:3|6   loss:0.4950193166732788  \n","Epoch:20/30     Step:4|6   loss:0.4931817948818207  \n","Epoch:20/30     Step:5|6   loss:0.4925176501274109  \n","Epoch:20/30     Step:6|6   loss:0.4960280656814575  \n","Epoch:20/30     Step:7|6   loss:0.5040093064308167  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.49436965584754944  \n","Epoch:21/30     Step:2|6   loss:0.4944879710674286  \n","Epoch:21/30     Step:3|6   loss:0.49608004093170166  \n","Epoch:21/30     Step:4|6   loss:0.49463793635368347  \n","Epoch:21/30     Step:5|6   loss:0.4945583641529083  \n","Epoch:21/30     Step:6|6   loss:0.4998309314250946  \n","Epoch:21/30     Step:7|6   loss:0.49486199021339417  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.49634885787963867  \n","Epoch:22/30     Step:2|6   loss:0.49284812808036804  \n","Epoch:22/30     Step:3|6   loss:0.49951329827308655  \n","Epoch:22/30     Step:4|6   loss:0.49277910590171814  \n","Epoch:22/30     Step:5|6   loss:0.4914994239807129  \n","Epoch:22/30     Step:6|6   loss:0.4938001036643982  \n","Epoch:22/30     Step:7|6   loss:0.5046941041946411  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4930111765861511  \n","Epoch:23/30     Step:2|6   loss:0.4918400049209595  \n","Epoch:23/30     Step:3|6   loss:0.49660688638687134  \n","Epoch:23/30     Step:4|6   loss:0.4939054548740387  \n","Epoch:23/30     Step:5|6   loss:0.5159133076667786  \n","Epoch:23/30     Step:6|6   loss:0.4945436716079712  \n","Epoch:23/30     Step:7|6   loss:0.49727392196655273  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4966006875038147  \n","Epoch:24/30     Step:2|6   loss:0.4922139346599579  \n","Epoch:24/30     Step:3|6   loss:0.4951707422733307  \n","Epoch:24/30     Step:4|6   loss:0.4939611256122589  \n","Epoch:24/30     Step:5|6   loss:0.4933757781982422  \n","Epoch:24/30     Step:6|6   loss:0.4944157898426056  \n","Epoch:24/30     Step:7|6   loss:0.4962737560272217  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4914119243621826  \n","Epoch:25/30     Step:2|6   loss:0.4923224449157715  \n","Epoch:25/30     Step:3|6   loss:0.4979274272918701  \n","Epoch:25/30     Step:4|6   loss:0.4954260587692261  \n","Epoch:25/30     Step:5|6   loss:0.49368569254875183  \n","Epoch:25/30     Step:6|6   loss:0.494301438331604  \n","Epoch:25/30     Step:7|6   loss:0.5091614127159119  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.490931898355484  \n","Epoch:26/30     Step:2|6   loss:0.5002914071083069  \n","Epoch:26/30     Step:3|6   loss:0.4991579055786133  \n","Epoch:26/30     Step:4|6   loss:0.4943125247955322  \n","Epoch:26/30     Step:5|6   loss:0.49199390411376953  \n","Epoch:26/30     Step:6|6   loss:0.4980209469795227  \n","Epoch:26/30     Step:7|6   loss:0.495347261428833  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49298393726348877  \n","Epoch:27/30     Step:2|6   loss:0.4917777180671692  \n","Epoch:27/30     Step:3|6   loss:0.4949132800102234  \n","Epoch:27/30     Step:4|6   loss:0.49456003308296204  \n","Epoch:27/30     Step:5|6   loss:0.4906630516052246  \n","Epoch:27/30     Step:6|6   loss:0.49440181255340576  \n","Epoch:27/30     Step:7|6   loss:0.4987137019634247  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.5003776550292969  \n","Epoch:28/30     Step:2|6   loss:0.49198657274246216  \n","Epoch:28/30     Step:3|6   loss:0.4931592345237732  \n","Epoch:28/30     Step:4|6   loss:0.4899297058582306  \n","Epoch:28/30     Step:5|6   loss:0.4906926155090332  \n","Epoch:28/30     Step:6|6   loss:0.49240654706954956  \n","Epoch:28/30     Step:7|6   loss:0.4928785562515259  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4936440587043762  \n","Epoch:29/30     Step:2|6   loss:0.49100053310394287  \n","Epoch:29/30     Step:3|6   loss:0.49802881479263306  \n","Epoch:29/30     Step:4|6   loss:0.4940425455570221  \n","Epoch:29/30     Step:5|6   loss:0.4929189682006836  \n","Epoch:29/30     Step:6|6   loss:0.4920462369918823  \n","Epoch:29/30     Step:7|6   loss:0.4928746223449707  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4911056458950043  \n","Epoch:30/30     Step:2|6   loss:0.4986317753791809  \n","Epoch:30/30     Step:3|6   loss:0.49372199177742004  \n","Epoch:30/30     Step:4|6   loss:0.49687275290489197  \n","Epoch:30/30     Step:5|6   loss:0.49371787905693054  \n","Epoch:30/30     Step:6|6   loss:0.5004462599754333  \n","Epoch:30/30     Step:7|6   loss:0.4946383833885193  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 100.00 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","4          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n"]},{"name":"stdout","output_type":"stream","text":["\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.20260751247406  \n","Epoch:1/30     Step:2|6   loss:0.9885575771331787  \n","Epoch:1/30     Step:3|6   loss:0.9580742120742798  \n","Epoch:1/30     Step:4|6   loss:0.7366275787353516  \n","Epoch:1/30     Step:5|6   loss:0.7475659847259521  \n","Epoch:1/30     Step:6|6   loss:0.6532737016677856  \n","Epoch:1/30     Step:7|6   loss:0.7038415670394897  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:82.24%\t train set:85.48%\n","Epoch:2/30     Step:1|6   loss:0.6317456960678101  \n","Epoch:2/30     Step:2|6   loss:0.6161395311355591  \n","Epoch:2/30     Step:3|6   loss:0.6259127855300903  \n","Epoch:2/30     Step:4|6   loss:0.5846795439720154  \n","Epoch:2/30     Step:5|6   loss:0.5861198306083679  \n","Epoch:2/30     Step:6|6   loss:0.5892395973205566  \n","Epoch:2/30     Step:7|6   loss:0.5880880951881409  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:95.33%\t train set:96.96%\n","Epoch:3/30     Step:1|6   loss:0.5784510374069214  \n","Epoch:3/30     Step:2|6   loss:0.5469020009040833  \n","Epoch:3/30     Step:3|6   loss:0.5686171054840088  \n","Epoch:3/30     Step:4|6   loss:0.5400036573410034  \n","Epoch:3/30     Step:5|6   loss:0.5571711659431458  \n","Epoch:3/30     Step:6|6   loss:0.5570163130760193  \n","Epoch:3/30     Step:7|6   loss:0.554816722869873  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:96.26%\t train set:98.59%\n","Epoch:4/30     Step:1|6   loss:0.5293695330619812  \n","Epoch:4/30     Step:2|6   loss:0.5199769735336304  \n","Epoch:4/30     Step:3|6   loss:0.5232932567596436  \n","Epoch:4/30     Step:4|6   loss:0.5249896049499512  \n","Epoch:4/30     Step:5|6   loss:0.518854558467865  \n","Epoch:4/30     Step:6|6   loss:0.5204226970672607  \n","Epoch:4/30     Step:7|6   loss:0.5180965662002563  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:5/30     Step:1|6   loss:0.5105098485946655  \n","Epoch:5/30     Step:2|6   loss:0.5178272128105164  \n","Epoch:5/30     Step:3|6   loss:0.5045782327651978  \n","Epoch:5/30     Step:4|6   loss:0.5152454376220703  \n","Epoch:5/30     Step:5|6   loss:0.5036741495132446  \n","Epoch:5/30     Step:6|6   loss:0.5151051878929138  \n","Epoch:5/30     Step:7|6   loss:0.497949481010437  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:6/30     Step:1|6   loss:0.506996750831604  \n","Epoch:6/30     Step:2|6   loss:0.5033787488937378  \n","Epoch:6/30     Step:3|6   loss:0.512843668460846  \n","Epoch:6/30     Step:4|6   loss:0.5045717358589172  \n","Epoch:6/30     Step:5|6   loss:0.5035358667373657  \n","Epoch:6/30     Step:6|6   loss:0.5008245706558228  \n","Epoch:6/30     Step:7|6   loss:0.5006558895111084  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.5019000172615051  \n","Epoch:7/30     Step:2|6   loss:0.4962337911128998  \n","Epoch:7/30     Step:3|6   loss:0.4994448125362396  \n","Epoch:7/30     Step:4|6   loss:0.5140770077705383  \n","Epoch:7/30     Step:5|6   loss:0.4991692900657654  \n","Epoch:7/30     Step:6|6   loss:0.4948437511920929  \n","Epoch:7/30     Step:7|6   loss:0.504248857498169  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49949920177459717  \n","Epoch:8/30     Step:2|6   loss:0.5001422762870789  \n","Epoch:8/30     Step:3|6   loss:0.4969204068183899  \n","Epoch:8/30     Step:4|6   loss:0.5040508508682251  \n","Epoch:8/30     Step:5|6   loss:0.49750834703445435  \n","Epoch:8/30     Step:6|6   loss:0.4955472946166992  \n","Epoch:8/30     Step:7|6   loss:0.4954991340637207  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49351513385772705  \n","Epoch:9/30     Step:2|6   loss:0.49831223487854004  \n","Epoch:9/30     Step:3|6   loss:0.4995317757129669  \n","Epoch:9/30     Step:4|6   loss:0.5060541033744812  \n","Epoch:9/30     Step:5|6   loss:0.49545857310295105  \n","Epoch:9/30     Step:6|6   loss:0.49865269660949707  \n","Epoch:9/30     Step:7|6   loss:0.5083239078521729  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4954271912574768  \n","Epoch:10/30     Step:2|6   loss:0.49370384216308594  \n","Epoch:10/30     Step:3|6   loss:0.4952390789985657  \n","Epoch:10/30     Step:4|6   loss:0.5103757381439209  \n","Epoch:10/30     Step:5|6   loss:0.505781888961792  \n","Epoch:10/30     Step:6|6   loss:0.49238842725753784  \n","Epoch:10/30     Step:7|6   loss:0.509560227394104  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4954425096511841  \n","Epoch:11/30     Step:2|6   loss:0.5040659308433533  \n","Epoch:11/30     Step:3|6   loss:0.49737152457237244  \n","Epoch:11/30     Step:4|6   loss:0.493605375289917  \n","Epoch:11/30     Step:5|6   loss:0.4981553554534912  \n","Epoch:11/30     Step:6|6   loss:0.49980542063713074  \n","Epoch:11/30     Step:7|6   loss:0.5014211535453796  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4945531189441681  \n","Epoch:12/30     Step:2|6   loss:0.49636033177375793  \n","Epoch:12/30     Step:3|6   loss:0.49406692385673523  \n","Epoch:12/30     Step:4|6   loss:0.49394649267196655  \n","Epoch:12/30     Step:5|6   loss:0.5024386048316956  \n","Epoch:12/30     Step:6|6   loss:0.4967559278011322  \n","Epoch:12/30     Step:7|6   loss:0.5000686049461365  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.49668169021606445  \n","Epoch:13/30     Step:2|6   loss:0.4937611520290375  \n","Epoch:13/30     Step:3|6   loss:0.4956446588039398  \n","Epoch:13/30     Step:4|6   loss:0.4935845732688904  \n","Epoch:13/30     Step:5|6   loss:0.49306440353393555  \n","Epoch:13/30     Step:6|6   loss:0.5044224262237549  \n","Epoch:13/30     Step:7|6   loss:0.49790170788764954  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.49314430356025696  \n","Epoch:14/30     Step:2|6   loss:0.49672192335128784  \n","Epoch:14/30     Step:3|6   loss:0.49343034625053406  \n","Epoch:14/30     Step:4|6   loss:0.49181774258613586  \n","Epoch:14/30     Step:5|6   loss:0.4928627610206604  \n","Epoch:14/30     Step:6|6   loss:0.49312835931777954  \n","Epoch:14/30     Step:7|6   loss:0.5122019052505493  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4915565550327301  \n","Epoch:15/30     Step:2|6   loss:0.4966001510620117  \n","Epoch:15/30     Step:3|6   loss:0.4950825870037079  \n","Epoch:15/30     Step:4|6   loss:0.5023435354232788  \n","Epoch:15/30     Step:5|6   loss:0.49460139870643616  \n","Epoch:15/30     Step:6|6   loss:0.4944688081741333  \n","Epoch:15/30     Step:7|6   loss:0.49409082531929016  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.49497801065444946  \n","Epoch:16/30     Step:2|6   loss:0.494806170463562  \n","Epoch:16/30     Step:3|6   loss:0.49390313029289246  \n","Epoch:16/30     Step:4|6   loss:0.4981970191001892  \n","Epoch:16/30     Step:5|6   loss:0.4934829771518707  \n","Epoch:16/30     Step:6|6   loss:0.49980926513671875  \n","Epoch:16/30     Step:7|6   loss:0.49969393014907837  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.49464765191078186  \n","Epoch:17/30     Step:2|6   loss:0.4934037923812866  \n","Epoch:17/30     Step:3|6   loss:0.4939629137516022  \n","Epoch:17/30     Step:4|6   loss:0.4989009201526642  \n","Epoch:17/30     Step:5|6   loss:0.5031124949455261  \n","Epoch:17/30     Step:6|6   loss:0.49631962180137634  \n","Epoch:17/30     Step:7|6   loss:0.4994576573371887  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.5009169578552246  \n","Epoch:18/30     Step:2|6   loss:0.49547749757766724  \n","Epoch:18/30     Step:3|6   loss:0.49329066276550293  \n","Epoch:18/30     Step:4|6   loss:0.49923208355903625  \n","Epoch:18/30     Step:5|6   loss:0.5005138516426086  \n","Epoch:18/30     Step:6|6   loss:0.5015057325363159  \n","Epoch:18/30     Step:7|6   loss:0.4972072243690491  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.5030370950698853  \n","Epoch:19/30     Step:2|6   loss:0.4939689338207245  \n","Epoch:19/30     Step:3|6   loss:0.5141196846961975  \n","Epoch:19/30     Step:4|6   loss:0.5019286870956421  \n","Epoch:19/30     Step:5|6   loss:0.49255844950675964  \n","Epoch:19/30     Step:6|6   loss:0.49657922983169556  \n","Epoch:19/30     Step:7|6   loss:0.49989446997642517  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4924124777317047  \n","Epoch:20/30     Step:2|6   loss:0.49392497539520264  \n","Epoch:20/30     Step:3|6   loss:0.49916571378707886  \n","Epoch:20/30     Step:4|6   loss:0.4975264370441437  \n","Epoch:20/30     Step:5|6   loss:0.49173974990844727  \n","Epoch:20/30     Step:6|6   loss:0.49544909596443176  \n","Epoch:20/30     Step:7|6   loss:0.49503886699676514  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4947444796562195  \n","Epoch:21/30     Step:2|6   loss:0.4952232241630554  \n","Epoch:21/30     Step:3|6   loss:0.4972466826438904  \n","Epoch:21/30     Step:4|6   loss:0.4937787652015686  \n","Epoch:21/30     Step:5|6   loss:0.4962884187698364  \n","Epoch:21/30     Step:6|6   loss:0.49587514996528625  \n","Epoch:21/30     Step:7|6   loss:0.4959465265274048  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4948221743106842  \n","Epoch:22/30     Step:2|6   loss:0.49199730157852173  \n","Epoch:22/30     Step:3|6   loss:0.5004607439041138  \n","Epoch:22/30     Step:4|6   loss:0.49821680784225464  \n","Epoch:22/30     Step:5|6   loss:0.4962294101715088  \n","Epoch:22/30     Step:6|6   loss:0.4931553304195404  \n","Epoch:22/30     Step:7|6   loss:0.5024176239967346  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4931547939777374  \n","Epoch:23/30     Step:2|6   loss:0.5001279711723328  \n","Epoch:23/30     Step:3|6   loss:0.5022298693656921  \n","Epoch:23/30     Step:4|6   loss:0.4931252598762512  \n","Epoch:23/30     Step:5|6   loss:0.49590134620666504  \n","Epoch:23/30     Step:6|6   loss:0.49311214685440063  \n","Epoch:23/30     Step:7|6   loss:0.4952535033226013  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4914223849773407  \n","Epoch:24/30     Step:2|6   loss:0.49835458397865295  \n","Epoch:24/30     Step:3|6   loss:0.49297118186950684  \n","Epoch:24/30     Step:4|6   loss:0.49512940645217896  \n","Epoch:24/30     Step:5|6   loss:0.493033230304718  \n","Epoch:24/30     Step:6|6   loss:0.493124395608902  \n","Epoch:24/30     Step:7|6   loss:0.4982086420059204  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49451959133148193  \n","Epoch:25/30     Step:2|6   loss:0.49884459376335144  \n","Epoch:25/30     Step:3|6   loss:0.49334633350372314  \n","Epoch:25/30     Step:4|6   loss:0.49869289994239807  \n","Epoch:25/30     Step:5|6   loss:0.4912755489349365  \n","Epoch:25/30     Step:6|6   loss:0.4995172917842865  \n","Epoch:25/30     Step:7|6   loss:0.496035635471344  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.49604928493499756  \n","Epoch:26/30     Step:2|6   loss:0.4937364161014557  \n","Epoch:26/30     Step:3|6   loss:0.49129801988601685  \n","Epoch:26/30     Step:4|6   loss:0.4920424222946167  \n","Epoch:26/30     Step:5|6   loss:0.494670569896698  \n","Epoch:26/30     Step:6|6   loss:0.4945152997970581  \n","Epoch:26/30     Step:7|6   loss:0.49905604124069214  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49293652176856995  \n","Epoch:27/30     Step:2|6   loss:0.49193546175956726  \n","Epoch:27/30     Step:3|6   loss:0.49111610651016235  \n","Epoch:27/30     Step:4|6   loss:0.5108116865158081  \n","Epoch:27/30     Step:5|6   loss:0.4918769896030426  \n","Epoch:27/30     Step:6|6   loss:0.5119726657867432  \n","Epoch:27/30     Step:7|6   loss:0.4958595037460327  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.49285146594047546  \n","Epoch:28/30     Step:2|6   loss:0.49605968594551086  \n","Epoch:28/30     Step:3|6   loss:0.4910968542098999  \n","Epoch:28/30     Step:4|6   loss:0.4975641965866089  \n","Epoch:28/30     Step:5|6   loss:0.4934578537940979  \n","Epoch:28/30     Step:6|6   loss:0.498251736164093  \n","Epoch:28/30     Step:7|6   loss:0.4947749078273773  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4972274899482727  \n","Epoch:29/30     Step:2|6   loss:0.49445170164108276  \n","Epoch:29/30     Step:3|6   loss:0.4969705641269684  \n","Epoch:29/30     Step:4|6   loss:0.49380365014076233  \n","Epoch:29/30     Step:5|6   loss:0.4951072931289673  \n","Epoch:29/30     Step:6|6   loss:0.4937250316143036  \n","Epoch:29/30     Step:7|6   loss:0.4908047914505005  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.49197062849998474  \n","Epoch:30/30     Step:2|6   loss:0.49186182022094727  \n","Epoch:30/30     Step:3|6   loss:0.4932176470756531  \n","Epoch:30/30     Step:4|6   loss:0.4935693144798279  \n","Epoch:30/30     Step:5|6   loss:0.49590492248535156  \n","Epoch:30/30     Step:6|6   loss:0.49413520097732544  \n","Epoch:30/30     Step:7|6   loss:0.4920896291732788  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Mobilenetv2', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n"]},{"name":"stdout","output_type":"stream","text":["        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1166964769363403  \n","Epoch:1/30     Step:2|6   loss:0.9918005466461182  \n","Epoch:1/30     Step:3|6   loss:0.8731631636619568  \n","Epoch:1/30     Step:4|6   loss:0.7109934091567993  \n","Epoch:1/30     Step:5|6   loss:0.7168093919754028  \n","Epoch:1/30     Step:6|6   loss:0.6840663552284241  \n","Epoch:1/30     Step:7|6   loss:0.6685643792152405  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:87.85%\t train set:87.35%\n","Epoch:2/30     Step:1|6   loss:0.6538615226745605  \n","Epoch:2/30     Step:2|6   loss:0.6076902151107788  \n","Epoch:2/30     Step:3|6   loss:0.5838873982429504  \n","Epoch:2/30     Step:4|6   loss:0.5738925337791443  \n","Epoch:2/30     Step:5|6   loss:0.5599467158317566  \n","Epoch:2/30     Step:6|6   loss:0.6098348498344421  \n","Epoch:2/30     Step:7|6   loss:0.5756120085716248  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:95.33%\t train set:96.25%\n","Epoch:3/30     Step:1|6   loss:0.5618732571601868  \n","Epoch:3/30     Step:2|6   loss:0.5499049425125122  \n","Epoch:3/30     Step:3|6   loss:0.5388433337211609  \n","Epoch:3/30     Step:4|6   loss:0.5516678690910339  \n","Epoch:3/30     Step:5|6   loss:0.5347872376441956  \n","Epoch:3/30     Step:6|6   loss:0.5219432711601257  \n","Epoch:3/30     Step:7|6   loss:0.5770350694656372  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:96.26%\t train set:99.06%\n","Epoch:4/30     Step:1|6   loss:0.5261098742485046  \n","Epoch:4/30     Step:2|6   loss:0.5243189334869385  \n","Epoch:4/30     Step:3|6   loss:0.5076156854629517  \n","Epoch:4/30     Step:4|6   loss:0.5352098345756531  \n","Epoch:4/30     Step:5|6   loss:0.5447943806648254  \n","Epoch:4/30     Step:6|6   loss:0.5229107141494751  \n","Epoch:4/30     Step:7|6   loss:0.5167508125305176  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:5/30     Step:1|6   loss:0.5126415491104126  \n","Epoch:5/30     Step:2|6   loss:0.5152168869972229  \n","Epoch:5/30     Step:3|6   loss:0.5035712122917175  \n","Epoch:5/30     Step:4|6   loss:0.5178354978561401  \n","Epoch:5/30     Step:5|6   loss:0.504971981048584  \n","Epoch:5/30     Step:6|6   loss:0.5165176391601562  \n","Epoch:5/30     Step:7|6   loss:0.5035929679870605  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5115305781364441  \n","Epoch:6/30     Step:2|6   loss:0.5028963088989258  \n","Epoch:6/30     Step:3|6   loss:0.500148355960846  \n","Epoch:6/30     Step:4|6   loss:0.5087523460388184  \n","Epoch:6/30     Step:5|6   loss:0.5030533075332642  \n","Epoch:6/30     Step:6|6   loss:0.5068098306655884  \n","Epoch:6/30     Step:7|6   loss:0.5084223747253418  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.5047687888145447  \n","Epoch:7/30     Step:2|6   loss:0.5092586278915405  \n","Epoch:7/30     Step:3|6   loss:0.49240344762802124  \n","Epoch:7/30     Step:4|6   loss:0.503912091255188  \n","Epoch:7/30     Step:5|6   loss:0.4947477877140045  \n","Epoch:7/30     Step:6|6   loss:0.4960798919200897  \n","Epoch:7/30     Step:7|6   loss:0.504406213760376  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.495420902967453  \n","Epoch:8/30     Step:2|6   loss:0.4977824091911316  \n","Epoch:8/30     Step:3|6   loss:0.49480897188186646  \n","Epoch:8/30     Step:4|6   loss:0.5173668265342712  \n","Epoch:8/30     Step:5|6   loss:0.5009267330169678  \n","Epoch:8/30     Step:6|6   loss:0.49124807119369507  \n","Epoch:8/30     Step:7|6   loss:0.518223226070404  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49268239736557007  \n","Epoch:9/30     Step:2|6   loss:0.49414390325546265  \n","Epoch:9/30     Step:3|6   loss:0.4963238835334778  \n","Epoch:9/30     Step:4|6   loss:0.49479955434799194  \n","Epoch:9/30     Step:5|6   loss:0.49270176887512207  \n","Epoch:9/30     Step:6|6   loss:0.4982881546020508  \n","Epoch:9/30     Step:7|6   loss:0.50083988904953  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49821335077285767  \n","Epoch:10/30     Step:2|6   loss:0.5224171876907349  \n","Epoch:10/30     Step:3|6   loss:0.5017277002334595  \n","Epoch:10/30     Step:4|6   loss:0.4968075752258301  \n","Epoch:10/30     Step:5|6   loss:0.4952036142349243  \n","Epoch:10/30     Step:6|6   loss:0.49633920192718506  \n","Epoch:10/30     Step:7|6   loss:0.4971870183944702  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49745240807533264  \n","Epoch:11/30     Step:2|6   loss:0.494884729385376  \n","Epoch:11/30     Step:3|6   loss:0.5017322897911072  \n","Epoch:11/30     Step:4|6   loss:0.4942888617515564  \n","Epoch:11/30     Step:5|6   loss:0.49223610758781433  \n","Epoch:11/30     Step:6|6   loss:0.49550390243530273  \n","Epoch:11/30     Step:7|6   loss:0.49142158031463623  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.5059114694595337  \n","Epoch:12/30     Step:2|6   loss:0.49197283387184143  \n","Epoch:12/30     Step:3|6   loss:0.4961269497871399  \n","Epoch:12/30     Step:4|6   loss:0.5173251032829285  \n","Epoch:12/30     Step:5|6   loss:0.4965391457080841  \n","Epoch:12/30     Step:6|6   loss:0.493954598903656  \n","Epoch:12/30     Step:7|6   loss:0.4956715703010559  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4935472309589386  \n","Epoch:13/30     Step:2|6   loss:0.49561765789985657  \n","Epoch:13/30     Step:3|6   loss:0.4977263808250427  \n","Epoch:13/30     Step:4|6   loss:0.4915480315685272  \n","Epoch:13/30     Step:5|6   loss:0.493734747171402  \n","Epoch:13/30     Step:6|6   loss:0.49692070484161377  \n","Epoch:13/30     Step:7|6   loss:0.5210332870483398  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4917716681957245  \n","Epoch:14/30     Step:2|6   loss:0.4949381351470947  \n","Epoch:14/30     Step:3|6   loss:0.4930342137813568  \n","Epoch:14/30     Step:4|6   loss:0.49479353427886963  \n","Epoch:14/30     Step:5|6   loss:0.49574747681617737  \n","Epoch:14/30     Step:6|6   loss:0.49290168285369873  \n","Epoch:14/30     Step:7|6   loss:0.49772244691848755  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.5018712282180786  \n","Epoch:15/30     Step:2|6   loss:0.49393877387046814  \n","Epoch:15/30     Step:3|6   loss:0.49436673521995544  \n","Epoch:15/30     Step:4|6   loss:0.49475350975990295  \n","Epoch:15/30     Step:5|6   loss:0.4971883296966553  \n","Epoch:15/30     Step:6|6   loss:0.4905760884284973  \n","Epoch:15/30     Step:7|6   loss:0.5000667572021484  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4917040467262268  \n","Epoch:16/30     Step:2|6   loss:0.4921654760837555  \n","Epoch:16/30     Step:3|6   loss:0.4969314932823181  \n","Epoch:16/30     Step:4|6   loss:0.4935166537761688  \n","Epoch:16/30     Step:5|6   loss:0.49586349725723267  \n","Epoch:16/30     Step:6|6   loss:0.4954126179218292  \n","Epoch:16/30     Step:7|6   loss:0.49347221851348877  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4938057065010071  \n","Epoch:17/30     Step:2|6   loss:0.494003027677536  \n","Epoch:17/30     Step:3|6   loss:0.49219152331352234  \n","Epoch:17/30     Step:4|6   loss:0.4937884211540222  \n","Epoch:17/30     Step:5|6   loss:0.4909715950489044  \n","Epoch:17/30     Step:6|6   loss:0.4917767643928528  \n","Epoch:17/30     Step:7|6   loss:0.49633103609085083  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.49672776460647583  \n","Epoch:18/30     Step:2|6   loss:0.49455803632736206  \n","Epoch:18/30     Step:3|6   loss:0.4921773672103882  \n","Epoch:18/30     Step:4|6   loss:0.4910563826560974  \n","Epoch:18/30     Step:5|6   loss:0.504223108291626  \n","Epoch:18/30     Step:6|6   loss:0.49120819568634033  \n","Epoch:18/30     Step:7|6   loss:0.5074440240859985  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.49097156524658203  \n","Epoch:19/30     Step:2|6   loss:0.5042819380760193  \n","Epoch:19/30     Step:3|6   loss:0.4982075095176697  \n","Epoch:19/30     Step:4|6   loss:0.5088388919830322  \n","Epoch:19/30     Step:5|6   loss:0.49336180090904236  \n","Epoch:19/30     Step:6|6   loss:0.4982285499572754  \n","Epoch:19/30     Step:7|6   loss:0.49668195843696594  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4934254288673401  \n","Epoch:20/30     Step:2|6   loss:0.5059655904769897  \n","Epoch:20/30     Step:3|6   loss:0.49979159235954285  \n","Epoch:20/30     Step:4|6   loss:0.4954458475112915  \n","Epoch:20/30     Step:5|6   loss:0.49732106924057007  \n","Epoch:20/30     Step:6|6   loss:0.4926169812679291  \n","Epoch:20/30     Step:7|6   loss:0.5070984363555908  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4934961199760437  \n","Epoch:21/30     Step:2|6   loss:0.49268531799316406  \n","Epoch:21/30     Step:3|6   loss:0.49295926094055176  \n","Epoch:21/30     Step:4|6   loss:0.49579834938049316  \n","Epoch:21/30     Step:5|6   loss:0.49141183495521545  \n","Epoch:21/30     Step:6|6   loss:0.4966564178466797  \n","Epoch:21/30     Step:7|6   loss:0.4943087100982666  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4922846853733063  \n","Epoch:22/30     Step:2|6   loss:0.4914935529232025  \n","Epoch:22/30     Step:3|6   loss:0.4932976961135864  \n","Epoch:22/30     Step:4|6   loss:0.49233895540237427  \n","Epoch:22/30     Step:5|6   loss:0.4936422109603882  \n","Epoch:22/30     Step:6|6   loss:0.5050467252731323  \n","Epoch:22/30     Step:7|6   loss:0.4925071895122528  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.495464026927948  \n","Epoch:23/30     Step:2|6   loss:0.49260014295578003  \n","Epoch:23/30     Step:3|6   loss:0.4967331290245056  \n","Epoch:23/30     Step:4|6   loss:0.4957735240459442  \n","Epoch:23/30     Step:5|6   loss:0.4949950575828552  \n","Epoch:23/30     Step:6|6   loss:0.49175965785980225  \n","Epoch:23/30     Step:7|6   loss:0.49298804998397827  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49346163868904114  \n","Epoch:24/30     Step:2|6   loss:0.49233654141426086  \n","Epoch:24/30     Step:3|6   loss:0.4975641667842865  \n","Epoch:24/30     Step:4|6   loss:0.492445707321167  \n","Epoch:24/30     Step:5|6   loss:0.4965198338031769  \n","Epoch:24/30     Step:6|6   loss:0.49372750520706177  \n","Epoch:24/30     Step:7|6   loss:0.4966822862625122  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49268215894699097  \n","Epoch:25/30     Step:2|6   loss:0.492115318775177  \n","Epoch:25/30     Step:3|6   loss:0.49359044432640076  \n","Epoch:25/30     Step:4|6   loss:0.4921187162399292  \n","Epoch:25/30     Step:5|6   loss:0.4999990165233612  \n","Epoch:25/30     Step:6|6   loss:0.498424768447876  \n","Epoch:25/30     Step:7|6   loss:0.4938172996044159  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4923557639122009  \n","Epoch:26/30     Step:2|6   loss:0.4944029152393341  \n","Epoch:26/30     Step:3|6   loss:0.49179455637931824  \n","Epoch:26/30     Step:4|6   loss:0.5000483989715576  \n","Epoch:26/30     Step:5|6   loss:0.4927961230278015  \n","Epoch:26/30     Step:6|6   loss:0.49349793791770935  \n","Epoch:26/30     Step:7|6   loss:0.49552616477012634  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49264001846313477  \n","Epoch:27/30     Step:2|6   loss:0.4932864308357239  \n","Epoch:27/30     Step:3|6   loss:0.48929688334465027  \n","Epoch:27/30     Step:4|6   loss:0.4978567361831665  \n","Epoch:27/30     Step:5|6   loss:0.5013805031776428  \n","Epoch:27/30     Step:6|6   loss:0.49259236454963684  \n","Epoch:27/30     Step:7|6   loss:0.4941662847995758  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.49347689747810364  \n","Epoch:28/30     Step:2|6   loss:0.4937913119792938  \n","Epoch:28/30     Step:3|6   loss:0.49345478415489197  \n","Epoch:28/30     Step:4|6   loss:0.4983404278755188  \n","Epoch:28/30     Step:5|6   loss:0.492023766040802  \n","Epoch:28/30     Step:6|6   loss:0.4938502013683319  \n","Epoch:28/30     Step:7|6   loss:0.49218636751174927  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4916662871837616  \n","Epoch:29/30     Step:2|6   loss:0.49468427896499634  \n","Epoch:29/30     Step:3|6   loss:0.4974614381790161  \n","Epoch:29/30     Step:4|6   loss:0.49418503046035767  \n","Epoch:29/30     Step:5|6   loss:0.492098867893219  \n","Epoch:29/30     Step:6|6   loss:0.49603936076164246  \n","Epoch:29/30     Step:7|6   loss:0.4921136200428009  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.49548017978668213  \n","Epoch:30/30     Step:2|6   loss:0.49984437227249146  \n","Epoch:30/30     Step:3|6   loss:0.4928218126296997  \n","Epoch:30/30     Step:4|6   loss:0.496429979801178  \n","Epoch:30/30     Step:5|6   loss:0.4935978055000305  \n","Epoch:30/30     Step:6|6   loss:0.4930468797683716  \n","Epoch:30/30     Step:7|6   loss:0.5059477090835571  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model Mobilenetv2 --mode ir --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":14,"id":"ecf7fd38","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Mobilenetv2_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Mobilenetv2_two_stream(\n","  (stream1): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (stream2): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","1\n"]},{"name":"stdout","output_type":"stream","text":["            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=2560, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.0517009496688843  \n","Epoch:1/30     Step:2|6   loss:0.8569663166999817  \n","Epoch:1/30     Step:3|6   loss:0.8182516694068909  \n","Epoch:1/30     Step:4|6   loss:0.7772980332374573  \n","Epoch:1/30     Step:5|6   loss:0.7738596200942993  \n","Epoch:1/30     Step:6|6   loss:0.8370791673660278  \n","Epoch:1/30     Step:7|6   loss:0.7348517179489136  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:98.13%\t train set:98.83%\n","Epoch:2/30     Step:1|6   loss:0.8201888203620911  \n","Epoch:2/30     Step:2|6   loss:0.805695116519928  \n","Epoch:2/30     Step:3|6   loss:0.8218902349472046  \n","Epoch:2/30     Step:4|6   loss:0.7798182964324951  \n","Epoch:2/30     Step:5|6   loss:0.7429186701774597  \n","Epoch:2/30     Step:6|6   loss:0.7648874521255493  \n","Epoch:2/30     Step:7|6   loss:0.8014975786209106  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.3%\n","Epoch:3/30     Step:1|6   loss:0.7710762023925781  \n","Epoch:3/30     Step:2|6   loss:0.8017573952674866  \n","Epoch:3/30     Step:3|6   loss:0.7277388572692871  \n","Epoch:3/30     Step:4|6   loss:0.7610784769058228  \n","Epoch:3/30     Step:5|6   loss:0.7781323194503784  \n","Epoch:3/30     Step:6|6   loss:0.6802374124526978  \n","Epoch:3/30     Step:7|6   loss:0.7473747730255127  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:4/30     Step:1|6   loss:0.6976016759872437  \n","Epoch:4/30     Step:2|6   loss:0.6950677633285522  \n","Epoch:4/30     Step:3|6   loss:0.7243489027023315  \n","Epoch:4/30     Step:4|6   loss:0.7581095695495605  \n","Epoch:4/30     Step:5|6   loss:0.7326109409332275  \n","Epoch:4/30     Step:6|6   loss:0.7352011799812317  \n","Epoch:4/30     Step:7|6   loss:0.7109875679016113  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.7572376728057861  \n","Epoch:5/30     Step:2|6   loss:0.7718638181686401  \n","Epoch:5/30     Step:3|6   loss:0.718058705329895  \n","Epoch:5/30     Step:4|6   loss:0.722641110420227  \n","Epoch:5/30     Step:5|6   loss:0.7249996066093445  \n","Epoch:5/30     Step:6|6   loss:0.7314123511314392  \n","Epoch:5/30     Step:7|6   loss:0.7430881857872009  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7395491600036621  \n","Epoch:6/30     Step:2|6   loss:0.6842322945594788  \n","Epoch:6/30     Step:3|6   loss:0.7038071751594543  \n","Epoch:6/30     Step:4|6   loss:0.7688313722610474  \n","Epoch:6/30     Step:5|6   loss:0.7512941956520081  \n","Epoch:6/30     Step:6|6   loss:0.7241274118423462  \n","Epoch:6/30     Step:7|6   loss:0.7617122530937195  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.70726478099823  \n","Epoch:7/30     Step:2|6   loss:0.7430355548858643  \n","Epoch:7/30     Step:3|6   loss:0.7676036357879639  \n","Epoch:7/30     Step:4|6   loss:0.6662766933441162  \n","Epoch:7/30     Step:5|6   loss:0.747943639755249  \n","Epoch:7/30     Step:6|6   loss:0.6878643035888672  \n","Epoch:7/30     Step:7|6   loss:0.7305554151535034  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.7341599464416504  \n","Epoch:8/30     Step:2|6   loss:0.6808555722236633  \n","Epoch:8/30     Step:3|6   loss:0.703072190284729  \n","Epoch:8/30     Step:4|6   loss:0.7317685484886169  \n","Epoch:8/30     Step:5|6   loss:0.7790384888648987  \n","Epoch:8/30     Step:6|6   loss:0.6788627505302429  \n","Epoch:8/30     Step:7|6   loss:0.7243114113807678  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7012622356414795  \n","Epoch:9/30     Step:2|6   loss:0.6694574356079102  \n","Epoch:9/30     Step:3|6   loss:0.7397514581680298  \n","Epoch:9/30     Step:4|6   loss:0.7085287570953369  \n","Epoch:9/30     Step:5|6   loss:0.7547542452812195  \n","Epoch:9/30     Step:6|6   loss:0.6694069504737854  \n","Epoch:9/30     Step:7|6   loss:0.7547478675842285  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.6589192152023315  \n","Epoch:10/30     Step:2|6   loss:0.6527376174926758  \n","Epoch:10/30     Step:3|6   loss:0.6955789923667908  \n","Epoch:10/30     Step:4|6   loss:0.6876989603042603  \n","Epoch:10/30     Step:5|6   loss:0.7455641627311707  \n","Epoch:10/30     Step:6|6   loss:0.6852493286132812  \n","Epoch:10/30     Step:7|6   loss:0.6794779300689697  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.7092862129211426  \n","Epoch:11/30     Step:2|6   loss:0.6876999139785767  \n","Epoch:11/30     Step:3|6   loss:0.7132575511932373  \n","Epoch:11/30     Step:4|6   loss:0.7124731540679932  \n","Epoch:11/30     Step:5|6   loss:0.7062199115753174  \n","Epoch:11/30     Step:6|6   loss:0.7058969736099243  \n","Epoch:11/30     Step:7|6   loss:0.6921442747116089  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6652551293373108  \n","Epoch:12/30     Step:2|6   loss:0.6867291927337646  \n","Epoch:12/30     Step:3|6   loss:0.705611526966095  \n","Epoch:12/30     Step:4|6   loss:0.706404447555542  \n","Epoch:12/30     Step:5|6   loss:0.6658196449279785  \n","Epoch:12/30     Step:6|6   loss:0.6976008415222168  \n","Epoch:12/30     Step:7|6   loss:0.7747484445571899  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7314608097076416  \n","Epoch:13/30     Step:2|6   loss:0.6713452339172363  \n","Epoch:13/30     Step:3|6   loss:0.7485377788543701  \n","Epoch:13/30     Step:4|6   loss:0.6881772875785828  \n","Epoch:13/30     Step:5|6   loss:0.7439662218093872  \n","Epoch:13/30     Step:6|6   loss:0.6636538505554199  \n","Epoch:13/30     Step:7|6   loss:0.7445530891418457  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7686375975608826  \n","Epoch:14/30     Step:2|6   loss:0.6589345932006836  \n","Epoch:14/30     Step:3|6   loss:0.6903049945831299  \n","Epoch:14/30     Step:4|6   loss:0.7184770107269287  \n","Epoch:14/30     Step:5|6   loss:0.6788833141326904  \n","Epoch:14/30     Step:6|6   loss:0.7505807876586914  \n","Epoch:14/30     Step:7|6   loss:0.8388372659683228  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.695736289024353  \n","Epoch:15/30     Step:2|6   loss:0.6908171772956848  \n","Epoch:15/30     Step:3|6   loss:0.7788494825363159  \n","Epoch:15/30     Step:4|6   loss:0.6930224895477295  \n","Epoch:15/30     Step:5|6   loss:0.7460389137268066  \n","Epoch:15/30     Step:6|6   loss:0.7010663747787476  \n","Epoch:15/30     Step:7|6   loss:0.7434763312339783  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7242798805236816  \n","Epoch:16/30     Step:2|6   loss:0.7353532314300537  \n","Epoch:16/30     Step:3|6   loss:0.7210648059844971  \n","Epoch:16/30     Step:4|6   loss:0.7636829614639282  \n","Epoch:16/30     Step:5|6   loss:0.6724976301193237  \n","Epoch:16/30     Step:6|6   loss:0.6962549686431885  \n","Epoch:16/30     Step:7|6   loss:0.7202564477920532  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.694778323173523  \n","Epoch:17/30     Step:2|6   loss:0.7792380452156067  \n","Epoch:17/30     Step:3|6   loss:0.6744340062141418  \n","Epoch:17/30     Step:4|6   loss:0.6440135836601257  \n","Epoch:17/30     Step:5|6   loss:0.7164618372917175  \n","Epoch:17/30     Step:6|6   loss:0.7010526657104492  \n","Epoch:17/30     Step:7|6   loss:0.6767473220825195  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.6806873679161072  \n","Epoch:18/30     Step:2|6   loss:0.7145445346832275  \n","Epoch:18/30     Step:3|6   loss:0.6845555305480957  \n","Epoch:18/30     Step:4|6   loss:0.681649923324585  \n","Epoch:18/30     Step:5|6   loss:0.6454716920852661  \n","Epoch:18/30     Step:6|6   loss:0.7083703875541687  \n","Epoch:18/30     Step:7|6   loss:0.6679269075393677  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.6963410973548889  \n","Epoch:19/30     Step:2|6   loss:0.7387999892234802  \n","Epoch:19/30     Step:3|6   loss:0.7690243721008301  \n","Epoch:19/30     Step:4|6   loss:0.7128477096557617  \n","Epoch:19/30     Step:5|6   loss:0.6713089346885681  \n","Epoch:19/30     Step:6|6   loss:0.6701968908309937  \n","Epoch:19/30     Step:7|6   loss:0.7034144401550293  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.7106930017471313  \n","Epoch:20/30     Step:2|6   loss:0.6981661319732666  \n","Epoch:20/30     Step:3|6   loss:0.6818602681159973  \n","Epoch:20/30     Step:4|6   loss:0.6907150745391846  \n","Epoch:20/30     Step:5|6   loss:0.7446625232696533  \n","Epoch:20/30     Step:6|6   loss:0.7290600538253784  \n","Epoch:20/30     Step:7|6   loss:0.7003854513168335  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7065920233726501  \n","Epoch:21/30     Step:2|6   loss:0.6985494494438171  \n","Epoch:21/30     Step:3|6   loss:0.7464305758476257  \n","Epoch:21/30     Step:4|6   loss:0.7562427520751953  \n","Epoch:21/30     Step:5|6   loss:0.7150964140892029  \n","Epoch:21/30     Step:6|6   loss:0.7492284178733826  \n","Epoch:21/30     Step:7|6   loss:0.7012201547622681  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.7113603353500366  \n","Epoch:22/30     Step:2|6   loss:0.7171465158462524  \n","Epoch:22/30     Step:3|6   loss:0.6931626796722412  \n","Epoch:22/30     Step:4|6   loss:0.6843061447143555  \n","Epoch:22/30     Step:5|6   loss:0.709318995475769  \n","Epoch:22/30     Step:6|6   loss:0.7151634693145752  \n","Epoch:22/30     Step:7|6   loss:0.7165933847427368  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.6618074178695679  \n","Epoch:23/30     Step:2|6   loss:0.7224704027175903  \n","Epoch:23/30     Step:3|6   loss:0.6835213899612427  \n","Epoch:23/30     Step:4|6   loss:0.711479663848877  \n","Epoch:23/30     Step:5|6   loss:0.7039079070091248  \n","Epoch:23/30     Step:6|6   loss:0.7315032482147217  \n","Epoch:23/30     Step:7|6   loss:0.7481563091278076  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.6958020925521851  \n","Epoch:24/30     Step:2|6   loss:0.7147448658943176  \n","Epoch:24/30     Step:3|6   loss:0.7526453733444214  \n","Epoch:24/30     Step:4|6   loss:0.7119648456573486  \n","Epoch:24/30     Step:5|6   loss:0.6786800026893616  \n","Epoch:24/30     Step:6|6   loss:0.7261215448379517  \n","Epoch:24/30     Step:7|6   loss:0.7050225734710693  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7400673627853394  \n","Epoch:25/30     Step:2|6   loss:0.6660456657409668  \n","Epoch:25/30     Step:3|6   loss:0.787268877029419  \n","Epoch:25/30     Step:4|6   loss:0.7128328680992126  \n","Epoch:25/30     Step:5|6   loss:0.6898910999298096  \n","Epoch:25/30     Step:6|6   loss:0.7390137910842896  \n","Epoch:25/30     Step:7|6   loss:0.7244832515716553  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7356554865837097  \n","Epoch:26/30     Step:2|6   loss:0.7961986064910889  \n","Epoch:26/30     Step:3|6   loss:0.6910618543624878  \n","Epoch:26/30     Step:4|6   loss:0.687061071395874  \n","Epoch:26/30     Step:5|6   loss:0.6943148374557495  \n","Epoch:26/30     Step:6|6   loss:0.6889348030090332  \n","Epoch:26/30     Step:7|6   loss:0.6748121380805969  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.6830721497535706  \n","Epoch:27/30     Step:2|6   loss:0.6674429178237915  \n","Epoch:27/30     Step:3|6   loss:0.7344998717308044  \n","Epoch:27/30     Step:4|6   loss:0.7158467173576355  \n","Epoch:27/30     Step:5|6   loss:0.7241182923316956  \n","Epoch:27/30     Step:6|6   loss:0.7172912359237671  \n","Epoch:27/30     Step:7|6   loss:0.7188961505889893  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.7002187967300415  \n","Epoch:28/30     Step:2|6   loss:0.7154027223587036  \n","Epoch:28/30     Step:3|6   loss:0.7123899459838867  \n","Epoch:28/30     Step:4|6   loss:0.6707187294960022  \n","Epoch:28/30     Step:5|6   loss:0.6970937252044678  \n","Epoch:28/30     Step:6|6   loss:0.6766279339790344  \n","Epoch:28/30     Step:7|6   loss:0.7132871150970459  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.671614408493042  \n","Epoch:29/30     Step:2|6   loss:0.7087615728378296  \n","Epoch:29/30     Step:3|6   loss:0.7258564233779907  \n","Epoch:29/30     Step:4|6   loss:0.6996568441390991  \n","Epoch:29/30     Step:5|6   loss:0.6791071891784668  \n","Epoch:29/30     Step:6|6   loss:0.7455496788024902  \n","Epoch:29/30     Step:7|6   loss:0.7147939205169678  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.7014070749282837  \n","Epoch:30/30     Step:2|6   loss:0.7187157869338989  \n","Epoch:30/30     Step:3|6   loss:0.6966918110847473  \n","Epoch:30/30     Step:4|6   loss:0.7444839477539062  \n","Epoch:30/30     Step:5|6   loss:0.6644755005836487  \n","Epoch:30/30     Step:6|6   loss:0.7289767265319824  \n","Epoch:30/30     Step:7|6   loss:0.724894642829895  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Mobilenetv2_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Mobilenetv2_two_stream(\n","  (stream1): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","2            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n"]},{"name":"stdout","output_type":"stream","text":["\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (stream2): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=2560, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.2281662225723267  \n","Epoch:1/30     Step:2|6   loss:1.0416008234024048  \n","Epoch:1/30     Step:3|6   loss:0.8940169811248779  \n","Epoch:1/30     Step:4|6   loss:0.8392035961151123  \n","Epoch:1/30     Step:5|6   loss:0.8211244940757751  \n","Epoch:1/30     Step:6|6   loss:0.734490692615509  \n","Epoch:1/30     Step:7|6   loss:0.8272745609283447  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:2/30     Step:1|6   loss:0.7843677401542664  \n","Epoch:2/30     Step:2|6   loss:0.8516032099723816  \n","Epoch:2/30     Step:3|6   loss:0.7087019085884094  \n","Epoch:2/30     Step:4|6   loss:0.7820526361465454  \n","Epoch:2/30     Step:5|6   loss:0.7739555239677429  \n","Epoch:2/30     Step:6|6   loss:0.7595655918121338  \n","Epoch:2/30     Step:7|6   loss:0.7230310440063477  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.3%\n","Epoch:3/30     Step:1|6   loss:0.742310106754303  \n","Epoch:3/30     Step:2|6   loss:0.7795100808143616  \n","Epoch:3/30     Step:3|6   loss:0.7287291884422302  \n","Epoch:3/30     Step:4|6   loss:0.7309304475784302  \n","Epoch:3/30     Step:5|6   loss:0.7719861268997192  \n","Epoch:3/30     Step:6|6   loss:0.7853549718856812  \n","Epoch:3/30     Step:7|6   loss:0.7374755144119263  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.7160773873329163  \n","Epoch:4/30     Step:2|6   loss:0.715461790561676  \n","Epoch:4/30     Step:3|6   loss:0.7452442646026611  \n","Epoch:4/30     Step:4|6   loss:0.7380177974700928  \n","Epoch:4/30     Step:5|6   loss:0.7237648963928223  \n","Epoch:4/30     Step:6|6   loss:0.7630637884140015  \n","Epoch:4/30     Step:7|6   loss:0.680366039276123  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.6900561451911926  \n","Epoch:5/30     Step:2|6   loss:0.7095835208892822  \n","Epoch:5/30     Step:3|6   loss:0.7915148735046387  \n","Epoch:5/30     Step:4|6   loss:0.7550969123840332  \n","Epoch:5/30     Step:5|6   loss:0.7672889232635498  \n","Epoch:5/30     Step:6|6   loss:0.7080265283584595  \n","Epoch:5/30     Step:7|6   loss:0.7425795793533325  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7077828645706177  \n","Epoch:6/30     Step:2|6   loss:0.7406264543533325  \n","Epoch:6/30     Step:3|6   loss:0.7244920134544373  \n","Epoch:6/30     Step:4|6   loss:0.7166325449943542  \n","Epoch:6/30     Step:5|6   loss:0.6726109981536865  \n","Epoch:6/30     Step:6|6   loss:0.6793209910392761  \n","Epoch:6/30     Step:7|6   loss:0.7339401841163635  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.7078527212142944  \n","Epoch:7/30     Step:2|6   loss:0.7498579621315002  \n","Epoch:7/30     Step:3|6   loss:0.6649283170700073  \n","Epoch:7/30     Step:4|6   loss:0.7563896775245667  \n","Epoch:7/30     Step:5|6   loss:0.7307943105697632  \n","Epoch:7/30     Step:6|6   loss:0.6682182550430298  \n","Epoch:7/30     Step:7|6   loss:0.8007780313491821  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.6856968998908997  \n","Epoch:8/30     Step:2|6   loss:0.7032175064086914  \n","Epoch:8/30     Step:3|6   loss:0.7355368137359619  \n","Epoch:8/30     Step:4|6   loss:0.7796355485916138  \n","Epoch:8/30     Step:5|6   loss:0.6714151501655579  \n","Epoch:8/30     Step:6|6   loss:0.7007656097412109  \n","Epoch:8/30     Step:7|6   loss:0.759445309638977  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.6648468375205994  \n","Epoch:9/30     Step:2|6   loss:0.7244982719421387  \n","Epoch:9/30     Step:3|6   loss:0.7534254789352417  \n","Epoch:9/30     Step:4|6   loss:0.6690454483032227  \n","Epoch:9/30     Step:5|6   loss:0.681037425994873  \n","Epoch:9/30     Step:6|6   loss:0.7090132236480713  \n","Epoch:9/30     Step:7|6   loss:0.6739697456359863  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.6939347982406616  \n","Epoch:10/30     Step:2|6   loss:0.6961714029312134  \n","Epoch:10/30     Step:3|6   loss:0.7351071834564209  \n","Epoch:10/30     Step:4|6   loss:0.7064499855041504  \n","Epoch:10/30     Step:5|6   loss:0.7450752258300781  \n","Epoch:10/30     Step:6|6   loss:0.734769880771637  \n","Epoch:10/30     Step:7|6   loss:0.663772702217102  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.7529610991477966  \n","Epoch:11/30     Step:2|6   loss:0.7275395393371582  \n","Epoch:11/30     Step:3|6   loss:0.7311617136001587  \n","Epoch:11/30     Step:4|6   loss:0.7473503947257996  \n","Epoch:11/30     Step:5|6   loss:0.6675937175750732  \n","Epoch:11/30     Step:6|6   loss:0.7072008848190308  \n","Epoch:11/30     Step:7|6   loss:0.7016225457191467  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6905801892280579  \n","Epoch:12/30     Step:2|6   loss:0.7160739302635193  \n","Epoch:12/30     Step:3|6   loss:0.7104452848434448  \n","Epoch:12/30     Step:4|6   loss:0.7285230755805969  \n","Epoch:12/30     Step:5|6   loss:0.6902501583099365  \n","Epoch:12/30     Step:6|6   loss:0.7320148348808289  \n","Epoch:12/30     Step:7|6   loss:0.6980525255203247  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7060565948486328  \n","Epoch:13/30     Step:2|6   loss:0.7425247430801392  \n","Epoch:13/30     Step:3|6   loss:0.7055308818817139  \n","Epoch:13/30     Step:4|6   loss:0.6940070390701294  \n","Epoch:13/30     Step:5|6   loss:0.6942609548568726  \n","Epoch:13/30     Step:6|6   loss:0.6767904758453369  \n","Epoch:13/30     Step:7|6   loss:0.7490810751914978  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7244458198547363  \n","Epoch:14/30     Step:2|6   loss:0.7387664318084717  \n","Epoch:14/30     Step:3|6   loss:0.7461941242218018  \n","Epoch:14/30     Step:4|6   loss:0.7225662469863892  \n","Epoch:14/30     Step:5|6   loss:0.7084910273551941  \n","Epoch:14/30     Step:6|6   loss:0.7001321315765381  \n","Epoch:14/30     Step:7|6   loss:0.7348698973655701  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.6998770236968994  \n","Epoch:15/30     Step:2|6   loss:0.6737276315689087  \n","Epoch:15/30     Step:3|6   loss:0.7418215274810791  \n","Epoch:15/30     Step:4|6   loss:0.7000349760055542  \n","Epoch:15/30     Step:5|6   loss:0.702009916305542  \n","Epoch:15/30     Step:6|6   loss:0.693991482257843  \n","Epoch:15/30     Step:7|6   loss:0.7339614629745483  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7067610025405884  \n","Epoch:16/30     Step:2|6   loss:0.7281296253204346  \n","Epoch:16/30     Step:3|6   loss:0.7420148253440857  \n","Epoch:16/30     Step:4|6   loss:0.6765597462654114  \n","Epoch:16/30     Step:5|6   loss:0.709378719329834  \n","Epoch:16/30     Step:6|6   loss:0.6814649105072021  \n","Epoch:16/30     Step:7|6   loss:0.7315030097961426  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.7139408588409424  \n","Epoch:17/30     Step:2|6   loss:0.7342489361763  \n","Epoch:17/30     Step:3|6   loss:0.7278958559036255  \n","Epoch:17/30     Step:4|6   loss:0.6785169839859009  \n","Epoch:17/30     Step:5|6   loss:0.7213934659957886  \n","Epoch:17/30     Step:6|6   loss:0.7454895973205566  \n","Epoch:17/30     Step:7|6   loss:0.7264171838760376  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.7121989130973816  \n","Epoch:18/30     Step:2|6   loss:0.6943206787109375  \n","Epoch:18/30     Step:3|6   loss:0.684757649898529  \n","Epoch:18/30     Step:4|6   loss:0.7577695250511169  \n","Epoch:18/30     Step:5|6   loss:0.7363440990447998  \n","Epoch:18/30     Step:6|6   loss:0.7365201711654663  \n","Epoch:18/30     Step:7|6   loss:0.7046626806259155  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.6590332984924316  \n","Epoch:19/30     Step:2|6   loss:0.6750198602676392  \n","Epoch:19/30     Step:3|6   loss:0.7171928882598877  \n","Epoch:19/30     Step:4|6   loss:0.7243606448173523  \n","Epoch:19/30     Step:5|6   loss:0.6662588119506836  \n","Epoch:19/30     Step:6|6   loss:0.6730225086212158  \n","Epoch:19/30     Step:7|6   loss:0.7376015782356262  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.7228597402572632  \n","Epoch:20/30     Step:2|6   loss:0.7238260507583618  \n","Epoch:20/30     Step:3|6   loss:0.7188817262649536  \n","Epoch:20/30     Step:4|6   loss:0.7535395622253418  \n","Epoch:20/30     Step:5|6   loss:0.7382441163063049  \n","Epoch:20/30     Step:6|6   loss:0.7853105068206787  \n","Epoch:20/30     Step:7|6   loss:0.672964870929718  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7159744501113892  \n","Epoch:21/30     Step:2|6   loss:0.6904091835021973  \n","Epoch:21/30     Step:3|6   loss:0.6832473278045654  \n","Epoch:21/30     Step:4|6   loss:0.6677552461624146  \n","Epoch:21/30     Step:5|6   loss:0.7144746780395508  \n","Epoch:21/30     Step:6|6   loss:0.6836631894111633  \n","Epoch:21/30     Step:7|6   loss:0.7146240472793579  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.6861810684204102  \n","Epoch:22/30     Step:2|6   loss:0.7166543006896973  \n","Epoch:22/30     Step:3|6   loss:0.667913556098938  \n","Epoch:22/30     Step:4|6   loss:0.702587366104126  \n","Epoch:22/30     Step:5|6   loss:0.7021692395210266  \n","Epoch:22/30     Step:6|6   loss:0.6789590716362  \n","Epoch:22/30     Step:7|6   loss:0.7327658534049988  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.6870891451835632  \n","Epoch:23/30     Step:2|6   loss:0.6996569633483887  \n","Epoch:23/30     Step:3|6   loss:0.7228471040725708  \n","Epoch:23/30     Step:4|6   loss:0.7224301099777222  \n","Epoch:23/30     Step:5|6   loss:0.6894183158874512  \n","Epoch:23/30     Step:6|6   loss:0.6635890603065491  \n","Epoch:23/30     Step:7|6   loss:0.767581582069397  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.727651834487915  \n","Epoch:24/30     Step:2|6   loss:0.6778481006622314  \n","Epoch:24/30     Step:3|6   loss:0.6923145651817322  \n","Epoch:24/30     Step:4|6   loss:0.7083836793899536  \n","Epoch:24/30     Step:5|6   loss:0.6222493052482605  \n","Epoch:24/30     Step:6|6   loss:0.722405195236206  \n","Epoch:24/30     Step:7|6   loss:0.694686770439148  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7079941034317017  \n","Epoch:25/30     Step:2|6   loss:0.7375073432922363  \n","Epoch:25/30     Step:3|6   loss:0.718666672706604  \n","Epoch:25/30     Step:4|6   loss:0.6891944408416748  \n","Epoch:25/30     Step:5|6   loss:0.7303797006607056  \n","Epoch:25/30     Step:6|6   loss:0.685814380645752  \n","Epoch:25/30     Step:7|6   loss:0.734588623046875  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7074414491653442  \n","Epoch:26/30     Step:2|6   loss:0.6891840696334839  \n","Epoch:26/30     Step:3|6   loss:0.6512712240219116  \n","Epoch:26/30     Step:4|6   loss:0.7116478085517883  \n","Epoch:26/30     Step:5|6   loss:0.6718833446502686  \n","Epoch:26/30     Step:6|6   loss:0.6798363327980042  \n","Epoch:26/30     Step:7|6   loss:0.6644129753112793  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.6771818399429321  \n","Epoch:27/30     Step:2|6   loss:0.6798449754714966  \n","Epoch:27/30     Step:3|6   loss:0.6978417038917542  \n","Epoch:27/30     Step:4|6   loss:0.7392003536224365  \n","Epoch:27/30     Step:5|6   loss:0.7039448022842407  \n","Epoch:27/30     Step:6|6   loss:0.6976591944694519  \n","Epoch:27/30     Step:7|6   loss:0.7308732271194458  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.8247385025024414  \n","Epoch:28/30     Step:2|6   loss:0.7067568302154541  \n","Epoch:28/30     Step:3|6   loss:0.6997213959693909  \n","Epoch:28/30     Step:4|6   loss:0.7131232023239136  \n","Epoch:28/30     Step:5|6   loss:0.7132778167724609  \n","Epoch:28/30     Step:6|6   loss:0.7692044973373413  \n","Epoch:28/30     Step:7|6   loss:0.7198147773742676  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.7169342041015625  \n","Epoch:29/30     Step:2|6   loss:0.6736432909965515  \n","Epoch:29/30     Step:3|6   loss:0.6946585178375244  \n","Epoch:29/30     Step:4|6   loss:0.7186774015426636  \n","Epoch:29/30     Step:5|6   loss:0.7347932457923889  \n","Epoch:29/30     Step:6|6   loss:0.7399553060531616  \n","Epoch:29/30     Step:7|6   loss:0.7605551481246948  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.6659154891967773  \n","Epoch:30/30     Step:2|6   loss:0.7068331837654114  \n","Epoch:30/30     Step:3|6   loss:0.6821916699409485  \n","Epoch:30/30     Step:4|6   loss:0.7613163590431213  \n","Epoch:30/30     Step:5|6   loss:0.7242069244384766  \n","Epoch:30/30     Step:6|6   loss:0.6783779859542847  \n","Epoch:30/30     Step:7|6   loss:0.6511404514312744  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Mobilenetv2_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Mobilenetv2_two_stream(\n","  (stream1): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (stream2): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","3\n"]},{"name":"stdout","output_type":"stream","text":["          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=2560, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1294305324554443  \n","Epoch:1/30     Step:2|6   loss:1.0344593524932861  \n","Epoch:1/30     Step:3|6   loss:0.8519182801246643  \n","Epoch:1/30     Step:4|6   loss:0.7896381616592407  \n","Epoch:1/30     Step:5|6   loss:0.8229149580001831  \n","Epoch:1/30     Step:6|6   loss:0.7388814091682434  \n","Epoch:1/30     Step:7|6   loss:0.8074673414230347  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:97.2%\t train set:96.96%\n","Epoch:2/30     Step:1|6   loss:0.8496707677841187  \n","Epoch:2/30     Step:2|6   loss:0.8120566606521606  \n","Epoch:2/30     Step:3|6   loss:0.8666825294494629  \n","Epoch:2/30     Step:4|6   loss:0.7996091842651367  \n","Epoch:2/30     Step:5|6   loss:0.7934204339981079  \n","Epoch:2/30     Step:6|6   loss:0.7707664966583252  \n","Epoch:2/30     Step:7|6   loss:0.7960326671600342  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:99.07%\t train set:98.59%\n","Epoch:3/30     Step:1|6   loss:0.7827482223510742  \n","Epoch:3/30     Step:2|6   loss:0.7475132942199707  \n","Epoch:3/30     Step:3|6   loss:0.7702016830444336  \n","Epoch:3/30     Step:4|6   loss:0.7167247533798218  \n","Epoch:3/30     Step:5|6   loss:0.7481940984725952  \n","Epoch:3/30     Step:6|6   loss:0.7384512424468994  \n","Epoch:3/30     Step:7|6   loss:0.7221182584762573  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:4/30     Step:1|6   loss:0.6967383623123169  \n","Epoch:4/30     Step:2|6   loss:0.706822395324707  \n","Epoch:4/30     Step:3|6   loss:0.7569617033004761  \n","Epoch:4/30     Step:4|6   loss:0.726521909236908  \n","Epoch:4/30     Step:5|6   loss:0.755684494972229  \n","Epoch:4/30     Step:6|6   loss:0.7352721691131592  \n","Epoch:4/30     Step:7|6   loss:0.6783878207206726  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:5/30     Step:1|6   loss:0.734184741973877  \n","Epoch:5/30     Step:2|6   loss:0.7153388261795044  \n","Epoch:5/30     Step:3|6   loss:0.7503570318222046  \n","Epoch:5/30     Step:4|6   loss:0.7324146032333374  \n","Epoch:5/30     Step:5|6   loss:0.7221226692199707  \n","Epoch:5/30     Step:6|6   loss:0.7013152837753296  \n","Epoch:5/30     Step:7|6   loss:0.7869330048561096  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7081348896026611  \n","Epoch:6/30     Step:2|6   loss:0.7033087611198425  \n","Epoch:6/30     Step:3|6   loss:0.7622379064559937  \n","Epoch:6/30     Step:4|6   loss:0.7520570755004883  \n","Epoch:6/30     Step:5|6   loss:0.6801168918609619  \n","Epoch:6/30     Step:6|6   loss:0.6946947574615479  \n","Epoch:6/30     Step:7|6   loss:0.777410089969635  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.704378604888916  \n","Epoch:7/30     Step:2|6   loss:0.7356841564178467  \n","Epoch:7/30     Step:3|6   loss:0.6904522180557251  \n","Epoch:7/30     Step:4|6   loss:0.7161225080490112  \n","Epoch:7/30     Step:5|6   loss:0.70524001121521  \n","Epoch:7/30     Step:6|6   loss:0.7666694521903992  \n","Epoch:7/30     Step:7|6   loss:0.7684537172317505  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.7014148235321045  \n","Epoch:8/30     Step:2|6   loss:0.7198289632797241  \n","Epoch:8/30     Step:3|6   loss:0.7355271577835083  \n","Epoch:8/30     Step:4|6   loss:0.7648607492446899  \n","Epoch:8/30     Step:5|6   loss:0.7275072932243347  \n","Epoch:8/30     Step:6|6   loss:0.7288861274719238  \n","Epoch:8/30     Step:7|6   loss:0.6952896118164062  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7181881666183472  \n","Epoch:9/30     Step:2|6   loss:0.69321209192276  \n","Epoch:9/30     Step:3|6   loss:0.6963209509849548  \n","Epoch:9/30     Step:4|6   loss:0.6599836349487305  \n","Epoch:9/30     Step:5|6   loss:0.7058817148208618  \n","Epoch:9/30     Step:6|6   loss:0.7313011884689331  \n","Epoch:9/30     Step:7|6   loss:0.713414192199707  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7186751365661621  \n","Epoch:10/30     Step:2|6   loss:0.6984198093414307  \n","Epoch:10/30     Step:3|6   loss:0.7096377611160278  \n","Epoch:10/30     Step:4|6   loss:0.7023730278015137  \n","Epoch:10/30     Step:5|6   loss:0.7198460102081299  \n","Epoch:10/30     Step:6|6   loss:0.731968879699707  \n","Epoch:10/30     Step:7|6   loss:0.7678912878036499  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.7602362632751465  \n","Epoch:11/30     Step:2|6   loss:0.7118551135063171  \n","Epoch:11/30     Step:3|6   loss:0.7105206847190857  \n","Epoch:11/30     Step:4|6   loss:0.7243454456329346  \n","Epoch:11/30     Step:5|6   loss:0.6930005550384521  \n","Epoch:11/30     Step:6|6   loss:0.6935464143753052  \n","Epoch:11/30     Step:7|6   loss:0.7039941549301147  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6552484035491943  \n","Epoch:12/30     Step:2|6   loss:0.7342005968093872  \n","Epoch:12/30     Step:3|6   loss:0.7750469446182251  \n","Epoch:12/30     Step:4|6   loss:0.7574795484542847  \n","Epoch:12/30     Step:5|6   loss:0.7159817814826965  \n","Epoch:12/30     Step:6|6   loss:0.6451166868209839  \n","Epoch:12/30     Step:7|6   loss:0.7264726758003235  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7197726964950562  \n","Epoch:13/30     Step:2|6   loss:0.6633740067481995  \n","Epoch:13/30     Step:3|6   loss:0.7107574939727783  \n","Epoch:13/30     Step:4|6   loss:0.6827632188796997  \n","Epoch:13/30     Step:5|6   loss:0.6765406131744385  \n","Epoch:13/30     Step:6|6   loss:0.7165679931640625  \n","Epoch:13/30     Step:7|6   loss:0.6783324480056763  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.6840418577194214  \n","Epoch:14/30     Step:2|6   loss:0.7519909143447876  \n","Epoch:14/30     Step:3|6   loss:0.7675222158432007  \n","Epoch:14/30     Step:4|6   loss:0.6955053210258484  \n","Epoch:14/30     Step:5|6   loss:0.7019658088684082  \n","Epoch:14/30     Step:6|6   loss:0.6932268142700195  \n","Epoch:14/30     Step:7|6   loss:0.7322165966033936  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.7252064943313599  \n","Epoch:15/30     Step:2|6   loss:0.6986351609230042  \n","Epoch:15/30     Step:3|6   loss:0.7104804515838623  \n","Epoch:15/30     Step:4|6   loss:0.6807719469070435  \n","Epoch:15/30     Step:5|6   loss:0.6787216663360596  \n","Epoch:15/30     Step:6|6   loss:0.7537904977798462  \n","Epoch:15/30     Step:7|6   loss:0.7301318645477295  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7032575607299805  \n","Epoch:16/30     Step:2|6   loss:0.7089589834213257  \n","Epoch:16/30     Step:3|6   loss:0.7000298500061035  \n","Epoch:16/30     Step:4|6   loss:0.70658940076828  \n","Epoch:16/30     Step:5|6   loss:0.7382262349128723  \n","Epoch:16/30     Step:6|6   loss:0.7102829813957214  \n","Epoch:16/30     Step:7|6   loss:0.7700787782669067  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.7006405591964722  \n","Epoch:17/30     Step:2|6   loss:0.6842266321182251  \n","Epoch:17/30     Step:3|6   loss:0.7039756774902344  \n","Epoch:17/30     Step:4|6   loss:0.6847401857376099  \n","Epoch:17/30     Step:5|6   loss:0.7106029987335205  \n","Epoch:17/30     Step:6|6   loss:0.6784220933914185  \n","Epoch:17/30     Step:7|6   loss:0.6647595167160034  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.6821094155311584  \n","Epoch:18/30     Step:2|6   loss:0.7101391553878784  \n","Epoch:18/30     Step:3|6   loss:0.6861968040466309  \n","Epoch:18/30     Step:4|6   loss:0.6806313991546631  \n","Epoch:18/30     Step:5|6   loss:0.7415857315063477  \n","Epoch:18/30     Step:6|6   loss:0.6646808385848999  \n","Epoch:18/30     Step:7|6   loss:0.679344654083252  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.6851588487625122  \n","Epoch:19/30     Step:2|6   loss:0.7300935387611389  \n","Epoch:19/30     Step:3|6   loss:0.6922097206115723  \n","Epoch:19/30     Step:4|6   loss:0.7251948118209839  \n","Epoch:19/30     Step:5|6   loss:0.7018029689788818  \n","Epoch:19/30     Step:6|6   loss:0.713223934173584  \n","Epoch:19/30     Step:7|6   loss:0.7002160549163818  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.7403372526168823  \n","Epoch:20/30     Step:2|6   loss:0.7670484185218811  \n","Epoch:20/30     Step:3|6   loss:0.7257698774337769  \n","Epoch:20/30     Step:4|6   loss:0.7356917858123779  \n","Epoch:20/30     Step:5|6   loss:0.7288967370986938  \n","Epoch:20/30     Step:6|6   loss:0.7043690085411072  \n","Epoch:20/30     Step:7|6   loss:0.6943427324295044  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7091529369354248  \n","Epoch:21/30     Step:2|6   loss:0.6712797284126282  \n","Epoch:21/30     Step:3|6   loss:0.7378067970275879  \n","Epoch:21/30     Step:4|6   loss:0.7485612630844116  \n","Epoch:21/30     Step:5|6   loss:0.6812864542007446  \n","Epoch:21/30     Step:6|6   loss:0.687579333782196  \n","Epoch:21/30     Step:7|6   loss:0.651821494102478  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.7367215156555176  \n","Epoch:22/30     Step:2|6   loss:0.7040349245071411  \n","Epoch:22/30     Step:3|6   loss:0.6787645816802979  \n","Epoch:22/30     Step:4|6   loss:0.729073166847229  \n","Epoch:22/30     Step:5|6   loss:0.7025932669639587  \n","Epoch:22/30     Step:6|6   loss:0.6617773771286011  \n","Epoch:22/30     Step:7|6   loss:0.6754040122032166  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.7232996821403503  \n","Epoch:23/30     Step:2|6   loss:0.7189072370529175  \n","Epoch:23/30     Step:3|6   loss:0.695052981376648  \n","Epoch:23/30     Step:4|6   loss:0.7194899916648865  \n","Epoch:23/30     Step:5|6   loss:0.7244152426719666  \n","Epoch:23/30     Step:6|6   loss:0.670751690864563  \n","Epoch:23/30     Step:7|6   loss:0.6668744087219238  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.6798400282859802  \n","Epoch:24/30     Step:2|6   loss:0.6709333658218384  \n","Epoch:24/30     Step:3|6   loss:0.6949907541275024  \n","Epoch:24/30     Step:4|6   loss:0.6972534656524658  \n","Epoch:24/30     Step:5|6   loss:0.6839374303817749  \n","Epoch:24/30     Step:6|6   loss:0.7421021461486816  \n","Epoch:24/30     Step:7|6   loss:0.6968936920166016  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.6842988133430481  \n","Epoch:25/30     Step:2|6   loss:0.7261472940444946  \n","Epoch:25/30     Step:3|6   loss:0.6981685757637024  \n","Epoch:25/30     Step:4|6   loss:0.711561918258667  \n","Epoch:25/30     Step:5|6   loss:0.6848233938217163  \n","Epoch:25/30     Step:6|6   loss:0.7229739427566528  \n","Epoch:25/30     Step:7|6   loss:0.6892712116241455  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7481375932693481  \n","Epoch:26/30     Step:2|6   loss:0.6992203593254089  \n","Epoch:26/30     Step:3|6   loss:0.661228358745575  \n","Epoch:26/30     Step:4|6   loss:0.7183022499084473  \n","Epoch:26/30     Step:5|6   loss:0.6765648126602173  \n","Epoch:26/30     Step:6|6   loss:0.6646140813827515  \n","Epoch:26/30     Step:7|6   loss:0.7123218178749084  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.7012107372283936  \n","Epoch:27/30     Step:2|6   loss:0.6429698467254639  \n","Epoch:27/30     Step:3|6   loss:0.708670973777771  \n","Epoch:27/30     Step:4|6   loss:0.6968914270401001  \n","Epoch:27/30     Step:5|6   loss:0.6915252208709717  \n","Epoch:27/30     Step:6|6   loss:0.7320519089698792  \n","Epoch:27/30     Step:7|6   loss:0.6836469173431396  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.6817820072174072  \n","Epoch:28/30     Step:2|6   loss:0.6385511755943298  \n","Epoch:28/30     Step:3|6   loss:0.7213176488876343  \n","Epoch:28/30     Step:4|6   loss:0.7114419937133789  \n","Epoch:28/30     Step:5|6   loss:0.6555038690567017  \n","Epoch:28/30     Step:6|6   loss:0.7081717848777771  \n","Epoch:28/30     Step:7|6   loss:0.7224076986312866  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.6937627196311951  \n","Epoch:29/30     Step:2|6   loss:0.6978131532669067  \n","Epoch:29/30     Step:3|6   loss:0.7081491947174072  \n","Epoch:29/30     Step:4|6   loss:0.6719266176223755  \n","Epoch:29/30     Step:5|6   loss:0.7371598482131958  \n","Epoch:29/30     Step:6|6   loss:0.7359378337860107  \n","Epoch:29/30     Step:7|6   loss:0.7272406816482544  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.6756865382194519  \n","Epoch:30/30     Step:2|6   loss:0.6507333517074585  \n","Epoch:30/30     Step:3|6   loss:0.7203848361968994  \n","Epoch:30/30     Step:4|6   loss:0.7243599891662598  \n","Epoch:30/30     Step:5|6   loss:0.6989516615867615  \n","Epoch:30/30     Step:6|6   loss:0.6558598279953003  \n","Epoch:30/30     Step:7|6   loss:0.6947882175445557  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Mobilenetv2_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Mobilenetv2_two_stream(\n","  (stream1): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","4\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (stream2): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=2560, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1020034551620483  \n","Epoch:1/30     Step:2|6   loss:0.9640082716941833  \n","Epoch:1/30     Step:3|6   loss:0.8110390901565552  \n","Epoch:1/30     Step:4|6   loss:0.9374697804450989  \n","Epoch:1/30     Step:5|6   loss:0.8114725351333618  \n","Epoch:1/30     Step:6|6   loss:0.767318844795227  \n","Epoch:1/30     Step:7|6   loss:0.8209962248802185  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:96.26%\t train set:95.55%\n","Epoch:2/30     Step:1|6   loss:0.8343585133552551  \n","Epoch:2/30     Step:2|6   loss:0.8323338031768799  \n","Epoch:2/30     Step:3|6   loss:0.7891671657562256  \n","Epoch:2/30     Step:4|6   loss:0.7619516849517822  \n","Epoch:2/30     Step:5|6   loss:0.7833825349807739  \n","Epoch:2/30     Step:6|6   loss:0.7218365669250488  \n","Epoch:2/30     Step:7|6   loss:0.7509845495223999  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.7323898077011108  \n","Epoch:3/30     Step:2|6   loss:0.7592892646789551  \n","Epoch:3/30     Step:3|6   loss:0.7190899848937988  \n","Epoch:3/30     Step:4|6   loss:0.7919348478317261  \n","Epoch:3/30     Step:5|6   loss:0.7610790729522705  \n","Epoch:3/30     Step:6|6   loss:0.7560527324676514  \n","Epoch:3/30     Step:7|6   loss:0.7164998054504395  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.7426331043243408  \n","Epoch:4/30     Step:2|6   loss:0.7150684595108032  \n","Epoch:4/30     Step:3|6   loss:0.6886216402053833  \n","Epoch:4/30     Step:4|6   loss:0.717729389667511  \n","Epoch:4/30     Step:5|6   loss:0.6904733180999756  \n","Epoch:4/30     Step:6|6   loss:0.7412703037261963  \n","Epoch:4/30     Step:7|6   loss:0.6764178276062012  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.713294267654419  \n","Epoch:5/30     Step:2|6   loss:0.6964071393013  \n","Epoch:5/30     Step:3|6   loss:0.7351058721542358  \n","Epoch:5/30     Step:4|6   loss:0.711828887462616  \n","Epoch:5/30     Step:5|6   loss:0.7136767506599426  \n","Epoch:5/30     Step:6|6   loss:0.7176529169082642  \n","Epoch:5/30     Step:7|6   loss:0.7436407804489136  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.6952488422393799  \n","Epoch:6/30     Step:2|6   loss:0.7754502296447754  \n","Epoch:6/30     Step:3|6   loss:0.7250813841819763  \n","Epoch:6/30     Step:4|6   loss:0.72674161195755  \n","Epoch:6/30     Step:5|6   loss:0.7140185832977295  \n","Epoch:6/30     Step:6|6   loss:0.7439566850662231  \n","Epoch:6/30     Step:7|6   loss:0.730951726436615  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.7297045588493347  \n","Epoch:7/30     Step:2|6   loss:0.7045924663543701  \n","Epoch:7/30     Step:3|6   loss:0.6838821172714233  \n","Epoch:7/30     Step:4|6   loss:0.7266010046005249  \n","Epoch:7/30     Step:5|6   loss:0.7432564496994019  \n","Epoch:7/30     Step:6|6   loss:0.6655776500701904  \n","Epoch:7/30     Step:7|6   loss:0.7526024580001831  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.6861876249313354  \n","Epoch:8/30     Step:2|6   loss:0.6987130641937256  \n","Epoch:8/30     Step:3|6   loss:0.7073485851287842  \n","Epoch:8/30     Step:4|6   loss:0.7483606338500977  \n","Epoch:8/30     Step:5|6   loss:0.7028757333755493  \n","Epoch:8/30     Step:6|6   loss:0.7293367385864258  \n","Epoch:8/30     Step:7|6   loss:0.7072106599807739  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.6881444454193115  \n","Epoch:9/30     Step:2|6   loss:0.7267738580703735  \n","Epoch:9/30     Step:3|6   loss:0.7255948781967163  \n","Epoch:9/30     Step:4|6   loss:0.7147352695465088  \n","Epoch:9/30     Step:5|6   loss:0.7444485425949097  \n","Epoch:9/30     Step:6|6   loss:0.739681601524353  \n","Epoch:9/30     Step:7|6   loss:0.7637369632720947  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7356468439102173  \n","Epoch:10/30     Step:2|6   loss:0.6722511053085327  \n","Epoch:10/30     Step:3|6   loss:0.7218900918960571  \n","Epoch:10/30     Step:4|6   loss:0.7777138948440552  \n","Epoch:10/30     Step:5|6   loss:0.71172696352005  \n","Epoch:10/30     Step:6|6   loss:0.7277308702468872  \n","Epoch:10/30     Step:7|6   loss:0.707545816898346  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.6472507119178772  \n","Epoch:11/30     Step:2|6   loss:0.7218413949012756  \n","Epoch:11/30     Step:3|6   loss:0.7220534086227417  \n","Epoch:11/30     Step:4|6   loss:0.7740177512168884  \n","Epoch:11/30     Step:5|6   loss:0.7168517708778381  \n","Epoch:11/30     Step:6|6   loss:0.7528601884841919  \n","Epoch:11/30     Step:7|6   loss:0.7411547303199768  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6999632716178894  \n","Epoch:12/30     Step:2|6   loss:0.7133424282073975  \n","Epoch:12/30     Step:3|6   loss:0.7204129695892334  \n","Epoch:12/30     Step:4|6   loss:0.7081809043884277  \n","Epoch:12/30     Step:5|6   loss:0.7266229391098022  \n","Epoch:12/30     Step:6|6   loss:0.6862314939498901  \n","Epoch:12/30     Step:7|6   loss:0.7288700938224792  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.6961299777030945  \n","Epoch:13/30     Step:2|6   loss:0.7292828559875488  \n","Epoch:13/30     Step:3|6   loss:0.711472749710083  \n","Epoch:13/30     Step:4|6   loss:0.685846209526062  \n","Epoch:13/30     Step:5|6   loss:0.6715072989463806  \n","Epoch:13/30     Step:6|6   loss:0.7005593776702881  \n","Epoch:13/30     Step:7|6   loss:0.7197946906089783  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7061370611190796  \n","Epoch:14/30     Step:2|6   loss:0.734110951423645  \n","Epoch:14/30     Step:3|6   loss:0.7232745885848999  \n","Epoch:14/30     Step:4|6   loss:0.7173668146133423  \n","Epoch:14/30     Step:5|6   loss:0.733153760433197  \n","Epoch:14/30     Step:6|6   loss:0.7197160720825195  \n","Epoch:14/30     Step:7|6   loss:0.7312036752700806  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.6839408278465271  \n","Epoch:15/30     Step:2|6   loss:0.7174323797225952  \n","Epoch:15/30     Step:3|6   loss:0.6915457248687744  \n","Epoch:15/30     Step:4|6   loss:0.8144243955612183  \n","Epoch:15/30     Step:5|6   loss:0.7421177625656128  \n","Epoch:15/30     Step:6|6   loss:0.7265373468399048  \n","Epoch:15/30     Step:7|6   loss:0.6645348072052002  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7279717326164246  \n","Epoch:16/30     Step:2|6   loss:0.6797431707382202  \n","Epoch:16/30     Step:3|6   loss:0.6990653276443481  \n","Epoch:16/30     Step:4|6   loss:0.6537951231002808  \n","Epoch:16/30     Step:5|6   loss:0.6801906824111938  \n","Epoch:16/30     Step:6|6   loss:0.7166570425033569  \n","Epoch:16/30     Step:7|6   loss:0.7336488962173462  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.6963552236557007  \n","Epoch:17/30     Step:2|6   loss:0.7146173715591431  \n","Epoch:17/30     Step:3|6   loss:0.6748448610305786  \n","Epoch:17/30     Step:4|6   loss:0.6912920475006104  \n","Epoch:17/30     Step:5|6   loss:0.7291635870933533  \n","Epoch:17/30     Step:6|6   loss:0.7296526432037354  \n","Epoch:17/30     Step:7|6   loss:0.7150551080703735  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.6718837022781372  \n","Epoch:18/30     Step:2|6   loss:0.7414757609367371  \n","Epoch:18/30     Step:3|6   loss:0.7229704856872559  \n","Epoch:18/30     Step:4|6   loss:0.7341217994689941  \n","Epoch:18/30     Step:5|6   loss:0.6988839507102966  \n","Epoch:18/30     Step:6|6   loss:0.6867905855178833  \n","Epoch:18/30     Step:7|6   loss:0.705217182636261  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.7289351224899292  \n","Epoch:19/30     Step:2|6   loss:0.7317531108856201  \n","Epoch:19/30     Step:3|6   loss:0.6992638111114502  \n","Epoch:19/30     Step:4|6   loss:0.6970113515853882  \n","Epoch:19/30     Step:5|6   loss:0.7132771015167236  \n","Epoch:19/30     Step:6|6   loss:0.6722218990325928  \n","Epoch:19/30     Step:7|6   loss:0.6966738700866699  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.7315778732299805  \n","Epoch:20/30     Step:2|6   loss:0.7091336846351624  \n","Epoch:20/30     Step:3|6   loss:0.6548741459846497  \n","Epoch:20/30     Step:4|6   loss:0.6642324924468994  \n","Epoch:20/30     Step:5|6   loss:0.6967543363571167  \n","Epoch:20/30     Step:6|6   loss:0.726182222366333  \n","Epoch:20/30     Step:7|6   loss:0.7121607065200806  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7339143753051758  \n","Epoch:21/30     Step:2|6   loss:0.7594096064567566  \n","Epoch:21/30     Step:3|6   loss:0.7817713618278503  \n","Epoch:21/30     Step:4|6   loss:0.7184017896652222  \n","Epoch:21/30     Step:5|6   loss:0.7219107747077942  \n","Epoch:21/30     Step:6|6   loss:0.682520866394043  \n","Epoch:21/30     Step:7|6   loss:0.7095399498939514  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.7265297174453735  \n","Epoch:22/30     Step:2|6   loss:0.7144743204116821  \n","Epoch:22/30     Step:3|6   loss:0.7003967761993408  \n","Epoch:22/30     Step:4|6   loss:0.73881596326828  \n","Epoch:22/30     Step:5|6   loss:0.6317260265350342  \n","Epoch:22/30     Step:6|6   loss:0.7228680849075317  \n","Epoch:22/30     Step:7|6   loss:0.695116400718689  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.7019246816635132  \n","Epoch:23/30     Step:2|6   loss:0.7560078501701355  \n","Epoch:23/30     Step:3|6   loss:0.6987745761871338  \n","Epoch:23/30     Step:4|6   loss:0.6730909943580627  \n","Epoch:23/30     Step:5|6   loss:0.6998848915100098  \n","Epoch:23/30     Step:6|6   loss:0.6875554323196411  \n","Epoch:23/30     Step:7|6   loss:0.6902157068252563  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.6824607849121094  \n","Epoch:24/30     Step:2|6   loss:0.6840780973434448  \n","Epoch:24/30     Step:3|6   loss:0.7716982960700989  \n","Epoch:24/30     Step:4|6   loss:0.7045861482620239  \n","Epoch:24/30     Step:5|6   loss:0.7056757211685181  \n","Epoch:24/30     Step:6|6   loss:0.700385570526123  \n","Epoch:24/30     Step:7|6   loss:0.7114923000335693  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7243515253067017  \n","Epoch:25/30     Step:2|6   loss:0.6909633874893188  \n","Epoch:25/30     Step:3|6   loss:0.70330810546875  \n","Epoch:25/30     Step:4|6   loss:0.6785815954208374  \n","Epoch:25/30     Step:5|6   loss:0.652151346206665  \n","Epoch:25/30     Step:6|6   loss:0.6283707022666931  \n","Epoch:25/30     Step:7|6   loss:0.7182654142379761  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7314203977584839  \n","Epoch:26/30     Step:2|6   loss:0.7256029844284058  \n","Epoch:26/30     Step:3|6   loss:0.7301307320594788  \n","Epoch:26/30     Step:4|6   loss:0.728472888469696  \n","Epoch:26/30     Step:5|6   loss:0.7127131223678589  \n","Epoch:26/30     Step:6|6   loss:0.6694489121437073  \n","Epoch:26/30     Step:7|6   loss:0.7218214273452759  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.7001001238822937  \n","Epoch:27/30     Step:2|6   loss:0.7205064296722412  \n","Epoch:27/30     Step:3|6   loss:0.6933481693267822  \n","Epoch:27/30     Step:4|6   loss:0.7068082094192505  \n","Epoch:27/30     Step:5|6   loss:0.6785310506820679  \n","Epoch:27/30     Step:6|6   loss:0.6824514865875244  \n","Epoch:27/30     Step:7|6   loss:0.6960769891738892  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.6783705949783325  \n","Epoch:28/30     Step:2|6   loss:0.7491400241851807  \n","Epoch:28/30     Step:3|6   loss:0.7545844912528992  \n","Epoch:28/30     Step:4|6   loss:0.6573377847671509  \n","Epoch:28/30     Step:5|6   loss:0.716301679611206  \n","Epoch:28/30     Step:6|6   loss:0.7253158092498779  \n","Epoch:28/30     Step:7|6   loss:0.7439011335372925  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.7244951725006104  \n","Epoch:29/30     Step:2|6   loss:0.7040201425552368  \n","Epoch:29/30     Step:3|6   loss:0.666135311126709  \n","Epoch:29/30     Step:4|6   loss:0.7110586166381836  \n","Epoch:29/30     Step:5|6   loss:0.698361337184906  \n","Epoch:29/30     Step:6|6   loss:0.7748405337333679  \n","Epoch:29/30     Step:7|6   loss:0.7236149311065674  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.7114598751068115  \n","Epoch:30/30     Step:2|6   loss:0.7404639720916748  \n","Epoch:30/30     Step:3|6   loss:0.6801437735557556  \n","Epoch:30/30     Step:4|6   loss:0.7176259756088257  \n","Epoch:30/30     Step:5|6   loss:0.7439793944358826  \n","Epoch:30/30     Step:6|6   loss:0.7022451162338257  \n","Epoch:30/30     Step:7|6   loss:0.7322590351104736  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Mobilenetv2_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Mobilenetv2_two_stream(\n","  (stream1): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (stream2): MobileNetV2(\n","    (features): Sequential(\n","      (0): ConvNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (9): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (10): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (11): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (12): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (13): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (14): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (15): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (16): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (17): InvertedResidual(\n","        (conv): Sequential(\n","          (0): ConvNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"]},{"name":"stdout","output_type":"stream","text":["            (2): ReLU6(inplace=True)\n","          )\n","          (1): ConvNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): ReLU6(inplace=True)\n","          )\n","          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (18): ConvNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=False)\n","      (1): Linear(in_features=1280, out_features=1280, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=2560, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.080694317817688  \n","Epoch:1/30     Step:2|6   loss:1.097116470336914  \n","Epoch:1/30     Step:3|6   loss:0.8217085599899292  \n","Epoch:1/30     Step:4|6   loss:0.7712152004241943  \n","Epoch:1/30     Step:5|6   loss:0.8754518032073975  \n","Epoch:1/30     Step:6|6   loss:0.9111366271972656  \n","Epoch:1/30     Step:7|6   loss:0.7942980527877808  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:2/30     Step:1|6   loss:0.7700268030166626  \n","Epoch:2/30     Step:2|6   loss:0.8410820364952087  \n","Epoch:2/30     Step:3|6   loss:0.784343957901001  \n","Epoch:2/30     Step:4|6   loss:0.7379843592643738  \n","Epoch:2/30     Step:5|6   loss:0.7657853364944458  \n","Epoch:2/30     Step:6|6   loss:0.7673461437225342  \n","Epoch:2/30     Step:7|6   loss:0.794967532157898  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.3%\n","Epoch:3/30     Step:1|6   loss:0.7305415868759155  \n","Epoch:3/30     Step:2|6   loss:0.6858338117599487  \n","Epoch:3/30     Step:3|6   loss:0.69353187084198  \n","Epoch:3/30     Step:4|6   loss:0.7396858334541321  \n","Epoch:3/30     Step:5|6   loss:0.7331874370574951  \n","Epoch:3/30     Step:6|6   loss:0.7715290784835815  \n","Epoch:3/30     Step:7|6   loss:0.7793848514556885  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.7079727649688721  \n","Epoch:4/30     Step:2|6   loss:0.697869062423706  \n","Epoch:4/30     Step:3|6   loss:0.7315965890884399  \n","Epoch:4/30     Step:4|6   loss:0.7128612399101257  \n","Epoch:4/30     Step:5|6   loss:0.7244036197662354  \n","Epoch:4/30     Step:6|6   loss:0.7245335578918457  \n","Epoch:4/30     Step:7|6   loss:0.7411091327667236  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.7667416334152222  \n","Epoch:5/30     Step:2|6   loss:0.6956418752670288  \n","Epoch:5/30     Step:3|6   loss:0.7096331119537354  \n","Epoch:5/30     Step:4|6   loss:0.6941617727279663  \n","Epoch:5/30     Step:5|6   loss:0.7564511299133301  \n","Epoch:5/30     Step:6|6   loss:0.7687893509864807  \n","Epoch:5/30     Step:7|6   loss:0.7452570199966431  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7131284475326538  \n","Epoch:6/30     Step:2|6   loss:0.7537586092948914  \n","Epoch:6/30     Step:3|6   loss:0.7068840265274048  \n","Epoch:6/30     Step:4|6   loss:0.7203304767608643  \n","Epoch:6/30     Step:5|6   loss:0.7598603963851929  \n","Epoch:6/30     Step:6|6   loss:0.7502560019493103  \n","Epoch:6/30     Step:7|6   loss:0.7836262583732605  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.7318350076675415  \n","Epoch:7/30     Step:2|6   loss:0.6958372592926025  \n","Epoch:7/30     Step:3|6   loss:0.70185387134552  \n","Epoch:7/30     Step:4|6   loss:0.692855954170227  \n","Epoch:7/30     Step:5|6   loss:0.7040762901306152  \n","Epoch:7/30     Step:6|6   loss:0.6948455572128296  \n","Epoch:7/30     Step:7|6   loss:0.7091840505599976  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.757733941078186  \n","Epoch:8/30     Step:2|6   loss:0.7126814126968384  \n","Epoch:8/30     Step:3|6   loss:0.7226303815841675  \n","Epoch:8/30     Step:4|6   loss:0.7275048494338989  \n","Epoch:8/30     Step:5|6   loss:0.6865783929824829  \n","Epoch:8/30     Step:6|6   loss:0.6899848580360413  \n","Epoch:8/30     Step:7|6   loss:0.7077454328536987  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7006953954696655  \n","Epoch:9/30     Step:2|6   loss:0.7180399894714355  \n","Epoch:9/30     Step:3|6   loss:0.6816680431365967  \n","Epoch:9/30     Step:4|6   loss:0.7177965641021729  \n","Epoch:9/30     Step:5|6   loss:0.7650808691978455  \n","Epoch:9/30     Step:6|6   loss:0.6876200437545776  \n","Epoch:9/30     Step:7|6   loss:0.7332327365875244  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7485253214836121  \n","Epoch:10/30     Step:2|6   loss:0.7356598973274231  \n","Epoch:10/30     Step:3|6   loss:0.7691388130187988  \n","Epoch:10/30     Step:4|6   loss:0.713991641998291  \n","Epoch:10/30     Step:5|6   loss:0.6321470737457275  \n","Epoch:10/30     Step:6|6   loss:0.6852116584777832  \n","Epoch:10/30     Step:7|6   loss:0.7217793464660645  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.7123532295227051  \n","Epoch:11/30     Step:2|6   loss:0.7190517783164978  \n","Epoch:11/30     Step:3|6   loss:0.7583658695220947  \n","Epoch:11/30     Step:4|6   loss:0.7477676272392273  \n","Epoch:11/30     Step:5|6   loss:0.7194685935974121  \n","Epoch:11/30     Step:6|6   loss:0.6897746324539185  \n","Epoch:11/30     Step:7|6   loss:0.7523730993270874  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6587110757827759  \n","Epoch:12/30     Step:2|6   loss:0.6802506446838379  \n","Epoch:12/30     Step:3|6   loss:0.7157666683197021  \n","Epoch:12/30     Step:4|6   loss:0.7318480014801025  \n","Epoch:12/30     Step:5|6   loss:0.7245957255363464  \n","Epoch:12/30     Step:6|6   loss:0.679307758808136  \n","Epoch:12/30     Step:7|6   loss:0.7713364362716675  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7687031030654907  \n","Epoch:13/30     Step:2|6   loss:0.7130858898162842  \n","Epoch:13/30     Step:3|6   loss:0.7068977355957031  \n","Epoch:13/30     Step:4|6   loss:0.6656274795532227  \n","Epoch:13/30     Step:5|6   loss:0.7165131568908691  \n","Epoch:13/30     Step:6|6   loss:0.721616804599762  \n","Epoch:13/30     Step:7|6   loss:0.7037889361381531  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7184454798698425  \n","Epoch:14/30     Step:2|6   loss:0.7214245796203613  \n","Epoch:14/30     Step:3|6   loss:0.7241920828819275  \n","Epoch:14/30     Step:4|6   loss:0.6818840503692627  \n","Epoch:14/30     Step:5|6   loss:0.6873735189437866  \n","Epoch:14/30     Step:6|6   loss:0.7145792841911316  \n","Epoch:14/30     Step:7|6   loss:0.7143006324768066  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.7289731502532959  \n","Epoch:15/30     Step:2|6   loss:0.7053864598274231  \n","Epoch:15/30     Step:3|6   loss:0.6899514198303223  \n","Epoch:15/30     Step:4|6   loss:0.7466237545013428  \n","Epoch:15/30     Step:5|6   loss:0.7200206518173218  \n","Epoch:15/30     Step:6|6   loss:0.7553180456161499  \n","Epoch:15/30     Step:7|6   loss:0.6646966934204102  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7145135402679443  \n","Epoch:16/30     Step:2|6   loss:0.7255967855453491  \n","Epoch:16/30     Step:3|6   loss:0.7249621152877808  \n","Epoch:16/30     Step:4|6   loss:0.710312008857727  \n","Epoch:16/30     Step:5|6   loss:0.6780213117599487  \n","Epoch:16/30     Step:6|6   loss:0.6680511236190796  \n","Epoch:16/30     Step:7|6   loss:0.7091628313064575  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.7071823477745056  \n","Epoch:17/30     Step:2|6   loss:0.6938050985336304  \n","Epoch:17/30     Step:3|6   loss:0.6823983192443848  \n","Epoch:17/30     Step:4|6   loss:0.7378337383270264  \n","Epoch:17/30     Step:5|6   loss:0.7077198028564453  \n","Epoch:17/30     Step:6|6   loss:0.7144970893859863  \n","Epoch:17/30     Step:7|6   loss:0.7483668327331543  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.6605944633483887  \n","Epoch:18/30     Step:2|6   loss:0.6931716799736023  \n","Epoch:18/30     Step:3|6   loss:0.7012643814086914  \n","Epoch:18/30     Step:4|6   loss:0.6697338819503784  \n","Epoch:18/30     Step:5|6   loss:0.7430562973022461  \n","Epoch:18/30     Step:6|6   loss:0.7243213653564453  \n","Epoch:18/30     Step:7|6   loss:0.6955443620681763  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.6870862245559692  \n","Epoch:19/30     Step:2|6   loss:0.7474826574325562  \n","Epoch:19/30     Step:3|6   loss:0.7263568639755249  \n","Epoch:19/30     Step:4|6   loss:0.7310444116592407  \n","Epoch:19/30     Step:5|6   loss:0.6766661405563354  \n","Epoch:19/30     Step:6|6   loss:0.6739825010299683  \n","Epoch:19/30     Step:7|6   loss:0.7483580112457275  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.6838471293449402  \n","Epoch:20/30     Step:2|6   loss:0.7373082637786865  \n","Epoch:20/30     Step:3|6   loss:0.7635469436645508  \n","Epoch:20/30     Step:4|6   loss:0.6719483733177185  \n","Epoch:20/30     Step:5|6   loss:0.7130030393600464  \n","Epoch:20/30     Step:6|6   loss:0.7099848985671997  \n","Epoch:20/30     Step:7|6   loss:0.7383949756622314  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7066861391067505  \n","Epoch:21/30     Step:2|6   loss:0.7171323895454407  \n","Epoch:21/30     Step:3|6   loss:0.7231897115707397  \n","Epoch:21/30     Step:4|6   loss:0.7151362895965576  \n","Epoch:21/30     Step:5|6   loss:0.727448582649231  \n","Epoch:21/30     Step:6|6   loss:0.7009080648422241  \n","Epoch:21/30     Step:7|6   loss:0.6523908376693726  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.6986003518104553  \n","Epoch:22/30     Step:2|6   loss:0.6910227537155151  \n","Epoch:22/30     Step:3|6   loss:0.6856293678283691  \n","Epoch:22/30     Step:4|6   loss:0.782871663570404  \n","Epoch:22/30     Step:5|6   loss:0.7303225994110107  \n","Epoch:22/30     Step:6|6   loss:0.6729469299316406  \n","Epoch:22/30     Step:7|6   loss:0.7033711671829224  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.7204381227493286  \n","Epoch:23/30     Step:2|6   loss:0.7253592610359192  \n","Epoch:23/30     Step:3|6   loss:0.7381327152252197  \n","Epoch:23/30     Step:4|6   loss:0.7130562663078308  \n","Epoch:23/30     Step:5|6   loss:0.6790235638618469  \n","Epoch:23/30     Step:6|6   loss:0.7026031017303467  \n","Epoch:23/30     Step:7|6   loss:0.7117776274681091  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.690396249294281  \n","Epoch:24/30     Step:2|6   loss:0.7966921329498291  \n","Epoch:24/30     Step:3|6   loss:0.6996428966522217  \n","Epoch:24/30     Step:4|6   loss:0.7383509874343872  \n","Epoch:24/30     Step:5|6   loss:0.7501440048217773  \n","Epoch:24/30     Step:6|6   loss:0.6973049640655518  \n","Epoch:24/30     Step:7|6   loss:0.714413046836853  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.6600524187088013  \n","Epoch:25/30     Step:2|6   loss:0.7661887407302856  \n","Epoch:25/30     Step:3|6   loss:0.7281650304794312  \n","Epoch:25/30     Step:4|6   loss:0.6280093193054199  \n","Epoch:25/30     Step:5|6   loss:0.6592714786529541  \n","Epoch:25/30     Step:6|6   loss:0.6999226808547974  \n","Epoch:25/30     Step:7|6   loss:0.688858687877655  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7470660209655762  \n","Epoch:26/30     Step:2|6   loss:0.7214000821113586  \n","Epoch:26/30     Step:3|6   loss:0.7338951826095581  \n","Epoch:26/30     Step:4|6   loss:0.6997218132019043  \n","Epoch:26/30     Step:5|6   loss:0.6818734407424927  \n","Epoch:26/30     Step:6|6   loss:0.6580308675765991  \n","Epoch:26/30     Step:7|6   loss:0.7249124050140381  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.7434775829315186  \n","Epoch:27/30     Step:2|6   loss:0.7622107863426208  \n","Epoch:27/30     Step:3|6   loss:0.7029172778129578  \n","Epoch:27/30     Step:4|6   loss:0.7157878875732422  \n","Epoch:27/30     Step:5|6   loss:0.6858906745910645  \n","Epoch:27/30     Step:6|6   loss:0.6957152485847473  \n","Epoch:27/30     Step:7|6   loss:0.7219281196594238  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.7066285610198975  \n","Epoch:28/30     Step:2|6   loss:0.7639741897583008  \n","Epoch:28/30     Step:3|6   loss:0.6383635997772217  \n","Epoch:28/30     Step:4|6   loss:0.7576301693916321  \n","Epoch:28/30     Step:5|6   loss:0.707855224609375  \n","Epoch:28/30     Step:6|6   loss:0.7227608561515808  \n","Epoch:28/30     Step:7|6   loss:0.7299703359603882  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.7312215566635132  \n","Epoch:29/30     Step:2|6   loss:0.6642709374427795  \n","Epoch:29/30     Step:3|6   loss:0.7064005732536316  \n","Epoch:29/30     Step:4|6   loss:0.6993988752365112  \n","Epoch:29/30     Step:5|6   loss:0.692001461982727  \n","Epoch:29/30     Step:6|6   loss:0.6742126941680908  \n","Epoch:29/30     Step:7|6   loss:0.6541756391525269  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.7160046100616455  \n","Epoch:30/30     Step:2|6   loss:0.7381517887115479  \n","Epoch:30/30     Step:3|6   loss:0.6784027814865112  \n","Epoch:30/30     Step:4|6   loss:0.718156099319458  \n","Epoch:30/30     Step:5|6   loss:0.7236965894699097  \n","Epoch:30/30     Step:6|6   loss:0.7495371103286743  \n","Epoch:30/30     Step:7|6   loss:0.6962090134620667  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model Mobilenetv2_two_stream --mode both --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":15,"id":"964ab740","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.105451226234436  \n","Epoch:1/50     Step:2|6   loss:3.1461856365203857  \n","Epoch:1/50     Step:3|6   loss:2.7474684715270996  \n","Epoch:1/50     Step:4|6   loss:2.6248786449432373  \n","Epoch:1/50     Step:5|6   loss:2.5357131958007812  \n","Epoch:1/50     Step:6|6   loss:3.003591299057007  \n","Epoch:1/50     Step:7|6   loss:2.787269115447998  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:2/50     Step:1|6   loss:3.118898391723633  \n","Epoch:2/50     Step:2|6   loss:2.8959758281707764  \n","Epoch:2/50     Step:3|6   loss:2.5119991302490234  \n","Epoch:2/50     Step:4|6   loss:2.867699146270752  \n","Epoch:2/50     Step:5|6   loss:2.6648073196411133  \n","Epoch:2/50     Step:6|6   loss:2.5235936641693115  \n","Epoch:2/50     Step:7|6   loss:2.2266340255737305  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:3/50     Step:1|6   loss:2.8087501525878906  \n","Epoch:3/50     Step:2|6   loss:2.865237236022949  \n","Epoch:3/50     Step:3|6   loss:2.382575750350952  \n","Epoch:3/50     Step:4|6   loss:2.822157859802246  \n","Epoch:3/50     Step:5|6   loss:2.5512776374816895  \n","Epoch:3/50     Step:6|6   loss:2.4309277534484863  \n","Epoch:3/50     Step:7|6   loss:2.6033520698547363  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:4/50     Step:1|6   loss:2.7889292240142822  \n","Epoch:4/50     Step:2|6   loss:2.506639003753662  \n","Epoch:4/50     Step:3|6   loss:2.8945462703704834  \n","Epoch:4/50     Step:4|6   loss:2.45332670211792  \n","Epoch:4/50     Step:5|6   loss:2.491420269012451  \n","Epoch:4/50     Step:6|6   loss:2.5532760620117188  \n","Epoch:4/50     Step:7|6   loss:2.2367730140686035  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:5/50     Step:1|6   loss:3.0623483657836914  \n","Epoch:5/50     Step:2|6   loss:2.60568904876709  \n","Epoch:5/50     Step:3|6   loss:2.6297502517700195  \n","Epoch:5/50     Step:4|6   loss:2.108703851699829  \n","Epoch:5/50     Step:5|6   loss:2.585236072540283  \n","Epoch:5/50     Step:6|6   loss:2.311716318130493  \n","Epoch:5/50     Step:7|6   loss:2.1400856971740723  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:6/50     Step:1|6   loss:2.5143203735351562  \n","Epoch:6/50     Step:2|6   loss:2.159656047821045  \n","Epoch:6/50     Step:3|6   loss:2.2215757369995117  \n","Epoch:6/50     Step:4|6   loss:2.5173351764678955  \n","Epoch:6/50     Step:5|6   loss:2.7791056632995605  \n","Epoch:6/50     Step:6|6   loss:2.614116907119751  \n","Epoch:6/50     Step:7|6   loss:2.182443380355835  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:7/50     Step:1|6   loss:2.28922700881958  \n","Epoch:7/50     Step:2|6   loss:2.1545605659484863  \n","Epoch:7/50     Step:3|6   loss:2.4283928871154785  \n","Epoch:7/50     Step:4|6   loss:2.6170005798339844  \n","Epoch:7/50     Step:5|6   loss:2.5511856079101562  \n","Epoch:7/50     Step:6|6   loss:2.07429575920105  \n","Epoch:7/50     Step:7|6   loss:2.6340761184692383  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:8/50     Step:1|6   loss:2.4961025714874268  \n","Epoch:8/50     Step:2|6   loss:2.349177837371826  \n","Epoch:8/50     Step:3|6   loss:2.4434680938720703  \n","Epoch:8/50     Step:4|6   loss:2.328662872314453  \n","Epoch:8/50     Step:5|6   loss:2.273327350616455  \n","Epoch:8/50     Step:6|6   loss:2.1871938705444336  \n","Epoch:8/50     Step:7|6   loss:2.131930112838745  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:9/50     Step:1|6   loss:2.561373472213745  \n","Epoch:9/50     Step:2|6   loss:2.190808057785034  \n","Epoch:9/50     Step:3|6   loss:2.223123550415039  \n","Epoch:9/50     Step:4|6   loss:1.8912166357040405  \n","Epoch:9/50     Step:5|6   loss:2.00923228263855  \n","Epoch:9/50     Step:6|6   loss:2.7041261196136475  \n","Epoch:9/50     Step:7|6   loss:2.281557559967041  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:10/50     Step:1|6   loss:2.3404219150543213  \n","Epoch:10/50     Step:2|6   loss:1.8618357181549072  \n","Epoch:10/50     Step:3|6   loss:2.267259120941162  \n","Epoch:10/50     Step:4|6   loss:2.420323371887207  \n","Epoch:10/50     Step:5|6   loss:2.4322667121887207  \n","Epoch:10/50     Step:6|6   loss:2.145484209060669  \n","Epoch:10/50     Step:7|6   loss:1.9384187459945679  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:11/50     Step:1|6   loss:2.193955421447754  \n","Epoch:11/50     Step:2|6   loss:2.3341567516326904  \n","Epoch:11/50     Step:3|6   loss:2.244420051574707  \n","Epoch:11/50     Step:4|6   loss:1.9878020286560059  \n","Epoch:11/50     Step:5|6   loss:2.141279935836792  \n","Epoch:11/50     Step:6|6   loss:2.282695770263672  \n","Epoch:11/50     Step:7|6   loss:1.8665838241577148  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:12/50     Step:1|6   loss:2.3554065227508545  \n","Epoch:12/50     Step:2|6   loss:2.3722612857818604  \n","Epoch:12/50     Step:3|6   loss:1.9980847835540771  \n","Epoch:12/50     Step:4|6   loss:2.268239736557007  \n","Epoch:12/50     Step:5|6   loss:1.9354889392852783  \n","Epoch:12/50     Step:6|6   loss:1.9293453693389893  \n","Epoch:12/50     Step:7|6   loss:1.8210647106170654  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:13/50     Step:1|6   loss:2.0799953937530518  \n","Epoch:13/50     Step:2|6   loss:1.950998306274414  \n","Epoch:13/50     Step:3|6   loss:2.224600076675415  \n","Epoch:13/50     Step:4|6   loss:1.9672622680664062  \n","Epoch:13/50     Step:5|6   loss:2.0563106536865234  \n","Epoch:13/50     Step:6|6   loss:2.0669307708740234  \n","Epoch:13/50     Step:7|6   loss:2.0408966541290283  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:14/50     Step:1|6   loss:1.8920724391937256  \n","Epoch:14/50     Step:2|6   loss:2.467283248901367  \n","Epoch:14/50     Step:3|6   loss:1.8565564155578613  1\n","Epoch:14/50     Step:4|6   loss:2.1474437713623047  \n","Epoch:14/50     Step:5|6   loss:1.9419690370559692  \n","Epoch:14/50     Step:6|6   loss:1.7764900922775269  \n","Epoch:14/50     Step:7|6   loss:1.9374513626098633  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:15/50     Step:1|6   loss:2.2434518337249756  \n","Epoch:15/50     Step:2|6   loss:1.9401166439056396  \n","Epoch:15/50     Step:3|6   loss:1.7949968576431274  \n","\n","Epoch:15/50     Step:4|6   loss:1.7884716987609863  \n","Epoch:15/50     Step:5|6   loss:2.072847843170166  \n","Epoch:15/50     Step:6|6   loss:1.7898001670837402  \n","Epoch:15/50     Step:7|6   loss:2.1555261611938477  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:16/50     Step:1|6   loss:1.864524245262146  \n","Epoch:16/50     Step:2|6   loss:2.1495752334594727  \n","Epoch:16/50     Step:3|6   loss:1.726563572883606  \n","Epoch:16/50     Step:4|6   loss:1.721724271774292  \n","Epoch:16/50     Step:5|6   loss:1.964450716972351  \n","Epoch:16/50     Step:6|6   loss:1.790750503540039  \n","Epoch:16/50     Step:7|6   loss:2.2208573818206787  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:17/50     Step:1|6   loss:1.8919248580932617  \n","Epoch:17/50     Step:2|6   loss:1.850695013999939  \n","Epoch:17/50     Step:3|6   loss:1.9060007333755493  \n","Epoch:17/50     Step:4|6   loss:1.8945367336273193  \n","Epoch:17/50     Step:5|6   loss:1.8994464874267578  \n","Epoch:17/50     Step:6|6   loss:1.5999661684036255  \n","Epoch:17/50     Step:7|6   loss:1.7867785692214966  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:18/50     Step:1|6   loss:1.6729512214660645  \n","Epoch:18/50     Step:2|6   loss:2.0618488788604736  \n","Epoch:18/50     Step:3|6   loss:1.8080134391784668  \n","Epoch:18/50     Step:4|6   loss:1.6550341844558716  \n","Epoch:18/50     Step:5|6   loss:1.8660290241241455  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch:18/50     Step:6|6   loss:1.7061140537261963  \n","Epoch:18/50     Step:7|6   loss:1.6612160205841064  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:42.06%\t train set:46.37%\n","Epoch:19/50     Step:1|6   loss:1.792784571647644  \n","Epoch:19/50     Step:2|6   loss:1.5325853824615479  \n","Epoch:19/50     Step:3|6   loss:1.7386833429336548  \n","Epoch:19/50     Step:4|6   loss:0.8951033353805542  \n","Epoch:19/50     Step:5|6   loss:0.9771825671195984  \n","Epoch:19/50     Step:6|6   loss:0.981932520866394  \n","Epoch:19/50     Step:7|6   loss:0.916541576385498  \n","Accuracy on test_set: 60.75 %\n","Accuracy on train_set: 65.34 %\n","current max accuracy\t test set:60.75%\t train set:65.34%\n","Epoch:20/50     Step:1|6   loss:0.7231131196022034  \n","Epoch:20/50     Step:2|6   loss:0.7385063171386719  \n","Epoch:20/50     Step:3|6   loss:0.7310552000999451  \n","Epoch:20/50     Step:4|6   loss:0.7019407749176025  \n","Epoch:20/50     Step:5|6   loss:0.799656093120575  \n","Epoch:20/50     Step:6|6   loss:0.731544017791748  \n","Epoch:20/50     Step:7|6   loss:0.6638748645782471  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:84.11%\t train set:87.82%\n","Epoch:21/50     Step:1|6   loss:0.6492853760719299  \n","Epoch:21/50     Step:2|6   loss:0.6849545240402222  \n","Epoch:21/50     Step:3|6   loss:0.7540867328643799  \n","Epoch:21/50     Step:4|6   loss:0.6198747754096985  \n","Epoch:21/50     Step:5|6   loss:0.6930639147758484  \n","Epoch:21/50     Step:6|6   loss:0.5924160480499268  \n","Epoch:21/50     Step:7|6   loss:0.5962473154067993  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:89.72%\t train set:92.74%\n","Epoch:22/50     Step:1|6   loss:0.6136046648025513  \n","Epoch:22/50     Step:2|6   loss:0.6669042706489563  \n","Epoch:22/50     Step:3|6   loss:0.5799104571342468  \n","Epoch:22/50     Step:4|6   loss:0.5809230208396912  \n","Epoch:22/50     Step:5|6   loss:0.586927056312561  \n","Epoch:22/50     Step:6|6   loss:0.6055017113685608  \n","Epoch:22/50     Step:7|6   loss:0.5710151195526123  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:93.46%\t train set:96.49%\n","Epoch:23/50     Step:1|6   loss:0.5931983590126038  \n","Epoch:23/50     Step:2|6   loss:0.5846970677375793  \n","Epoch:23/50     Step:3|6   loss:0.55655437707901  \n","Epoch:23/50     Step:4|6   loss:0.5770193338394165  \n","Epoch:23/50     Step:5|6   loss:0.5417377352714539  \n","Epoch:23/50     Step:6|6   loss:0.553161084651947  \n","Epoch:23/50     Step:7|6   loss:0.5691174268722534  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:93.46%\t train set:97.89%\n","Epoch:24/50     Step:1|6   loss:0.5467610955238342  \n","Epoch:24/50     Step:2|6   loss:0.5508231520652771  \n","Epoch:24/50     Step:3|6   loss:0.5493943691253662  \n","Epoch:24/50     Step:4|6   loss:0.517598569393158  \n","Epoch:24/50     Step:5|6   loss:0.548509418964386  \n","Epoch:24/50     Step:6|6   loss:0.5414454936981201  \n","Epoch:24/50     Step:7|6   loss:0.5397502183914185  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:25/50     Step:1|6   loss:0.5339975953102112  \n","Epoch:25/50     Step:2|6   loss:0.554465115070343  \n","Epoch:25/50     Step:3|6   loss:0.5334746241569519  \n","Epoch:25/50     Step:4|6   loss:0.5547773241996765  \n","Epoch:25/50     Step:5|6   loss:0.5328185558319092  \n","Epoch:25/50     Step:6|6   loss:0.5218698978424072  \n","Epoch:25/50     Step:7|6   loss:0.5205216407775879  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:94.39%\t train set:98.36%\n","Epoch:26/50     Step:1|6   loss:0.5176145434379578  \n","Epoch:26/50     Step:2|6   loss:0.5160928964614868  \n","Epoch:26/50     Step:3|6   loss:0.5332738757133484  \n","Epoch:26/50     Step:4|6   loss:0.5607228875160217  \n","Epoch:26/50     Step:5|6   loss:0.557578444480896  \n","Epoch:26/50     Step:6|6   loss:0.5170049071311951  \n","Epoch:26/50     Step:7|6   loss:0.5149024128913879  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:94.39%\t train set:98.36%\n","Epoch:27/50     Step:1|6   loss:0.5071448683738708  \n","Epoch:27/50     Step:2|6   loss:0.5530093312263489  \n","Epoch:27/50     Step:3|6   loss:0.5204588174819946  \n","Epoch:27/50     Step:4|6   loss:0.5412364602088928  \n","Epoch:27/50     Step:5|6   loss:0.5345221161842346  \n","Epoch:27/50     Step:6|6   loss:0.5168696045875549  \n","Epoch:27/50     Step:7|6   loss:0.5119085907936096  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:94.39%\t train set:98.59%\n","Epoch:28/50     Step:1|6   loss:0.5296024084091187  \n","Epoch:28/50     Step:2|6   loss:0.5094462633132935  \n","Epoch:28/50     Step:3|6   loss:0.5131450891494751  \n","Epoch:28/50     Step:4|6   loss:0.526012659072876  \n","Epoch:28/50     Step:5|6   loss:0.5534766912460327  \n","Epoch:28/50     Step:6|6   loss:0.5259084701538086  \n","Epoch:28/50     Step:7|6   loss:0.5106204152107239  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:94.39%\t train set:98.83%\n","Epoch:29/50     Step:1|6   loss:0.5388146638870239  \n","Epoch:29/50     Step:2|6   loss:0.5115575790405273  \n","Epoch:29/50     Step:3|6   loss:0.5294380187988281  \n","Epoch:29/50     Step:4|6   loss:0.5051419734954834  \n","Epoch:29/50     Step:5|6   loss:0.5208067297935486  \n","Epoch:29/50     Step:6|6   loss:0.5067781805992126  \n","Epoch:29/50     Step:7|6   loss:0.5209795832633972  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:94.39%\t train set:98.83%\n","Epoch:30/50     Step:1|6   loss:0.5195275545120239  \n","Epoch:30/50     Step:2|6   loss:0.5265898704528809  \n","Epoch:30/50     Step:3|6   loss:0.5117416381835938  \n","Epoch:30/50     Step:4|6   loss:0.5036758184432983  \n","Epoch:30/50     Step:5|6   loss:0.5073821544647217  \n","Epoch:30/50     Step:6|6   loss:0.50859534740448  \n","Epoch:30/50     Step:7|6   loss:0.5056524276733398  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.3%\n","Epoch:31/50     Step:1|6   loss:0.509477436542511  \n","Epoch:31/50     Step:2|6   loss:0.5240609645843506  \n","Epoch:31/50     Step:3|6   loss:0.505142867565155  \n","Epoch:31/50     Step:4|6   loss:0.4972309172153473  \n","Epoch:31/50     Step:5|6   loss:0.5128408670425415  \n","Epoch:31/50     Step:6|6   loss:0.5067789554595947  \n","Epoch:31/50     Step:7|6   loss:0.5070452690124512  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.3%\n","Epoch:32/50     Step:1|6   loss:0.5046241879463196  \n","Epoch:32/50     Step:2|6   loss:0.5086992383003235  \n","Epoch:32/50     Step:3|6   loss:0.5229188799858093  \n","Epoch:32/50     Step:4|6   loss:0.5080334544181824  \n","Epoch:32/50     Step:5|6   loss:0.4973471164703369  \n","Epoch:32/50     Step:6|6   loss:0.5069985389709473  \n","Epoch:32/50     Step:7|6   loss:0.49446022510528564  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.3%\n","Epoch:33/50     Step:1|6   loss:0.4951900243759155  \n","Epoch:33/50     Step:2|6   loss:0.5072524547576904  \n","Epoch:33/50     Step:3|6   loss:0.5189299583435059  \n","Epoch:33/50     Step:4|6   loss:0.5003713369369507  \n","Epoch:33/50     Step:5|6   loss:0.5048136711120605  \n","Epoch:33/50     Step:6|6   loss:0.5022491812705994  \n","Epoch:33/50     Step:7|6   loss:0.4987559914588928  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.3%\n","Epoch:34/50     Step:1|6   loss:0.5024147033691406  \n","Epoch:34/50     Step:2|6   loss:0.4973742663860321  \n","Epoch:34/50     Step:3|6   loss:0.5168497562408447  \n","Epoch:34/50     Step:4|6   loss:0.4968075454235077  \n","Epoch:34/50     Step:5|6   loss:0.49887001514434814  \n","Epoch:34/50     Step:6|6   loss:0.4973965287208557  \n","Epoch:34/50     Step:7|6   loss:0.5126253962516785  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:95.33%\t train set:99.3%\n","Epoch:35/50     Step:1|6   loss:0.4974907338619232  \n","Epoch:35/50     Step:2|6   loss:0.4962250590324402  \n","Epoch:35/50     Step:3|6   loss:0.5153420567512512  \n","Epoch:35/50     Step:4|6   loss:0.49841031432151794  \n","Epoch:35/50     Step:5|6   loss:0.49271467328071594  \n","Epoch:35/50     Step:6|6   loss:0.5000513792037964  \n","Epoch:35/50     Step:7|6   loss:0.5180389881134033  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:95.33%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.49615466594696045  \n","Epoch:36/50     Step:2|6   loss:0.5162124633789062  \n","Epoch:36/50     Step:3|6   loss:0.4976392090320587  \n","Epoch:36/50     Step:4|6   loss:0.49975040555000305  \n","Epoch:36/50     Step:5|6   loss:0.49812355637550354  \n","Epoch:36/50     Step:6|6   loss:0.5005722641944885  \n","Epoch:36/50     Step:7|6   loss:0.49955081939697266  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.5015878677368164  \n","Epoch:37/50     Step:2|6   loss:0.5022110939025879  \n","Epoch:37/50     Step:3|6   loss:0.5008068084716797  \n","Epoch:37/50     Step:4|6   loss:0.49824923276901245  \n","Epoch:37/50     Step:5|6   loss:0.5014410018920898  \n","Epoch:37/50     Step:6|6   loss:0.4987514019012451  \n","Epoch:37/50     Step:7|6   loss:0.5015328526496887  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.496158242225647  \n","Epoch:38/50     Step:2|6   loss:0.5036060214042664  \n","Epoch:38/50     Step:3|6   loss:0.5048969984054565  \n","Epoch:38/50     Step:4|6   loss:0.49837905168533325  \n","Epoch:38/50     Step:5|6   loss:0.496188223361969  \n","Epoch:38/50     Step:6|6   loss:0.49232637882232666  \n","Epoch:38/50     Step:7|6   loss:0.4970453977584839  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.49406760931015015  \n","Epoch:39/50     Step:2|6   loss:0.500235915184021  \n","Epoch:39/50     Step:3|6   loss:0.49628502130508423  \n","Epoch:39/50     Step:4|6   loss:0.49668794870376587  \n","Epoch:39/50     Step:5|6   loss:0.4908488988876343  \n","Epoch:39/50     Step:6|6   loss:0.501937985420227  \n","Epoch:39/50     Step:7|6   loss:0.49967288970947266  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.5020512938499451  \n","Epoch:40/50     Step:2|6   loss:0.4932768940925598  \n","Epoch:40/50     Step:3|6   loss:0.4975871443748474  \n","Epoch:40/50     Step:4|6   loss:0.4975464344024658  \n","Epoch:40/50     Step:5|6   loss:0.4972761869430542  \n","Epoch:40/50     Step:6|6   loss:0.491332471370697  \n","Epoch:40/50     Step:7|6   loss:0.4993583559989929  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4945220351219177  \n","Epoch:41/50     Step:2|6   loss:0.4958856701850891  \n","Epoch:41/50     Step:3|6   loss:0.49580317735671997  \n","Epoch:41/50     Step:4|6   loss:0.49093952775001526  \n","Epoch:41/50     Step:5|6   loss:0.49699583649635315  \n","Epoch:41/50     Step:6|6   loss:0.4965651333332062  \n","Epoch:41/50     Step:7|6   loss:0.49882036447525024  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4917750954627991  \n","Epoch:42/50     Step:2|6   loss:0.49836480617523193  \n","Epoch:42/50     Step:3|6   loss:0.49344903230667114  \n","Epoch:42/50     Step:4|6   loss:0.49488115310668945  \n","Epoch:42/50     Step:5|6   loss:0.4952423572540283  \n","Epoch:42/50     Step:6|6   loss:0.49688369035720825  \n","Epoch:42/50     Step:7|6   loss:0.4945219159126282  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4955858588218689  \n","Epoch:43/50     Step:2|6   loss:0.49223271012306213  \n","Epoch:43/50     Step:3|6   loss:0.496451735496521  \n","Epoch:43/50     Step:4|6   loss:0.49263402819633484  \n","Epoch:43/50     Step:5|6   loss:0.4980918765068054  \n","Epoch:43/50     Step:6|6   loss:0.4935777485370636  \n","Epoch:43/50     Step:7|6   loss:0.4916006922721863  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.494907021522522  \n","Epoch:44/50     Step:2|6   loss:0.4964666962623596  \n","Epoch:44/50     Step:3|6   loss:0.49230289459228516  \n","Epoch:44/50     Step:4|6   loss:0.4953390061855316  \n","Epoch:44/50     Step:5|6   loss:0.4928378462791443  \n","Epoch:44/50     Step:6|6   loss:0.4919981360435486  \n","Epoch:44/50     Step:7|6   loss:0.4943724274635315  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4901163578033447  \n","Epoch:45/50     Step:2|6   loss:0.49370014667510986  \n","Epoch:45/50     Step:3|6   loss:0.49429595470428467  \n","Epoch:45/50     Step:4|6   loss:0.4919164180755615  \n","Epoch:45/50     Step:5|6   loss:0.4920136630535126  \n","Epoch:45/50     Step:6|6   loss:0.4995500445365906  \n","Epoch:45/50     Step:7|6   loss:0.493325799703598  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4943736791610718  \n","Epoch:46/50     Step:2|6   loss:0.49474069476127625  \n","Epoch:46/50     Step:3|6   loss:0.4916723668575287  \n","Epoch:46/50     Step:4|6   loss:0.4911205768585205  \n","Epoch:46/50     Step:5|6   loss:0.4916541278362274  \n","Epoch:46/50     Step:6|6   loss:0.49589070677757263  \n","Epoch:46/50     Step:7|6   loss:0.49474722146987915  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.4920467734336853  \n","Epoch:47/50     Step:2|6   loss:0.4894489645957947  \n","Epoch:47/50     Step:3|6   loss:0.4958028197288513  \n","Epoch:47/50     Step:4|6   loss:0.49085402488708496  \n","Epoch:47/50     Step:5|6   loss:0.49734777212142944  \n","Epoch:47/50     Step:6|6   loss:0.4942775368690491  \n","Epoch:47/50     Step:7|6   loss:0.49100205302238464  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4916728138923645  \n","Epoch:48/50     Step:2|6   loss:0.4940979480743408  \n","Epoch:48/50     Step:3|6   loss:0.49798381328582764  \n","Epoch:48/50     Step:4|6   loss:0.4915016293525696  \n","Epoch:48/50     Step:5|6   loss:0.4917277991771698  \n","Epoch:48/50     Step:6|6   loss:0.49076515436172485  \n","Epoch:48/50     Step:7|6   loss:0.4931703209877014  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4907076060771942  \n","Epoch:49/50     Step:2|6   loss:0.49718987941741943  \n","Epoch:49/50     Step:3|6   loss:0.491657018661499  \n","Epoch:49/50     Step:4|6   loss:0.49250519275665283  \n","Epoch:49/50     Step:5|6   loss:0.4911087453365326  \n","Epoch:49/50     Step:6|6   loss:0.49040186405181885  \n","Epoch:49/50     Step:7|6   loss:0.4955505132675171  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4910898804664612  \n","Epoch:50/50     Step:2|6   loss:0.4957747757434845  \n","Epoch:50/50     Step:3|6   loss:0.4900839328765869  \n","Epoch:50/50     Step:4|6   loss:0.4894307553768158  \n","Epoch:50/50     Step:5|6   loss:0.49218472838401794  \n","Epoch:50/50     Step:6|6   loss:0.49143946170806885  \n","Epoch:50/50     Step:7|6   loss:0.4936613142490387  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Accuracy on test_set: 94.39 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.098447322845459  \n","Epoch:1/50     Step:2|6   loss:2.9567766189575195  \n","Epoch:1/50     Step:3|6   loss:0.9822431802749634  \n","Epoch:1/50     Step:4|6   loss:1.42949640750885  \n","Epoch:1/50     Step:5|6   loss:1.2293095588684082  \n","Epoch:1/50     Step:6|6   loss:1.1487598419189453  \n","Epoch:1/50     Step:7|6   loss:0.9560564756393433  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 70.73 %\n","current max accuracy\t test set:75.7%\t train set:70.73%\n","Epoch:2/50     Step:1|6   loss:0.9887212514877319  \n","Epoch:2/50     Step:2|6   loss:1.000611662864685  \n","Epoch:2/50     Step:3|6   loss:0.9680379033088684  \n","Epoch:2/50     Step:4|6   loss:1.0066624879837036  \n","Epoch:2/50     Step:5|6   loss:0.918000340461731  \n","Epoch:2/50     Step:6|6   loss:0.9044987559318542  \n","Epoch:2/50     Step:7|6   loss:0.9099409580230713  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 73.54 %\n","current max accuracy\t test set:80.37%\t train set:73.54%\n","Epoch:3/50     Step:1|6   loss:0.8549723029136658  \n","Epoch:3/50     Step:2|6   loss:0.8864110708236694  \n","Epoch:3/50     Step:3|6   loss:0.8286252021789551  \n","Epoch:3/50     Step:4|6   loss:0.8567348718643188  \n","Epoch:3/50     Step:5|6   loss:0.8714967966079712  \n","Epoch:3/50     Step:6|6   loss:0.8476996421813965  \n","Epoch:3/50     Step:7|6   loss:0.838289201259613  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 74.00 %\n","current max accuracy\t test set:80.37%\t train set:74.0%\n","Epoch:4/50     Step:1|6   loss:0.7552221417427063  \n","Epoch:4/50     Step:2|6   loss:0.815208911895752  \n","Epoch:4/50     Step:3|6   loss:0.8209238052368164  \n","Epoch:4/50     Step:4|6   loss:0.7616479992866516  \n","Epoch:4/50     Step:5|6   loss:0.7525734901428223  \n","Epoch:4/50     Step:6|6   loss:0.7981864213943481  \n","Epoch:4/50     Step:7|6   loss:0.7287672758102417  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 80.09 %\n","current max accuracy\t test set:80.37%\t train set:80.09%\n","Epoch:5/50     Step:1|6   loss:0.7362344861030579  \n","Epoch:5/50     Step:2|6   loss:0.7475842237472534  \n","Epoch:5/50     Step:3|6   loss:0.7135895490646362  \n","Epoch:5/50     Step:4|6   loss:0.6913691163063049  \n","Epoch:5/50     Step:5|6   loss:0.7098510265350342  \n","Epoch:5/50     Step:6|6   loss:0.6568180322647095  \n","Epoch:5/50     Step:7|6   loss:0.763302206993103  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 88.76 %\n","current max accuracy\t test set:89.72%\t train set:88.76%\n","Epoch:6/50     Step:1|6   loss:0.6648075580596924  \n","Epoch:6/50     Step:2|6   loss:0.645384669303894  \n","Epoch:6/50     Step:3|6   loss:0.6653403639793396  \n","Epoch:6/50     Step:4|6   loss:0.6819742918014526  \n","Epoch:6/50     Step:5|6   loss:0.6043070554733276  \n","Epoch:6/50     Step:6|6   loss:0.6256402730941772  \n","Epoch:6/50     Step:7|6   loss:0.6537357568740845  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:92.52%\t train set:93.68%\n","Epoch:7/50     Step:1|6   loss:0.7110065221786499  \n","Epoch:7/50     Step:2|6   loss:0.595993161201477  \n","Epoch:7/50     Step:3|6   loss:0.5904865264892578  \n","Epoch:7/50     Step:4|6   loss:0.6379252672195435  \n","Epoch:7/50     Step:5|6   loss:0.6177809238433838  \n","Epoch:7/50     Step:6|6   loss:0.5945397615432739  \n","Epoch:7/50     Step:7|6   loss:0.555237889289856  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:8/50     Step:1|6   loss:0.6292853355407715  \n","Epoch:8/50     Step:2|6   loss:0.6199300289154053  \n","Epoch:8/50     Step:3|6   loss:0.5800907611846924  \n","Epoch:8/50     Step:4|6   loss:0.5803404450416565  \n","Epoch:8/50     Step:5|6   loss:0.5443841218948364  \n","Epoch:8/50     Step:6|6   loss:0.578289270401001  \n","Epoch:8/50     Step:7|6   loss:0.5948293209075928  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:9/50     Step:1|6   loss:0.5344073176383972  \n","Epoch:9/50     Step:2|6   loss:0.5851491093635559  \n","Epoch:9/50     Step:3|6   loss:0.5747763514518738  \n","Epoch:9/50     Step:4|6   loss:0.6425889730453491  \n","Epoch:9/50     Step:5|6   loss:0.611586332321167  \n","Epoch:9/50     Step:6|6   loss:0.5726805925369263  \n","Epoch:9/50     Step:7|6   loss:0.5328429937362671  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:10/50     Step:1|6   loss:0.5729568004608154  \n","Epoch:10/50     Step:2|6   loss:0.596453070640564  \n","Epoch:10/50     Step:3|6   loss:0.5580806136131287  \n","Epoch:10/50     Step:4|6   loss:0.5628066658973694  \n","Epoch:10/50     Step:5|6   loss:0.5367300510406494  \n","Epoch:10/50     Step:6|6   loss:0.5663249492645264  \n","Epoch:10/50     Step:7|6   loss:0.5716337561607361  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:96.96%\n","Epoch:11/50     Step:1|6   loss:0.5628583431243896  \n","Epoch:11/50     Step:2|6   loss:0.5551320910453796  \n","Epoch:11/50     Step:3|6   loss:0.5235639810562134  \n","Epoch:11/50     Step:4|6   loss:0.5548409819602966  \n","Epoch:11/50     Step:5|6   loss:0.5558129549026489  \n","Epoch:11/50     Step:6|6   loss:0.5619783997535706  \n","Epoch:11/50     Step:7|6   loss:0.5421797633171082  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:98.13%\t train set:98.83%\n","Epoch:12/50     Step:1|6   loss:0.5668505430221558  \n","Epoch:12/50     Step:2|6   loss:0.5458000898361206  \n","Epoch:12/50     Step:3|6   loss:0.544737696647644  \n","Epoch:12/50     Step:4|6   loss:0.5285651087760925  \n","Epoch:12/50     Step:5|6   loss:0.5325738191604614  \n","Epoch:12/50     Step:6|6   loss:0.5480812788009644  \n","Epoch:12/50     Step:7|6   loss:0.5214047431945801  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:98.13%\t train set:99.06%\n","Epoch:13/50     Step:1|6   loss:0.5393708348274231  \n","Epoch:13/50     Step:2|6   loss:0.533318281173706  \n","Epoch:13/50     Step:3|6   loss:0.5215421915054321  \n","Epoch:13/50     Step:4|6   loss:0.5150042772293091  \n","Epoch:13/50     Step:5|6   loss:0.5786059498786926  \n","Epoch:13/50     Step:6|6   loss:0.5550532341003418  \n","Epoch:13/50     Step:7|6   loss:0.5116700530052185  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:98.13%\t train set:99.06%\n","Epoch:14/50     Step:1|6   loss:0.5277668237686157  \n","Epoch:14/50     Step:2|6   loss:0.5371864438056946  \n","Epoch:14/50     Step:3|6   loss:0.5314093232154846  \n","Epoch:14/50     Step:4|6   loss:0.5178880095481873  \n","Epoch:14/50     Step:5|6   loss:0.5347384214401245  \n","Epoch:14/50     Step:6|6   loss:0.541257381439209  \n","Epoch:14/50     Step:7|6   loss:0.5280411839485168  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:15/50     Step:1|6   loss:0.5353462100028992  \n","Epoch:15/50     Step:2|6   loss:0.5191754102706909  \n","Epoch:15/50     Step:3|6   loss:0.5259110927581787  \n","Epoch:15/50     Step:4|6   loss:0.5359708666801453  \n","Epoch:15/50     Step:5|6   loss:0.5109549760818481  \n","Epoch:15/50     Step:6|6   loss:0.5162875056266785  \n","Epoch:15/50     Step:7|6   loss:0.5075142979621887  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:16/50     Step:1|6   loss:0.5130627751350403  \n","Epoch:16/50     Step:2|6   loss:0.5089435577392578  \n","Epoch:16/50     Step:3|6   loss:0.5131133794784546  \n","Epoch:16/50     Step:4|6   loss:0.5147810578346252  \n","Epoch:16/50     Step:5|6   loss:0.521286129951477  \n","Epoch:16/50     Step:6|6   loss:0.5446840524673462  \n","Epoch:16/50     Step:7|6   loss:0.5134505033493042  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:17/50     Step:1|6   loss:0.5251586437225342  \n","Epoch:17/50     Step:2|6   loss:0.5100822448730469  \n","Epoch:17/50     Step:3|6   loss:0.5092810988426208  \n","Epoch:17/50     Step:4|6   loss:0.519355833530426  \n","Epoch:17/50     Step:5|6   loss:0.5133336782455444  \n","Epoch:17/50     Step:6|6   loss:0.51186603307724  \n","Epoch:17/50     Step:7|6   loss:0.5319145321846008  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:18/50     Step:1|6   loss:0.5082826614379883  \n","Epoch:18/50     Step:2|6   loss:0.5081847906112671  \n","Epoch:18/50     Step:3|6   loss:0.5274849534034729  \n","Epoch:18/50     Step:4|6   loss:0.5215880870819092  \n","Epoch:18/50     Step:5|6   loss:0.5054668188095093  \n","Epoch:18/50     Step:6|6   loss:0.5115700364112854  \n","Epoch:18/50     Step:7|6   loss:0.5070315599441528  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:19/50     Step:1|6   loss:0.5163838267326355  \n","Epoch:19/50     Step:2|6   loss:0.50169837474823  \n","Epoch:19/50     Step:3|6   loss:0.5250903367996216  \n","Epoch:19/50     Step:4|6   loss:0.5047416090965271  \n","2Epoch:19/50     Step:5|6   loss:0.5074747800827026  \n","Epoch:19/50     Step:6|6   loss:0.5061419010162354  \n","Epoch:19/50     Step:7|6   loss:0.5327588319778442  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:20/50     Step:1|6   loss:0.506198525428772  \n","Epoch:20/50     Step:2|6   loss:0.5015426874160767  \n","Epoch:20/50     Step:3|6   loss:0.5058223009109497  \n","Epoch:20/50     Step:4|6   loss:0.5238000750541687  \n","Epoch:20/50     Step:5|6   loss:0.5028807520866394  \n","Epoch:20/50     Step:6|6   loss:0.5080629587173462  \n","Epoch:20/50     Step:7|6   loss:0.5132180452346802  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:21/50     Step:1|6   loss:0.505071222782135  \n","Epoch:21/50     Step:2|6   loss:0.5132546424865723  \n","Epoch:21/50     Step:3|6   loss:0.5118988752365112  \n","Epoch:21/50     Step:4|6   loss:0.517861008644104  \n","Epoch:21/50     Step:5|6   loss:0.4988303780555725  \n","Epoch:21/50     Step:6|6   loss:0.5020349025726318  \n","Epoch:21/50     Step:7|6   loss:0.5120750665664673  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:22/50     Step:1|6   loss:0.5081454515457153  \n","Epoch:22/50     Step:2|6   loss:0.5075892806053162  \n","Epoch:22/50     Step:3|6   loss:0.4993351101875305  \n","Epoch:22/50     Step:4|6   loss:0.498079776763916  \n","Epoch:22/50     Step:5|6   loss:0.5056261420249939  \n","Epoch:22/50     Step:6|6   loss:0.5069519281387329  \n","Epoch:22/50     Step:7|6   loss:0.5260380506515503  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:23/50     Step:1|6   loss:0.504621148109436  \n","Epoch:23/50     Step:2|6   loss:0.501180112361908  \n","Epoch:23/50     Step:3|6   loss:0.5141098499298096  \n","Epoch:23/50     Step:4|6   loss:0.49877557158470154  \n","Epoch:23/50     Step:5|6   loss:0.501558244228363  \n","Epoch:23/50     Step:6|6   loss:0.5050822496414185  \n","Epoch:23/50     Step:7|6   loss:0.49826472997665405  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:24/50     Step:1|6   loss:0.4991919994354248  \n","Epoch:24/50     Step:2|6   loss:0.5028218626976013  \n","Epoch:24/50     Step:3|6   loss:0.4996277093887329  \n","Epoch:24/50     Step:4|6   loss:0.4983879327774048  \n","Epoch:24/50     Step:5|6   loss:0.5020514726638794  \n","Epoch:24/50     Step:6|6   loss:0.5054962038993835  \n","Epoch:24/50     Step:7|6   loss:0.5170220136642456  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:25/50     Step:1|6   loss:0.5008395314216614  \n","Epoch:25/50     Step:2|6   loss:0.5029013156890869  \n","Epoch:25/50     Step:3|6   loss:0.4979192018508911  \n","Epoch:25/50     Step:4|6   loss:0.5106298923492432  \n","Epoch:25/50     Step:5|6   loss:0.49750763177871704  \n","Epoch:25/50     Step:6|6   loss:0.5025407671928406  \n","Epoch:25/50     Step:7|6   loss:0.4959004819393158  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.4976530373096466  \n","Epoch:26/50     Step:2|6   loss:0.49834203720092773  \n","Epoch:26/50     Step:3|6   loss:0.5006371736526489  \n","Epoch:26/50     Step:4|6   loss:0.5114442110061646  \n","Epoch:26/50     Step:5|6   loss:0.4990386366844177  \n","Epoch:26/50     Step:6|6   loss:0.4967852830886841  \n","Epoch:26/50     Step:7|6   loss:0.5029174089431763  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.5012301206588745  \n","Epoch:27/50     Step:2|6   loss:0.49791914224624634  \n","Epoch:27/50     Step:3|6   loss:0.49469974637031555  \n","Epoch:27/50     Step:4|6   loss:0.5013505220413208  \n","Epoch:27/50     Step:5|6   loss:0.5042388439178467  \n","Epoch:27/50     Step:6|6   loss:0.49570512771606445  \n","Epoch:27/50     Step:7|6   loss:0.49621784687042236  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.49668973684310913  \n","Epoch:28/50     Step:2|6   loss:0.4979535937309265  \n","Epoch:28/50     Step:3|6   loss:0.5009322762489319  \n","Epoch:28/50     Step:4|6   loss:0.4995802640914917  \n","Epoch:28/50     Step:5|6   loss:0.5047026872634888  \n","Epoch:28/50     Step:6|6   loss:0.49455684423446655  \n","Epoch:28/50     Step:7|6   loss:0.50289386510849  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4946173131465912  \n","Epoch:29/50     Step:2|6   loss:0.49567925930023193  \n","Epoch:29/50     Step:3|6   loss:0.4987446069717407  \n","Epoch:29/50     Step:4|6   loss:0.5075608491897583  \n","Epoch:29/50     Step:5|6   loss:0.494338721036911  \n","Epoch:29/50     Step:6|6   loss:0.4962758421897888  \n","Epoch:29/50     Step:7|6   loss:0.49973198771476746  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4992051124572754  \n","Epoch:30/50     Step:2|6   loss:0.4931454062461853  \n","Epoch:30/50     Step:3|6   loss:0.501469075679779  \n","Epoch:30/50     Step:4|6   loss:0.4956014156341553  \n","Epoch:30/50     Step:5|6   loss:0.49426043033599854  \n","Epoch:30/50     Step:6|6   loss:0.49478912353515625  \n","Epoch:30/50     Step:7|6   loss:0.4968957304954529  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.49522072076797485  \n","Epoch:31/50     Step:2|6   loss:0.5050334334373474  \n","Epoch:31/50     Step:3|6   loss:0.4944782555103302  \n","Epoch:31/50     Step:4|6   loss:0.49202674627304077  \n","Epoch:31/50     Step:5|6   loss:0.494235098361969  \n","Epoch:31/50     Step:6|6   loss:0.4945882260799408  \n","Epoch:31/50     Step:7|6   loss:0.4978010058403015  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4983411431312561  \n","Epoch:32/50     Step:2|6   loss:0.49285340309143066  \n","Epoch:32/50     Step:3|6   loss:0.4933769404888153  \n","Epoch:32/50     Step:4|6   loss:0.4955264925956726  \n","Epoch:32/50     Step:5|6   loss:0.4937439560890198  \n","Epoch:32/50     Step:6|6   loss:0.4958350658416748  \n","Epoch:32/50     Step:7|6   loss:0.5047225952148438  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4938122034072876  \n","Epoch:33/50     Step:2|6   loss:0.49506455659866333  \n","Epoch:33/50     Step:3|6   loss:0.5017533898353577  \n","Epoch:33/50     Step:4|6   loss:0.4960508346557617  \n","Epoch:33/50     Step:5|6   loss:0.4938516616821289  \n","Epoch:33/50     Step:6|6   loss:0.4929705262184143  \n","Epoch:33/50     Step:7|6   loss:0.49137043952941895  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.49940788745880127  \n","Epoch:34/50     Step:2|6   loss:0.49228131771087646  \n","Epoch:34/50     Step:3|6   loss:0.49559706449508667  \n","Epoch:34/50     Step:4|6   loss:0.4909279942512512  \n","Epoch:34/50     Step:5|6   loss:0.4944767951965332  \n","Epoch:34/50     Step:6|6   loss:0.4930747151374817  \n","Epoch:34/50     Step:7|6   loss:0.49174997210502625  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4938358664512634  \n","Epoch:35/50     Step:2|6   loss:0.4924315810203552  \n","Epoch:35/50     Step:3|6   loss:0.49466320872306824  \n","Epoch:35/50     Step:4|6   loss:0.4914586842060089  \n","Epoch:35/50     Step:5|6   loss:0.49755537509918213  \n","Epoch:35/50     Step:6|6   loss:0.49250972270965576  \n","Epoch:35/50     Step:7|6   loss:0.49058669805526733  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4965001344680786  \n","Epoch:36/50     Step:2|6   loss:0.49215492606163025  \n","Epoch:36/50     Step:3|6   loss:0.49299803376197815  \n","Epoch:36/50     Step:4|6   loss:0.4917798340320587  \n","Epoch:36/50     Step:5|6   loss:0.49100756645202637  \n","Epoch:36/50     Step:6|6   loss:0.4927539527416229  \n","Epoch:36/50     Step:7|6   loss:0.4909639060497284  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4950801134109497  \n","Epoch:37/50     Step:2|6   loss:0.492077112197876  \n","Epoch:37/50     Step:3|6   loss:0.49065372347831726  \n","Epoch:37/50     Step:4|6   loss:0.4985657036304474  \n","Epoch:37/50     Step:5|6   loss:0.4899982810020447  \n","Epoch:37/50     Step:6|6   loss:0.4898667335510254  \n","Epoch:37/50     Step:7|6   loss:0.49012285470962524  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.49193859100341797  \n","Epoch:38/50     Step:2|6   loss:0.491777241230011  \n","Epoch:38/50     Step:3|6   loss:0.4923053979873657  \n","Epoch:38/50     Step:4|6   loss:0.49083104729652405  \n","Epoch:38/50     Step:5|6   loss:0.48948246240615845  \n","Epoch:38/50     Step:6|6   loss:0.49542510509490967  \n","Epoch:38/50     Step:7|6   loss:0.4894944429397583  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.49177855253219604  \n","Epoch:39/50     Step:2|6   loss:0.4907190203666687  \n","Epoch:39/50     Step:3|6   loss:0.489288330078125  \n","Epoch:39/50     Step:4|6   loss:0.49713432788848877  \n","Epoch:39/50     Step:5|6   loss:0.4898856282234192  \n","Epoch:39/50     Step:6|6   loss:0.4914211630821228  \n","Epoch:39/50     Step:7|6   loss:0.4922313392162323  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.49168577790260315  \n","Epoch:40/50     Step:2|6   loss:0.4902089536190033  \n","Epoch:40/50     Step:3|6   loss:0.48926061391830444  \n","Epoch:40/50     Step:4|6   loss:0.49561217427253723  \n","Epoch:40/50     Step:5|6   loss:0.49194303154945374  \n","Epoch:40/50     Step:6|6   loss:0.4914381504058838  \n","Epoch:40/50     Step:7|6   loss:0.48786139488220215  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.49100205302238464  \n","Epoch:41/50     Step:2|6   loss:0.49284955859184265  \n","Epoch:41/50     Step:3|6   loss:0.4912136197090149  \n","Epoch:41/50     Step:4|6   loss:0.48997554183006287  \n","Epoch:41/50     Step:5|6   loss:0.49204427003860474  \n","Epoch:41/50     Step:6|6   loss:0.4895976185798645  \n","Epoch:41/50     Step:7|6   loss:0.49103546142578125  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4899006187915802  \n","Epoch:42/50     Step:2|6   loss:0.49051153659820557  \n","Epoch:42/50     Step:3|6   loss:0.4911562204360962  \n","Epoch:42/50     Step:4|6   loss:0.4946058988571167  \n","Epoch:42/50     Step:5|6   loss:0.4881928861141205  \n","Epoch:42/50     Step:6|6   loss:0.4900140166282654  \n","Epoch:42/50     Step:7|6   loss:0.49031057953834534  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4898621439933777  \n","Epoch:43/50     Step:2|6   loss:0.4900261163711548  \n","Epoch:43/50     Step:3|6   loss:0.49053579568862915  \n","Epoch:43/50     Step:4|6   loss:0.49179914593696594  \n","Epoch:43/50     Step:5|6   loss:0.49075770378112793  \n","Epoch:43/50     Step:6|6   loss:0.48966872692108154  \n","Epoch:43/50     Step:7|6   loss:0.4916539490222931  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4916725158691406  \n","Epoch:44/50     Step:2|6   loss:0.4891076982021332  \n","Epoch:44/50     Step:3|6   loss:0.4925423264503479  \n","Epoch:44/50     Step:4|6   loss:0.4907676875591278  \n","Epoch:44/50     Step:5|6   loss:0.4921395480632782  \n","Epoch:44/50     Step:6|6   loss:0.4898955821990967  \n","Epoch:44/50     Step:7|6   loss:0.48888200521469116  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.49199581146240234  \n","Epoch:45/50     Step:2|6   loss:0.4893839955329895  \n","Epoch:45/50     Step:3|6   loss:0.48779767751693726  \n","Epoch:45/50     Step:4|6   loss:0.4908770024776459  \n","Epoch:45/50     Step:5|6   loss:0.4905744194984436  \n","Epoch:45/50     Step:6|6   loss:0.4901910722255707  \n","Epoch:45/50     Step:7|6   loss:0.4892518222332001  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4899306297302246  \n","Epoch:46/50     Step:2|6   loss:0.48958390951156616  \n","Epoch:46/50     Step:3|6   loss:0.4885830283164978  \n","Epoch:46/50     Step:4|6   loss:0.4884086549282074  \n","Epoch:46/50     Step:5|6   loss:0.4899199903011322  \n","Epoch:46/50     Step:6|6   loss:0.489402174949646  \n","Epoch:46/50     Step:7|6   loss:0.4938979744911194  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48906517028808594  \n","Epoch:47/50     Step:2|6   loss:0.4899773597717285  \n","Epoch:47/50     Step:3|6   loss:0.48873722553253174  \n","Epoch:47/50     Step:4|6   loss:0.48805633187294006  \n","Epoch:47/50     Step:5|6   loss:0.49009865522384644  \n","Epoch:47/50     Step:6|6   loss:0.48911553621292114  \n","Epoch:47/50     Step:7|6   loss:0.48930126428604126  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.48882558941841125  \n","Epoch:48/50     Step:2|6   loss:0.4905356168746948  \n","Epoch:48/50     Step:3|6   loss:0.4882189631462097  \n","Epoch:48/50     Step:4|6   loss:0.4884202182292938  \n","Epoch:48/50     Step:5|6   loss:0.48821598291397095  \n","Epoch:48/50     Step:6|6   loss:0.4924876093864441  \n","Epoch:48/50     Step:7|6   loss:0.4874646067619324  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4884355366230011  \n","Epoch:49/50     Step:2|6   loss:0.487661749124527  \n","Epoch:49/50     Step:3|6   loss:0.4881596267223358  \n","Epoch:49/50     Step:4|6   loss:0.4915657639503479  \n","Epoch:49/50     Step:5|6   loss:0.4883614778518677  \n","Epoch:49/50     Step:6|6   loss:0.48909521102905273  \n","Epoch:49/50     Step:7|6   loss:0.48845598101615906  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4908146858215332  \n","Epoch:50/50     Step:2|6   loss:0.48815491795539856  \n","Epoch:50/50     Step:3|6   loss:0.4873649477958679  \n","Epoch:50/50     Step:4|6   loss:0.48774245381355286  \n","Epoch:50/50     Step:5|6   loss:0.48875492811203003  \n","Epoch:50/50     Step:6|6   loss:0.4894462525844574  \n","Epoch:50/50     Step:7|6   loss:0.48823076486587524  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1226110458374023  \n","Epoch:1/50     Step:2|6   loss:2.475015640258789  \n","Epoch:1/50     Step:3|6   loss:2.066624164581299  \n","Epoch:1/50     Step:4|6   loss:1.874648094177246  \n","Epoch:1/50     Step:5|6   loss:2.484959363937378  \n","Epoch:1/50     Step:6|6   loss:2.2284438610076904  \n","Epoch:1/50     Step:7|6   loss:2.6847121715545654  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:2/50     Step:1|6   loss:2.1648473739624023  \n","Epoch:2/50     Step:2|6   loss:2.2641592025756836  \n","Epoch:2/50     Step:3|6   loss:2.0383243560791016  \n","Epoch:2/50     Step:4|6   loss:2.5750367641448975  \n","Epoch:2/50     Step:5|6   loss:2.135732889175415  \n","Epoch:2/50     Step:6|6   loss:1.6580307483673096  \n","Epoch:2/50     Step:7|6   loss:2.5459401607513428  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:3/50     Step:1|6   loss:2.2367780208587646  \n","Epoch:3/50     Step:2|6   loss:2.333125591278076  \n","Epoch:3/50     Step:3|6   loss:2.1705210208892822  \n","Epoch:3/50     Step:4|6   loss:2.2843241691589355  \n","Epoch:3/50     Step:5|6   loss:1.8305026292800903  \n","Epoch:3/50     Step:6|6   loss:1.9667924642562866  \n","Epoch:3/50     Step:7|6   loss:1.9306422472000122  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:4/50     Step:1|6   loss:2.311432123184204  \n","Epoch:4/50     Step:2|6   loss:2.063109874725342  \n","Epoch:4/50     Step:3|6   loss:1.7737451791763306  \n","Epoch:4/50     Step:4|6   loss:2.4719529151916504  \n","Epoch:4/50     Step:5|6   loss:1.885925531387329  \n","Epoch:4/50     Step:6|6   loss:1.8549706935882568  \n","Epoch:4/50     Step:7|6   loss:2.0749154090881348  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:5/50     Step:1|6   loss:2.192065715789795  \n","Epoch:5/50     Step:2|6   loss:2.0998551845550537  \n","Epoch:5/50     Step:3|6   loss:2.1196889877319336  \n","Epoch:5/50     Step:4|6   loss:2.165524482727051  \n","Epoch:5/50     Step:5|6   loss:2.0105819702148438  \n","Epoch:5/50     Step:6|6   loss:1.5565770864486694  \n","Epoch:5/50     Step:7|6   loss:1.9525701999664307  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:6/50     Step:1|6   loss:2.1876606941223145  \n","Epoch:6/50     Step:2|6   loss:1.874312400817871  \n","Epoch:6/50     Step:3|6   loss:2.0388970375061035  \n","Epoch:6/50     Step:4|6   loss:1.6518831253051758  \n","Epoch:6/50     Step:5|6   loss:1.7640924453735352  \n","Epoch:6/50     Step:6|6   loss:2.2787604331970215  \n","Epoch:6/50     Step:7|6   loss:2.022676706314087  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:7/50     Step:1|6   loss:2.3493258953094482  \n","Epoch:7/50     Step:2|6   loss:1.7310858964920044  \n","Epoch:7/50     Step:3|6   loss:2.012744665145874  \n","Epoch:7/50     Step:4|6   loss:2.1712169647216797  \n","Epoch:7/50     Step:5|6   loss:1.9385788440704346  \n","Epoch:7/50     Step:6|6   loss:1.6546525955200195  \n","Epoch:7/50     Step:7|6   loss:1.5247249603271484  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:8/50     Step:1|6   loss:1.8375837802886963  \n","Epoch:8/50     Step:2|6   loss:1.9885525703430176  \n","Epoch:8/50     Step:3|6   loss:1.897520661354065  \n","Epoch:8/50     Step:4|6   loss:1.7328296899795532  \n","Epoch:8/50     Step:5|6   loss:1.7323092222213745  \n","Epoch:8/50     Step:6|6   loss:1.9017478227615356  \n","Epoch:8/50     Step:7|6   loss:2.2550082206726074  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:9/50     Step:1|6   loss:1.6318938732147217  \n","Epoch:9/50     Step:2|6   loss:2.1165082454681396  \n","Epoch:9/50     Step:3|6   loss:1.7927013635635376  \n","Epoch:9/50     Step:4|6   loss:1.7661306858062744  \n","Epoch:9/50     Step:5|6   loss:1.866951823234558  \n","Epoch:9/50     Step:6|6   loss:1.8626062870025635  \n","Epoch:9/50     Step:7|6   loss:1.959333062171936  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:10/50     Step:1|6   loss:1.8093218803405762  \n","Epoch:10/50     Step:2|6   loss:2.1329543590545654  \n","Epoch:10/50     Step:3|6   loss:2.0479657649993896  \n","Epoch:10/50     Step:4|6   loss:1.831238031387329  \n","Epoch:10/50     Step:5|6   loss:1.5473252534866333  \n","Epoch:10/50     Step:6|6   loss:1.521230936050415  \n","Epoch:10/50     Step:7|6   loss:1.8312437534332275  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:11/50     Step:1|6   loss:2.003851890563965  \n","Epoch:11/50     Step:2|6   loss:1.6858094930648804  \n","Epoch:11/50     Step:3|6   loss:1.6477829217910767  \n","Epoch:11/50     Step:4|6   loss:1.8121615648269653  \n","Epoch:11/50     Step:5|6   loss:1.9372599124908447  \n","Epoch:11/50     Step:6|6   loss:1.5206958055496216  \n","Epoch:11/50     Step:7|6   loss:1.8985514640808105  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:12/50     Step:1|6   loss:1.7967206239700317  \n","Epoch:12/50     Step:2|6   loss:2.0600013732910156  \n","Epoch:12/50     Step:3|6   loss:1.8701295852661133  \n","Epoch:12/50     Step:4|6   loss:1.4856048822402954  \n","Epoch:12/50     Step:5|6   loss:1.7420542240142822  \n","Epoch:12/50     Step:6|6   loss:1.6856825351715088  \n","Epoch:12/50     Step:7|6   loss:1.540207862854004  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:13/50     Step:1|6   loss:1.5609086751937866  \n","Epoch:13/50     Step:2|6   loss:1.9071694612503052  \n","Epoch:13/50     Step:3|6   loss:1.7116104364395142  \n","Epoch:13/50     Step:4|6   loss:1.774164080619812  \n","Epoch:13/50     Step:5|6   loss:1.6543972492218018  \n","Epoch:13/50     Step:6|6   loss:1.8557040691375732  \n","Epoch:13/50     Step:7|6   loss:1.491546630859375  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:14/50     Step:1|6   loss:1.6426069736480713  \n","Epoch:14/50     Step:2|6   loss:1.7275558710098267  \n","Epoch:14/50     Step:3|6   loss:1.4897775650024414  \n","Epoch:14/50     Step:4|6   loss:1.7443068027496338  \n","Epoch:14/50     Step:5|6   loss:1.565292477607727  \n","Epoch:14/50     Step:6|6   loss:1.9456210136413574  \n","Epoch:14/50     Step:7|6   loss:1.731228232383728  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:15/50     Step:1|6   loss:1.6617363691329956  \n","Epoch:15/50     Step:2|6   loss:1.389974594116211  \n","Epoch:15/50     Step:3|6   loss:1.8159955739974976  \n","Epoch:15/50     Step:4|6   loss:1.6716530323028564  \n","Epoch:15/50     Step:5|6   loss:1.7560088634490967  \n","Epoch:15/50     Step:6|6   loss:1.5982513427734375  \n","Epoch:15/50     Step:7|6   loss:1.7973606586456299  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:16/50     Step:1|6   loss:1.5107355117797852  \n","Epoch:16/50     Step:2|6   loss:1.6161575317382812  \n","Epoch:16/50     Step:3|6   loss:1.8270231485366821  \n","Epoch:16/50     Step:4|6   loss:1.5128830671310425  \n","Epoch:16/50     Step:5|6   loss:1.2667770385742188  \n","Epoch:16/50     Step:6|6   loss:1.9757118225097656  \n","Epoch:16/50     Step:7|6   loss:1.815398931503296  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:17/50     Step:1|6   loss:1.6604540348052979  \n","Epoch:17/50     Step:2|6   loss:1.7108176946640015  \n","Epoch:17/50     Step:3|6   loss:1.4817975759506226  \n","Epoch:17/50     Step:4|6   loss:1.570298671722412  \n","Epoch:17/50     Step:5|6   loss:1.5148942470550537  \n","Epoch:17/50     Step:6|6   loss:1.8781307935714722  \n","Epoch:17/50     Step:7|6   loss:1.418044090270996  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:18/50     Step:1|6   loss:1.7395761013031006  \n","Epoch:18/50     Step:2|6   loss:1.6188840866088867  \n","Epoch:18/50     Step:3|6   loss:1.499315857887268  \n","Epoch:18/50     Step:4|6   loss:1.7027418613433838  \n","Epoch:18/50     Step:5|6   loss:1.3780622482299805  \n","Epoch:18/50     Step:6|6   loss:1.6579642295837402  \n","Epoch:18/50     Step:7|6   loss:1.511795163154602  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:19/50     Step:1|6   loss:1.5114750862121582  \n","Epoch:19/50     Step:2|6   loss:1.5196611881256104  \n","Epoch:19/50     Step:3|6   loss:1.4921729564666748  \n","Epoch:19/50     Step:4|6   loss:1.9032971858978271  \n","Epoch:19/50     Step:5|6   loss:1.4090430736541748  \n","Epoch:19/50     Step:6|6   loss:1.5334465503692627  \n","Epoch:19/50     Step:7|6   loss:1.620619535446167  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:20/50     Step:1|6   loss:1.428376317024231  \n","Epoch:20/50     Step:2|6   loss:1.9073508977890015  \n","Epoch:20/50     Step:3|6   loss:1.6432651281356812  \n","Epoch:20/50     Step:4|6   loss:1.3830286264419556  \n","Epoch:20/50     Step:5|6   loss:1.4642672538757324  \n","Epoch:20/50     Step:6|6   loss:1.6095399856567383  \n","Epoch:20/50     Step:7|6   loss:1.3081166744232178  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:21/50     Step:1|6   loss:1.446594476699829  \n","Epoch:21/50     Step:2|6   loss:1.4072339534759521  \n","Epoch:21/50     Step:3|6   loss:1.4363468885421753  \n","Epoch:21/50     Step:4|6   loss:1.649958610534668  \n","Epoch:21/50     Step:5|6   loss:1.3494774103164673  \n","Epoch:21/50     Step:6|6   loss:1.7684578895568848  \n","Epoch:21/50     Step:7|6   loss:1.6485483646392822  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:22/50     Step:1|6   loss:1.5306884050369263  \n","Epoch:22/50     Step:2|6   loss:1.4308514595031738  \n","Epoch:22/50     Step:3|6   loss:1.5741053819656372  \n","Epoch:22/50     Step:4|6   loss:1.4529051780700684  \n","Epoch:22/50     Step:5|6   loss:1.4777990579605103  \n","Epoch:22/50     Step:6|6   loss:1.461121916770935  \n","Epoch:22/50     Step:7|6   loss:1.6404765844345093  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:23/50     Step:1|6   loss:1.4524625539779663  \n","Epoch:23/50     Step:2|6   loss:1.4311810731887817  \n","Epoch:23/50     Step:3|6   loss:1.4361683130264282  \n","Epoch:23/50     Step:4|6   loss:1.559025764465332  \n","Epoch:23/50     Step:5|6   loss:1.5635817050933838  \n","Epoch:23/50     Step:6|6   loss:1.4968886375427246  \n","Epoch:23/50     Step:7|6   loss:1.415413737297058  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:24/50     Step:1|6   loss:1.4013389348983765  \n","Epoch:24/50     Step:2|6   loss:1.5114359855651855  \n","Epoch:24/50     Step:3|6   loss:1.6493582725524902  \n","Epoch:24/50     Step:4|6   loss:1.4270598888397217  \n","Epoch:24/50     Step:5|6   loss:1.255869746208191  \n","Epoch:24/50     Step:6|6   loss:1.4293951988220215  \n","Epoch:24/50     Step:7|6   loss:1.607006549835205  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:25/50     Step:1|6   loss:1.3081045150756836  \n","Epoch:25/50     Step:2|6   loss:1.3343639373779297  \n","Epoch:25/50     Step:3|6   loss:1.562822699546814  \n","Epoch:25/50     Step:4|6   loss:1.579931616783142  \n","Epoch:25/50     Step:5|6   loss:1.3598970174789429  \n","Epoch:25/50     Step:6|6   loss:1.5144039392471313  \n","Epoch:25/50     Step:7|6   loss:1.4257268905639648  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:26/50     Step:1|6   loss:1.5237079858779907  \n","Epoch:26/50     Step:2|6   loss:1.5085606575012207  \n","Epoch:26/50     Step:3|6   loss:1.3066754341125488  \n","Epoch:26/50     Step:4|6   loss:1.4400579929351807  \n","Epoch:26/50     Step:5|6   loss:1.1650104522705078  \n","Epoch:26/50     Step:6|6   loss:1.4744774103164673  \n","Epoch:26/50     Step:7|6   loss:1.588621973991394  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:27/50     Step:1|6   loss:1.552209496498108  \n","Epoch:27/50     Step:2|6   loss:1.5487253665924072  \n","Epoch:27/50     Step:3|6   loss:1.3196043968200684  \n","Epoch:27/50     Step:4|6   loss:1.3280065059661865  \n","Epoch:27/50     Step:5|6   loss:1.2938950061798096  \n","Epoch:27/50     Step:6|6   loss:1.5341377258300781  \n","Epoch:27/50     Step:7|6   loss:1.1604076623916626  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:28/50     Step:1|6   loss:1.317857027053833  \n","Epoch:28/50     Step:2|6   loss:1.3548036813735962  \n","Epoch:28/50     Step:3|6   loss:1.5606162548065186  \n","Epoch:28/50     Step:4|6   loss:1.2904752492904663  \n","Epoch:28/50     Step:5|6   loss:1.3673796653747559  \n","Epoch:28/50     Step:6|6   loss:1.3939409255981445  \n","Epoch:28/50     Step:7|6   loss:1.3952029943466187  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:29/50     Step:1|6   loss:1.592951774597168  \n","Epoch:29/50     Step:2|6   loss:1.3952507972717285  \n","Epoch:29/50     Step:3|6   loss:1.4501241445541382  \n","Epoch:29/50     Step:4|6   loss:1.1296591758728027  \n","Epoch:29/50     Step:5|6   loss:1.3478007316589355  \n","Epoch:29/50     Step:6|6   loss:1.2600795030593872  \n","Epoch:29/50     Step:7|6   loss:1.3754056692123413  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:30/50     Step:1|6   loss:1.3403396606445312  \n","Epoch:30/50     Step:2|6   loss:1.3754305839538574  \n","Epoch:30/50     Step:3|6   loss:1.4487476348876953  \n","Epoch:30/50     Step:4|6   loss:1.2011574506759644  \n","Epoch:30/50     Step:5|6   loss:1.2831149101257324  \n","Epoch:30/50     Step:6|6   loss:1.4673899412155151  \n","Epoch:30/50     Step:7|6   loss:1.2728173732757568  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:31/50     Step:1|6   loss:1.349392294883728  \n","Epoch:31/50     Step:2|6   loss:1.292665719985962  \n","Epoch:31/50     Step:3|6   loss:1.3803976774215698  \n","Epoch:31/50     Step:4|6   loss:1.3679381608963013  \n","Epoch:31/50     Step:5|6   loss:1.1240001916885376  \n","Epoch:31/50     Step:6|6   loss:1.4533394575119019  \n","Epoch:31/50     Step:7|6   loss:1.31267511844635  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:32/50     Step:1|6   loss:1.3731216192245483  \n","Epoch:32/50     Step:2|6   loss:1.3373699188232422  \n","Epoch:32/50     Step:3|6   loss:1.3537849187850952  \n","Epoch:32/50     Step:4|6   loss:1.3766887187957764  \n","Epoch:32/50     Step:5|6   loss:1.2687416076660156  \n","Epoch:32/50     Step:6|6   loss:1.0983078479766846  \n","Epoch:32/50     Step:7|6   loss:1.3755872249603271  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:33/50     Step:1|6   loss:1.2557942867279053  \n","Epoch:33/50     Step:2|6   loss:1.3780832290649414  \n","Epoch:33/50     Step:3|6   loss:1.2629735469818115  \n","Epoch:33/50     Step:4|6   loss:1.4537914991378784  \n","Epoch:33/50     Step:5|6   loss:1.0829588174819946  \n","Epoch:33/50     Step:6|6   loss:1.338205099105835  \n","Epoch:33/50     Step:7|6   loss:1.2508443593978882  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:34/50     Step:1|6   loss:1.0931217670440674  \n","Epoch:34/50     Step:2|6   loss:1.4297504425048828  \n","Epoch:34/50     Step:3|6   loss:1.331519603729248  \n","Epoch:34/50     Step:4|6   loss:1.2674723863601685  \n","Epoch:34/50     Step:5|6   loss:1.3593873977661133  \n","Epoch:34/50     Step:6|6   loss:1.257980465888977  \n","Epoch:34/50     Step:7|6   loss:1.131611943244934  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:35/50     Step:1|6   loss:1.1790786981582642  \n","Epoch:35/50     Step:2|6   loss:1.237644910812378  \n","Epoch:35/50     Step:3|6   loss:1.2222601175308228  \n","Epoch:35/50     Step:4|6   loss:1.3331040143966675  \n","Epoch:35/50     Step:5|6   loss:1.2574212551116943  \n","Epoch:35/50     Step:6|6   loss:1.2421380281448364  \n","Epoch:35/50     Step:7|6   loss:1.3604649305343628  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:36/50     Step:1|6   loss:1.212365984916687  \n","Epoch:36/50     Step:2|6   loss:1.3477225303649902  \n","Epoch:36/50     Step:3|6   loss:1.2207434177398682  \n","Epoch:36/50     Step:4|6   loss:1.2279499769210815  \n","Epoch:36/50     Step:5|6   loss:1.2651399374008179  \n","Epoch:36/50     Step:6|6   loss:1.2783596515655518  \n","Epoch:36/50     Step:7|6   loss:1.086454153060913  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:37/50     Step:1|6   loss:1.2313238382339478  \n","Epoch:37/50     Step:2|6   loss:1.1085491180419922  \n","Epoch:37/50     Step:3|6   loss:1.3513824939727783  \n","Epoch:37/50     Step:4|6   loss:1.1333494186401367  \n","Epoch:37/50     Step:5|6   loss:1.3305935859680176  \n","Epoch:37/50     Step:6|6   loss:1.0542019605636597  \n","Epoch:37/50     Step:7|6   loss:1.439488410949707  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:38/50     Step:1|6   loss:1.2750706672668457  \n","Epoch:38/50     Step:2|6   loss:1.3811081647872925  \n","Epoch:38/50     Step:3|6   loss:1.1749167442321777  \n","Epoch:38/50     Step:4|6   loss:1.1029982566833496  \n","Epoch:38/50     Step:5|6   loss:1.121779441833496  \n","Epoch:38/50     Step:6|6   loss:1.1586449146270752  \n","Epoch:38/50     Step:7|6   loss:1.2884753942489624  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:39/50     Step:1|6   loss:1.2765374183654785  \n","Epoch:39/50     Step:2|6   loss:1.200226068496704  \n","Epoch:39/50     Step:3|6   loss:1.1044288873672485  \n","Epoch:39/50     Step:4|6   loss:1.2328321933746338  \n","Epoch:39/50     Step:5|6   loss:1.1844966411590576  \n","Epoch:39/50     Step:6|6   loss:1.228616714477539  \n","Epoch:39/50     Step:7|6   loss:1.1221814155578613  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:40/50     Step:1|6   loss:1.132896900177002  \n","Epoch:40/50     Step:2|6   loss:1.1496880054473877  \n","Epoch:40/50     Step:3|6   loss:1.1934945583343506  \n","Epoch:40/50     Step:4|6   loss:1.0740429162979126  \n","Epoch:40/50     Step:5|6   loss:1.4105706214904785  \n","Epoch:40/50     Step:6|6   loss:1.1972681283950806  \n","Epoch:40/50     Step:7|6   loss:1.0877528190612793  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:41/50     Step:1|6   loss:1.3512942790985107  \n","Epoch:41/50     Step:2|6   loss:1.1453653573989868  \n","Epoch:41/50     Step:3|6   loss:1.1175541877746582  \n","Epoch:41/50     Step:4|6   loss:1.2508140802383423  \n","Epoch:41/50     Step:5|6   loss:1.0628573894500732  \n","Epoch:41/50     Step:6|6   loss:1.0707707405090332  \n","Epoch:41/50     Step:7|6   loss:1.2006473541259766  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %3\n","\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:42/50     Step:1|6   loss:1.0727895498275757  \n","Epoch:42/50     Step:2|6   loss:1.252482295036316  \n","Epoch:42/50     Step:3|6   loss:1.193494200706482  \n","Epoch:42/50     Step:4|6   loss:1.0894057750701904  \n","Epoch:42/50     Step:5|6   loss:1.1661840677261353  \n","Epoch:42/50     Step:6|6   loss:1.1754860877990723  \n","Epoch:42/50     Step:7|6   loss:1.1461265087127686  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:43/50     Step:1|6   loss:1.1906938552856445  \n","Epoch:43/50     Step:2|6   loss:1.1160093545913696  \n","Epoch:43/50     Step:3|6   loss:1.1169565916061401  \n","Epoch:43/50     Step:4|6   loss:1.1646196842193604  \n","Epoch:43/50     Step:5|6   loss:1.163063406944275  \n","Epoch:43/50     Step:6|6   loss:1.0718914270401  \n","Epoch:43/50     Step:7|6   loss:1.222557783126831  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:44/50     Step:1|6   loss:1.187077283859253  \n","Epoch:44/50     Step:2|6   loss:1.1060124635696411  \n","Epoch:44/50     Step:3|6   loss:1.2024362087249756  \n","Epoch:44/50     Step:4|6   loss:1.2276184558868408  \n","Epoch:44/50     Step:5|6   loss:1.0972168445587158  \n","Epoch:44/50     Step:6|6   loss:1.000023603439331  \n","Epoch:44/50     Step:7|6   loss:1.1203159093856812  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:45/50     Step:1|6   loss:1.143113136291504  \n","Epoch:45/50     Step:2|6   loss:1.0974845886230469  \n","Epoch:45/50     Step:3|6   loss:1.0141701698303223  \n","Epoch:45/50     Step:4|6   loss:1.1831412315368652  \n","Epoch:45/50     Step:5|6   loss:1.1113382577896118  \n","Epoch:45/50     Step:6|6   loss:1.1358258724212646  \n","Epoch:45/50     Step:7|6   loss:1.214831829071045  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:46/50     Step:1|6   loss:1.2382404804229736  \n","Epoch:46/50     Step:2|6   loss:1.1439136266708374  \n","Epoch:46/50     Step:3|6   loss:0.985453724861145  \n","Epoch:46/50     Step:4|6   loss:1.0797808170318604  \n","Epoch:46/50     Step:5|6   loss:1.0785300731658936  \n","Epoch:46/50     Step:6|6   loss:1.2412848472595215  \n","Epoch:46/50     Step:7|6   loss:1.0040481090545654  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:47/50     Step:1|6   loss:1.180617094039917  \n","Epoch:47/50     Step:2|6   loss:1.1127161979675293  \n","Epoch:47/50     Step:3|6   loss:1.113816738128662  \n","Epoch:47/50     Step:4|6   loss:0.9982311129570007  \n","Epoch:47/50     Step:5|6   loss:1.1319327354431152  \n","Epoch:47/50     Step:6|6   loss:1.1777317523956299  \n","Epoch:47/50     Step:7|6   loss:0.9946979284286499  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:48/50     Step:1|6   loss:1.1161651611328125  \n","Epoch:48/50     Step:2|6   loss:1.0023274421691895  \n","Epoch:48/50     Step:3|6   loss:1.1243607997894287  \n","Epoch:48/50     Step:4|6   loss:1.0606818199157715  \n","Epoch:48/50     Step:5|6   loss:1.1280994415283203  \n","Epoch:48/50     Step:6|6   loss:1.0982606410980225  \n","Epoch:48/50     Step:7|6   loss:1.1894969940185547  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:49/50     Step:1|6   loss:1.0666948556900024  \n","Epoch:49/50     Step:2|6   loss:1.0750643014907837  \n","Epoch:49/50     Step:3|6   loss:1.0760565996170044  \n","Epoch:49/50     Step:4|6   loss:1.0743415355682373  \n","Epoch:49/50     Step:5|6   loss:1.1864447593688965  \n","Epoch:49/50     Step:6|6   loss:1.064246654510498  \n","Epoch:49/50     Step:7|6   loss:1.0986989736557007  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Epoch:50/50     Step:1|6   loss:1.0533454418182373  \n","Epoch:50/50     Step:2|6   loss:1.0433262586593628  \n","Epoch:50/50     Step:3|6   loss:1.1344444751739502  \n","Epoch:50/50     Step:4|6   loss:1.0776036977767944  \n","Epoch:50/50     Step:5|6   loss:1.0222939252853394  \n","Epoch:50/50     Step:6|6   loss:1.1943979263305664  \n","Epoch:50/50     Step:7|6   loss:1.0636794567108154  \n","Accuracy on test_set: 43.93 %\n","Accuracy on train_set: 53.86 %\n","current max accuracy\t test set:43.93%\t train set:53.86%\n","Accuracy on test_set: 43.93 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()4\n","\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.110186219215393  \n","Epoch:1/50     Step:2|6   loss:1.8104835748672485  \n","Epoch:1/50     Step:3|6   loss:1.8133190870285034  \n","Epoch:1/50     Step:4|6   loss:1.529835820198059  \n","Epoch:1/50     Step:5|6   loss:2.3866569995880127  \n","Epoch:1/50     Step:6|6   loss:1.5193179845809937  \n","Epoch:1/50     Step:7|6   loss:2.1564745903015137  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:2/50     Step:1|6   loss:1.9366365671157837  \n","Epoch:2/50     Step:2|6   loss:1.825675368309021  \n","Epoch:2/50     Step:3|6   loss:1.757847785949707  \n","Epoch:2/50     Step:4|6   loss:1.9245450496673584  \n","Epoch:2/50     Step:5|6   loss:1.9579671621322632  \n","Epoch:2/50     Step:6|6   loss:1.730116367340088  \n","Epoch:2/50     Step:7|6   loss:1.574922800064087  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:3/50     Step:1|6   loss:1.9750990867614746  \n","Epoch:3/50     Step:2|6   loss:1.7594187259674072  \n","Epoch:3/50     Step:3|6   loss:1.833665132522583  \n","Epoch:3/50     Step:4|6   loss:1.719611644744873  \n","Epoch:3/50     Step:5|6   loss:1.703942060470581  \n","Epoch:3/50     Step:6|6   loss:1.8246192932128906  \n","Epoch:3/50     Step:7|6   loss:1.7283965349197388  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:4/50     Step:1|6   loss:1.638635516166687  \n","Epoch:4/50     Step:2|6   loss:1.6371421813964844  \n","Epoch:4/50     Step:3|6   loss:1.8503906726837158  \n","Epoch:4/50     Step:4|6   loss:2.0357418060302734  \n","Epoch:4/50     Step:5|6   loss:1.7494072914123535  \n","Epoch:4/50     Step:6|6   loss:1.5518879890441895  \n","Epoch:4/50     Step:7|6   loss:1.8766156435012817  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:5/50     Step:1|6   loss:2.009115695953369  \n","Epoch:5/50     Step:2|6   loss:1.7099213600158691  \n","Epoch:5/50     Step:3|6   loss:1.8111251592636108  \n","Epoch:5/50     Step:4|6   loss:1.4819614887237549  \n","Epoch:5/50     Step:5|6   loss:1.916214942932129  \n","Epoch:5/50     Step:6|6   loss:1.588975429534912  \n","Epoch:5/50     Step:7|6   loss:1.4996471405029297  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:6/50     Step:1|6   loss:1.6561602354049683  \n","Epoch:6/50     Step:2|6   loss:1.4243348836898804  \n","Epoch:6/50     Step:3|6   loss:2.121582269668579  \n","Epoch:6/50     Step:4|6   loss:1.7571290731430054  \n","Epoch:6/50     Step:5|6   loss:1.5614378452301025  \n","Epoch:6/50     Step:6|6   loss:1.778785228729248  \n","Epoch:6/50     Step:7|6   loss:1.5290725231170654  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:7/50     Step:1|6   loss:1.922149658203125  \n","Epoch:7/50     Step:2|6   loss:1.3941113948822021  \n","Epoch:7/50     Step:3|6   loss:2.0091352462768555  \n","Epoch:7/50     Step:4|6   loss:1.643755316734314  \n","Epoch:7/50     Step:5|6   loss:1.4378358125686646  \n","Epoch:7/50     Step:6|6   loss:1.6781888008117676  \n","Epoch:7/50     Step:7|6   loss:1.522904872894287  \n","Accuracy on test_set: 44.86 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:44.86%\t train set:49.18%\n","Epoch:8/50     Step:1|6   loss:1.7435081005096436  \n","Epoch:8/50     Step:2|6   loss:1.6658098697662354  \n","Epoch:8/50     Step:3|6   loss:1.4580965042114258  \n","Epoch:8/50     Step:4|6   loss:1.2351951599121094  \n","Epoch:8/50     Step:5|6   loss:1.8050150871276855  \n","Epoch:8/50     Step:6|6   loss:1.957180142402649  \n","Epoch:8/50     Step:7|6   loss:1.483873963356018  \n","Accuracy on test_set: 52.34 %\n","Accuracy on train_set: 63.70 %\n","current max accuracy\t test set:52.34%\t train set:63.7%\n","Epoch:9/50     Step:1|6   loss:1.4564510583877563  \n","Epoch:9/50     Step:2|6   loss:1.5871707201004028  \n","Epoch:9/50     Step:3|6   loss:1.3692221641540527  \n","Epoch:9/50     Step:4|6   loss:1.77865469455719  \n","Epoch:9/50     Step:5|6   loss:1.6326264142990112  \n","Epoch:9/50     Step:6|6   loss:1.7087128162384033  \n","Epoch:9/50     Step:7|6   loss:1.5936460494995117  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 62.53 %\n","current max accuracy\t test set:52.34%\t train set:63.7%\n","Epoch:10/50     Step:1|6   loss:1.611970067024231  \n","Epoch:10/50     Step:2|6   loss:1.6580955982208252  \n","Epoch:10/50     Step:3|6   loss:1.651036262512207  \n","Epoch:10/50     Step:4|6   loss:1.4362610578536987  \n","Epoch:10/50     Step:5|6   loss:1.6291677951812744  \n","Epoch:10/50     Step:6|6   loss:1.3233526945114136  \n","Epoch:10/50     Step:7|6   loss:1.6411813497543335  \n","Accuracy on test_set: 57.94 %\n","Accuracy on train_set: 68.15 %\n","current max accuracy\t test set:57.94%\t train set:68.15%\n","Epoch:11/50     Step:1|6   loss:1.7179241180419922  \n","Epoch:11/50     Step:2|6   loss:1.4694048166275024  \n","Epoch:11/50     Step:3|6   loss:1.6479281187057495  \n","Epoch:11/50     Step:4|6   loss:1.392199993133545  \n","Epoch:11/50     Step:5|6   loss:1.4098563194274902  \n","Epoch:11/50     Step:6|6   loss:1.6479500532150269  \n","Epoch:11/50     Step:7|6   loss:1.3351801633834839  \n","Accuracy on test_set: 66.36 %\n","Accuracy on train_set: 74.47 %\n","current max accuracy\t test set:66.36%\t train set:74.47%\n","Epoch:12/50     Step:1|6   loss:1.611754059791565  \n","Epoch:12/50     Step:2|6   loss:1.5177738666534424  \n","Epoch:12/50     Step:3|6   loss:1.4260568618774414  \n","Epoch:12/50     Step:4|6   loss:1.4160274267196655  \n","Epoch:12/50     Step:5|6   loss:1.4302879571914673  \n","Epoch:12/50     Step:6|6   loss:1.3153009414672852  \n","Epoch:12/50     Step:7|6   loss:1.1703380346298218  \n","Accuracy on test_set: 29.91 %\n","Accuracy on train_set: 26.46 %\n","current max accuracy\t test set:66.36%\t train set:74.47%\n","Epoch:13/50     Step:1|6   loss:1.4974381923675537  \n","Epoch:13/50     Step:2|6   loss:1.5495574474334717  \n","Epoch:13/50     Step:3|6   loss:1.6936521530151367  \n","Epoch:13/50     Step:4|6   loss:1.3303513526916504  \n","Epoch:13/50     Step:5|6   loss:1.217186450958252  \n","Epoch:13/50     Step:6|6   loss:1.037977933883667  \n","Epoch:13/50     Step:7|6   loss:0.8741507530212402  \n","Accuracy on test_set: 65.42 %\n","Accuracy on train_set: 73.07 %\n","current max accuracy\t test set:66.36%\t train set:74.47%\n","Epoch:14/50     Step:1|6   loss:0.9173963069915771  \n","Epoch:14/50     Step:2|6   loss:0.8887572288513184  \n","Epoch:14/50     Step:3|6   loss:0.9116778373718262  \n","Epoch:14/50     Step:4|6   loss:0.8808878660202026  \n","Epoch:14/50     Step:5|6   loss:0.9090471267700195  \n","Epoch:14/50     Step:6|6   loss:0.9346054792404175  \n","Epoch:14/50     Step:7|6   loss:0.8571941256523132  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 79.86 %\n","current max accuracy\t test set:74.77%\t train set:79.86%\n","Epoch:15/50     Step:1|6   loss:0.8696157932281494  \n","Epoch:15/50     Step:2|6   loss:0.8023686408996582  \n","Epoch:15/50     Step:3|6   loss:0.8290514349937439  \n","Epoch:15/50     Step:4|6   loss:0.8145861029624939  \n","Epoch:15/50     Step:5|6   loss:0.8467550277709961  \n","Epoch:15/50     Step:6|6   loss:0.8258093595504761  \n","Epoch:15/50     Step:7|6   loss:0.7803510427474976  \n","Accuracy on test_set: 61.68 %\n","Accuracy on train_set: 72.37 %\n","current max accuracy\t test set:74.77%\t train set:79.86%\n","Epoch:16/50     Step:1|6   loss:0.8402199745178223  \n","Epoch:16/50     Step:2|6   loss:0.745618462562561  \n","Epoch:16/50     Step:3|6   loss:0.7681562900543213  \n","Epoch:16/50     Step:4|6   loss:0.777461051940918  \n","Epoch:16/50     Step:5|6   loss:0.8074144124984741  \n","Epoch:16/50     Step:6|6   loss:0.7578895688056946  \n","Epoch:16/50     Step:7|6   loss:0.7979912757873535  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:82.24%\t train set:87.82%\n","Epoch:17/50     Step:1|6   loss:0.7673742771148682  \n","Epoch:17/50     Step:2|6   loss:0.7822326421737671  \n","Epoch:17/50     Step:3|6   loss:0.7388173341751099  \n","Epoch:17/50     Step:4|6   loss:0.7312532663345337  \n","Epoch:17/50     Step:5|6   loss:0.6877733469009399  \n","Epoch:17/50     Step:6|6   loss:0.8038308024406433  \n","Epoch:17/50     Step:7|6   loss:0.7340804934501648  \n","Accuracy on test_set: 71.03 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:82.24%\t train set:87.82%\n","Epoch:18/50     Step:1|6   loss:0.7208705544471741  \n","Epoch:18/50     Step:2|6   loss:0.7418696284294128  \n","Epoch:18/50     Step:3|6   loss:0.7359386682510376  \n","Epoch:18/50     Step:4|6   loss:0.7045271396636963  \n","Epoch:18/50     Step:5|6   loss:0.7202909588813782  \n","Epoch:18/50     Step:6|6   loss:0.6995136141777039  \n","Epoch:18/50     Step:7|6   loss:0.7289005517959595  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:84.11%\t train set:90.16%\n","Epoch:19/50     Step:1|6   loss:0.6966975927352905  \n","Epoch:19/50     Step:2|6   loss:0.715502142906189  \n","Epoch:19/50     Step:3|6   loss:0.6880595088005066  \n","Epoch:19/50     Step:4|6   loss:0.731359601020813  \n","Epoch:19/50     Step:5|6   loss:0.6943453550338745  \n","Epoch:19/50     Step:6|6   loss:0.689690113067627  \n","Epoch:19/50     Step:7|6   loss:0.7182507514953613  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 88.99 %\n","current max accuracy\t test set:84.11%\t train set:90.16%\n","Epoch:20/50     Step:1|6   loss:0.6876299977302551  \n","Epoch:20/50     Step:2|6   loss:0.718845784664154  \n","Epoch:20/50     Step:3|6   loss:0.6733146905899048  \n","Epoch:20/50     Step:4|6   loss:0.6931529641151428  \n","Epoch:20/50     Step:5|6   loss:0.6692804098129272  \n","Epoch:20/50     Step:6|6   loss:0.7133036851882935  \n","Epoch:20/50     Step:7|6   loss:0.6532907485961914  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:86.92%\t train set:93.44%\n","Epoch:21/50     Step:1|6   loss:0.6384074687957764  \n","Epoch:21/50     Step:2|6   loss:0.6582738161087036  \n","Epoch:21/50     Step:3|6   loss:0.6624037027359009  \n","Epoch:21/50     Step:4|6   loss:0.6265116333961487  \n","Epoch:21/50     Step:5|6   loss:0.688411295413971  \n","Epoch:21/50     Step:6|6   loss:0.7055908441543579  \n","Epoch:21/50     Step:7|6   loss:0.6888574361801147  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:88.79%\t train set:95.08%\n","Epoch:22/50     Step:1|6   loss:0.6615442633628845  \n","Epoch:22/50     Step:2|6   loss:0.6378875970840454  \n","Epoch:22/50     Step:3|6   loss:0.7092577219009399  \n","Epoch:22/50     Step:4|6   loss:0.6699927449226379  \n","Epoch:22/50     Step:5|6   loss:0.6353060007095337  \n","Epoch:22/50     Step:6|6   loss:0.6217687129974365  \n","Epoch:22/50     Step:7|6   loss:0.6423824429512024  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:91.59%\t train set:95.55%\n","Epoch:23/50     Step:1|6   loss:0.6484171152114868  \n","Epoch:23/50     Step:2|6   loss:0.6445260047912598  \n","Epoch:23/50     Step:3|6   loss:0.6257103681564331  \n","Epoch:23/50     Step:4|6   loss:0.6248530745506287  \n","Epoch:23/50     Step:5|6   loss:0.6617031097412109  \n","Epoch:23/50     Step:6|6   loss:0.666184663772583  \n","Epoch:23/50     Step:7|6   loss:0.627360463142395  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:92.52%\t train set:95.78%\n","Epoch:24/50     Step:1|6   loss:0.6178222894668579  \n","Epoch:24/50     Step:2|6   loss:0.621208131313324  \n","Epoch:24/50     Step:3|6   loss:0.6276876926422119  \n","Epoch:24/50     Step:4|6   loss:0.6153092384338379  \n","Epoch:24/50     Step:5|6   loss:0.6843989491462708  \n","Epoch:24/50     Step:6|6   loss:0.617121696472168  \n","Epoch:24/50     Step:7|6   loss:0.6605046987533569  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:92.52%\t train set:95.78%\n","Epoch:25/50     Step:1|6   loss:0.6068902015686035  \n","Epoch:25/50     Step:2|6   loss:0.6313565969467163  \n","Epoch:25/50     Step:3|6   loss:0.6472673416137695  \n","Epoch:25/50     Step:4|6   loss:0.6446774005889893  \n","Epoch:25/50     Step:5|6   loss:0.6117562055587769  \n","Epoch:25/50     Step:6|6   loss:0.6447544097900391  \n","Epoch:25/50     Step:7|6   loss:0.6337354183197021  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:92.52%\t train set:95.78%\n","Epoch:26/50     Step:1|6   loss:0.6299313306808472  \n","Epoch:26/50     Step:2|6   loss:0.5835400819778442  \n","Epoch:26/50     Step:3|6   loss:0.6170567274093628  \n","Epoch:26/50     Step:4|6   loss:0.6662609577178955  \n","Epoch:26/50     Step:5|6   loss:0.6764495372772217  \n","Epoch:26/50     Step:6|6   loss:0.5983096361160278  \n","Epoch:26/50     Step:7|6   loss:0.5761686563491821  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:92.52%\t train set:95.78%\n","Epoch:27/50     Step:1|6   loss:0.6840144395828247  \n","Epoch:27/50     Step:2|6   loss:0.6364870071411133  \n","Epoch:27/50     Step:3|6   loss:0.5951343774795532  \n","Epoch:27/50     Step:4|6   loss:0.583279013633728  \n","Epoch:27/50     Step:5|6   loss:0.5970251560211182  \n","Epoch:27/50     Step:6|6   loss:0.5748070478439331  \n","Epoch:27/50     Step:7|6   loss:0.6396824717521667  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:92.52%\t train set:95.78%\n","Epoch:28/50     Step:1|6   loss:0.559262752532959  \n","Epoch:28/50     Step:2|6   loss:0.6845306158065796  \n","Epoch:28/50     Step:3|6   loss:0.5685145854949951  \n","Epoch:28/50     Step:4|6   loss:0.6618271470069885  \n","Epoch:28/50     Step:5|6   loss:0.5903074741363525  \n","Epoch:28/50     Step:6|6   loss:0.5658382773399353  \n","Epoch:28/50     Step:7|6   loss:0.56252521276474  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:92.52%\t train set:96.25%\n","Epoch:29/50     Step:1|6   loss:0.5812636613845825  \n","Epoch:29/50     Step:2|6   loss:0.5736739635467529  \n","Epoch:29/50     Step:3|6   loss:0.5603927373886108  \n","Epoch:29/50     Step:4|6   loss:0.6309643983840942  \n","Epoch:29/50     Step:5|6   loss:0.6229451894760132  \n","Epoch:29/50     Step:6|6   loss:0.5936192274093628  \n","Epoch:29/50     Step:7|6   loss:0.6367384195327759  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:92.52%\t train set:96.49%\n","Epoch:30/50     Step:1|6   loss:0.5859933495521545  \n","Epoch:30/50     Step:2|6   loss:0.5943911075592041  \n","Epoch:30/50     Step:3|6   loss:0.563316822052002  \n","Epoch:30/50     Step:4|6   loss:0.5866634845733643  \n","Epoch:30/50     Step:5|6   loss:0.5725737810134888  \n","Epoch:30/50     Step:6|6   loss:0.6182888746261597  \n","Epoch:30/50     Step:7|6   loss:0.6168798208236694  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:93.46%\t train set:97.19%\n","Epoch:31/50     Step:1|6   loss:0.5897722244262695  \n","Epoch:31/50     Step:2|6   loss:0.5971787571907043  \n","Epoch:31/50     Step:3|6   loss:0.5770847797393799  \n","Epoch:31/50     Step:4|6   loss:0.6028347611427307  \n","Epoch:31/50     Step:5|6   loss:0.5742355585098267  \n","Epoch:31/50     Step:6|6   loss:0.5543919801712036  \n","Epoch:31/50     Step:7|6   loss:0.5763562917709351  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:93.46%\t train set:97.19%\n","Epoch:32/50     Step:1|6   loss:0.5521902441978455  \n","Epoch:32/50     Step:2|6   loss:0.5947867631912231  \n","Epoch:32/50     Step:3|6   loss:0.5660649538040161  \n","Epoch:32/50     Step:4|6   loss:0.5464521646499634  \n","Epoch:32/50     Step:5|6   loss:0.5620342493057251  \n","Epoch:32/50     Step:6|6   loss:0.615309476852417  \n","Epoch:32/50     Step:7|6   loss:0.5875171422958374  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:93.46%\t train set:97.42%\n","Epoch:33/50     Step:1|6   loss:0.5604588985443115  \n","Epoch:33/50     Step:2|6   loss:0.5445745587348938  \n","Epoch:33/50     Step:3|6   loss:0.5669747591018677  \n","Epoch:33/50     Step:4|6   loss:0.5726830959320068  \n","Epoch:33/50     Step:5|6   loss:0.5840480327606201  \n","Epoch:33/50     Step:6|6   loss:0.5621199607849121  \n","Epoch:33/50     Step:7|6   loss:0.6130509972572327  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:93.46%\t train set:97.42%\n","Epoch:34/50     Step:1|6   loss:0.5778021812438965  \n","Epoch:34/50     Step:2|6   loss:0.5602855682373047  \n","Epoch:34/50     Step:3|6   loss:0.5975754261016846  \n","Epoch:34/50     Step:4|6   loss:0.531624436378479  \n","Epoch:34/50     Step:5|6   loss:0.5791115164756775  \n","Epoch:34/50     Step:6|6   loss:0.5638591647148132  \n","Epoch:34/50     Step:7|6   loss:0.5322831273078918  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:93.46%\t train set:97.42%\n","Epoch:35/50     Step:1|6   loss:0.5459352135658264  \n","Epoch:35/50     Step:2|6   loss:0.5693287253379822  \n","Epoch:35/50     Step:3|6   loss:0.569010853767395  \n","Epoch:35/50     Step:4|6   loss:0.5552886128425598  \n","Epoch:35/50     Step:5|6   loss:0.5415633916854858  \n","Epoch:35/50     Step:6|6   loss:0.5483803749084473  \n","Epoch:35/50     Step:7|6   loss:0.5864050388336182  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:93.46%\t train set:97.66%\n","Epoch:36/50     Step:1|6   loss:0.5588812828063965  \n","Epoch:36/50     Step:2|6   loss:0.5393338203430176  \n","Epoch:36/50     Step:3|6   loss:0.5252475142478943  \n","Epoch:36/50     Step:4|6   loss:0.5207968950271606  \n","Epoch:36/50     Step:5|6   loss:0.5670518279075623  \n","Epoch:36/50     Step:6|6   loss:0.5595431327819824  \n","Epoch:36/50     Step:7|6   loss:0.6168776750564575  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:93.46%\t train set:97.66%\n","Epoch:37/50     Step:1|6   loss:0.5264759063720703  \n","Epoch:37/50     Step:2|6   loss:0.563457190990448  \n","Epoch:37/50     Step:3|6   loss:0.5866212844848633  \n","Epoch:37/50     Step:4|6   loss:0.54096919298172  \n","Epoch:37/50     Step:5|6   loss:0.5553683042526245  \n","Epoch:37/50     Step:6|6   loss:0.514151930809021  \n","Epoch:37/50     Step:7|6   loss:0.5463272333145142  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:93.46%\t train set:97.66%\n","Epoch:38/50     Step:1|6   loss:0.5630056858062744  \n","Epoch:38/50     Step:2|6   loss:0.5197696685791016  \n","Epoch:38/50     Step:3|6   loss:0.556216299533844  \n","Epoch:38/50     Step:4|6   loss:0.5308961868286133  \n","Epoch:38/50     Step:5|6   loss:0.5815640091896057  \n","Epoch:38/50     Step:6|6   loss:0.5180948972702026  \n","Epoch:38/50     Step:7|6   loss:0.5352502465248108  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:94.39%\t train set:97.89%\n","Epoch:39/50     Step:1|6   loss:0.5162482857704163  \n","Epoch:39/50     Step:2|6   loss:0.5126041173934937  \n","Epoch:39/50     Step:3|6   loss:0.5402511358261108  \n","Epoch:39/50     Step:4|6   loss:0.5832892060279846  \n","Epoch:39/50     Step:5|6   loss:0.5480868220329285  \n","Epoch:39/50     Step:6|6   loss:0.54377681016922  \n","Epoch:39/50     Step:7|6   loss:0.5384802222251892  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:94.39%\t train set:97.89%\n","Epoch:40/50     Step:1|6   loss:0.5382876992225647  \n","Epoch:40/50     Step:2|6   loss:0.5513635277748108  \n","Epoch:40/50     Step:3|6   loss:0.5340953469276428  \n","Epoch:40/50     Step:4|6   loss:0.5360069870948792  \n","Epoch:40/50     Step:5|6   loss:0.5633360147476196  \n","Epoch:40/50     Step:6|6   loss:0.5254992842674255  \n","Epoch:40/50     Step:7|6   loss:0.5132527351379395  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:94.39%\t train set:97.89%\n","Epoch:41/50     Step:1|6   loss:0.5156944394111633  \n","Epoch:41/50     Step:2|6   loss:0.5327039957046509  \n","Epoch:41/50     Step:3|6   loss:0.5218471884727478  \n","Epoch:41/50     Step:4|6   loss:0.5619814395904541  \n","Epoch:41/50     Step:5|6   loss:0.5281837582588196  \n","Epoch:41/50     Step:6|6   loss:0.5802962183952332  \n","Epoch:41/50     Step:7|6   loss:0.5047982931137085  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:94.39%\t train set:97.89%\n","Epoch:42/50     Step:1|6   loss:0.5260517597198486  \n","Epoch:42/50     Step:2|6   loss:0.5222477316856384  \n","Epoch:42/50     Step:3|6   loss:0.5242249369621277  \n","Epoch:42/50     Step:4|6   loss:0.5225608944892883  \n","Epoch:42/50     Step:5|6   loss:0.5828090310096741  \n","Epoch:42/50     Step:6|6   loss:0.5278175473213196  \n","Epoch:42/50     Step:7|6   loss:0.5410899519920349  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:94.39%\t train set:97.89%\n","Epoch:43/50     Step:1|6   loss:0.5454304218292236  \n","Epoch:43/50     Step:2|6   loss:0.506941556930542  \n","Epoch:43/50     Step:3|6   loss:0.5052750110626221  \n","Epoch:43/50     Step:4|6   loss:0.5800722241401672  \n","Epoch:43/50     Step:5|6   loss:0.5430623292922974  \n","Epoch:43/50     Step:6|6   loss:0.5284658670425415  \n","Epoch:43/50     Step:7|6   loss:0.5020816326141357  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:44/50     Step:1|6   loss:0.5101646184921265  \n","Epoch:44/50     Step:2|6   loss:0.49906086921691895  \n","Epoch:44/50     Step:3|6   loss:0.5230120420455933  \n","Epoch:44/50     Step:4|6   loss:0.5782646536827087  \n","Epoch:44/50     Step:5|6   loss:0.5047339797019958  \n","Epoch:44/50     Step:6|6   loss:0.5184091925621033  \n","Epoch:44/50     Step:7|6   loss:0.5922852158546448  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:45/50     Step:1|6   loss:0.5046098232269287  \n","Epoch:45/50     Step:2|6   loss:0.5199489593505859  \n","Epoch:45/50     Step:3|6   loss:0.5170445442199707  \n","Epoch:45/50     Step:4|6   loss:0.5435050129890442  \n","Epoch:45/50     Step:5|6   loss:0.5223748683929443  \n","Epoch:45/50     Step:6|6   loss:0.5188425183296204  \n","Epoch:45/50     Step:7|6   loss:0.5950191617012024  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:46/50     Step:1|6   loss:0.5073235034942627  \n","Epoch:46/50     Step:2|6   loss:0.520254373550415  \n","Epoch:46/50     Step:3|6   loss:0.5191007852554321  \n","Epoch:46/50     Step:4|6   loss:0.555887758731842  \n","Epoch:46/50     Step:5|6   loss:0.5368654727935791  \n","Epoch:46/50     Step:6|6   loss:0.5158337950706482  \n","Epoch:46/50     Step:7|6   loss:0.5310661792755127  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:47/50     Step:1|6   loss:0.5215337872505188  \n","Epoch:47/50     Step:2|6   loss:0.5575363636016846  \n","Epoch:47/50     Step:3|6   loss:0.4995116591453552  \n","Epoch:47/50     Step:4|6   loss:0.49388986825942993  \n","Epoch:47/50     Step:5|6   loss:0.5156316757202148  \n","Epoch:47/50     Step:6|6   loss:0.5375005602836609  \n","Epoch:47/50     Step:7|6   loss:0.5584639310836792  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:48/50     Step:1|6   loss:0.5351849794387817  \n","Epoch:48/50     Step:2|6   loss:0.5137131810188293  \n","Epoch:48/50     Step:3|6   loss:0.5370727777481079  \n","Epoch:48/50     Step:4|6   loss:0.5183306932449341  \n","Epoch:48/50     Step:5|6   loss:0.5330694913864136  \n","Epoch:48/50     Step:6|6   loss:0.5001320242881775  \n","Epoch:48/50     Step:7|6   loss:0.5214968919754028  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:49/50     Step:1|6   loss:0.5363626480102539  \n","Epoch:49/50     Step:2|6   loss:0.5706665515899658  \n","Epoch:49/50     Step:3|6   loss:0.5115751028060913  \n","Epoch:49/50     Step:4|6   loss:0.5159127712249756  \n","Epoch:49/50     Step:5|6   loss:0.4980008602142334  \n","Epoch:49/50     Step:6|6   loss:0.5132603049278259  \n","Epoch:49/50     Step:7|6   loss:0.5008996725082397  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Epoch:50/50     Step:1|6   loss:0.5102483630180359  \n","Epoch:50/50     Step:2|6   loss:0.5376767516136169  \n","Epoch:50/50     Step:3|6   loss:0.5713813900947571  \n","Epoch:50/50     Step:4|6   loss:0.4955393075942993  \n","Epoch:50/50     Step:5|6   loss:0.5130516886711121  \n","Epoch:50/50     Step:6|6   loss:0.4914436340332031  \n","Epoch:50/50     Step:7|6   loss:0.5218502879142761  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:95.33%\t train set:97.89%\n","Accuracy on test_set: 94.39 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0982342958450317  \n","Epoch:1/50     Step:2|6   loss:2.610713481903076  \n","Epoch:1/50     Step:3|6   loss:2.1290903091430664  \n","Epoch:1/50     Step:4|6   loss:2.5291926860809326  \n","Epoch:1/50     Step:5|6   loss:2.3244192600250244  \n","Epoch:1/50     Step:6|6   loss:2.452439069747925  \n","Epoch:1/50     Step:7|6   loss:1.9308207035064697  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:2/50     Step:1|6   loss:2.0057034492492676  \n","Epoch:2/50     Step:2|6   loss:2.8837015628814697  \n","Epoch:2/50     Step:3|6   loss:2.201181411743164  \n","Epoch:2/50     Step:4|6   loss:2.2641801834106445  \n","Epoch:2/50     Step:5|6   loss:1.8065407276153564  \n","Epoch:2/50     Step:6|6   loss:2.505202531814575  \n","Epoch:2/50     Step:7|6   loss:1.5485899448394775  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:3/50     Step:1|6   loss:2.3111555576324463  \n","Epoch:3/50     Step:2|6   loss:1.8970390558242798  \n","Epoch:3/50     Step:3|6   loss:1.8297979831695557  \n","Epoch:3/50     Step:4|6   loss:2.4843909740448  \n","Epoch:3/50     Step:5|6   loss:1.8853247165679932  \n","Epoch:3/50     Step:6|6   loss:2.3481199741363525  \n","Epoch:3/50     Step:7|6   loss:2.3986494541168213  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:4/50     Step:1|6   loss:2.180753231048584  \n","Epoch:4/50     Step:2|6   loss:1.9405832290649414  \n","Epoch:4/50     Step:3|6   loss:2.2713024616241455  \n","Epoch:4/50     Step:4|6   loss:2.083622694015503  \n","Epoch:4/50     Step:5|6   loss:1.5429255962371826  \n","Epoch:4/50     Step:6|6   loss:2.4134035110473633  \n","Epoch:4/50     Step:7|6   loss:2.504169225692749  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:5/50     Step:1|6   loss:1.776397466659546  \n","Epoch:5/50     Step:2|6   loss:2.227947235107422  \n","Epoch:5/50     Step:3|6   loss:2.266115188598633  \n","Epoch:5/50     Step:4|6   loss:2.1439757347106934  \n","Epoch:5/50     Step:5|6   loss:1.9803756475448608  \n","Epoch:5/50     Step:6|6   loss:2.052473545074463  \n","Epoch:5/50     Step:7|6   loss:2.0428972244262695  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:6/50     Step:1|6   loss:1.893537998199463  \n","Epoch:6/50     Step:2|6   loss:1.770868182182312  \n","Epoch:6/50     Step:3|6   loss:2.5752601623535156  \n","Epoch:6/50     Step:4|6   loss:2.0633692741394043  \n","Epoch:6/50     Step:5|6   loss:2.075047492980957  \n","Epoch:6/50     Step:6|6   loss:1.8238518238067627  \n","Epoch:6/50     Step:7|6   loss:2.032407522201538  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:7/50     Step:1|6   loss:1.9934711456298828  \n","Epoch:7/50     Step:2|6   loss:2.280956268310547  \n","Epoch:7/50     Step:3|6   loss:1.6229522228240967  \n","Epoch:7/50     Step:4|6   loss:1.9608967304229736  \n","Epoch:7/50     Step:5|6   loss:1.897371768951416  \n","Epoch:7/50     Step:6|6   loss:1.952538013458252  \n","Epoch:7/50     Step:7|6   loss:2.259053945541382  \n","Accuracy on test_set: 42.99 %\n","Accuracy on train_set: 46.14 %\n","current max accuracy\t test set:42.99%\t train set:46.14%\n","Epoch:8/50     Step:1|6   loss:1.5769875049591064  \n","Epoch:8/50     Step:2|6   loss:2.0555286407470703  \n","Epoch:8/50     Step:3|6   loss:2.2106924057006836  \n","Epoch:8/50     Step:4|6   loss:2.052151679992676  \n","Epoch:8/50     Step:5|6   loss:1.7707749605178833  \n","Epoch:8/50     Step:6|6   loss:1.7377679347991943  \n","Epoch:8/50     Step:7|6   loss:2.268178701400757  \n","Accuracy on test_set: 67.29 %\n","Accuracy on train_set: 69.32 %\n","current max accuracy\t test set:67.29%\t train set:69.32%\n","Epoch:9/50     Step:1|6   loss:1.771824598312378  \n","Epoch:9/50     Step:2|6   loss:2.3275530338287354  \n","Epoch:9/50     Step:3|6   loss:1.983859658241272  \n","Epoch:9/50     Step:4|6   loss:1.8766200542449951  \n","Epoch:9/50     Step:5|6   loss:1.7282748222351074  \n","Epoch:9/50     Step:6|6   loss:1.4743552207946777  \n","Epoch:9/50     Step:7|6   loss:1.038151502609253  \n","Accuracy on test_set: 46.73 %\n","Accuracy on train_set: 46.84 %\n","current max accuracy\t test set:67.29%\t train set:69.32%\n","Epoch:10/50     Step:1|6   loss:1.2712401151657104  \n","Epoch:10/50     Step:2|6   loss:1.2649083137512207  \n","Epoch:10/50     Step:3|6   loss:0.9732084274291992  \n","Epoch:10/50     Step:4|6   loss:0.7767412662506104  \n","Epoch:10/50     Step:5|6   loss:0.7180795669555664  \n","Epoch:10/50     Step:6|6   loss:0.781023383140564  \n","Epoch:10/50     Step:7|6   loss:0.6252268552780151  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.89 %\n","current max accuracy\t test set:84.11%\t train set:86.89%\n","Epoch:11/50     Step:1|6   loss:0.6605459451675415  \n","Epoch:11/50     Step:2|6   loss:0.7014169096946716  \n","Epoch:11/50     Step:3|6   loss:0.6590858697891235  \n","Epoch:11/50     Step:4|6   loss:0.6082435846328735  \n","Epoch:11/50     Step:5|6   loss:0.667273998260498  \n","Epoch:11/50     Step:6|6   loss:0.6157571077346802  \n","Epoch:11/50     Step:7|6   loss:0.7900514006614685  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:96.26%\t train set:94.61%\n","Epoch:12/50     Step:1|6   loss:0.5706632733345032  \n","Epoch:12/50     Step:2|6   loss:0.6267915964126587  \n","Epoch:12/50     Step:3|6   loss:0.6440058946609497  \n","Epoch:12/50     Step:4|6   loss:0.6780421733856201  \n","Epoch:12/50     Step:5|6   loss:0.5722009539604187  \n","Epoch:12/50     Step:6|6   loss:0.6660566329956055  \n","Epoch:12/50     Step:7|6   loss:0.5527022480964661  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:98.13%\t train set:95.08%\n","Epoch:13/50     Step:1|6   loss:0.6072847843170166  \n","Epoch:13/50     Step:2|6   loss:0.639157772064209  \n","Epoch:13/50     Step:3|6   loss:0.5429854393005371  \n","Epoch:13/50     Step:4|6   loss:0.5644900798797607  \n","Epoch:13/50     Step:5|6   loss:0.5866554975509644  \n","Epoch:13/50     Step:6|6   loss:0.6507681608200073  \n","Epoch:13/50     Step:7|6   loss:0.5442438721656799  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:98.13%\t train set:96.72%\n","Epoch:14/50     Step:1|6   loss:0.5220502018928528  \n","Epoch:14/50     Step:2|6   loss:0.6442322134971619  \n","Epoch:14/50     Step:3|6   loss:0.5685782432556152  \n","Epoch:14/50     Step:4|6   loss:0.5767461061477661  \n","Epoch:14/50     Step:5|6   loss:0.607086181640625  \n","Epoch:14/50     Step:6|6   loss:0.5485342144966125  \n","Epoch:14/50     Step:7|6   loss:0.5504385828971863  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:15/50     Step:1|6   loss:0.5613903403282166  \n","Epoch:15/50     Step:2|6   loss:0.5709534287452698  \n","Epoch:15/50     Step:3|6   loss:0.5792776942253113  \n","Epoch:15/50     Step:4|6   loss:0.6421713829040527  \n","Epoch:15/50     Step:5|6   loss:0.5468175411224365  \n","Epoch:15/50     Step:6|6   loss:0.5202677249908447  \n","Epoch:15/50     Step:7|6   loss:0.520691990852356  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:16/50     Step:1|6   loss:0.5926134586334229  \n","Epoch:16/50     Step:2|6   loss:0.529443621635437  \n","Epoch:16/50     Step:3|6   loss:0.6005827188491821  \n","Epoch:16/50     Step:4|6   loss:0.5836595296859741  \n","Epoch:16/50     Step:5|6   loss:0.5544366240501404  \n","Epoch:16/50     Step:6|6   loss:0.509920597076416  \n","Epoch:16/50     Step:7|6   loss:0.5528022050857544  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:98.13%\t train set:98.13%\n","Epoch:17/50     Step:1|6   loss:0.5588337779045105  \n","Epoch:17/50     Step:2|6   loss:0.5081808567047119  \n","Epoch:17/50     Step:3|6   loss:0.5234893560409546  \n","Epoch:17/50     Step:4|6   loss:0.5564428567886353  \n","Epoch:17/50     Step:5|6   loss:0.552038848400116  \n","Epoch:17/50     Step:6|6   loss:0.5562363862991333  \n","Epoch:17/50     Step:7|6   loss:0.6397365927696228  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:98.13%\n","Epoch:18/50     Step:1|6   loss:0.5178754329681396  \n","Epoch:18/50     Step:2|6   loss:0.625682532787323  \n","Epoch:18/50     Step:3|6   loss:0.5445107817649841  \n","Epoch:18/50     Step:4|6   loss:0.5444837212562561  \n","Epoch:18/50     Step:5|6   loss:0.5546846985816956  \n","Epoch:18/50     Step:6|6   loss:0.5062587857246399  \n","Epoch:18/50     Step:7|6   loss:0.5022760629653931  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:19/50     Step:1|6   loss:0.5433973670005798  \n","Epoch:19/50     Step:2|6   loss:0.5442942976951599  \n","Epoch:19/50     Step:3|6   loss:0.509111762046814  \n","Epoch:19/50     Step:4|6   loss:0.5477644801139832  \n","Epoch:19/50     Step:5|6   loss:0.5414563417434692  \n","Epoch:19/50     Step:6|6   loss:0.5523568391799927  \n","Epoch:19/50     Step:7|6   loss:0.5340508222579956  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:20/50     Step:1|6   loss:0.5731270909309387  \n","Epoch:20/50     Step:2|6   loss:0.5532308220863342  \n","Epoch:20/50     Step:3|6   loss:0.4968520402908325  \n","Epoch:20/50     Step:4|6   loss:0.553506076335907  \n","Epoch:20/50     Step:5|6   loss:0.5453143119812012  \n","Epoch:20/50     Step:6|6   loss:0.5052239894866943  \n","Epoch:20/50     Step:7|6   loss:0.5104075074195862  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:21/50     Step:1|6   loss:0.5405138731002808  \n","Epoch:21/50     Step:2|6   loss:0.49979716539382935  \n","Epoch:21/50     Step:3|6   loss:0.501166582107544  \n","Epoch:21/50     Step:4|6   loss:0.5344776511192322  \n","Epoch:21/50     Step:5|6   loss:0.5510260462760925  \n","Epoch:21/50     Step:6|6   loss:0.5731861591339111  \n","Epoch:21/50     Step:7|6   loss:0.5265363454818726  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:99.07%\t train set:98.13%\n","Epoch:22/50     Step:1|6   loss:0.5653203725814819  \n","Epoch:22/50     Step:2|6   loss:0.5559920072555542  \n","Epoch:22/50     Step:3|6   loss:0.5076162219047546  \n","Epoch:22/50     Step:4|6   loss:0.5187386274337769  \n","Epoch:22/50     Step:5|6   loss:0.53963303565979  \n","Epoch:22/50     Step:6|6   loss:0.5215715169906616  \n","Epoch:22/50     Step:7|6   loss:0.49787312746047974  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:98.36%\n","Epoch:23/50     Step:1|6   loss:0.510486364364624  \n","Epoch:23/50     Step:2|6   loss:0.531662106513977  \n","Epoch:23/50     Step:3|6   loss:0.5087081789970398  \n","Epoch:23/50     Step:4|6   loss:0.5199375152587891  \n","Epoch:23/50     Step:5|6   loss:0.536347508430481  \n","Epoch:23/50     Step:6|6   loss:0.541661262512207  \n","Epoch:23/50     Step:7|6   loss:0.5586004257202148  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:98.36%\n","Epoch:24/50     Step:1|6   loss:0.5393364429473877  \n","Epoch:24/50     Step:2|6   loss:0.5014402866363525  \n","Epoch:24/50     Step:3|6   loss:0.5381118059158325  \n","Epoch:24/50     Step:4|6   loss:0.521061897277832  \n","Epoch:24/50     Step:5|6   loss:0.5368637442588806  \n","Epoch:24/50     Step:6|6   loss:0.5441328287124634  \n","Epoch:24/50     Step:7|6   loss:0.4942223131656647  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:99.07%\t train set:98.36%\n","Epoch:25/50     Step:1|6   loss:0.5901771187782288  \n","Epoch:25/50     Step:2|6   loss:0.5381066203117371  \n","Epoch:25/50     Step:3|6   loss:0.5078328847885132  \n","Epoch:25/50     Step:4|6   loss:0.49552035331726074  \n","Epoch:25/50     Step:5|6   loss:0.4940856695175171  \n","Epoch:25/50     Step:6|6   loss:0.5254380702972412  \n","Epoch:25/50     Step:7|6   loss:0.5209649205207825  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:98.36%\n","Epoch:26/50     Step:1|6   loss:0.5055205821990967  \n","Epoch:26/50     Step:2|6   loss:0.5683927536010742  \n","Epoch:26/50     Step:3|6   loss:0.5250400304794312  \n","Epoch:26/50     Step:4|6   loss:0.5066764950752258  \n","Epoch:26/50     Step:5|6   loss:0.5563998222351074  \n","Epoch:26/50     Step:6|6   loss:0.4994988441467285  \n","Epoch:26/50     Step:7|6   loss:0.49529337882995605  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:98.36%\n","Epoch:27/50     Step:1|6   loss:0.5160733461380005  \n","Epoch:27/50     Step:2|6   loss:0.5001071691513062  \n","Epoch:27/50     Step:3|6   loss:0.5076152086257935  \n","Epoch:27/50     Step:4|6   loss:0.5364540219306946  \n","Epoch:27/50     Step:5|6   loss:0.5266609787940979  \n","Epoch:27/50     Step:6|6   loss:0.5270891785621643  \n","Epoch:27/50     Step:7|6   loss:0.5567286014556885  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:28/50     Step:1|6   loss:0.499322772026062  \n","Epoch:28/50     Step:2|6   loss:0.5344890356063843  \n","Epoch:28/50     Step:3|6   loss:0.5325927734375  \n","Epoch:28/50     Step:4|6   loss:0.5315344333648682  \n","Epoch:28/50     Step:5|6   loss:0.5321470499038696  \n","Epoch:28/50     Step:6|6   loss:0.5152544975280762  \n","Epoch:28/50     Step:7|6   loss:0.49320241808891296  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:29/50     Step:1|6   loss:0.5078295469284058  \n","Epoch:29/50     Step:2|6   loss:0.5004734992980957  \n","Epoch:29/50     Step:3|6   loss:0.5288846492767334  \n","Epoch:29/50     Step:4|6   loss:0.5285803079605103  \n","Epoch:29/50     Step:5|6   loss:0.4981488585472107  \n","Epoch:29/50     Step:6|6   loss:0.528676450252533  \n","Epoch:29/50     Step:7|6   loss:0.5465010404586792  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:30/50     Step:1|6   loss:0.49583715200424194  \n","Epoch:30/50     Step:2|6   loss:0.4946444034576416  \n","Epoch:30/50     Step:3|6   loss:0.5692793130874634  \n","Epoch:30/50     Step:4|6   loss:0.5315596461296082  \n","Epoch:30/50     Step:5|6   loss:0.5302968621253967  \n","Epoch:30/50     Step:6|6   loss:0.4910959303379059  \n","Epoch:30/50     Step:7|6   loss:0.49561694264411926  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:31/50     Step:1|6   loss:0.4973280727863312  \n","Epoch:31/50     Step:2|6   loss:0.49272072315216064  \n","Epoch:31/50     Step:3|6   loss:0.5474047660827637  \n","Epoch:31/50     Step:4|6   loss:0.5486980676651001  \n","Epoch:31/50     Step:5|6   loss:0.4947926998138428  \n","Epoch:31/50     Step:6|6   loss:0.5114263296127319  \n","Epoch:31/50     Step:7|6   loss:0.49351611733436584  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:32/50     Step:1|6   loss:0.5069716572761536  \n","Epoch:32/50     Step:2|6   loss:0.5157240629196167  \n","Epoch:32/50     Step:3|6   loss:0.5208765268325806  \n","Epoch:32/50     Step:4|6   loss:0.5226758718490601  \n","Epoch:32/50     Step:5|6   loss:0.4964611232280731  \n","Epoch:32/50     Step:6|6   loss:0.5221151113510132  \n","Epoch:32/50     Step:7|6   loss:0.4959726333618164  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:33/50     Step:1|6   loss:0.5081284046173096  \n","Epoch:33/50     Step:2|6   loss:0.5033494234085083  \n","Epoch:33/50     Step:3|6   loss:0.549531102180481  \n","Epoch:33/50     Step:4|6   loss:0.5173763036727905  \n","Epoch:33/50     Step:5|6   loss:0.4923630356788635  \n","Epoch:33/50     Step:6|6   loss:0.5191625356674194  \n","Epoch:33/50     Step:7|6   loss:0.49989253282546997  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:34/50     Step:1|6   loss:0.49932122230529785  \n","Epoch:34/50     Step:2|6   loss:0.5142663717269897  \n","Epoch:34/50     Step:3|6   loss:0.5220887660980225  \n","Epoch:34/50     Step:4|6   loss:0.5214295387268066  \n","Epoch:34/50     Step:5|6   loss:0.49502402544021606  \n","Epoch:34/50     Step:6|6   loss:0.5301039218902588  \n","Epoch:34/50     Step:7|6   loss:0.49506038427352905  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:35/50     Step:1|6   loss:0.4922448396682739  \n","Epoch:35/50     Step:2|6   loss:0.5188806056976318  \n","Epoch:35/50     Step:3|6   loss:0.5034342408180237  \n","Epoch:35/50     Step:4|6   loss:0.5208404064178467  \n","Epoch:35/50     Step:5|6   loss:0.519853949546814  \n","Epoch:35/50     Step:6|6   loss:0.5197751522064209  \n","Epoch:35/50     Step:7|6   loss:0.4924056828022003  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:36/50     Step:1|6   loss:0.5453864336013794  \n","Epoch:36/50     Step:2|6   loss:0.5321969985961914  \n","Epoch:36/50     Step:3|6   loss:0.490985631942749  \n","Epoch:36/50     Step:4|6   loss:0.4958135485649109  \n","Epoch:36/50     Step:5|6   loss:0.5131257176399231  \n","Epoch:36/50     Step:6|6   loss:0.49097388982772827  \n","Epoch:36/50     Step:7|6   loss:0.4952771067619324  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:37/50     Step:1|6   loss:0.5139778256416321  \n","Epoch:37/50     Step:2|6   loss:0.49069273471832275  \n","Epoch:37/50     Step:3|6   loss:0.5428937673568726  \n","Epoch:37/50     Step:4|6   loss:0.49070224165916443  \n","Epoch:37/50     Step:5|6   loss:0.4977266788482666  \n","Epoch:37/50     Step:6|6   loss:0.49512892961502075  \n","Epoch:37/50     Step:7|6   loss:0.5439243316650391  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:38/50     Step:1|6   loss:0.4925704598426819  \n","Epoch:38/50     Step:2|6   loss:0.49410468339920044  \n","Epoch:38/50     Step:3|6   loss:0.5356729030609131  \n","Epoch:38/50     Step:4|6   loss:0.5140208005905151  \n","Epoch:38/50     Step:5|6   loss:0.49173861742019653  \n","Epoch:38/50     Step:6|6   loss:0.5062912702560425  \n","Epoch:38/50     Step:7|6   loss:0.5310441255569458  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:39/50     Step:1|6   loss:0.49428606033325195  \n","Epoch:39/50     Step:2|6   loss:0.5137060880661011  \n","Epoch:39/50     Step:3|6   loss:0.5033851861953735  \n","Epoch:39/50     Step:4|6   loss:0.5162835717201233  \n","Epoch:39/50     Step:5|6   loss:0.5167818665504456  \n","Epoch:39/50     Step:6|6   loss:0.49076056480407715  \n","Epoch:39/50     Step:7|6   loss:0.523873507976532  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:40/50     Step:1|6   loss:0.4921939969062805  \n","Epoch:40/50     Step:2|6   loss:0.5107942819595337  \n","Epoch:40/50     Step:3|6   loss:0.535379946231842  \n","Epoch:40/50     Step:4|6   loss:0.5232807397842407  \n","Epoch:40/50     Step:5|6   loss:0.49151110649108887  \n","Epoch:40/50     Step:6|6   loss:0.49115079641342163  \n","Epoch:40/50     Step:7|6   loss:0.5080799460411072  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:41/50     Step:1|6   loss:0.4905596077442169  \n","Epoch:41/50     Step:2|6   loss:0.5145897269248962  \n","Epoch:41/50     Step:3|6   loss:0.5155068039894104  \n","Epoch:41/50     Step:4|6   loss:0.5306993722915649  \n","Epoch:41/50     Step:5|6   loss:0.5075894594192505  \n","Epoch:41/50     Step:6|6   loss:0.49110931158065796  \n","Epoch:41/50     Step:7|6   loss:0.4905996322631836  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:42/50     Step:1|6   loss:0.4902891516685486  \n","Epoch:42/50     Step:2|6   loss:0.4931979179382324  \n","Epoch:42/50     Step:3|6   loss:0.5301223993301392  \n","Epoch:42/50     Step:4|6   loss:0.547245979309082  \n","Epoch:42/50     Step:5|6   loss:0.4891767203807831  \n","Epoch:42/50     Step:6|6   loss:0.4909082055091858  \n","Epoch:42/50     Step:7|6   loss:0.4887970983982086  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:43/50     Step:1|6   loss:0.49255645275115967  \n","Epoch:43/50     Step:2|6   loss:0.49289727210998535  \n","Epoch:43/50     Step:3|6   loss:0.4907507300376892  \n","Epoch:43/50     Step:4|6   loss:0.5072965621948242  \n","Epoch:43/50     Step:5|6   loss:0.5100311636924744  \n","Epoch:43/50     Step:6|6   loss:0.50633305311203  \n","Epoch:43/50     Step:7|6   loss:0.5363238453865051  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:44/50     Step:1|6   loss:0.525926411151886  \n","Epoch:44/50     Step:2|6   loss:0.48905014991760254  \n","Epoch:44/50     Step:3|6   loss:0.511060893535614  \n","Epoch:44/50     Step:4|6   loss:0.5042110085487366  \n","Epoch:44/50     Step:5|6   loss:0.5014158487319946  \n","Epoch:44/50     Step:6|6   loss:0.4948018193244934  \n","Epoch:44/50     Step:7|6   loss:0.49048280715942383  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:45/50     Step:1|6   loss:0.4926795959472656  \n","Epoch:45/50     Step:2|6   loss:0.5209592580795288  \n","Epoch:45/50     Step:3|6   loss:0.48871493339538574  \n","Epoch:45/50     Step:4|6   loss:0.49188685417175293  \n","Epoch:45/50     Step:5|6   loss:0.5148539543151855  \n","Epoch:45/50     Step:6|6   loss:0.5063230395317078  \n","Epoch:45/50     Step:7|6   loss:0.4936339259147644  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:46/50     Step:1|6   loss:0.4929053485393524  \n","Epoch:46/50     Step:2|6   loss:0.5061358213424683  \n","Epoch:46/50     Step:3|6   loss:0.4901399612426758  \n","Epoch:46/50     Step:4|6   loss:0.4953826069831848  \n","Epoch:46/50     Step:5|6   loss:0.4888567626476288  \n","Epoch:46/50     Step:6|6   loss:0.5184026956558228  \n","Epoch:46/50     Step:7|6   loss:0.527077317237854  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:47/50     Step:1|6   loss:0.48947516083717346  \n","Epoch:47/50     Step:2|6   loss:0.5058192610740662  \n","Epoch:47/50     Step:3|6   loss:0.5077958106994629  \n","Epoch:47/50     Step:4|6   loss:0.4878777861595154  \n","Epoch:47/50     Step:5|6   loss:0.4884853959083557  \n","Epoch:47/50     Step:6|6   loss:0.5183376669883728  \n","Epoch:47/50     Step:7|6   loss:0.5122793912887573  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:48/50     Step:1|6   loss:0.5040019154548645  \n","Epoch:48/50     Step:2|6   loss:0.5232192277908325  \n","Epoch:48/50     Step:3|6   loss:0.5009335875511169  \n","Epoch:48/50     Step:4|6   loss:0.5023778676986694  \n","Epoch:48/50     Step:5|6   loss:0.49083012342453003  \n","Epoch:48/50     Step:6|6   loss:0.4880824089050293  \n","Epoch:48/50     Step:7|6   loss:0.4891759753227234  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:49/50     Step:1|6   loss:0.5198914408683777  \n","Epoch:49/50     Step:2|6   loss:0.4902955889701843  \n","Epoch:49/50     Step:3|6   loss:0.4900468587875366  \n","Epoch:49/50     Step:4|6   loss:0.49186646938323975  \n","Epoch:49/50     Step:5|6   loss:0.5273061394691467  \n","Epoch:49/50     Step:6|6   loss:0.489243745803833  \n","Epoch:49/50     Step:7|6   loss:0.4874749183654785  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Epoch:50/50     Step:1|6   loss:0.5044521689414978  \n","Epoch:50/50     Step:2|6   loss:0.5038954019546509  \n","Epoch:50/50     Step:3|6   loss:0.48826998472213745  \n","Epoch:50/50     Step:4|6   loss:0.5014451742172241  \n","Epoch:50/50     Step:5|6   loss:0.48911431431770325  \n","Epoch:50/50     Step:6|6   loss:0.5151355266571045  \n","Epoch:50/50     Step:7|6   loss:0.49326837062835693  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:98.83%\n","Accuracy on test_set: 98.13 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model LeNet5_one_stream --mode rgb --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":16,"id":"632d458a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0814266204833984  \n","Epoch:1/50     Step:2|6   loss:1.5695348978042603  \n","Epoch:1/50     Step:3|6   loss:1.4583426713943481  \n","Epoch:1/50     Step:4|6   loss:1.0426924228668213  \n","Epoch:1/50     Step:5|6   loss:0.8149125576019287  \n","Epoch:1/50     Step:6|6   loss:0.755958080291748  \n","Epoch:1/50     Step:7|6   loss:0.7905488014221191  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 79.63 %\n","current max accuracy\t test set:72.9%\t train set:79.63%\n","Epoch:2/50     Step:1|6   loss:0.7015641927719116  \n","Epoch:2/50     Step:2|6   loss:0.7158113718032837  \n","Epoch:2/50     Step:3|6   loss:0.6723470687866211  \n","Epoch:2/50     Step:4|6   loss:0.7255241870880127  \n","Epoch:2/50     Step:5|6   loss:0.660117506980896  \n","Epoch:2/50     Step:6|6   loss:0.7000032663345337  \n","Epoch:2/50     Step:7|6   loss:0.8446760773658752  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:83.18%\t train set:87.35%\n","Epoch:3/50     Step:1|6   loss:0.6706281900405884  \n","Epoch:3/50     Step:2|6   loss:0.6644831895828247  \n","Epoch:3/50     Step:3|6   loss:0.6920872330665588  \n","Epoch:3/50     Step:4|6   loss:0.6784194707870483  \n","Epoch:3/50     Step:5|6   loss:0.694435715675354  \n","Epoch:3/50     Step:6|6   loss:0.6229298114776611  \n","Epoch:3/50     Step:7|6   loss:0.6135857105255127  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:83.18%\t train set:88.29%\n","Epoch:4/50     Step:1|6   loss:0.6002781987190247  \n","Epoch:4/50     Step:2|6   loss:0.6215640306472778  \n","Epoch:4/50     Step:3|6   loss:0.6434251070022583  \n","Epoch:4/50     Step:4|6   loss:0.6379748582839966  \n","Epoch:4/50     Step:5|6   loss:0.7125575542449951  \n","Epoch:4/50     Step:6|6   loss:0.6219620704650879  \n","Epoch:4/50     Step:7|6   loss:0.6294350624084473  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 89.93 %\n","current max accuracy\t test set:85.98%\t train set:89.93%\n","Epoch:5/50     Step:1|6   loss:0.5792618989944458  \n","Epoch:5/50     Step:2|6   loss:0.5990323424339294  \n","Epoch:5/50     Step:3|6   loss:0.6241751313209534  \n","Epoch:5/50     Step:4|6   loss:0.6247194409370422  \n","Epoch:5/50     Step:5|6   loss:0.5837090611457825  \n","Epoch:5/50     Step:6|6   loss:0.6841514110565186  \n","Epoch:5/50     Step:7|6   loss:0.560824453830719  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:87.85%\t train set:91.33%\n","Epoch:6/50     Step:1|6   loss:0.6122205853462219  \n","Epoch:6/50     Step:2|6   loss:0.5815420150756836  \n","Epoch:6/50     Step:3|6   loss:0.6000665426254272  \n","Epoch:6/50     Step:4|6   loss:0.5776914954185486  \n","Epoch:6/50     Step:5|6   loss:0.6035664081573486  \n","Epoch:6/50     Step:6|6   loss:0.5687546730041504  \n","Epoch:6/50     Step:7|6   loss:0.6225138902664185  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:88.79%\t train set:93.91%\n","Epoch:7/50     Step:1|6   loss:0.6269199848175049  \n","Epoch:7/50     Step:2|6   loss:0.601769208908081  \n","Epoch:7/50     Step:3|6   loss:0.5372192859649658  \n","Epoch:7/50     Step:4|6   loss:0.6002910137176514  \n","Epoch:7/50     Step:5|6   loss:0.5802634358406067  \n","Epoch:7/50     Step:6|6   loss:0.5579887628555298  \n","Epoch:7/50     Step:7|6   loss:0.5787947177886963  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:88.79%\t train set:95.78%\n","Epoch:8/50     Step:1|6   loss:0.5645190477371216  \n","Epoch:8/50     Step:2|6   loss:0.5683668851852417  \n","Epoch:8/50     Step:3|6   loss:0.5631009936332703  \n","Epoch:8/50     Step:4|6   loss:0.5381608605384827  \n","Epoch:8/50     Step:5|6   loss:0.5758508443832397  \n","Epoch:8/50     Step:6|6   loss:0.5752024054527283  \n","Epoch:8/50     Step:7|6   loss:0.6168148517608643  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:88.79%\t train set:96.25%\n","Epoch:9/50     Step:1|6   loss:0.5748187303543091  \n","Epoch:9/50     Step:2|6   loss:0.5440901517868042  \n","Epoch:9/50     Step:3|6   loss:0.5781993269920349  \n","Epoch:9/50     Step:4|6   loss:0.556501030921936  \n","Epoch:9/50     Step:5|6   loss:0.5560203790664673  \n","Epoch:9/50     Step:6|6   loss:0.547333300113678  \n","Epoch:9/50     Step:7|6   loss:0.5556764602661133  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:89.72%\t train set:96.25%\n","Epoch:10/50     Step:1|6   loss:0.5493971109390259  \n","Epoch:10/50     Step:2|6   loss:0.5452761650085449  \n","Epoch:10/50     Step:3|6   loss:0.54035484790802  \n","Epoch:10/50     Step:4|6   loss:0.5429068207740784  \n","Epoch:10/50     Step:5|6   loss:0.5359143614768982  \n","Epoch:10/50     Step:6|6   loss:0.5741776823997498  \n","Epoch:10/50     Step:7|6   loss:0.5710246562957764  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:89.72%\t train set:96.49%\n","Epoch:11/50     Step:1|6   loss:0.5431429147720337  \n","Epoch:11/50     Step:2|6   loss:0.5563733577728271  \n","Epoch:11/50     Step:3|6   loss:0.5296040177345276  \n","Epoch:11/50     Step:4|6   loss:0.5413491725921631  \n","Epoch:11/50     Step:5|6   loss:0.5402300357818604  \n","Epoch:11/50     Step:6|6   loss:0.5606433153152466  \n","Epoch:11/50     Step:7|6   loss:0.521482527256012  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:90.65%\t train set:97.89%\n","Epoch:12/50     Step:1|6   loss:0.5428478121757507  \n","Epoch:12/50     Step:2|6   loss:0.5334041118621826  \n","Epoch:12/50     Step:3|6   loss:0.5329098701477051  \n","Epoch:12/50     Step:4|6   loss:0.5407448410987854  \n","Epoch:12/50     Step:5|6   loss:0.528832733631134  \n","Epoch:12/50     Step:6|6   loss:0.541348934173584  \n","Epoch:12/50     Step:7|6   loss:0.536307156085968  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:90.65%\t train set:98.13%\n","Epoch:13/50     Step:1|6   loss:0.5179028511047363  \n","Epoch:13/50     Step:2|6   loss:0.5242453217506409  \n","Epoch:13/50     Step:3|6   loss:0.5515314340591431  \n","Epoch:13/50     Step:4|6   loss:0.5145957469940186  \n","Epoch:13/50     Step:5|6   loss:0.5233139395713806  \n","Epoch:13/50     Step:6|6   loss:0.5532411336898804  \n","Epoch:13/50     Step:7|6   loss:0.5367774963378906  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:14/50     Step:1|6   loss:0.5186159610748291  \n","Epoch:14/50     Step:2|6   loss:0.5283429026603699  \n","Epoch:14/50     Step:3|6   loss:0.538365364074707  \n","Epoch:14/50     Step:4|6   loss:0.5230687260627747  \n","Epoch:14/50     Step:5|6   loss:0.521313488483429  \n","Epoch:14/50     Step:6|6   loss:0.5238788723945618  \n","Epoch:14/50     Step:7|6   loss:0.5310837626457214  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:92.52%\t train set:98.59%\n","Epoch:15/50     Step:1|6   loss:0.5045415163040161  \n","Epoch:15/50     Step:2|6   loss:0.520589292049408  \n","Epoch:15/50     Step:3|6   loss:0.5184645056724548  \n","Epoch:15/50     Step:4|6   loss:0.5242451429367065  \n","Epoch:15/50     Step:5|6   loss:0.5339453220367432  \n","Epoch:15/50     Step:6|6   loss:0.5286098718643188  \n","Epoch:15/50     Step:7|6   loss:0.5244032144546509  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:92.52%\t train set:98.83%\n","Epoch:16/50     Step:1|6   loss:0.5141858458518982  \n","Epoch:16/50     Step:2|6   loss:0.5071338415145874  \n","Epoch:16/50     Step:3|6   loss:0.5062140226364136  \n","Epoch:16/50     Step:4|6   loss:0.5209245681762695  \n","Epoch:16/50     Step:5|6   loss:0.5355572700500488  \n","Epoch:16/50     Step:6|6   loss:0.5218148231506348  \n","Epoch:16/50     Step:7|6   loss:0.5310719609260559  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:93.46%\t train set:99.06%\n","Epoch:17/50     Step:1|6   loss:0.5146650075912476  \n","Epoch:17/50     Step:2|6   loss:0.5101601481437683  \n","Epoch:17/50     Step:3|6   loss:0.5149874091148376  \n","Epoch:17/50     Step:4|6   loss:0.5389854907989502  \n","Epoch:17/50     Step:5|6   loss:0.5084232687950134  \n","Epoch:17/50     Step:6|6   loss:0.5184574127197266  \n","Epoch:17/50     Step:7|6   loss:0.5096071362495422  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:18/50     Step:1|6   loss:0.516579270362854  \n","Epoch:18/50     Step:2|6   loss:0.5140602588653564  \n","Epoch:18/50     Step:3|6   loss:0.5059190988540649  \n","Epoch:18/50     Step:4|6   loss:0.5251822471618652  \n","Epoch:18/50     Step:5|6   loss:0.5047387480735779  \n","Epoch:18/50     Step:6|6   loss:0.5171648263931274  \n","Epoch:18/50     Step:7|6   loss:0.5028674006462097  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:19/50     Step:1|6   loss:0.5203763246536255  \n","Epoch:19/50     Step:2|6   loss:0.5090764164924622  \n","Epoch:19/50     Step:3|6   loss:0.5083118677139282  \n","Epoch:19/50     Step:4|6   loss:0.5139415860176086  \n","Epoch:19/50     Step:5|6   loss:0.5077160596847534  \n","Epoch:19/50     Step:6|6   loss:0.5014523863792419  \n","Epoch:19/50     Step:7|6   loss:0.5047194957733154  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:20/50     Step:1|6   loss:0.5071507692337036  \n","Epoch:20/50     Step:2|6   loss:0.5070858001708984  \n","Epoch:20/50     Step:3|6   loss:0.5167285203933716  \n","Epoch:20/50     Step:4|6   loss:0.4968799948692322  \n","Epoch:20/50     Step:5|6   loss:0.49627721309661865  \n","Epoch:20/50     Step:6|6   loss:0.5076555013656616  \n","Epoch:20/50     Step:7|6   loss:0.5198032855987549  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:21/50     Step:1|6   loss:0.5033043622970581  \n","Epoch:21/50     Step:2|6   loss:0.5091585516929626  \n","Epoch:21/50     Step:3|6   loss:0.4984799325466156  \n","Epoch:21/50     Step:4|6   loss:0.506264328956604  \n","Epoch:21/50     Step:5|6   loss:0.5045009255409241  \n","Epoch:21/50     Step:6|6   loss:0.5114858150482178  \n","Epoch:21/50     Step:7|6   loss:0.4993578791618347  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:22/50     Step:1|6   loss:0.5061074495315552  \n","Epoch:22/50     Step:2|6   loss:0.5022799968719482  \n","Epoch:22/50     Step:3|6   loss:0.5050309896469116  \n","Epoch:22/50     Step:4|6   loss:0.4996079206466675  1\n","Epoch:22/50     Step:5|6   loss:0.5054461359977722  \n","Epoch:22/50     Step:6|6   loss:0.5039695501327515  \n","Epoch:22/50     Step:7|6   loss:0.49163180589675903  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:23/50     Step:1|6   loss:0.4945298433303833  \n","Epoch:23/50     Step:2|6   loss:0.502890408039093  \n","Epoch:23/50     Step:3|6   loss:0.4956456422805786  \n","Epoch:23/50     Step:4|6   loss:0.5106462240219116  \n","Epoch:23/50     Step:5|6   loss:0.49353235960006714  \n","Epoch:23/50     Step:6|6   loss:0.5095780491828918  \n","Epoch:23/50     Step:7|6   loss:0.5009562969207764  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:24/50     Step:1|6   loss:0.4965226650238037  \n","Epoch:24/50     Step:2|6   loss:0.49908626079559326  \n","Epoch:24/50     Step:3|6   loss:0.5044932961463928  \n","Epoch:24/50     Step:4|6   loss:0.5081424713134766  \n","Epoch:24/50     Step:5|6   loss:0.49209409952163696  \n","Epoch:24/50     Step:6|6   loss:0.5039303302764893  \n","Epoch:24/50     Step:7|6   loss:0.49392813444137573  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:25/50     Step:1|6   loss:0.4989893138408661  \n","Epoch:25/50     Step:2|6   loss:0.5138135552406311  \n","Epoch:25/50     Step:3|6   loss:0.49503380060195923  \n","Epoch:25/50     Step:4|6   loss:0.49515441060066223  \n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:25/50     Step:5|6   loss:0.4939352869987488  \n","Epoch:25/50     Step:6|6   loss:0.5000371932983398  \n","Epoch:25/50     Step:7|6   loss:0.4931267201900482  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:26/50     Step:1|6   loss:0.4977571666240692  \n","Epoch:26/50     Step:2|6   loss:0.4986552894115448  \n","Epoch:26/50     Step:3|6   loss:0.4988868832588196  \n","Epoch:26/50     Step:4|6   loss:0.48827674984931946  \n","Epoch:26/50     Step:5|6   loss:0.4978153705596924  \n","Epoch:26/50     Step:6|6   loss:0.5020409822463989  \n","Epoch:26/50     Step:7|6   loss:0.5082861185073853  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.49223583936691284  \n","Epoch:27/50     Step:2|6   loss:0.4977668523788452  \n","Epoch:27/50     Step:3|6   loss:0.5016146898269653  \n","Epoch:27/50     Step:4|6   loss:0.5018860697746277  \n","Epoch:27/50     Step:5|6   loss:0.4925082325935364  \n","Epoch:27/50     Step:6|6   loss:0.4931294918060303  \n","Epoch:27/50     Step:7|6   loss:0.4995538592338562  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48958051204681396  \n","Epoch:28/50     Step:2|6   loss:0.4956101179122925  \n","Epoch:28/50     Step:3|6   loss:0.5010604858398438  \n","Epoch:28/50     Step:4|6   loss:0.497252881526947  \n","Epoch:28/50     Step:5|6   loss:0.4930819571018219  \n","Epoch:28/50     Step:6|6   loss:0.4923347532749176  \n","Epoch:28/50     Step:7|6   loss:0.5048036575317383  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.49693429470062256  \n","Epoch:29/50     Step:2|6   loss:0.4909791052341461  \n","Epoch:29/50     Step:3|6   loss:0.49020451307296753  \n","Epoch:29/50     Step:4|6   loss:0.5017359256744385  \n","Epoch:29/50     Step:5|6   loss:0.4920327663421631  \n","Epoch:29/50     Step:6|6   loss:0.5049046277999878  \n","Epoch:29/50     Step:7|6   loss:0.4909094572067261  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.49558746814727783  \n","Epoch:30/50     Step:2|6   loss:0.49333399534225464  \n","Epoch:30/50     Step:3|6   loss:0.4920145869255066  \n","Epoch:30/50     Step:4|6   loss:0.4951799511909485  \n","Epoch:30/50     Step:5|6   loss:0.4929690957069397  \n","Epoch:30/50     Step:6|6   loss:0.4958154857158661  \n","Epoch:30/50     Step:7|6   loss:0.49739277362823486  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.4927932620048523  \n","Epoch:31/50     Step:2|6   loss:0.4895627498626709  \n","Epoch:31/50     Step:3|6   loss:0.4944135546684265  \n","Epoch:31/50     Step:4|6   loss:0.49510347843170166  \n","Epoch:31/50     Step:5|6   loss:0.49340569972991943  \n","Epoch:31/50     Step:6|6   loss:0.49555426836013794  \n","Epoch:31/50     Step:7|6   loss:0.4932243525981903  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4893060326576233  \n","Epoch:32/50     Step:2|6   loss:0.491492360830307  \n","Epoch:32/50     Step:3|6   loss:0.4927974343299866  \n","Epoch:32/50     Step:4|6   loss:0.5014358758926392  \n","Epoch:32/50     Step:5|6   loss:0.48791009187698364  \n","Epoch:32/50     Step:6|6   loss:0.4927651882171631  \n","Epoch:32/50     Step:7|6   loss:0.49025923013687134  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.49120813608169556  \n","Epoch:33/50     Step:2|6   loss:0.49103325605392456  \n","Epoch:33/50     Step:3|6   loss:0.4916670322418213  \n","Epoch:33/50     Step:4|6   loss:0.49133211374282837  \n","Epoch:33/50     Step:5|6   loss:0.4930886924266815  \n","Epoch:33/50     Step:6|6   loss:0.4916667342185974  \n","Epoch:33/50     Step:7|6   loss:0.4877418279647827  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.48870742321014404  \n","Epoch:34/50     Step:2|6   loss:0.4906049966812134  \n","Epoch:34/50     Step:3|6   loss:0.4916783571243286  \n","Epoch:34/50     Step:4|6   loss:0.4934912323951721  \n","Epoch:34/50     Step:5|6   loss:0.4907441735267639  \n","Epoch:34/50     Step:6|6   loss:0.4884156882762909  \n","Epoch:34/50     Step:7|6   loss:0.49315086007118225  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4884185791015625  \n","Epoch:35/50     Step:2|6   loss:0.495772123336792  \n","Epoch:35/50     Step:3|6   loss:0.48892489075660706  \n","Epoch:35/50     Step:4|6   loss:0.48933863639831543  \n","Epoch:35/50     Step:5|6   loss:0.4867098927497864  \n","Epoch:35/50     Step:6|6   loss:0.4934362769126892  \n","Epoch:35/50     Step:7|6   loss:0.4905328154563904  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4912591576576233  \n","Epoch:36/50     Step:2|6   loss:0.4888814389705658  \n","Epoch:36/50     Step:3|6   loss:0.48818448185920715  \n","Epoch:36/50     Step:4|6   loss:0.4897681772708893  \n","Epoch:36/50     Step:5|6   loss:0.4909638464450836  \n","Epoch:36/50     Step:6|6   loss:0.49133533239364624  \n","Epoch:36/50     Step:7|6   loss:0.4896235764026642  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48780301213264465  \n","Epoch:37/50     Step:2|6   loss:0.4894474148750305  \n","Epoch:37/50     Step:3|6   loss:0.49137812852859497  \n","Epoch:37/50     Step:4|6   loss:0.49138784408569336  \n","Epoch:37/50     Step:5|6   loss:0.49029162526130676  \n","Epoch:37/50     Step:6|6   loss:0.4888964295387268  \n","Epoch:37/50     Step:7|6   loss:0.48777124285697937  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.49023956060409546  \n","Epoch:38/50     Step:2|6   loss:0.4904273748397827  \n","Epoch:38/50     Step:3|6   loss:0.4867720305919647  \n","Epoch:38/50     Step:4|6   loss:0.48830658197402954  \n","Epoch:38/50     Step:5|6   loss:0.49026551842689514  \n","Epoch:38/50     Step:6|6   loss:0.48924633860588074  \n","Epoch:38/50     Step:7|6   loss:0.48840075731277466  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4896640479564667  \n","Epoch:39/50     Step:2|6   loss:0.48650527000427246  \n","Epoch:39/50     Step:3|6   loss:0.48873549699783325  \n","Epoch:39/50     Step:4|6   loss:0.49062561988830566  \n","Epoch:39/50     Step:5|6   loss:0.49130314588546753  \n","Epoch:39/50     Step:6|6   loss:0.4888516664505005  \n","Epoch:39/50     Step:7|6   loss:0.4867129921913147  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.4873843789100647  \n","Epoch:40/50     Step:2|6   loss:0.49014580249786377  \n","Epoch:40/50     Step:3|6   loss:0.49178558588027954  \n","Epoch:40/50     Step:4|6   loss:0.4885715842247009  \n","Epoch:40/50     Step:5|6   loss:0.4872737228870392  \n","Epoch:40/50     Step:6|6   loss:0.48687422275543213  \n","Epoch:40/50     Step:7|6   loss:0.4902462959289551  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4899332523345947  \n","Epoch:41/50     Step:2|6   loss:0.487551748752594  \n","Epoch:41/50     Step:3|6   loss:0.4876449406147003  \n","Epoch:41/50     Step:4|6   loss:0.4902424216270447  \n","Epoch:41/50     Step:5|6   loss:0.4906196594238281  \n","Epoch:41/50     Step:6|6   loss:0.48764073848724365  \n","Epoch:41/50     Step:7|6   loss:0.4878850281238556  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4875941872596741  \n","Epoch:42/50     Step:2|6   loss:0.48842477798461914  \n","Epoch:42/50     Step:3|6   loss:0.48738402128219604  \n","Epoch:42/50     Step:4|6   loss:0.4883747398853302  \n","Epoch:42/50     Step:5|6   loss:0.4904325604438782  \n","Epoch:42/50     Step:6|6   loss:0.4873488247394562  \n","Epoch:42/50     Step:7|6   loss:0.487722784280777  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4869476556777954  \n","Epoch:43/50     Step:2|6   loss:0.4879908561706543  \n","Epoch:43/50     Step:3|6   loss:0.48658448457717896  \n","Epoch:43/50     Step:4|6   loss:0.4869143068790436  \n","Epoch:43/50     Step:5|6   loss:0.4884974956512451  \n","Epoch:43/50     Step:6|6   loss:0.48868176341056824  \n","Epoch:43/50     Step:7|6   loss:0.49022409319877625  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48605871200561523  \n","Epoch:44/50     Step:2|6   loss:0.49073708057403564  \n","Epoch:44/50     Step:3|6   loss:0.4880150258541107  \n","Epoch:44/50     Step:4|6   loss:0.48856163024902344  \n","Epoch:44/50     Step:5|6   loss:0.48669278621673584  \n","Epoch:44/50     Step:6|6   loss:0.48730772733688354  \n","Epoch:44/50     Step:7|6   loss:0.4861224889755249  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4860386848449707  \n","Epoch:45/50     Step:2|6   loss:0.4883960485458374  \n","Epoch:45/50     Step:3|6   loss:0.4879787862300873  \n","Epoch:45/50     Step:4|6   loss:0.4881684482097626  \n","Epoch:45/50     Step:5|6   loss:0.48626476526260376  \n","Epoch:45/50     Step:6|6   loss:0.4888218939304352  \n","Epoch:45/50     Step:7|6   loss:0.48711439967155457  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.48724567890167236  \n","Epoch:46/50     Step:2|6   loss:0.4867290258407593  \n","Epoch:46/50     Step:3|6   loss:0.48754847049713135  \n","Epoch:46/50     Step:4|6   loss:0.49052149057388306  \n","Epoch:46/50     Step:5|6   loss:0.4860683083534241  \n","Epoch:46/50     Step:6|6   loss:0.4868895411491394  \n","Epoch:46/50     Step:7|6   loss:0.4866611957550049  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48782604932785034  \n","Epoch:47/50     Step:2|6   loss:0.4876443147659302  \n","Epoch:47/50     Step:3|6   loss:0.48631489276885986  \n","Epoch:47/50     Step:4|6   loss:0.4874768555164337  \n","Epoch:47/50     Step:5|6   loss:0.48789194226264954  \n","Epoch:47/50     Step:6|6   loss:0.48587968945503235  \n","Epoch:47/50     Step:7|6   loss:0.48872777819633484  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.486417293548584  \n","Epoch:48/50     Step:2|6   loss:0.4879887104034424  \n","Epoch:48/50     Step:3|6   loss:0.4868907928466797  \n","Epoch:48/50     Step:4|6   loss:0.4888423681259155  \n","Epoch:48/50     Step:5|6   loss:0.48788100481033325  \n","Epoch:48/50     Step:6|6   loss:0.48616570234298706  \n","Epoch:48/50     Step:7|6   loss:0.48610955476760864  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4868246018886566  \n","Epoch:49/50     Step:2|6   loss:0.4867132306098938  \n","Epoch:49/50     Step:3|6   loss:0.4872520864009857  \n","Epoch:49/50     Step:4|6   loss:0.48751839995384216  \n","Epoch:49/50     Step:5|6   loss:0.4868628680706024  \n","Epoch:49/50     Step:6|6   loss:0.48633503913879395  \n","Epoch:49/50     Step:7|6   loss:0.4882999658584595  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48673492670059204  \n","Epoch:50/50     Step:2|6   loss:0.4865356981754303  \n","Epoch:50/50     Step:3|6   loss:0.4859406352043152  \n","Epoch:50/50     Step:4|6   loss:0.4878031015396118  \n","Epoch:50/50     Step:5|6   loss:0.4860956370830536  \n","Epoch:50/50     Step:6|6   loss:0.48941028118133545  \n","Epoch:50/50     Step:7|6   loss:0.48587751388549805  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Accuracy on test_set: 93.46 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.081850528717041  \n","Epoch:1/50     Step:2|6   loss:2.4758570194244385  \n","Epoch:1/50     Step:3|6   loss:1.2117518186569214  \n","Epoch:1/50     Step:4|6   loss:1.2281705141067505  \n","Epoch:1/50     Step:5|6   loss:0.9930864572525024  \n","Epoch:1/50     Step:6|6   loss:0.8028848767280579  \n","Epoch:1/50     Step:7|6   loss:0.7832634449005127  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 74.00 %\n","current max accuracy\t test set:78.5%\t train set:74.0%\n","Epoch:2/50     Step:1|6   loss:0.7829533815383911  \n","Epoch:2/50     Step:2|6   loss:0.8156602382659912  \n","Epoch:2/50     Step:3|6   loss:0.7782915830612183  \n","Epoch:2/50     Step:4|6   loss:0.8421717286109924  \n","Epoch:2/50     Step:5|6   loss:0.7337236404418945  \n","Epoch:2/50     Step:6|6   loss:0.7428470849990845  \n","Epoch:2/50     Step:7|6   loss:0.7106555104255676  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 80.09 %\n","current max accuracy\t test set:78.5%\t train set:80.09%\n","Epoch:3/50     Step:1|6   loss:0.7446666955947876  \n","Epoch:3/50     Step:2|6   loss:0.6732866764068604  \n","Epoch:3/50     Step:3|6   loss:0.7600579261779785  \n","Epoch:3/50     Step:4|6   loss:0.6914219856262207  \n","Epoch:3/50     Step:5|6   loss:0.7033801078796387  \n","Epoch:3/50     Step:6|6   loss:0.7253062725067139  \n","Epoch:3/50     Step:7|6   loss:0.7301538586616516  \n","Accuracy on test_set: 73.83 %\n","Accuracy on train_set: 78.69 %\n","current max accuracy\t test set:78.5%\t train set:80.09%\n","Epoch:4/50     Step:1|6   loss:0.6929783821105957  \n","Epoch:4/50     Step:2|6   loss:0.6629153490066528  \n","Epoch:4/50     Step:3|6   loss:0.6555638909339905  \n","Epoch:4/50     Step:4|6   loss:0.6936906576156616  \n","Epoch:4/50     Step:5|6   loss:0.63522869348526  \n","Epoch:4/50     Step:6|6   loss:0.6476572751998901  \n","Epoch:4/50     Step:7|6   loss:0.7091292142868042  \n","Accuracy on test_set: 77.57 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:78.5%\t train set:87.59%\n","Epoch:5/50     Step:1|6   loss:0.6576223373413086  \n","Epoch:5/50     Step:2|6   loss:0.6803966164588928  \n","Epoch:5/50     Step:3|6   loss:0.614595890045166  \n","Epoch:5/50     Step:4|6   loss:0.6671096086502075  \n","Epoch:5/50     Step:5|6   loss:0.6385970711708069  \n","Epoch:5/50     Step:6|6   loss:0.6084722280502319  \n","Epoch:5/50     Step:7|6   loss:0.6341240406036377  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:83.18%\t train set:92.27%\n","Epoch:6/50     Step:1|6   loss:0.6275876760482788  \n","Epoch:6/50     Step:2|6   loss:0.6250079274177551  \n","Epoch:6/50     Step:3|6   loss:0.6124439239501953  \n","Epoch:6/50     Step:4|6   loss:0.6258070468902588  \n","Epoch:6/50     Step:5|6   loss:0.6348954439163208  \n","Epoch:6/50     Step:6|6   loss:0.6023657321929932  \n","Epoch:6/50     Step:7|6   loss:0.6310418248176575  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:83.18%\t train set:93.91%\n","Epoch:7/50     Step:1|6   loss:0.5870658159255981  \n","Epoch:7/50     Step:2|6   loss:0.6258443593978882  \n","Epoch:7/50     Step:3|6   loss:0.6194006204605103  \n","Epoch:7/50     Step:4|6   loss:0.5990258455276489  \n","Epoch:7/50     Step:5|6   loss:0.6098597645759583  \n","Epoch:7/50     Step:6|6   loss:0.5961763858795166  \n","Epoch:7/50     Step:7|6   loss:0.5806070566177368  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:85.05%\t train set:95.08%\n","Epoch:8/50     Step:1|6   loss:0.5665091872215271  \n","Epoch:8/50     Step:2|6   loss:0.5784637331962585  \n","Epoch:8/50     Step:3|6   loss:0.5969869494438171  \n","Epoch:8/50     Step:4|6   loss:0.5927596092224121  \n","Epoch:8/50     Step:5|6   loss:0.597161591053009  \n","Epoch:8/50     Step:6|6   loss:0.5989010334014893  \n","Epoch:8/50     Step:7|6   loss:0.5835408568382263  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:85.05%\t train set:96.72%\n","Epoch:9/50     Step:1|6   loss:0.5845879912376404  \n","Epoch:9/50     Step:2|6   loss:0.5506121516227722  \n","Epoch:9/50     Step:3|6   loss:0.5934915542602539  \n","Epoch:9/50     Step:4|6   loss:0.5834338665008545  \n","Epoch:9/50     Step:5|6   loss:0.5600589513778687  \n","Epoch:9/50     Step:6|6   loss:0.5780505537986755  \n","Epoch:9/50     Step:7|6   loss:0.5701202750205994  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:85.05%\t train set:96.72%\n","Epoch:10/50     Step:1|6   loss:0.5489544868469238  \n","Epoch:10/50     Step:2|6   loss:0.6026982665061951  \n","Epoch:10/50     Step:3|6   loss:0.5520301461219788  \n","Epoch:10/50     Step:4|6   loss:0.5726335644721985  \n","Epoch:10/50     Step:5|6   loss:0.5521945953369141  \n","Epoch:10/50     Step:6|6   loss:0.5472797155380249  \n","Epoch:10/50     Step:7|6   loss:0.5591718554496765  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:86.92%\t train set:97.66%\n","Epoch:11/50     Step:1|6   loss:0.5288899540901184  \n","Epoch:11/50     Step:2|6   loss:0.5520548820495605  \n","Epoch:11/50     Step:3|6   loss:0.5377452373504639  \n","Epoch:11/50     Step:4|6   loss:0.5559205412864685  \n","Epoch:11/50     Step:5|6   loss:0.5615113973617554  \n","Epoch:11/50     Step:6|6   loss:0.5734007358551025  \n","Epoch:11/50     Step:7|6   loss:0.5753797292709351  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:86.92%\t train set:97.89%\n","Epoch:12/50     Step:1|6   loss:0.5544816851615906  \n","Epoch:12/50     Step:2|6   loss:0.5460202097892761  \n","Epoch:12/50     Step:3|6   loss:0.5423933267593384  \n","Epoch:12/50     Step:4|6   loss:0.536279559135437  \n","Epoch:12/50     Step:5|6   loss:0.5255826711654663  \n","Epoch:12/50     Step:6|6   loss:0.5675947070121765  \n","Epoch:12/50     Step:7|6   loss:0.5583573579788208  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:86.92%\t train set:98.36%\n","Epoch:13/50     Step:1|6   loss:0.5197559595108032  \n","Epoch:13/50     Step:2|6   loss:0.5275131464004517  \n","Epoch:13/50     Step:3|6   loss:0.5165660381317139  \n","Epoch:13/50     Step:4|6   loss:0.5395449995994568  \n","Epoch:13/50     Step:5|6   loss:0.5657338500022888  \n","Epoch:13/50     Step:6|6   loss:0.5464034676551819  \n","Epoch:13/50     Step:7|6   loss:0.555381178855896  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:87.85%\t train set:98.59%\n","Epoch:14/50     Step:1|6   loss:0.5271555781364441  \n","Epoch:14/50     Step:2|6   loss:0.5360159873962402  \n","Epoch:14/50     Step:3|6   loss:0.5353672504425049  \n","Epoch:14/50     Step:4|6   loss:0.5718668699264526  \n","Epoch:14/50     Step:5|6   loss:0.5266281366348267  \n","Epoch:14/50     Step:6|6   loss:0.5207300186157227  \n","Epoch:14/50     Step:7|6   loss:0.5140599012374878  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:88.79%\t train set:98.59%\n","Epoch:15/50     Step:1|6   loss:0.5578781366348267  \n","Epoch:15/50     Step:2|6   loss:0.5197303295135498  \n","Epoch:15/50     Step:3|6   loss:0.5088182687759399  \n","Epoch:15/50     Step:4|6   loss:0.5405060052871704  \n","Epoch:15/50     Step:5|6   loss:0.5156200528144836  \n","Epoch:15/50     Step:6|6   loss:0.5144177079200745  \n","Epoch:15/50     Step:7|6   loss:0.5468367338180542  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:88.79%\t train set:99.06%\n","Epoch:16/50     Step:1|6   loss:0.5121259689331055  \n","Epoch:16/50     Step:2|6   loss:0.5008757710456848  \n","Epoch:16/50     Step:3|6   loss:0.514121949672699  \n","Epoch:16/50     Step:4|6   loss:0.5588443279266357  \n","Epoch:16/50     Step:5|6   loss:0.5271534323692322  \n","Epoch:16/50     Step:6|6   loss:0.5126410722732544  \n","Epoch:16/50     Step:7|6   loss:0.5045437812805176  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:17/50     Step:1|6   loss:0.5128716230392456  \n","Epoch:17/50     Step:2|6   loss:0.5316585302352905  \n","Epoch:17/50     Step:3|6   loss:0.5154328942298889  \n","Epoch:17/50     Step:4|6   loss:0.5073977708816528  \n","Epoch:17/50     Step:5|6   loss:0.5208801031112671  \n","Epoch:17/50     Step:6|6   loss:0.5175924301147461  \n","Epoch:17/50     Step:7|6   loss:0.49336767196655273  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:18/50     Step:1|6   loss:0.4990810453891754  \n","Epoch:18/50     Step:2|6   loss:0.5040025115013123  \n","Epoch:18/50     Step:3|6   loss:0.5234086513519287  \n","Epoch:18/50     Step:4|6   loss:0.508930504322052  \n","Epoch:18/50     Step:5|6   loss:0.5246776938438416  \n","Epoch:18/50     Step:6|6   loss:0.5145803689956665  \n","Epoch:18/50     Step:7|6   loss:0.5008447766304016  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:19/50     Step:1|6   loss:0.4997895359992981  \n","Epoch:19/50     Step:2|6   loss:0.5191524028778076  \n","Epoch:19/50     Step:3|6   loss:0.5047339200973511  \n","Epoch:19/50     Step:4|6   loss:0.5146536827087402  \n","Epoch:19/50     Step:5|6   loss:0.5096501111984253  \n","Epoch:19/50     Step:6|6   loss:0.5079808235168457  \n","Epoch:19/50     Step:7|6   loss:0.5000877380371094  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:20/50     Step:1|6   loss:0.4956010580062866  \n","Epoch:20/50     Step:2|6   loss:0.5150324106216431  \n","Epoch:20/50     Step:3|6   loss:0.5111604928970337  \n","Epoch:20/50     Step:4|6   loss:0.505804181098938  \n","Epoch:20/50     Step:5|6   loss:0.4950483441352844  \n","Epoch:20/50     Step:6|6   loss:0.5212324857711792  \n","Epoch:20/50     Step:7|6   loss:0.49259793758392334  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:21/50     Step:1|6   loss:0.5181806087493896  \n","Epoch:21/50     Step:2|6   loss:0.4959425628185272  \n","Epoch:21/50     Step:3|6   loss:0.5096979737281799  \n","Epoch:21/50     Step:4|6   loss:0.4934680759906769  \n","Epoch:21/50     Step:5|6   loss:0.5115388035774231  \n","Epoch:21/50     Step:6|6   loss:0.49674853682518005  \n","Epoch:21/50     Step:7|6   loss:0.4949420094490051  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.3%\n","Epoch:22/50     Step:1|6   loss:0.49684542417526245  \n","Epoch:22/50     Step:2|6   loss:0.49688607454299927  \n","Epoch:22/50     Step:3|6   loss:0.5064913034439087  \n","Epoch:22/50     Step:4|6   loss:0.5089942216873169  \n","Epoch:22/50     Step:5|6   loss:0.5012689828872681  \n","Epoch:22/50     Step:6|6   loss:0.49479779601097107  \n","Epoch:22/50     Step:7|6   loss:0.5054678320884705  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:90.65%\t train set:99.3%\n","Epoch:23/50     Step:1|6   loss:0.49724310636520386  \n","Epoch:23/50     Step:2|6   loss:0.5044578909873962  \n","Epoch:23/50     Step:3|6   loss:0.4925636649131775  \n","Epoch:23/50     Step:4|6   loss:0.4988548755645752  \n","Epoch:23/50     Step:5|6   loss:0.5137773752212524  \n","Epoch:23/50     Step:6|6   loss:0.4964956045150757  \n","Epoch:23/50     Step:7|6   loss:0.4936918616294861  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:24/50     Step:1|6   loss:0.5035473704338074  \n","Epoch:24/50     Step:2|6   loss:0.4931262731552124  \n","Epoch:24/50     Step:3|6   loss:0.4913783669471741  \n","Epoch:24/50     Step:4|6   loss:0.4986894428730011  \n","Epoch:24/50     Step:5|6   loss:0.492867112159729  \n","Epoch:24/50     Step:6|6   loss:0.512531578540802  \n","Epoch:24/50     Step:7|6   loss:0.4965677261352539  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:90.65%\t train set:99.53%\n","Epoch:25/50     Step:1|6   loss:0.5049086213111877  \n","Epoch:25/50     Step:2|6   loss:0.49634885787963867  \n","Epoch:25/50     Step:3|6   loss:0.4972606897354126  \n","Epoch:25/50     Step:4|6   loss:0.49359849095344543  \n","Epoch:25/50     Step:5|6   loss:0.4925694465637207  \n","Epoch:25/50     Step:6|6   loss:0.5022634267807007  \n","Epoch:25/50     Step:7|6   loss:0.48937904834747314  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:26/50     Step:1|6   loss:0.48986130952835083  \n","Epoch:26/50     Step:2|6   loss:0.4978368878364563  \n","Epoch:26/50     Step:3|6   loss:0.4915556311607361  \n","Epoch:26/50     Step:4|6   loss:0.4932299852371216  \n","Epoch:26/50     Step:5|6   loss:0.491960734128952  \n","Epoch:26/50     Step:6|6   loss:0.5086820125579834  \n","Epoch:26/50     Step:7|6   loss:0.494316041469574  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:27/50     Step:1|6   loss:0.4959654211997986  \n","Epoch:27/50     Step:2|6   loss:0.4980894923210144  \n","Epoch:27/50     Step:3|6   loss:0.49414095282554626  \n","Epoch:27/50     Step:4|6   loss:0.49130454659461975  \n","Epoch:27/50     Step:5|6   loss:0.4893225431442261  \n","Epoch:27/50     Step:6|6   loss:0.5009288787841797  \n","Epoch:27/50     Step:7|6   loss:0.4899941682815552  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:28/50     Step:1|6   loss:0.49321746826171875  \n","Epoch:28/50     Step:2|6   loss:0.4895493984222412  \n","Epoch:28/50     Step:3|6   loss:0.4979746341705322  \n","Epoch:28/50     Step:4|6   loss:0.4955761432647705  \n","Epoch:28/50     Step:5|6   loss:0.49674564599990845  \n","Epoch:28/50     Step:6|6   loss:0.4900403618812561  \n","Epoch:28/50     Step:7|6   loss:0.49062496423721313  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:29/50     Step:1|6   loss:0.4954985976219177  \n","Epoch:29/50     Step:2|6   loss:0.4887821078300476  \n","Epoch:29/50     Step:3|6   loss:0.49575620889663696  \n","Epoch:29/50     Step:4|6   loss:0.48914211988449097  \n","Epoch:29/50     Step:5|6   loss:0.49059492349624634  \n","Epoch:29/50     Step:6|6   loss:0.48876938223838806  \n","Epoch:29/50     Step:7|6   loss:0.502738356590271  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:90.65%\t train set:99.77%\n","Epoch:30/50     Step:1|6   loss:0.4942948520183563  \n","Epoch:30/50     Step:2|6   loss:0.49038147926330566  \n","Epoch:30/50     Step:3|6   loss:0.49125027656555176  \n","Epoch:30/50     Step:4|6   loss:0.4887554347515106  \n","Epoch:30/50     Step:5|6   loss:0.48977798223495483  \n","Epoch:30/50     Step:6|6   loss:0.4988951086997986  \n","Epoch:30/50     Step:7|6   loss:0.4876360595226288  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48869776725769043  \n","Epoch:31/50     Step:2|6   loss:0.4882078766822815  \n","Epoch:31/50     Step:3|6   loss:0.4922291040420532  \n","Epoch:31/50     Step:4|6   loss:0.4982690215110779  \n","Epoch:31/50     Step:5|6   loss:0.48828789591789246  \n","Epoch:31/50     Step:6|6   loss:0.4891059398651123  \n","Epoch:31/50     Step:7|6   loss:0.4948401153087616  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4936482906341553  \n","Epoch:32/50     Step:2|6   loss:0.48852458596229553  \n","Epoch:32/50     Step:3|6   loss:0.4922606348991394  \n","Epoch:32/50     Step:4|6   loss:0.4889911711215973  \n","Epoch:32/50     Step:5|6   loss:0.4891153573989868  \n","Epoch:32/50     Step:6|6   loss:0.4939345717430115  \n","Epoch:32/50     Step:7|6   loss:0.4876529276371002  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48916321992874146  \n","Epoch:33/50     Step:2|6   loss:0.4976217746734619  \n","Epoch:33/50     Step:3|6   loss:0.4876191020011902  \n","Epoch:33/50     Step:4|6   loss:0.4870934784412384  \n","Epoch:33/50     Step:5|6   loss:0.48887184262275696  \n","Epoch:33/50     Step:6|6   loss:0.4936804175376892  \n","Epoch:33/50     Step:7|6   loss:0.48667871952056885  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:90.65%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.48715901374816895  \n","Epoch:34/50     Step:2|6   loss:0.49162983894348145  \n","Epoch:34/50     Step:3|6   loss:0.49748694896698  \n","Epoch:34/50     Step:4|6   loss:0.48774734139442444  \n","Epoch:34/50     Step:5|6   loss:0.48961853981018066  \n","Epoch:34/50     Step:6|6   loss:0.4875120520591736  \n","Epoch:34/50     Step:7|6   loss:0.4875704050064087  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4932056665420532  \n","Epoch:35/50     Step:2|6   loss:0.48699483275413513  \n","Epoch:35/50     Step:3|6   loss:0.48779118061065674  \n","Epoch:35/50     Step:4|6   loss:0.4870213270187378  \n","Epoch:35/50     Step:5|6   loss:0.4917176365852356  \n","Epoch:35/50     Step:6|6   loss:0.4918781518936157  \n","Epoch:35/50     Step:7|6   loss:0.4877583980560303  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.48782265186309814  \n","Epoch:36/50     Step:2|6   loss:0.4880378246307373  \n","Epoch:36/50     Step:3|6   loss:0.4869458079338074  \n","Epoch:36/50     Step:4|6   loss:0.49121224880218506  \n","Epoch:36/50     Step:5|6   loss:0.4870316684246063  \n","Epoch:36/50     Step:6|6   loss:0.4965108633041382  \n","Epoch:36/50     Step:7|6   loss:0.48700737953186035  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48673853278160095  \n","Epoch:37/50     Step:2|6   loss:0.4952594041824341  \n","Epoch:37/50     Step:3|6   loss:0.4868440628051758  \n","Epoch:37/50     Step:4|6   loss:0.48699498176574707  \n","Epoch:37/50     Step:5|6   loss:0.48762503266334534  \n","Epoch:37/50     Step:6|6   loss:0.4914398193359375  \n","Epoch:37/50     Step:7|6   loss:0.4876444339752197  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4875602722167969  \n","Epoch:38/50     Step:2|6   loss:0.49037545919418335  \n","Epoch:38/50     Step:3|6   loss:0.48720499873161316  \n","Epoch:38/50     Step:4|6   loss:0.4878580570220947  \n","Epoch:38/50     Step:5|6   loss:0.48638713359832764  \n","Epoch:38/50     Step:6|6   loss:0.49446773529052734  \n","Epoch:38/50     Step:7|6   loss:0.486925333738327  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4864211976528168  \n","Epoch:39/50     Step:2|6   loss:0.48642498254776  \n","Epoch:39/50     Step:3|6   loss:0.4901307225227356  \n","Epoch:39/50     Step:4|6   loss:0.48752373456954956  \n","Epoch:39/50     Step:5|6   loss:0.4951852560043335  \n","Epoch:39/50     Step:6|6   loss:0.4868342876434326  \n","Epoch:39/50     Step:7|6   loss:0.4861440062522888  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48662036657333374  \n","Epoch:40/50     Step:2|6   loss:0.4863455891609192  \n","Epoch:40/50     Step:3|6   loss:0.4901620149612427  \n","Epoch:40/50     Step:4|6   loss:0.48714956641197205  \n","Epoch:40/50     Step:5|6   loss:0.48631709814071655  \n","Epoch:40/50     Step:6|6   loss:0.48626217246055603  \n","Epoch:40/50     Step:7|6   loss:0.49886107444763184  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:91.59%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.48640120029449463  \n","Epoch:41/50     Step:2|6   loss:0.490185022354126  \n","Epoch:41/50     Step:3|6   loss:0.48998135328292847  \n","Epoch:41/50     Step:4|6   loss:0.4862675666809082  \n","Epoch:41/50     Step:5|6   loss:0.4901121258735657  \n","Epoch:41/50     Step:6|6   loss:0.48707476258277893  \n","Epoch:41/50     Step:7|6   loss:0.4860000014305115  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48670464754104614  \n","Epoch:42/50     Step:2|6   loss:0.4888697862625122  \n","Epoch:42/50     Step:3|6   loss:0.4899241328239441  \n","Epoch:42/50     Step:4|6   loss:0.48700523376464844  \n","Epoch:42/50     Step:5|6   loss:0.4864412546157837  \n","Epoch:42/50     Step:6|6   loss:0.48635321855545044  \n","Epoch:42/50     Step:7|6   loss:0.4916691780090332  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4859217703342438  \n","Epoch:43/50     Step:2|6   loss:0.48612552881240845  \n","Epoch:43/50     Step:3|6   loss:0.48956701159477234  \n","Epoch:43/50     Step:4|6   loss:0.4939808249473572  \n","Epoch:43/50     Step:5|6   loss:0.485940158367157  \n","Epoch:43/50     Step:6|6   loss:0.4859861731529236  \n","Epoch:43/50     Step:7|6   loss:0.48691484332084656  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48605021834373474  \n","Epoch:44/50     Step:2|6   loss:0.4931321144104004  \n","Epoch:44/50     Step:3|6   loss:0.48594170808792114  \n","Epoch:44/50     Step:4|6   loss:0.48610779643058777  \n","Epoch:44/50     Step:5|6   loss:0.48700183629989624  \n","Epoch:44/50     Step:6|6   loss:0.48887476325035095  \n","Epoch:44/50     Step:7|6   loss:0.486115962266922  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4862287938594818  \n","Epoch:45/50     Step:2|6   loss:0.4881024658679962  \n","Epoch:45/50     Step:3|6   loss:0.48678967356681824  \n","Epoch:45/50     Step:4|6   loss:0.48924878239631653  \n","Epoch:45/50     Step:5|6   loss:0.4863168001174927  \n","Epoch:45/50     Step:6|6   loss:0.48612260818481445  \n","Epoch:45/50     Step:7|6   loss:0.491206556558609  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.489127516746521  \n","Epoch:46/50     Step:2|6   loss:0.4896710515022278  \n","Epoch:46/50     Step:3|6   loss:0.48623624444007874  \n","Epoch:46/50     Step:4|6   loss:0.48645728826522827  \n","Epoch:46/50     Step:5|6   loss:0.48611557483673096  \n","Epoch:46/50     Step:6|6   loss:0.4881560802459717  \n","Epoch:46/50     Step:7|6   loss:0.4858916997909546  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48611608147621155  \n","Epoch:47/50     Step:2|6   loss:0.4859835207462311  \n","Epoch:47/50     Step:3|6   loss:0.48639965057373047  \n","Epoch:47/50     Step:4|6   loss:0.4877472221851349  \n","Epoch:47/50     Step:5|6   loss:0.4862046241760254  \n","Epoch:47/50     Step:6|6   loss:0.4855630397796631  \n","Epoch:47/50     Step:7|6   loss:0.496462881565094  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:92.52%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4884621500968933  \n","Epoch:48/50     Step:2|6   loss:0.48927760124206543  \n","Epoch:48/50     Step:3|6   loss:0.4859384298324585  \n","Epoch:48/50     Step:4|6   loss:0.48571354150772095  \n","Epoch:48/50     Step:5|6   loss:0.486016184091568  \n","Epoch:48/50     Step:6|6   loss:0.48917531967163086  \n","Epoch:48/50     Step:7|6   loss:0.4859442412853241  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4857354164123535  \n","Epoch:49/50     Step:2|6   loss:0.4889659583568573  \n","Epoch:49/50     Step:3|6   loss:0.48785313963890076  \n","Epoch:49/50     Step:4|6   loss:0.48905256390571594  \n","Epoch:49/50     Step:5|6   loss:0.4862430989742279  \n","Epoch:49/50     Step:6|6   loss:0.48593246936798096  \n","Epoch:49/50     Step:7|6   loss:0.48595282435417175  2\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48600131273269653  \n","Epoch:50/50     Step:2|6   loss:0.485822468996048  \n","Epoch:50/50     Step:3|6   loss:0.48558753728866577  \n","Epoch:50/50     Step:4|6   loss:0.49120283126831055  \n","Epoch:50/50     Step:5|6   loss:0.4857347905635834  \n","Epoch:50/50     Step:6|6   loss:0.4857460856437683  \n","Epoch:50/50     Step:7|6   loss:0.490594744682312  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Accuracy on test_set: 92.52 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0944691896438599  \n","Epoch:1/50     Step:2|6   loss:2.2557790279388428  \n","Epoch:1/50     Step:3|6   loss:1.6102713346481323  \n","Epoch:1/50     Step:4|6   loss:0.9912467002868652  \n","Epoch:1/50     Step:5|6   loss:1.4275946617126465  \n","Epoch:1/50     Step:6|6   loss:1.0545032024383545  \n","Epoch:1/50     Step:7|6   loss:0.8650726079940796  \n","Accuracy on test_set: 56.07 %\n","Accuracy on train_set: 61.36 %\n","current max accuracy\t test set:56.07%\t train set:61.36%\n","Epoch:2/50     Step:1|6   loss:0.866773247718811  \n","Epoch:2/50     Step:2|6   loss:0.8818868398666382  \n","Epoch:2/50     Step:3|6   loss:1.0520915985107422  \n","Epoch:2/50     Step:4|6   loss:0.940176784992218  \n","Epoch:2/50     Step:5|6   loss:0.8141531944274902  \n","Epoch:2/50     Step:6|6   loss:0.8300843834877014  \n","Epoch:2/50     Step:7|6   loss:0.7986936569213867  \n","Accuracy on test_set: 71.03 %\n","Accuracy on train_set: 77.05 %\n","current max accuracy\t test set:71.03%\t train set:77.05%\n","Epoch:3/50     Step:1|6   loss:0.6940276026725769  \n","Epoch:3/50     Step:2|6   loss:0.7630964517593384  \n","Epoch:3/50     Step:3|6   loss:0.7247695922851562  \n","Epoch:3/50     Step:4|6   loss:0.7757381200790405  \n","Epoch:3/50     Step:5|6   loss:0.7073882818222046  \n","Epoch:3/50     Step:6|6   loss:0.7564824819564819  \n","Epoch:3/50     Step:7|6   loss:0.7162376642227173  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 83.37 %\n","current max accuracy\t test set:80.37%\t train set:83.37%\n","Epoch:4/50     Step:1|6   loss:0.7352975606918335  \n","Epoch:4/50     Step:2|6   loss:0.7150942087173462  \n","Epoch:4/50     Step:3|6   loss:0.677862286567688  \n","Epoch:4/50     Step:4|6   loss:0.708763599395752  \n","Epoch:4/50     Step:5|6   loss:0.7191648483276367  \n","Epoch:4/50     Step:6|6   loss:0.6910986304283142  \n","Epoch:4/50     Step:7|6   loss:0.6559440493583679  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 85.48 %\n","current max accuracy\t test set:80.37%\t train set:85.48%\n","Epoch:5/50     Step:1|6   loss:0.6700557470321655  \n","Epoch:5/50     Step:2|6   loss:0.6928538084030151  \n","Epoch:5/50     Step:3|6   loss:0.6874775886535645  \n","Epoch:5/50     Step:4|6   loss:0.6851485371589661  \n","Epoch:5/50     Step:5|6   loss:0.656103253364563  \n","Epoch:5/50     Step:6|6   loss:0.6316341161727905  \n","Epoch:5/50     Step:7|6   loss:0.646307110786438  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 85.95 %\n","current max accuracy\t test set:82.24%\t train set:85.95%\n","Epoch:6/50     Step:1|6   loss:0.6676875352859497  \n","Epoch:6/50     Step:2|6   loss:0.600175142288208  \n","Epoch:6/50     Step:3|6   loss:0.6484653353691101  \n","Epoch:6/50     Step:4|6   loss:0.6307471990585327  \n","Epoch:6/50     Step:5|6   loss:0.704364538192749  \n","Epoch:6/50     Step:6|6   loss:0.6936312913894653  \n","Epoch:6/50     Step:7|6   loss:0.5627565383911133  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:84.11%\t train set:91.33%\n","Epoch:7/50     Step:1|6   loss:0.6548606157302856  \n","Epoch:7/50     Step:2|6   loss:0.6586618423461914  \n","Epoch:7/50     Step:3|6   loss:0.6261969804763794  \n","Epoch:7/50     Step:4|6   loss:0.5983227491378784  \n","Epoch:7/50     Step:5|6   loss:0.6273443698883057  \n","Epoch:7/50     Step:6|6   loss:0.6151922941207886  \n","Epoch:7/50     Step:7|6   loss:0.6318882703781128  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:84.11%\t train set:92.04%\n","Epoch:8/50     Step:1|6   loss:0.6075639724731445  \n","Epoch:8/50     Step:2|6   loss:0.6211172938346863  \n","Epoch:8/50     Step:3|6   loss:0.6216338872909546  \n","Epoch:8/50     Step:4|6   loss:0.5568207502365112  \n","Epoch:8/50     Step:5|6   loss:0.6468522548675537  \n","Epoch:8/50     Step:6|6   loss:0.5938581228256226  \n","Epoch:8/50     Step:7|6   loss:0.5833055973052979  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:85.05%\t train set:93.68%\n","Epoch:9/50     Step:1|6   loss:0.575224757194519  \n","Epoch:9/50     Step:2|6   loss:0.5849313735961914  \n","Epoch:9/50     Step:3|6   loss:0.5643230080604553  \n","Epoch:9/50     Step:4|6   loss:0.6175853610038757  \n","Epoch:9/50     Step:5|6   loss:0.6080660820007324  \n","Epoch:9/50     Step:6|6   loss:0.5806254744529724  \n","Epoch:9/50     Step:7|6   loss:0.569094181060791  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 94.38 %\n","current max accuracy\t test set:86.92%\t train set:94.38%\n","Epoch:10/50     Step:1|6   loss:0.5726012587547302  \n","Epoch:10/50     Step:2|6   loss:0.6077122688293457  \n","Epoch:10/50     Step:3|6   loss:0.5787962079048157  \n","Epoch:10/50     Step:4|6   loss:0.5674190521240234  \n","Epoch:10/50     Step:5|6   loss:0.5587756037712097  \n","Epoch:10/50     Step:6|6   loss:0.5437421202659607  \n","Epoch:10/50     Step:7|6   loss:0.5646730661392212  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:86.92%\t train set:96.02%\n","Epoch:11/50     Step:1|6   loss:0.5574150085449219  \n","Epoch:11/50     Step:2|6   loss:0.5448847413063049  \n","Epoch:11/50     Step:3|6   loss:0.5426608920097351  \n","Epoch:11/50     Step:4|6   loss:0.5849736332893372  \n","Epoch:11/50     Step:5|6   loss:0.5352019667625427  \n","Epoch:11/50     Step:6|6   loss:0.5485954880714417  \n","Epoch:11/50     Step:7|6   loss:0.6021562814712524  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:86.92%\t train set:97.66%\n","Epoch:12/50     Step:1|6   loss:0.586590588092804  \n","Epoch:12/50     Step:2|6   loss:0.5422819256782532  \n","Epoch:12/50     Step:3|6   loss:0.5511003136634827  \n","Epoch:12/50     Step:4|6   loss:0.5426380038261414  \n","Epoch:12/50     Step:5|6   loss:0.5215267539024353  \n","Epoch:12/50     Step:6|6   loss:0.5275207757949829  \n","Epoch:12/50     Step:7|6   loss:0.5305459499359131  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:86.92%\t train set:97.89%\n","Epoch:13/50     Step:1|6   loss:0.5378290414810181  \n","Epoch:13/50     Step:2|6   loss:0.5240111947059631  \n","Epoch:13/50     Step:3|6   loss:0.542795717716217  \n","Epoch:13/50     Step:4|6   loss:0.5452842116355896  \n","Epoch:13/50     Step:5|6   loss:0.5054494738578796  \n","Epoch:13/50     Step:6|6   loss:0.5167400240898132  \n","Epoch:13/50     Step:7|6   loss:0.5497028827667236  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:86.92%\t train set:98.36%\n","Epoch:14/50     Step:1|6   loss:0.5118435025215149  \n","Epoch:14/50     Step:2|6   loss:0.521221399307251  \n","Epoch:14/50     Step:3|6   loss:0.521156907081604  \n","Epoch:14/50     Step:4|6   loss:0.5095412731170654  \n","Epoch:14/50     Step:5|6   loss:0.5322875380516052  \n","Epoch:14/50     Step:6|6   loss:0.5263948440551758  \n","Epoch:14/50     Step:7|6   loss:0.520090639591217  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:86.92%\t train set:99.77%\n","Epoch:15/50     Step:1|6   loss:0.5213348865509033  \n","Epoch:15/50     Step:2|6   loss:0.5107252597808838  \n","Epoch:15/50     Step:3|6   loss:0.511413037776947  \n","Epoch:15/50     Step:4|6   loss:0.5126087665557861  \n","Epoch:15/50     Step:5|6   loss:0.5176479816436768  \n","Epoch:15/50     Step:6|6   loss:0.513558566570282  \n","Epoch:15/50     Step:7|6   loss:0.5116857886314392  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:86.92%\t train set:99.77%\n","Epoch:16/50     Step:1|6   loss:0.5129852294921875  \n","Epoch:16/50     Step:2|6   loss:0.5018927454948425  \n","Epoch:16/50     Step:3|6   loss:0.5147684812545776  \n","Epoch:16/50     Step:4|6   loss:0.5107070803642273  \n","Epoch:16/50     Step:5|6   loss:0.5105112791061401  \n","Epoch:16/50     Step:6|6   loss:0.503832221031189  \n","Epoch:16/50     Step:7|6   loss:0.5056536197662354  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:86.92%\t train set:99.77%\n","Epoch:17/50     Step:1|6   loss:0.5053552985191345  \n","Epoch:17/50     Step:2|6   loss:0.5018920302391052  \n","Epoch:17/50     Step:3|6   loss:0.5070756673812866  \n","Epoch:17/50     Step:4|6   loss:0.5039479732513428  \n","Epoch:17/50     Step:5|6   loss:0.5079692006111145  \n","Epoch:17/50     Step:6|6   loss:0.4995728135108948  \n","Epoch:17/50     Step:7|6   loss:0.5131895542144775  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.5050968527793884  \n","Epoch:18/50     Step:2|6   loss:0.5049432516098022  \n","Epoch:18/50     Step:3|6   loss:0.4994220733642578  \n","Epoch:18/50     Step:4|6   loss:0.5028293132781982  \n","Epoch:18/50     Step:5|6   loss:0.4944741725921631  \n","Epoch:18/50     Step:6|6   loss:0.49950605630874634  \n","Epoch:18/50     Step:7|6   loss:0.5000017881393433  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.49953439831733704  \n","Epoch:19/50     Step:2|6   loss:0.49789273738861084  \n","Epoch:19/50     Step:3|6   loss:0.5035911202430725  \n","Epoch:19/50     Step:4|6   loss:0.5008455514907837  \n","Epoch:19/50     Step:5|6   loss:0.492335706949234  \n","Epoch:19/50     Step:6|6   loss:0.4971253573894501  \n","Epoch:19/50     Step:7|6   loss:0.4982764720916748  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.49899548292160034  \n","Epoch:20/50     Step:2|6   loss:0.4955432415008545  \n","Epoch:20/50     Step:3|6   loss:0.4942731261253357  \n","Epoch:20/50     Step:4|6   loss:0.49818575382232666  \n","Epoch:20/50     Step:5|6   loss:0.49778586626052856  \n","Epoch:20/50     Step:6|6   loss:0.49183088541030884  \n","Epoch:20/50     Step:7|6   loss:0.49436432123184204  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.4915279746055603  \n","Epoch:21/50     Step:2|6   loss:0.491668164730072  \n","Epoch:21/50     Step:3|6   loss:0.4956960082054138  \n","Epoch:21/50     Step:4|6   loss:0.4939836263656616  \n","Epoch:21/50     Step:5|6   loss:0.4972010850906372  \n","Epoch:21/50     Step:6|6   loss:0.4978135824203491  \n","Epoch:21/50     Step:7|6   loss:0.490837424993515  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.49415966868400574  \n","Epoch:22/50     Step:2|6   loss:0.4915560185909271  \n","Epoch:22/50     Step:3|6   loss:0.4940764307975769  \n","Epoch:22/50     Step:4|6   loss:0.4915493130683899  \n","Epoch:22/50     Step:5|6   loss:0.491679847240448  \n","Epoch:22/50     Step:6|6   loss:0.4956035614013672  \n","Epoch:22/50     Step:7|6   loss:0.49504634737968445  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.49667221307754517  \n","Epoch:23/50     Step:2|6   loss:0.49134334921836853  \n","Epoch:23/50     Step:3|6   loss:0.49282950162887573  \n","Epoch:23/50     Step:4|6   loss:0.4909181594848633  \n","Epoch:23/50     Step:5|6   loss:0.48980408906936646  \n","Epoch:23/50     Step:6|6   loss:0.49329614639282227  \n","Epoch:23/50     Step:7|6   loss:0.49277469515800476  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4965132474899292  \n","Epoch:24/50     Step:2|6   loss:0.48971864581108093  \n","Epoch:24/50     Step:3|6   loss:0.4906255006790161  \n","Epoch:24/50     Step:4|6   loss:0.49349045753479004  \n","Epoch:24/50     Step:5|6   loss:0.49305570125579834  \n","Epoch:24/50     Step:6|6   loss:0.49042415618896484  \n","Epoch:24/50     Step:7|6   loss:0.4875783324241638  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.4941090941429138  \n","Epoch:25/50     Step:2|6   loss:0.48841592669487  \n","Epoch:25/50     Step:3|6   loss:0.4929656982421875  \n","Epoch:25/50     Step:4|6   loss:0.48908352851867676  \n","Epoch:25/50     Step:5|6   loss:0.48803237080574036  \n","Epoch:25/50     Step:6|6   loss:0.49085232615470886  \n","Epoch:25/50     Step:7|6   loss:0.4966687560081482  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.48927751183509827  \n","Epoch:26/50     Step:2|6   loss:0.48946526646614075  \n","Epoch:26/50     Step:3|6   loss:0.4886513948440552  \n","Epoch:26/50     Step:4|6   loss:0.4916518032550812  \n","Epoch:26/50     Step:5|6   loss:0.4882105886936188  \n","Epoch:26/50     Step:6|6   loss:0.49454158544540405  \n","Epoch:26/50     Step:7|6   loss:0.4917178153991699  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4917559027671814  \n","Epoch:27/50     Step:2|6   loss:0.48854774236679077  \n","Epoch:27/50     Step:3|6   loss:0.49054598808288574  \n","Epoch:27/50     Step:4|6   loss:0.49079546332359314  \n","Epoch:27/50     Step:5|6   loss:0.4900696277618408  \n","Epoch:27/50     Step:6|6   loss:0.48862844705581665  \n","Epoch:27/50     Step:7|6   loss:0.4900813102722168  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48835867643356323  \n","Epoch:28/50     Step:2|6   loss:0.49408555030822754  \n","Epoch:28/50     Step:3|6   loss:0.48934251070022583  \n","Epoch:28/50     Step:4|6   loss:0.48976200819015503  \n","Epoch:28/50     Step:5|6   loss:0.49054065346717834  \n","Epoch:28/50     Step:6|6   loss:0.4872046411037445  \n","Epoch:28/50     Step:7|6   loss:0.48879194259643555  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4890059530735016  \n","Epoch:29/50     Step:2|6   loss:0.48991167545318604  \n","Epoch:29/50     Step:3|6   loss:0.4868544936180115  \n","Epoch:29/50     Step:4|6   loss:0.4900954067707062  \n","Epoch:29/50     Step:5|6   loss:0.4887239336967468  \n","Epoch:29/50     Step:6|6   loss:0.48916083574295044  \n","Epoch:29/50     Step:7|6   loss:0.49272385239601135  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:86.92%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.49176451563835144  \n","Epoch:30/50     Step:2|6   loss:0.4886021912097931  \n","Epoch:30/50     Step:3|6   loss:0.4890378713607788  \n","Epoch:30/50     Step:4|6   loss:0.4901757836341858  \n","Epoch:30/50     Step:5|6   loss:0.4876846373081207  \n","Epoch:30/50     Step:6|6   loss:0.48887088894844055  \n","Epoch:30/50     Step:7|6   loss:0.48753297328948975  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.49120649695396423  \n","Epoch:31/50     Step:2|6   loss:0.49042877554893494  \n","Epoch:31/50     Step:3|6   loss:0.4879647493362427  \n","Epoch:31/50     Step:4|6   loss:0.49016067385673523  \n","Epoch:31/50     Step:5|6   loss:0.48846548795700073  \n","Epoch:31/50     Step:6|6   loss:0.48664313554763794  \n","Epoch:31/50     Step:7|6   loss:0.48680639266967773  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4875534176826477  \n","Epoch:32/50     Step:2|6   loss:0.4892244040966034  \n","Epoch:32/50     Step:3|6   loss:0.4930921792984009  \n","Epoch:32/50     Step:4|6   loss:0.48874038457870483  \n","Epoch:32/50     Step:5|6   loss:0.487249493598938  \n","Epoch:32/50     Step:6|6   loss:0.4862736463546753  \n","Epoch:32/50     Step:7|6   loss:0.4876171350479126  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.48776158690452576  \n","Epoch:33/50     Step:2|6   loss:0.4878033399581909  \n","Epoch:33/50     Step:3|6   loss:0.4895173907279968  \n","Epoch:33/50     Step:4|6   loss:0.48619359731674194  \n","Epoch:33/50     Step:5|6   loss:0.4902416467666626  \n","Epoch:33/50     Step:6|6   loss:0.4872436821460724  \n","Epoch:33/50     Step:7|6   loss:0.4900750517845154  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4861280918121338  \n","Epoch:34/50     Step:2|6   loss:0.49251681566238403  \n","Epoch:34/50     Step:3|6   loss:0.48901429772377014  \n","Epoch:34/50     Step:4|6   loss:0.48629873991012573  \n","Epoch:34/50     Step:5|6   loss:0.48806750774383545  \n","Epoch:34/50     Step:6|6   loss:0.4877188205718994  \n","Epoch:34/50     Step:7|6   loss:0.4872586727142334  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4876881539821625  \n","Epoch:35/50     Step:2|6   loss:0.4876624345779419  \n","Epoch:35/50     Step:3|6   loss:0.48844754695892334  \n","Epoch:35/50     Step:4|6   loss:0.48765966296195984  \n","Epoch:35/50     Step:5|6   loss:0.4882808327674866  \n","Epoch:35/50     Step:6|6   loss:0.4880545437335968  \n","Epoch:35/50     Step:7|6   loss:0.4884151220321655  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.487988144159317  \n","Epoch:36/50     Step:2|6   loss:0.4858696460723877  \n","Epoch:36/50     Step:3|6   loss:0.4883630871772766  \n","Epoch:36/50     Step:4|6   loss:0.48948079347610474  \n","Epoch:36/50     Step:5|6   loss:0.486147940158844  \n","Epoch:36/50     Step:6|6   loss:0.48888713121414185  \n","Epoch:36/50     Step:7|6   loss:0.4880724251270294  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.48943355679512024  \n","Epoch:37/50     Step:2|6   loss:0.4885610044002533  \n","Epoch:37/50     Step:3|6   loss:0.48739105463027954  \n","Epoch:37/50     Step:4|6   loss:0.4879573583602905  \n","Epoch:37/50     Step:5|6   loss:0.48644328117370605  \n","Epoch:37/50     Step:6|6   loss:0.48697996139526367  \n","Epoch:37/50     Step:7|6   loss:0.4867272973060608  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4858017563819885  \n","Epoch:38/50     Step:2|6   loss:0.4873736500740051  \n","Epoch:38/50     Step:3|6   loss:0.4873315393924713  \n","Epoch:38/50     Step:4|6   loss:0.48891136050224304  \n","Epoch:38/50     Step:5|6   loss:0.4870246648788452  \n","Epoch:38/50     Step:6|6   loss:0.48846739530563354  \n","Epoch:38/50     Step:7|6   loss:0.4880410134792328  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4883580505847931  \n","Epoch:39/50     Step:2|6   loss:0.4863852560520172  \n","Epoch:39/50     Step:3|6   loss:0.48692649602890015  \n","Epoch:39/50     Step:4|6   loss:0.49119383096694946  \n","Epoch:39/50     Step:5|6   loss:0.4857807755470276  \n","Epoch:39/50     Step:6|6   loss:0.48703399300575256  \n","Epoch:39/50     Step:7|6   loss:0.48570874333381653  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.4870535135269165  \n","Epoch:40/50     Step:2|6   loss:0.48571646213531494  \n","Epoch:40/50     Step:3|6   loss:0.4878508150577545  \n","Epoch:40/50     Step:4|6   loss:0.4880813956260681  \n","Epoch:40/50     Step:5|6   loss:0.4858834445476532  \n","Epoch:40/50     Step:6|6   loss:0.4883384108543396  \n","Epoch:40/50     Step:7|6   loss:0.48861077427864075  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4881019592285156  \n","Epoch:41/50     Step:2|6   loss:0.48639723658561707  \n","Epoch:41/50     Step:3|6   loss:0.4855057895183563  \n","Epoch:41/50     Step:4|6   loss:0.4869976043701172  \n","Epoch:41/50     Step:5|6   loss:0.485806941986084  \n","Epoch:41/50     Step:6|6   loss:0.490053653717041  \n","Epoch:41/50     Step:7|6   loss:0.48780232667922974  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48802077770233154  \n","Epoch:42/50     Step:2|6   loss:0.4871666133403778  \n","Epoch:42/50     Step:3|6   loss:0.48617246747016907  \n","Epoch:42/50     Step:4|6   loss:0.4888680875301361  \n","Epoch:42/50     Step:5|6   loss:0.4856089949607849  \n","Epoch:42/50     Step:6|6   loss:0.4871722459793091  \n","Epoch:42/50     Step:7|6   loss:0.48664167523384094  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4898020625114441  \n","Epoch:43/50     Step:2|6   loss:0.48762476444244385  \n","Epoch:43/50     Step:3|6   loss:0.4855802655220032  \n","Epoch:43/50     Step:4|6   loss:0.4863852858543396  \n","Epoch:43/50     Step:5|6   loss:0.4869791865348816  \n","Epoch:43/50     Step:6|6   loss:0.4861343801021576  \n","Epoch:43/50     Step:7|6   loss:0.48649507761001587  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48554691672325134  \n","Epoch:44/50     Step:2|6   loss:0.48627740144729614  \n","Epoch:44/50     Step:3|6   loss:0.48561346530914307  \n","Epoch:44/50     Step:4|6   loss:0.48936545848846436  \n","Epoch:44/50     Step:5|6   loss:0.48616132140159607  \n","Epoch:44/50     Step:6|6   loss:0.488504558801651  \n","Epoch:44/50     Step:7|6   loss:0.4873954653739929  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4878723621368408  \n","Epoch:45/50     Step:2|6   loss:0.48693180084228516  \n","Epoch:45/50     Step:3|6   loss:0.48740583658218384  \n","Epoch:45/50     Step:4|6   loss:0.485975980758667  \n","Epoch:45/50     Step:5|6   loss:0.486675500869751  \n","Epoch:45/50     Step:6|6   loss:0.486274778842926  \n","Epoch:45/50     Step:7|6   loss:0.48699966073036194  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.48744338750839233  \n","Epoch:46/50     Step:2|6   loss:0.48540976643562317  \n","Epoch:46/50     Step:3|6   loss:0.4866982698440552  \n","Epoch:46/50     Step:4|6   loss:0.48776090145111084  \n","Epoch:46/50     Step:5|6   loss:0.48699748516082764  \n","Epoch:46/50     Step:6|6   loss:0.48673367500305176  \n","Epoch:46/50     Step:7|6   loss:0.4863843619823456  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48542436957359314  \n","Epoch:47/50     Step:2|6   loss:0.4865393042564392  \n","Epoch:47/50     Step:3|6   loss:0.48659464716911316  \n","Epoch:47/50     Step:4|6   loss:0.48732730746269226  \n","Epoch:47/50     Step:5|6   loss:0.48837876319885254  \n","Epoch:47/50     Step:6|6   loss:0.48648911714553833  \n","Epoch:47/50     Step:7|6   loss:0.48615264892578125  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4872004985809326  \n","Epoch:48/50     Step:2|6   loss:0.48683732748031616  \n","Epoch:48/50     Step:3|6   loss:0.4859851002693176  \n","Epoch:48/50     Step:4|6   loss:0.4868450164794922  \n","Epoch:48/50     Step:5|6   loss:0.4867459535598755  \n","Epoch:48/50     Step:6|6   loss:0.48596033453941345  \n","Epoch:48/50     Step:7|6   loss:0.487294465303421  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48737454414367676  \n","Epoch:49/50     Step:2|6   loss:0.48597320914268494  \n","Epoch:49/50     Step:3|6   loss:0.4873192012310028  \n","Epoch:49/50     Step:4|6   loss:0.4854310154914856  \n","Epoch:49/50     Step:5|6   loss:0.4877798557281494  \n","Epoch:49/50     Step:6|6   loss:0.48601141571998596  \n","Epoch:49/50     Step:7|6   loss:0.4862363636493683  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.48674002289772034  \n","Epoch:50/50     Step:2|6   loss:0.48670437932014465  \n","Epoch:50/50     Step:3|6   loss:0.4874843955039978  \n","Epoch:50/50     Step:4|6   loss:0.4853127896785736  \n","Epoch:50/50     Step:5|6   loss:0.486331045627594  \n","Epoch:50/50     Step:6|6   loss:0.4869525730609894  \n","Epoch:50/50     Step:7|6   loss:0.48618409037590027  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:88.79%\t train set:100.0%\n","Accuracy on test_set: 85.98 %\n","3\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0965328216552734  \n","Epoch:1/50     Step:2|6   loss:2.27909517288208  \n","Epoch:1/50     Step:3|6   loss:2.262672185897827  \n","Epoch:1/50     Step:4|6   loss:1.8983118534088135  \n","Epoch:1/50     Step:5|6   loss:1.7791110277175903  \n","Epoch:1/50     Step:6|6   loss:1.8203327655792236  \n","Epoch:1/50     Step:7|6   loss:2.9260599613189697  \n","Accuracy on test_set: 48.60 %\n","Accuracy on train_set: 52.22 %\n","current max accuracy\t test set:48.6%\t train set:52.22%4\n","\n","Epoch:2/50     Step:1|6   loss:2.1095807552337646  \n","Epoch:2/50     Step:2|6   loss:2.1843109130859375  \n","Epoch:2/50     Step:3|6   loss:2.436802387237549  \n","Epoch:2/50     Step:4|6   loss:2.1143884658813477  \n","Epoch:2/50     Step:5|6   loss:1.733130693435669  \n","Epoch:2/50     Step:6|6   loss:1.8179618120193481  \n","Epoch:2/50     Step:7|6   loss:1.6701579093933105  \n","Accuracy on test_set: 52.34 %\n","Accuracy on train_set: 56.44 %\n","current max accuracy\t test set:52.34%\t train set:56.44%\n","Epoch:3/50     Step:1|6   loss:1.993896484375  \n","Epoch:3/50     Step:2|6   loss:2.094944477081299  \n","Epoch:3/50     Step:3|6   loss:1.9672212600708008  \n","Epoch:3/50     Step:4|6   loss:1.8131135702133179  \n","Epoch:3/50     Step:5|6   loss:1.868497371673584  \n","Epoch:3/50     Step:6|6   loss:1.690242052078247  \n","Epoch:3/50     Step:7|6   loss:2.3070619106292725  \n","Accuracy on test_set: 60.75 %\n","Accuracy on train_set: 63.93 %\n","current max accuracy\t test set:60.75%\t train set:63.93%\n","Epoch:4/50     Step:1|6   loss:2.3823094367980957  \n","Epoch:4/50     Step:2|6   loss:1.738966464996338  \n","Epoch:4/50     Step:3|6   loss:1.5081138610839844  \n","Epoch:4/50     Step:4|6   loss:1.0260173082351685  \n","Epoch:4/50     Step:5|6   loss:0.7864117622375488  \n","Epoch:4/50     Step:6|6   loss:2.048532724380493  \n","Epoch:4/50     Step:7|6   loss:0.8778051137924194  \n","Accuracy on test_set: 76.64 %\n","Accuracy on train_set: 78.22 %\n","current max accuracy\t test set:76.64%\t train set:78.22%\n","Epoch:5/50     Step:1|6   loss:0.8203076124191284  \n","Epoch:5/50     Step:2|6   loss:0.8539652824401855  \n","Epoch:5/50     Step:3|6   loss:0.9258507490158081  \n","Epoch:5/50     Step:4|6   loss:1.0741997957229614  \n","Epoch:5/50     Step:5|6   loss:1.1730300188064575  \n","Epoch:5/50     Step:6|6   loss:1.1635456085205078  \n","Epoch:5/50     Step:7|6   loss:1.1987825632095337  \n","Accuracy on test_set: 75.70 %\n","Accuracy on train_set: 78.92 %\n","current max accuracy\t test set:76.64%\t train set:78.92%\n","Epoch:6/50     Step:1|6   loss:0.893786609172821  \n","Epoch:6/50     Step:2|6   loss:0.9505900144577026  \n","Epoch:6/50     Step:3|6   loss:0.8338150382041931  \n","Epoch:6/50     Step:4|6   loss:0.7448984384536743  \n","Epoch:6/50     Step:5|6   loss:0.763418436050415  \n","Epoch:6/50     Step:6|6   loss:0.638849675655365  \n","Epoch:6/50     Step:7|6   loss:0.65682452917099  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:87.85%\t train set:85.71%\n","Epoch:7/50     Step:1|6   loss:0.679705023765564  \n","Epoch:7/50     Step:2|6   loss:0.7226487398147583  \n","Epoch:7/50     Step:3|6   loss:0.7450750470161438  \n","Epoch:7/50     Step:4|6   loss:0.6683571338653564  \n","Epoch:7/50     Step:5|6   loss:0.7233076691627502  \n","Epoch:7/50     Step:6|6   loss:0.686848521232605  \n","Epoch:7/50     Step:7|6   loss:0.6218250393867493  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 86.42 %\n","current max accuracy\t test set:87.85%\t train set:86.42%\n","Epoch:8/50     Step:1|6   loss:0.6779009103775024  \n","Epoch:8/50     Step:2|6   loss:0.6473039388656616  \n","Epoch:8/50     Step:3|6   loss:0.6922589540481567  \n","Epoch:8/50     Step:4|6   loss:0.6438063383102417  \n","Epoch:8/50     Step:5|6   loss:0.654036283493042  \n","Epoch:8/50     Step:6|6   loss:0.6239155530929565  \n","Epoch:8/50     Step:7|6   loss:0.651922881603241  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 90.40 %\n","current max accuracy\t test set:88.79%\t train set:90.4%\n","Epoch:9/50     Step:1|6   loss:0.6633594036102295  \n","Epoch:9/50     Step:2|6   loss:0.6372079253196716  \n","Epoch:9/50     Step:3|6   loss:0.6591700315475464  \n","Epoch:9/50     Step:4|6   loss:0.628461480140686  \n","Epoch:9/50     Step:5|6   loss:0.6333363652229309  \n","Epoch:9/50     Step:6|6   loss:0.6275514364242554  \n","Epoch:9/50     Step:7|6   loss:0.5757335424423218  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:89.72%\t train set:92.27%\n","Epoch:10/50     Step:1|6   loss:0.5937027931213379  \n","Epoch:10/50     Step:2|6   loss:0.6715272665023804  \n","Epoch:10/50     Step:3|6   loss:0.6414406299591064  \n","Epoch:10/50     Step:4|6   loss:0.6111964583396912  \n","Epoch:10/50     Step:5|6   loss:0.6029706001281738  \n","Epoch:10/50     Step:6|6   loss:0.5690435171127319  \n","Epoch:10/50     Step:7|6   loss:0.622353196144104  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:89.72%\t train set:92.27%\n","Epoch:11/50     Step:1|6   loss:0.5802143812179565  \n","Epoch:11/50     Step:2|6   loss:0.6040017604827881  \n","Epoch:11/50     Step:3|6   loss:0.566368579864502  \n","Epoch:11/50     Step:4|6   loss:0.6296272277832031  \n","Epoch:11/50     Step:5|6   loss:0.6172096729278564  \n","Epoch:11/50     Step:6|6   loss:0.5612782835960388  \n","Epoch:11/50     Step:7|6   loss:0.6518926620483398  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:89.72%\t train set:93.68%\n","Epoch:12/50     Step:1|6   loss:0.599532961845398  \n","Epoch:12/50     Step:2|6   loss:0.5909569263458252  \n","Epoch:12/50     Step:3|6   loss:0.6280312538146973  \n","Epoch:12/50     Step:4|6   loss:0.5875579118728638  \n","Epoch:12/50     Step:5|6   loss:0.5723877549171448  \n","Epoch:12/50     Step:6|6   loss:0.5700467824935913  \n","Epoch:12/50     Step:7|6   loss:0.5515220165252686  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:90.65%\t train set:93.91%\n","Epoch:13/50     Step:1|6   loss:0.6014671921730042  \n","Epoch:13/50     Step:2|6   loss:0.5457103848457336  \n","Epoch:13/50     Step:3|6   loss:0.560735821723938  \n","Epoch:13/50     Step:4|6   loss:0.5996882915496826  \n","Epoch:13/50     Step:5|6   loss:0.5836244821548462  \n","Epoch:13/50     Step:6|6   loss:0.5800395607948303  \n","Epoch:13/50     Step:7|6   loss:0.5696910619735718  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:90.65%\t train set:95.55%\n","Epoch:14/50     Step:1|6   loss:0.5719851851463318  \n","Epoch:14/50     Step:2|6   loss:0.5435916185379028  \n","Epoch:14/50     Step:3|6   loss:0.5715572237968445  \n","Epoch:14/50     Step:4|6   loss:0.5712490081787109  \n","Epoch:14/50     Step:5|6   loss:0.5810979604721069  \n","Epoch:14/50     Step:6|6   loss:0.5498529672622681  \n","Epoch:14/50     Step:7|6   loss:0.6148794889450073  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:91.59%\t train set:96.02%\n","Epoch:15/50     Step:1|6   loss:0.5647128820419312  \n","Epoch:15/50     Step:2|6   loss:0.5636464357376099  \n","Epoch:15/50     Step:3|6   loss:0.5739891529083252  \n","Epoch:15/50     Step:4|6   loss:0.60715651512146  \n","Epoch:15/50     Step:5|6   loss:0.5532497763633728  \n","Epoch:15/50     Step:6|6   loss:0.5438275337219238  \n","Epoch:15/50     Step:7|6   loss:0.5422816276550293  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:91.59%\t train set:97.19%\n","Epoch:16/50     Step:1|6   loss:0.5462301969528198  \n","Epoch:16/50     Step:2|6   loss:0.5646030902862549  \n","Epoch:16/50     Step:3|6   loss:0.5738259553909302  \n","Epoch:16/50     Step:4|6   loss:0.5503605604171753  \n","Epoch:16/50     Step:5|6   loss:0.5549166202545166  \n","Epoch:16/50     Step:6|6   loss:0.5511323809623718  \n","Epoch:16/50     Step:7|6   loss:0.5403651595115662  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:91.59%\t train set:97.19%\n","Epoch:17/50     Step:1|6   loss:0.549116849899292  \n","Epoch:17/50     Step:2|6   loss:0.5797731280326843  \n","Epoch:17/50     Step:3|6   loss:0.5314357876777649  \n","Epoch:17/50     Step:4|6   loss:0.5531734824180603  \n","Epoch:17/50     Step:5|6   loss:0.5373036861419678  \n","Epoch:17/50     Step:6|6   loss:0.5361759662628174  \n","Epoch:17/50     Step:7|6   loss:0.552714467048645  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:91.59%\t train set:97.42%\n","Epoch:18/50     Step:1|6   loss:0.5388517379760742  \n","Epoch:18/50     Step:2|6   loss:0.5373250842094421  \n","Epoch:18/50     Step:3|6   loss:0.5435971617698669  \n","Epoch:18/50     Step:4|6   loss:0.5535523891448975  \n","Epoch:18/50     Step:5|6   loss:0.5308690071105957  \n","Epoch:18/50     Step:6|6   loss:0.545217752456665  \n","Epoch:18/50     Step:7|6   loss:0.5470557808876038  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:91.59%\t train set:97.89%\n","Epoch:19/50     Step:1|6   loss:0.5439289808273315  \n","Epoch:19/50     Step:2|6   loss:0.5299161672592163  \n","Epoch:19/50     Step:3|6   loss:0.5511305928230286  \n","Epoch:19/50     Step:4|6   loss:0.5313960313796997  \n","Epoch:19/50     Step:5|6   loss:0.5247415900230408  \n","Epoch:19/50     Step:6|6   loss:0.5568950176239014  \n","Epoch:19/50     Step:7|6   loss:0.5177319645881653  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:92.52%\t train set:98.59%\n","Epoch:20/50     Step:1|6   loss:0.5371965169906616  \n","Epoch:20/50     Step:2|6   loss:0.5373298525810242  \n","Epoch:20/50     Step:3|6   loss:0.5313434600830078  \n","Epoch:20/50     Step:4|6   loss:0.5235581994056702  \n","Epoch:20/50     Step:5|6   loss:0.5372192859649658  \n","Epoch:20/50     Step:6|6   loss:0.5262759923934937  \n","Epoch:20/50     Step:7|6   loss:0.533582329750061  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:92.52%\t train set:99.53%\n","Epoch:21/50     Step:1|6   loss:0.5484447479248047  \n","Epoch:21/50     Step:2|6   loss:0.5339297652244568  \n","Epoch:21/50     Step:3|6   loss:0.5109879970550537  \n","Epoch:21/50     Step:4|6   loss:0.5305497646331787  \n","Epoch:21/50     Step:5|6   loss:0.5188826322555542  \n","Epoch:21/50     Step:6|6   loss:0.5316641926765442  \n","Epoch:21/50     Step:7|6   loss:0.5244908332824707  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:22/50     Step:1|6   loss:0.5229662656784058  \n","Epoch:22/50     Step:2|6   loss:0.5291146039962769  \n","Epoch:22/50     Step:3|6   loss:0.5114092230796814  \n","Epoch:22/50     Step:4|6   loss:0.5228877663612366  \n","Epoch:22/50     Step:5|6   loss:0.5420312285423279  \n","Epoch:22/50     Step:6|6   loss:0.5244454145431519  \n","Epoch:22/50     Step:7|6   loss:0.5243265628814697  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:23/50     Step:1|6   loss:0.5295007228851318  \n","Epoch:23/50     Step:2|6   loss:0.5060994625091553  \n","Epoch:23/50     Step:3|6   loss:0.5190654993057251  \n","Epoch:23/50     Step:4|6   loss:0.5219681859016418  \n","Epoch:23/50     Step:5|6   loss:0.525815486907959  \n","Epoch:23/50     Step:6|6   loss:0.5198265314102173  \n","Epoch:23/50     Step:7|6   loss:0.5325630307197571  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:24/50     Step:1|6   loss:0.5320411920547485  \n","Epoch:24/50     Step:2|6   loss:0.5253214836120605  \n","Epoch:24/50     Step:3|6   loss:0.5227063894271851  \n","Epoch:24/50     Step:4|6   loss:0.5175901055335999  \n","Epoch:24/50     Step:5|6   loss:0.5053500533103943  \n","Epoch:24/50     Step:6|6   loss:0.518484890460968  \n","Epoch:24/50     Step:7|6   loss:0.5131826996803284  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.5179049372673035  \n","Epoch:25/50     Step:2|6   loss:0.5234127640724182  \n","Epoch:25/50     Step:3|6   loss:0.5109297037124634  \n","Epoch:25/50     Step:4|6   loss:0.5201787948608398  \n","Epoch:25/50     Step:5|6   loss:0.5197847485542297  \n","Epoch:25/50     Step:6|6   loss:0.5083211064338684  \n","Epoch:25/50     Step:7|6   loss:0.5092292428016663  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.5152869820594788  \n","Epoch:26/50     Step:2|6   loss:0.5006593465805054  \n","Epoch:26/50     Step:3|6   loss:0.5286824703216553  \n","Epoch:26/50     Step:4|6   loss:0.5200040936470032  \n","Epoch:26/50     Step:5|6   loss:0.5031615495681763  \n","Epoch:26/50     Step:6|6   loss:0.5220974683761597  \n","Epoch:26/50     Step:7|6   loss:0.5227727890014648  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.500842809677124  \n","Epoch:27/50     Step:2|6   loss:0.5186920762062073  \n","Epoch:27/50     Step:3|6   loss:0.5078158974647522  \n","Epoch:27/50     Step:4|6   loss:0.5187457799911499  \n","Epoch:27/50     Step:5|6   loss:0.5202274322509766  \n","Epoch:27/50     Step:6|6   loss:0.5098984837532043  \n","Epoch:27/50     Step:7|6   loss:0.5086745619773865  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.5077435374259949  \n","Epoch:28/50     Step:2|6   loss:0.5025298595428467  \n","Epoch:28/50     Step:3|6   loss:0.5094479918479919  \n","Epoch:28/50     Step:4|6   loss:0.5108820796012878  \n","Epoch:28/50     Step:5|6   loss:0.5114649534225464  \n","Epoch:28/50     Step:6|6   loss:0.5122483968734741  \n","Epoch:28/50     Step:7|6   loss:0.5192798376083374  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.5067588090896606  \n","Epoch:29/50     Step:2|6   loss:0.5104120969772339  \n","Epoch:29/50     Step:3|6   loss:0.5091163516044617  \n","Epoch:29/50     Step:4|6   loss:0.5102896690368652  \n","Epoch:29/50     Step:5|6   loss:0.5061894655227661  \n","Epoch:29/50     Step:6|6   loss:0.5016895532608032  \n","Epoch:29/50     Step:7|6   loss:0.5199223756790161  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:93.46%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.5083440542221069  \n","Epoch:30/50     Step:2|6   loss:0.5080690383911133  \n","Epoch:30/50     Step:3|6   loss:0.5067235827445984  \n","Epoch:30/50     Step:4|6   loss:0.508014976978302  \n","Epoch:30/50     Step:5|6   loss:0.5067970752716064  \n","Epoch:30/50     Step:6|6   loss:0.504298746585846  \n","Epoch:30/50     Step:7|6   loss:0.5035735964775085  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.5000795125961304  \n","Epoch:31/50     Step:2|6   loss:0.5089549422264099  \n","Epoch:31/50     Step:3|6   loss:0.5035348534584045  \n","Epoch:31/50     Step:4|6   loss:0.5081291794776917  \n","Epoch:31/50     Step:5|6   loss:0.5024579167366028  \n","Epoch:31/50     Step:6|6   loss:0.5078891515731812  \n","Epoch:31/50     Step:7|6   loss:0.5041854381561279  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.5036083459854126  \n","Epoch:32/50     Step:2|6   loss:0.5037635564804077  \n","Epoch:32/50     Step:3|6   loss:0.5024092197418213  \n","Epoch:32/50     Step:4|6   loss:0.5064436793327332  \n","Epoch:32/50     Step:5|6   loss:0.5016758441925049  \n","Epoch:32/50     Step:6|6   loss:0.5071609020233154  \n","Epoch:32/50     Step:7|6   loss:0.5013810396194458  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.5046327114105225  \n","Epoch:33/50     Step:2|6   loss:0.5060460567474365  \n","Epoch:33/50     Step:3|6   loss:0.503380298614502  \n","Epoch:33/50     Step:4|6   loss:0.5033661127090454  \n","Epoch:33/50     Step:5|6   loss:0.5051081776618958  \n","Epoch:33/50     Step:6|6   loss:0.5024399161338806  \n","Epoch:33/50     Step:7|6   loss:0.49395880103111267  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4984208643436432  \n","Epoch:34/50     Step:2|6   loss:0.5078218579292297  \n","Epoch:34/50     Step:3|6   loss:0.5103917121887207  \n","Epoch:34/50     Step:4|6   loss:0.5109071135520935  \n","Epoch:34/50     Step:5|6   loss:0.49408748745918274  \n","Epoch:34/50     Step:6|6   loss:0.49776148796081543  \n","Epoch:34/50     Step:7|6   loss:0.4972410202026367  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.5021436214447021  \n","Epoch:35/50     Step:2|6   loss:0.5006594657897949  \n","Epoch:35/50     Step:3|6   loss:0.49984169006347656  \n","Epoch:35/50     Step:4|6   loss:0.4977549910545349  \n","Epoch:35/50     Step:5|6   loss:0.5108875632286072  \n","Epoch:35/50     Step:6|6   loss:0.49370574951171875  \n","Epoch:35/50     Step:7|6   loss:0.5039821267127991  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.49907386302948  \n","Epoch:36/50     Step:2|6   loss:0.4976813793182373  \n","Epoch:36/50     Step:3|6   loss:0.5032030344009399  \n","Epoch:36/50     Step:4|6   loss:0.49820268154144287  \n","Epoch:36/50     Step:5|6   loss:0.500568687915802  \n","Epoch:36/50     Step:6|6   loss:0.4973255395889282  \n","Epoch:36/50     Step:7|6   loss:0.5050467252731323  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.5029062032699585  \n","Epoch:37/50     Step:2|6   loss:0.4964321255683899  \n","Epoch:37/50     Step:3|6   loss:0.498948335647583  \n","Epoch:37/50     Step:4|6   loss:0.5009446740150452  \n","Epoch:37/50     Step:5|6   loss:0.4975329637527466  \n","Epoch:37/50     Step:6|6   loss:0.5005927085876465  \n","Epoch:37/50     Step:7|6   loss:0.49383360147476196  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.49152928590774536  \n","Epoch:38/50     Step:2|6   loss:0.5024032592773438  \n","Epoch:38/50     Step:3|6   loss:0.4944016635417938  \n","Epoch:38/50     Step:4|6   loss:0.5003313422203064  \n","Epoch:38/50     Step:5|6   loss:0.4976784884929657  \n","Epoch:38/50     Step:6|6   loss:0.4983712434768677  \n","Epoch:38/50     Step:7|6   loss:0.5060558319091797  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4970611333847046  \n","Epoch:39/50     Step:2|6   loss:0.4990549087524414  \n","Epoch:39/50     Step:3|6   loss:0.4937154948711395  \n","Epoch:39/50     Step:4|6   loss:0.502712607383728  \n","Epoch:39/50     Step:5|6   loss:0.4938508868217468  \n","Epoch:39/50     Step:6|6   loss:0.4966665506362915  \n","Epoch:39/50     Step:7|6   loss:0.49973154067993164  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.5006341338157654  \n","Epoch:40/50     Step:2|6   loss:0.503242015838623  \n","Epoch:40/50     Step:3|6   loss:0.49195313453674316  \n","Epoch:40/50     Step:4|6   loss:0.49063700437545776  \n","Epoch:40/50     Step:5|6   loss:0.4984000027179718  \n","Epoch:40/50     Step:6|6   loss:0.49498680233955383  \n","Epoch:40/50     Step:7|6   loss:0.49667519330978394  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4937952756881714  \n","Epoch:41/50     Step:2|6   loss:0.4966501295566559  \n","Epoch:41/50     Step:3|6   loss:0.5019699335098267  \n","Epoch:41/50     Step:4|6   loss:0.4928712248802185  \n","Epoch:41/50     Step:5|6   loss:0.49790871143341064  \n","Epoch:41/50     Step:6|6   loss:0.49596238136291504  \n","Epoch:41/50     Step:7|6   loss:0.4921361804008484  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4992665946483612  \n","Epoch:42/50     Step:2|6   loss:0.5018740296363831  \n","Epoch:42/50     Step:3|6   loss:0.4932895302772522  \n","Epoch:42/50     Step:4|6   loss:0.4938920736312866  \n","Epoch:42/50     Step:5|6   loss:0.49460160732269287  \n","Epoch:42/50     Step:6|6   loss:0.49113336205482483  \n","Epoch:42/50     Step:7|6   loss:0.49430203437805176  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4944666624069214  \n","Epoch:43/50     Step:2|6   loss:0.4977342486381531  \n","Epoch:43/50     Step:3|6   loss:0.4938565790653229  \n","Epoch:43/50     Step:4|6   loss:0.49590739607810974  \n","Epoch:43/50     Step:5|6   loss:0.4924459457397461  \n","Epoch:43/50     Step:6|6   loss:0.49572357535362244  \n","Epoch:43/50     Step:7|6   loss:0.4958221912384033  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4924810528755188  \n","Epoch:44/50     Step:2|6   loss:0.4965015649795532  \n","Epoch:44/50     Step:3|6   loss:0.49147677421569824  \n","Epoch:44/50     Step:4|6   loss:0.49638935923576355  \n","Epoch:44/50     Step:5|6   loss:0.49943554401397705  \n","Epoch:44/50     Step:6|6   loss:0.49289488792419434  \n","Epoch:44/50     Step:7|6   loss:0.49200236797332764  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.49390730261802673  \n","Epoch:45/50     Step:2|6   loss:0.49424463510513306  \n","Epoch:45/50     Step:3|6   loss:0.49495360255241394  \n","Epoch:45/50     Step:4|6   loss:0.49209898710250854  \n","Epoch:45/50     Step:5|6   loss:0.49590030312538147  \n","Epoch:45/50     Step:6|6   loss:0.49383676052093506  \n","Epoch:45/50     Step:7|6   loss:0.4946843683719635  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.492545485496521  \n","Epoch:46/50     Step:2|6   loss:0.4966956377029419  \n","Epoch:46/50     Step:3|6   loss:0.4932979345321655  \n","Epoch:46/50     Step:4|6   loss:0.49715572595596313  \n","Epoch:46/50     Step:5|6   loss:0.4916078448295593  \n","Epoch:46/50     Step:6|6   loss:0.494144082069397  \n","Epoch:46/50     Step:7|6   loss:0.49063190817832947  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.49426358938217163  \n","Epoch:47/50     Step:2|6   loss:0.4943271279335022  \n","Epoch:47/50     Step:3|6   loss:0.4936152696609497  \n","Epoch:47/50     Step:4|6   loss:0.49295514822006226  \n","Epoch:47/50     Step:5|6   loss:0.4931430220603943  \n","Epoch:47/50     Step:6|6   loss:0.4938672184944153  \n","Epoch:47/50     Step:7|6   loss:0.4906136393547058  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.49365556240081787  \n","Epoch:48/50     Step:2|6   loss:0.493936687707901  \n","Epoch:48/50     Step:3|6   loss:0.4897744059562683  \n","Epoch:48/50     Step:4|6   loss:0.49155178666114807  \n","Epoch:48/50     Step:5|6   loss:0.4920560121536255  \n","Epoch:48/50     Step:6|6   loss:0.4968411922454834  \n","Epoch:48/50     Step:7|6   loss:0.4942708909511566  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.4923568367958069  \n","Epoch:49/50     Step:2|6   loss:0.49090486764907837  \n","Epoch:49/50     Step:3|6   loss:0.49346300959587097  \n","Epoch:49/50     Step:4|6   loss:0.49388614296913147  \n","Epoch:49/50     Step:5|6   loss:0.4973756670951843  \n","Epoch:49/50     Step:6|6   loss:0.49002623558044434  \n","Epoch:49/50     Step:7|6   loss:0.4909043610095978  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4941004514694214  \n","Epoch:50/50     Step:2|6   loss:0.49031028151512146  \n","Epoch:50/50     Step:3|6   loss:0.4945545494556427  \n","Epoch:50/50     Step:4|6   loss:0.49511462450027466  \n","Epoch:50/50     Step:5|6   loss:0.490678995847702  \n","Epoch:50/50     Step:6|6   loss:0.49199312925338745  \n","Epoch:50/50     Step:7|6   loss:0.48937249183654785  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Accuracy on test_set: 94.39 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0943121910095215  \n","Epoch:1/50     Step:2|6   loss:1.785035490989685  \n","Epoch:1/50     Step:3|6   loss:1.4890191555023193  \n","Epoch:1/50     Step:4|6   loss:1.1111133098602295  \n","Epoch:1/50     Step:5|6   loss:0.7669851779937744  \n","Epoch:1/50     Step:6|6   loss:0.8762997388839722  \n","Epoch:1/50     Step:7|6   loss:0.8406873941421509  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 73.07 %\n","current max accuracy\t test set:82.24%\t train set:73.07%\n","Epoch:2/50     Step:1|6   loss:0.9806421995162964  \n","Epoch:2/50     Step:2|6   loss:0.7780910730361938  \n","Epoch:2/50     Step:3|6   loss:0.7208439111709595  \n","Epoch:2/50     Step:4|6   loss:0.6864491701126099  \n","Epoch:2/50     Step:5|6   loss:0.7189429998397827  \n","Epoch:2/50     Step:6|6   loss:0.6952162384986877  \n","Epoch:2/50     Step:7|6   loss:0.6772433519363403  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:82.24%\t train set:88.52%\n","Epoch:3/50     Step:1|6   loss:0.7343704700469971  \n","Epoch:3/50     Step:2|6   loss:0.7029668092727661  \n","Epoch:3/50     Step:3|6   loss:0.612349271774292  \n","Epoch:3/50     Step:4|6   loss:0.6425231695175171  \n","Epoch:3/50     Step:5|6   loss:0.6934133768081665  \n","Epoch:3/50     Step:6|6   loss:0.7221282720565796  \n","Epoch:3/50     Step:7|6   loss:0.6844748258590698  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:82.24%\t train set:88.52%\n","Epoch:4/50     Step:1|6   loss:0.6471101641654968  \n","Epoch:4/50     Step:2|6   loss:0.6432560682296753  \n","Epoch:4/50     Step:3|6   loss:0.7028462886810303  \n","Epoch:4/50     Step:4|6   loss:0.6446155309677124  \n","Epoch:4/50     Step:5|6   loss:0.6028801202774048  \n","Epoch:4/50     Step:6|6   loss:0.669054388999939  \n","Epoch:4/50     Step:7|6   loss:0.6704268455505371  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:82.24%\t train set:88.52%\n","Epoch:5/50     Step:1|6   loss:0.6675868034362793  \n","Epoch:5/50     Step:2|6   loss:0.6474074721336365  \n","Epoch:5/50     Step:3|6   loss:0.6250272989273071  \n","Epoch:5/50     Step:4|6   loss:0.5953994989395142  \n","Epoch:5/50     Step:5|6   loss:0.6881455183029175  \n","Epoch:5/50     Step:6|6   loss:0.622740626335144  \n","Epoch:5/50     Step:7|6   loss:0.5807481408119202  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:84.11%\t train set:90.87%\n","Epoch:6/50     Step:1|6   loss:0.6582380533218384  \n","Epoch:6/50     Step:2|6   loss:0.6029998064041138  \n","Epoch:6/50     Step:3|6   loss:0.6407387256622314  \n","Epoch:6/50     Step:4|6   loss:0.610133171081543  \n","Epoch:6/50     Step:5|6   loss:0.5670946836471558  \n","Epoch:6/50     Step:6|6   loss:0.6437200307846069  \n","Epoch:6/50     Step:7|6   loss:0.6153317093849182  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:84.11%\t train set:92.27%\n","Epoch:7/50     Step:1|6   loss:0.5920424461364746  \n","Epoch:7/50     Step:2|6   loss:0.6173129081726074  \n","Epoch:7/50     Step:3|6   loss:0.5823296308517456  \n","Epoch:7/50     Step:4|6   loss:0.6335597038269043  \n","Epoch:7/50     Step:5|6   loss:0.5496861934661865  \n","Epoch:7/50     Step:6|6   loss:0.5716352462768555  \n","Epoch:7/50     Step:7|6   loss:0.6970183849334717  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 92.51 %\n","current max accuracy\t test set:85.05%\t train set:92.51%\n","Epoch:8/50     Step:1|6   loss:0.6181368827819824  \n","Epoch:8/50     Step:2|6   loss:0.5769051909446716  \n","Epoch:8/50     Step:3|6   loss:0.6005485653877258  \n","Epoch:8/50     Step:4|6   loss:0.5869999527931213  \n","Epoch:8/50     Step:5|6   loss:0.5587388277053833  \n","Epoch:8/50     Step:6|6   loss:0.5622333288192749  \n","Epoch:8/50     Step:7|6   loss:0.6485010385513306  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:85.05%\t train set:93.44%\n","Epoch:9/50     Step:1|6   loss:0.6021168231964111  \n","Epoch:9/50     Step:2|6   loss:0.5673916935920715  \n","Epoch:9/50     Step:3|6   loss:0.5971513390541077  \n","Epoch:9/50     Step:4|6   loss:0.6053787469863892  \n","Epoch:9/50     Step:5|6   loss:0.5585728883743286  \n","Epoch:9/50     Step:6|6   loss:0.5761706233024597  \n","Epoch:9/50     Step:7|6   loss:0.5652115941047668  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:85.98%\t train set:94.15%\n","Epoch:10/50     Step:1|6   loss:0.5713696479797363  \n","Epoch:10/50     Step:2|6   loss:0.5633434653282166  \n","Epoch:10/50     Step:3|6   loss:0.5493612289428711  \n","Epoch:10/50     Step:4|6   loss:0.5911508798599243  \n","Epoch:10/50     Step:5|6   loss:0.5385586023330688  \n","Epoch:10/50     Step:6|6   loss:0.5661795735359192  \n","Epoch:10/50     Step:7|6   loss:0.6364384889602661  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:85.98%\t train set:94.15%\n","Epoch:11/50     Step:1|6   loss:0.619023859500885  \n","Epoch:11/50     Step:2|6   loss:0.5331143140792847  \n","Epoch:11/50     Step:3|6   loss:0.5600258111953735  \n","Epoch:11/50     Step:4|6   loss:0.5964911580085754  \n","Epoch:11/50     Step:5|6   loss:0.5366986989974976  \n","Epoch:11/50     Step:6|6   loss:0.5356998443603516  \n","Epoch:11/50     Step:7|6   loss:0.584348201751709  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:85.98%\t train set:95.32%\n","Epoch:12/50     Step:1|6   loss:0.5585123896598816  \n","Epoch:12/50     Step:2|6   loss:0.594478964805603  \n","Epoch:12/50     Step:3|6   loss:0.5601856112480164  \n","Epoch:12/50     Step:4|6   loss:0.5589812994003296  \n","Epoch:12/50     Step:5|6   loss:0.5476906299591064  \n","Epoch:12/50     Step:6|6   loss:0.5721868872642517  \n","Epoch:12/50     Step:7|6   loss:0.5117928385734558  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:85.98%\t train set:95.32%\n","Epoch:13/50     Step:1|6   loss:0.5585290789604187  \n","Epoch:13/50     Step:2|6   loss:0.5715107321739197  \n","Epoch:13/50     Step:3|6   loss:0.5532594323158264  \n","Epoch:13/50     Step:4|6   loss:0.5388978719711304  \n","Epoch:13/50     Step:5|6   loss:0.5713770985603333  \n","Epoch:13/50     Step:6|6   loss:0.5521533489227295  \n","Epoch:13/50     Step:7|6   loss:0.5431999564170837  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:95.33%\t train set:95.32%\n","Epoch:14/50     Step:1|6   loss:0.533491313457489  \n","Epoch:14/50     Step:2|6   loss:0.5332684516906738  \n","Epoch:14/50     Step:3|6   loss:0.5742884874343872  \n","Epoch:14/50     Step:4|6   loss:0.5391049385070801  \n","Epoch:14/50     Step:5|6   loss:0.5450688600540161  \n","Epoch:14/50     Step:6|6   loss:0.5646995306015015  \n","Epoch:14/50     Step:7|6   loss:0.5570236444473267  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:95.33%\t train set:95.55%\n","Epoch:15/50     Step:1|6   loss:0.5800460577011108  \n","Epoch:15/50     Step:2|6   loss:0.5522302389144897  \n","Epoch:15/50     Step:3|6   loss:0.5345319509506226  \n","Epoch:15/50     Step:4|6   loss:0.5453133583068848  \n","Epoch:15/50     Step:5|6   loss:0.5278394222259521  \n","Epoch:15/50     Step:6|6   loss:0.5297954082489014  \n","Epoch:15/50     Step:7|6   loss:0.528221845626831  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:95.33%\t train set:96.96%\n","Epoch:16/50     Step:1|6   loss:0.5573694705963135  \n","Epoch:16/50     Step:2|6   loss:0.5246509313583374  \n","Epoch:16/50     Step:3|6   loss:0.5375388264656067  \n","Epoch:16/50     Step:4|6   loss:0.5496860146522522  \n","Epoch:16/50     Step:5|6   loss:0.52545166015625  \n","Epoch:16/50     Step:6|6   loss:0.5317428708076477  \n","Epoch:16/50     Step:7|6   loss:0.5474421381950378  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:95.33%\t train set:97.66%\n","Epoch:17/50     Step:1|6   loss:0.5162579417228699  \n","Epoch:17/50     Step:2|6   loss:0.5726115107536316  \n","Epoch:17/50     Step:3|6   loss:0.5415075421333313  \n","Epoch:17/50     Step:4|6   loss:0.5476571917533875  \n","Epoch:17/50     Step:5|6   loss:0.5158219337463379  \n","Epoch:17/50     Step:6|6   loss:0.5320169925689697  \n","Epoch:17/50     Step:7|6   loss:0.535054087638855  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:95.33%\t train set:97.66%\n","Epoch:18/50     Step:1|6   loss:0.5196360945701599  \n","Epoch:18/50     Step:2|6   loss:0.5287951827049255  \n","Epoch:18/50     Step:3|6   loss:0.519514799118042  \n","Epoch:18/50     Step:4|6   loss:0.5465213060379028  \n","Epoch:18/50     Step:5|6   loss:0.5337470769882202  \n","Epoch:18/50     Step:6|6   loss:0.5352305173873901  \n","Epoch:18/50     Step:7|6   loss:0.5451020002365112  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:97.2%\t train set:98.13%\n","Epoch:19/50     Step:1|6   loss:0.5128726959228516  \n","Epoch:19/50     Step:2|6   loss:0.5257126092910767  \n","Epoch:19/50     Step:3|6   loss:0.5433445572853088  \n","Epoch:19/50     Step:4|6   loss:0.5262624025344849  \n","Epoch:19/50     Step:5|6   loss:0.522608757019043  \n","Epoch:19/50     Step:6|6   loss:0.5481624007225037  \n","Epoch:19/50     Step:7|6   loss:0.5075787305831909  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:97.2%\t train set:98.13%\n","Epoch:20/50     Step:1|6   loss:0.5131179094314575  \n","Epoch:20/50     Step:2|6   loss:0.5206248164176941  \n","Epoch:20/50     Step:3|6   loss:0.4979950189590454  \n","Epoch:20/50     Step:4|6   loss:0.5515082478523254  \n","Epoch:20/50     Step:5|6   loss:0.5333040952682495  \n","Epoch:20/50     Step:6|6   loss:0.5342696905136108  \n","Epoch:20/50     Step:7|6   loss:0.5108650922775269  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:97.2%\t train set:98.36%\n","Epoch:21/50     Step:1|6   loss:0.5364627838134766  \n","Epoch:21/50     Step:2|6   loss:0.5324579477310181  \n","Epoch:21/50     Step:3|6   loss:0.5285125374794006  \n","Epoch:21/50     Step:4|6   loss:0.5124502778053284  \n","Epoch:21/50     Step:5|6   loss:0.5207349061965942  \n","Epoch:21/50     Step:6|6   loss:0.5055605173110962  \n","Epoch:21/50     Step:7|6   loss:0.5049139261245728  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:97.2%\t train set:98.36%\n","Epoch:22/50     Step:1|6   loss:0.5316411852836609  \n","Epoch:22/50     Step:2|6   loss:0.5306375026702881  \n","Epoch:22/50     Step:3|6   loss:0.5183159708976746  \n","Epoch:22/50     Step:4|6   loss:0.49876105785369873  \n","Epoch:22/50     Step:5|6   loss:0.5211514830589294  \n","Epoch:22/50     Step:6|6   loss:0.5043383836746216  \n","Epoch:22/50     Step:7|6   loss:0.5246380567550659  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:97.2%\t train set:98.59%\n","Epoch:23/50     Step:1|6   loss:0.5069141387939453  \n","Epoch:23/50     Step:2|6   loss:0.5346006155014038  \n","Epoch:23/50     Step:3|6   loss:0.5398244857788086  \n","Epoch:23/50     Step:4|6   loss:0.5087149143218994  \n","Epoch:23/50     Step:5|6   loss:0.5091028213500977  \n","Epoch:23/50     Step:6|6   loss:0.5075406432151794  \n","Epoch:23/50     Step:7|6   loss:0.5068410038948059  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:98.13%\t train set:98.83%\n","Epoch:24/50     Step:1|6   loss:0.5072966814041138  \n","Epoch:24/50     Step:2|6   loss:0.5113722681999207  \n","Epoch:24/50     Step:3|6   loss:0.5032933950424194  \n","Epoch:24/50     Step:4|6   loss:0.5290290117263794  \n","Epoch:24/50     Step:5|6   loss:0.508145272731781  \n","Epoch:24/50     Step:6|6   loss:0.526984691619873  \n","Epoch:24/50     Step:7|6   loss:0.5183215737342834  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:98.13%\t train set:98.83%\n","Epoch:25/50     Step:1|6   loss:0.49748924374580383  \n","Epoch:25/50     Step:2|6   loss:0.5071214437484741  \n","Epoch:25/50     Step:3|6   loss:0.5038458108901978  \n","Epoch:25/50     Step:4|6   loss:0.5386933088302612  \n","Epoch:25/50     Step:5|6   loss:0.5074259042739868  \n","Epoch:25/50     Step:6|6   loss:0.5359882116317749  \n","Epoch:25/50     Step:7|6   loss:0.4968342185020447  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:98.13%\t train set:99.06%\n","Epoch:26/50     Step:1|6   loss:0.5096312165260315  \n","Epoch:26/50     Step:2|6   loss:0.5092239379882812  \n","Epoch:26/50     Step:3|6   loss:0.5076311826705933  \n","Epoch:26/50     Step:4|6   loss:0.5047675967216492  \n","Epoch:26/50     Step:5|6   loss:0.5199459791183472  \n","Epoch:26/50     Step:6|6   loss:0.522161066532135  \n","Epoch:26/50     Step:7|6   loss:0.5072207450866699  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:98.13%\t train set:99.06%\n","Epoch:27/50     Step:1|6   loss:0.5107966661453247  \n","Epoch:27/50     Step:2|6   loss:0.5180243253707886  \n","Epoch:27/50     Step:3|6   loss:0.49749743938446045  \n","Epoch:27/50     Step:4|6   loss:0.5003757476806641  \n","Epoch:27/50     Step:5|6   loss:0.5102618932723999  \n","Epoch:27/50     Step:6|6   loss:0.5228403210639954  \n","Epoch:27/50     Step:7|6   loss:0.5013078451156616  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.3%\n","Epoch:28/50     Step:1|6   loss:0.5033206343650818  \n","Epoch:28/50     Step:2|6   loss:0.5069867372512817  \n","Epoch:28/50     Step:3|6   loss:0.4941560626029968  \n","Epoch:28/50     Step:4|6   loss:0.521594762802124  \n","Epoch:28/50     Step:5|6   loss:0.49875932931900024  \n","Epoch:28/50     Step:6|6   loss:0.5204708576202393  \n","Epoch:28/50     Step:7|6   loss:0.5150572657585144  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:98.13%\t train set:99.3%\n","Epoch:29/50     Step:1|6   loss:0.49725374579429626  \n","Epoch:29/50     Step:2|6   loss:0.5034590363502502  \n","Epoch:29/50     Step:3|6   loss:0.5074371099472046  \n","Epoch:29/50     Step:4|6   loss:0.5040479898452759  \n","Epoch:29/50     Step:5|6   loss:0.5107461214065552  \n","Epoch:29/50     Step:6|6   loss:0.5245012044906616  \n","Epoch:29/50     Step:7|6   loss:0.4917507767677307  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:30/50     Step:1|6   loss:0.5313549041748047  \n","Epoch:30/50     Step:2|6   loss:0.5000077486038208  \n","Epoch:30/50     Step:3|6   loss:0.5189207196235657  \n","Epoch:30/50     Step:4|6   loss:0.4954454302787781  \n","Epoch:30/50     Step:5|6   loss:0.5015590190887451  \n","Epoch:30/50     Step:6|6   loss:0.4897918701171875  \n","Epoch:30/50     Step:7|6   loss:0.49552473425865173  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:31/50     Step:1|6   loss:0.49297958612442017  \n","Epoch:31/50     Step:2|6   loss:0.49535003304481506  \n","Epoch:31/50     Step:3|6   loss:0.4978480339050293  \n","Epoch:31/50     Step:4|6   loss:0.4969905614852905  \n","Epoch:31/50     Step:5|6   loss:0.5024381279945374  \n","Epoch:31/50     Step:6|6   loss:0.5207055807113647  \n","Epoch:31/50     Step:7|6   loss:0.5295302867889404  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:32/50     Step:1|6   loss:0.4982328414916992  \n","Epoch:32/50     Step:2|6   loss:0.5187326669692993  \n","Epoch:32/50     Step:3|6   loss:0.5175726413726807  \n","Epoch:32/50     Step:4|6   loss:0.49964621663093567  \n","Epoch:32/50     Step:5|6   loss:0.4926983416080475  \n","Epoch:32/50     Step:6|6   loss:0.49960634112358093  \n","Epoch:32/50     Step:7|6   loss:0.49106043577194214  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:33/50     Step:1|6   loss:0.4947173595428467  \n","Epoch:33/50     Step:2|6   loss:0.5255888104438782  \n","Epoch:33/50     Step:3|6   loss:0.5162539482116699  \n","Epoch:33/50     Step:4|6   loss:0.4964229464530945  \n","Epoch:33/50     Step:5|6   loss:0.4955826699733734  \n","Epoch:33/50     Step:6|6   loss:0.4924359917640686  \n","Epoch:33/50     Step:7|6   loss:0.4914563298225403  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:34/50     Step:1|6   loss:0.4990071952342987  \n","Epoch:34/50     Step:2|6   loss:0.4975157380104065  \n","Epoch:34/50     Step:3|6   loss:0.5119866728782654  \n","Epoch:34/50     Step:4|6   loss:0.5115988850593567  \n","Epoch:34/50     Step:5|6   loss:0.4949086308479309  \n","Epoch:34/50     Step:6|6   loss:0.5014839172363281  \n","Epoch:34/50     Step:7|6   loss:0.49027204513549805  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:35/50     Step:1|6   loss:0.5196609497070312  \n","Epoch:35/50     Step:2|6   loss:0.5146572589874268  \n","Epoch:35/50     Step:3|6   loss:0.49654799699783325  \n","Epoch:35/50     Step:4|6   loss:0.4929838180541992  \n","Epoch:35/50     Step:5|6   loss:0.4955294728279114  \n","Epoch:35/50     Step:6|6   loss:0.4927666187286377  \n","Epoch:35/50     Step:7|6   loss:0.48864641785621643  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.4882604479789734  \n","Epoch:36/50     Step:2|6   loss:0.49420785903930664  \n","Epoch:36/50     Step:3|6   loss:0.5297407507896423  \n","Epoch:36/50     Step:4|6   loss:0.49261388182640076  \n","Epoch:36/50     Step:5|6   loss:0.505038857460022  \n","Epoch:36/50     Step:6|6   loss:0.4957953691482544  \n","Epoch:36/50     Step:7|6   loss:0.4909207820892334  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:37/50     Step:1|6   loss:0.5137105584144592  \n","Epoch:37/50     Step:2|6   loss:0.49161988496780396  \n","Epoch:37/50     Step:3|6   loss:0.494878351688385  \n","Epoch:37/50     Step:4|6   loss:0.5120644569396973  \n","Epoch:37/50     Step:5|6   loss:0.49470460414886475  \n","Epoch:37/50     Step:6|6   loss:0.49116235971450806  \n","Epoch:37/50     Step:7|6   loss:0.49700284004211426  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:38/50     Step:1|6   loss:0.49634644389152527  \n","Epoch:38/50     Step:2|6   loss:0.489959716796875  \n","Epoch:38/50     Step:3|6   loss:0.4966389536857605  \n","Epoch:38/50     Step:4|6   loss:0.5102070569992065  \n","Epoch:38/50     Step:5|6   loss:0.5104862451553345  \n","Epoch:38/50     Step:6|6   loss:0.4902620315551758  \n","Epoch:38/50     Step:7|6   loss:0.5002369284629822  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:39/50     Step:1|6   loss:0.49744975566864014  \n","Epoch:39/50     Step:2|6   loss:0.5304442048072815  \n","Epoch:39/50     Step:3|6   loss:0.49095410108566284  \n","Epoch:39/50     Step:4|6   loss:0.4932578206062317  \n","Epoch:39/50     Step:5|6   loss:0.49459123611450195  \n","Epoch:39/50     Step:6|6   loss:0.49175238609313965  \n","Epoch:39/50     Step:7|6   loss:0.48817458748817444  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:40/50     Step:1|6   loss:0.509014904499054  \n","Epoch:40/50     Step:2|6   loss:0.5090585947036743  \n","Epoch:40/50     Step:3|6   loss:0.49238377809524536  \n","Epoch:40/50     Step:4|6   loss:0.4948790669441223  \n","Epoch:40/50     Step:5|6   loss:0.4907168745994568  \n","Epoch:40/50     Step:6|6   loss:0.49626606702804565  \n","Epoch:40/50     Step:7|6   loss:0.4908357858657837  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:41/50     Step:1|6   loss:0.493937224149704  \n","Epoch:41/50     Step:2|6   loss:0.489383339881897  \n","Epoch:41/50     Step:3|6   loss:0.49447619915008545  \n","Epoch:41/50     Step:4|6   loss:0.5273324251174927  \n","Epoch:41/50     Step:5|6   loss:0.49187323451042175  \n","Epoch:41/50     Step:6|6   loss:0.4924844205379486  \n","Epoch:41/50     Step:7|6   loss:0.48903077840805054  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:42/50     Step:1|6   loss:0.5131942629814148  \n","Epoch:42/50     Step:2|6   loss:0.4916740655899048  \n","Epoch:42/50     Step:3|6   loss:0.49132606387138367  \n","Epoch:42/50     Step:4|6   loss:0.4896964132785797  \n","Epoch:42/50     Step:5|6   loss:0.4907543659210205  \n","Epoch:42/50     Step:6|6   loss:0.5076128244400024  \n","Epoch:42/50     Step:7|6   loss:0.49188581109046936  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:43/50     Step:1|6   loss:0.49249371886253357  \n","Epoch:43/50     Step:2|6   loss:0.4897577464580536  \n","Epoch:43/50     Step:3|6   loss:0.5070573091506958  \n","Epoch:43/50     Step:4|6   loss:0.49168550968170166  \n","Epoch:43/50     Step:5|6   loss:0.4908745288848877  \n","Epoch:43/50     Step:6|6   loss:0.49387210607528687  \n","Epoch:43/50     Step:7|6   loss:0.5153450965881348  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:44/50     Step:1|6   loss:0.4879288971424103  \n","Epoch:44/50     Step:2|6   loss:0.4890616834163666  \n","Epoch:44/50     Step:3|6   loss:0.49084940552711487  \n","Epoch:44/50     Step:4|6   loss:0.48916926980018616  \n","Epoch:44/50     Step:5|6   loss:0.5170185565948486  \n","Epoch:44/50     Step:6|6   loss:0.48806533217430115  \n","Epoch:44/50     Step:7|6   loss:0.5174242854118347  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model LeNet5_one_stream --mode ir --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":17,"id":"c12092f7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch:45/50     Step:1|6   loss:0.4876820743083954  \n","Epoch:45/50     Step:2|6   loss:0.4886772036552429  \n","Epoch:45/50     Step:3|6   loss:0.48673170804977417  \n","Epoch:45/50     Step:4|6   loss:0.4924999475479126  \n","Epoch:45/50     Step:5|6   loss:0.4941246211528778  \n","Epoch:45/50     Step:6|6   loss:0.4919426441192627  \n","Epoch:45/50     Step:7|6   loss:0.5443786978721619  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:46/50     Step:1|6   loss:0.5077512860298157  \n","Epoch:46/50     Step:2|6   loss:0.4876827597618103  \n","Epoch:46/50     Step:3|6   loss:0.49205243587493896  \n","Epoch:46/50     Step:4|6   loss:0.487567663192749  \n","Epoch:46/50     Step:5|6   loss:0.49000710248947144  \n","Epoch:46/50     Step:6|6   loss:0.5086389183998108  \n","Epoch:46/50     Step:7|6   loss:0.4941976070404053  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:47/50     Step:1|6   loss:0.5115252137184143  \n","Epoch:47/50     Step:2|6   loss:0.48836278915405273  \n","Epoch:47/50     Step:3|6   loss:0.48912692070007324  \n","Epoch:47/50     Step:4|6   loss:0.48768940567970276  \n","Epoch:47/50     Step:5|6   loss:0.5094355344772339  \n","Epoch:47/50     Step:6|6   loss:0.49073490500450134  \n","Epoch:47/50     Step:7|6   loss:0.48671820759773254  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:48/50     Step:1|6   loss:0.4871383011341095  \n","Epoch:48/50     Step:2|6   loss:0.49089953303337097  \n","Epoch:48/50     Step:3|6   loss:0.4887605905532837  \n","Epoch:48/50     Step:4|6   loss:0.4870554506778717  \n","Epoch:48/50     Step:5|6   loss:0.524863600730896  \n","Epoch:48/50     Step:6|6   loss:0.486773282289505  \n","Epoch:48/50     Step:7|6   loss:0.5013948678970337  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:49/50     Step:1|6   loss:0.4925648272037506  \n","Epoch:49/50     Step:2|6   loss:0.48989662528038025  \n","Epoch:49/50     Step:3|6   loss:0.4869617819786072  \n","Epoch:49/50     Step:4|6   loss:0.48900091648101807  \n","Epoch:49/50     Step:5|6   loss:0.4892241954803467  \n","Epoch:49/50     Step:6|6   loss:0.5072647333145142  \n","Epoch:49/50     Step:7|6   loss:0.5145131349563599  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:50/50     Step:1|6   loss:0.5096645951271057  \n","Epoch:50/50     Step:2|6   loss:0.4923136234283447  \n","Epoch:50/50     Step:3|6   loss:0.48855704069137573  \n","Epoch:50/50     Step:4|6   loss:0.48814934492111206  \n","Epoch:50/50     Step:5|6   loss:0.48754560947418213  \n","Epoch:50/50     Step:6|6   loss:0.4878029227256775  \n","Epoch:50/50     Step:7|6   loss:0.5142912268638611  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Accuracy on test_set: 97.20 %\n","0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1152199506759644  \n","Epoch:1/50     Step:2|6   loss:1.6621859073638916  \n","Epoch:1/50     Step:3|6   loss:0.9923658967018127  \n","Epoch:1/50     Step:4|6   loss:1.1552376747131348  \n","Epoch:1/50     Step:5|6   loss:1.1639618873596191  \n","Epoch:1/50     Step:6|6   loss:0.9090197086334229  \n","Epoch:1/50     Step:7|6   loss:0.8238497972488403  \n","Accuracy on test_set: 69.16 %\n","Accuracy on train_set: 76.11 %\n","current max accuracy\t test set:69.16%\t train set:76.11%\n","Epoch:2/50     Step:1|6   loss:0.8365173935890198  \n","Epoch:2/50     Step:2|6   loss:0.866155743598938  1\n","\n","Epoch:2/50     Step:3|6   loss:0.823421835899353  \n","Epoch:2/50     Step:4|6   loss:0.8100956082344055  \n","Epoch:2/50     Step:5|6   loss:0.8539023399353027  \n","Epoch:2/50     Step:6|6   loss:0.8565502166748047  \n","Epoch:2/50     Step:7|6   loss:0.7034184336662292  \n","Accuracy on test_set: 74.77 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:74.77%\t train set:84.07%\n","Epoch:3/50     Step:1|6   loss:0.7457922697067261  \n","Epoch:3/50     Step:2|6   loss:0.6841064095497131  \n","Epoch:3/50     Step:3|6   loss:0.7258063554763794  \n","Epoch:3/50     Step:4|6   loss:0.7303370237350464  \n","Epoch:3/50     Step:5|6   loss:0.7498732805252075  \n","Epoch:3/50     Step:6|6   loss:0.6960619688034058  \n","Epoch:3/50     Step:7|6   loss:0.7115980386734009  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:78.5%\t train set:87.59%\n","Epoch:4/50     Step:1|6   loss:0.6501016020774841  \n","Epoch:4/50     Step:2|6   loss:0.6760696172714233  \n","Epoch:4/50     Step:3|6   loss:0.7033378481864929  \n","Epoch:4/50     Step:4|6   loss:0.6517806649208069  \n","Epoch:4/50     Step:5|6   loss:0.6690179705619812  \n","Epoch:4/50     Step:6|6   loss:0.6465368866920471  \n","Epoch:4/50     Step:7|6   loss:0.7079341411590576  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 87.59 %\n","current max accuracy\t test set:78.5%\t train set:87.59%\n","Epoch:5/50     Step:1|6   loss:0.6534052491188049  \n","Epoch:5/50     Step:2|6   loss:0.6941331624984741  \n","Epoch:5/50     Step:3|6   loss:0.5973581075668335  \n","Epoch:5/50     Step:4|6   loss:0.6361277103424072  \n","Epoch:5/50     Step:5|6   loss:0.6648434996604919  \n","Epoch:5/50     Step:6|6   loss:0.6096491813659668  \n","Epoch:5/50     Step:7|6   loss:0.6351242661476135  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:85.05%\t train set:90.63%\n","Epoch:6/50     Step:1|6   loss:0.6381351947784424  \n","Epoch:6/50     Step:2|6   loss:0.5836468935012817  \n","Epoch:6/50     Step:3|6   loss:0.5706230998039246  \n","Epoch:6/50     Step:4|6   loss:0.628107488155365  \n","Epoch:6/50     Step:5|6   loss:0.6297468543052673  \n","Epoch:6/50     Step:6|6   loss:0.5771821737289429  \n","Epoch:6/50     Step:7|6   loss:0.6450680494308472  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:86.92%\t train set:93.21%\n","Epoch:7/50     Step:1|6   loss:0.6162118911743164  \n","Epoch:7/50     Step:2|6   loss:0.5694294571876526  \n","Epoch:7/50     Step:3|6   loss:0.6399039030075073  \n","Epoch:7/50     Step:4|6   loss:0.6048144698143005  \n","Epoch:7/50     Step:5|6   loss:0.5369438529014587  \n","Epoch:7/50     Step:6|6   loss:0.5562335252761841  \n","Epoch:7/50     Step:7|6   loss:0.5860629081726074  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:91.59%\t train set:95.08%\n","Epoch:8/50     Step:1|6   loss:0.5739943385124207  \n","Epoch:8/50     Step:2|6   loss:0.5703174471855164  \n","Epoch:8/50     Step:3|6   loss:0.5528871417045593  \n","Epoch:8/50     Step:4|6   loss:0.5659559965133667  \n","Epoch:8/50     Step:5|6   loss:0.5818557739257812  \n","Epoch:8/50     Step:6|6   loss:0.5891318321228027  \n","Epoch:8/50     Step:7|6   loss:0.5652625560760498  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:92.52%\t train set:95.55%\n","Epoch:9/50     Step:1|6   loss:0.5775066614151001  \n","Epoch:9/50     Step:2|6   loss:0.5780457258224487  \n","Epoch:9/50     Step:3|6   loss:0.5517050623893738  \n","Epoch:9/50     Step:4|6   loss:0.5340663194656372  \n","Epoch:9/50     Step:5|6   loss:0.575127363204956  \n","Epoch:9/50     Step:6|6   loss:0.5446103811264038  \n","Epoch:9/50     Step:7|6   loss:0.5811942219734192  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:92.52%\t train set:95.78%\n","Epoch:10/50     Step:1|6   loss:0.5251094102859497  \n","Epoch:10/50     Step:2|6   loss:0.525132954120636  \n","Epoch:10/50     Step:3|6   loss:0.5473304986953735  \n","Epoch:10/50     Step:4|6   loss:0.5541517734527588  \n","Epoch:10/50     Step:5|6   loss:0.5633946061134338  \n","Epoch:10/50     Step:6|6   loss:0.5803908109664917  \n","Epoch:10/50     Step:7|6   loss:0.60328209400177  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:94.39%\t train set:95.78%\n","Epoch:11/50     Step:1|6   loss:0.5338372588157654  \n","Epoch:11/50     Step:2|6   loss:0.599852442741394  \n","Epoch:11/50     Step:3|6   loss:0.5541937351226807  \n","Epoch:11/50     Step:4|6   loss:0.5411115288734436  \n","Epoch:11/50     Step:5|6   loss:0.5307093262672424  \n","Epoch:11/50     Step:6|6   loss:0.5470578074455261  \n","Epoch:11/50     Step:7|6   loss:0.5358831286430359  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:12/50     Step:1|6   loss:0.5308971405029297  \n","Epoch:12/50     Step:2|6   loss:0.5697351694107056  \n","Epoch:12/50     Step:3|6   loss:0.5192282199859619  \n","Epoch:12/50     Step:4|6   loss:0.551772952079773  \n","Epoch:12/50     Step:5|6   loss:0.570022463798523  \n","Epoch:12/50     Step:6|6   loss:0.5283688306808472  \n","Epoch:12/50     Step:7|6   loss:0.5084975361824036  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:94.39%\t train set:96.25%\n","Epoch:13/50     Step:1|6   loss:0.5328234434127808  \n","Epoch:13/50     Step:2|6   loss:0.5503968596458435  \n","Epoch:13/50     Step:3|6   loss:0.529411256313324  \n","Epoch:13/50     Step:4|6   loss:0.5197281241416931  \n","Epoch:13/50     Step:5|6   loss:0.5484501123428345  \n","Epoch:13/50     Step:6|6   loss:0.5470654964447021  \n","Epoch:13/50     Step:7|6   loss:0.5181070566177368  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:94.39%\t train set:96.49%\n","Epoch:14/50     Step:1|6   loss:0.5186953544616699  \n","Epoch:14/50     Step:2|6   loss:0.5149221420288086  \n","Epoch:14/50     Step:3|6   loss:0.5576227903366089  \n","Epoch:14/50     Step:4|6   loss:0.5099852681159973  \n","Epoch:14/50     Step:5|6   loss:0.5118178725242615  \n","Epoch:14/50     Step:6|6   loss:0.5586555004119873  \n","Epoch:14/50     Step:7|6   loss:0.5528368353843689  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:15/50     Step:1|6   loss:0.5311045050621033  \n","Epoch:15/50     Step:2|6   loss:0.51414555311203  \n","Epoch:15/50     Step:3|6   loss:0.510221540927887  \n","Epoch:15/50     Step:4|6   loss:0.5126890540122986  \n","Epoch:15/50     Step:5|6   loss:0.5216788053512573  \n","Epoch:15/50     Step:6|6   loss:0.5520097613334656  \n","Epoch:15/50     Step:7|6   loss:0.5553097128868103  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:16/50     Step:1|6   loss:0.5334211587905884  \n","Epoch:16/50     Step:2|6   loss:0.5006086826324463  \n","Epoch:16/50     Step:3|6   loss:0.5097649693489075  \n","Epoch:16/50     Step:4|6   loss:0.5078428983688354  \n","Epoch:16/50     Step:5|6   loss:0.529844343662262  \n","Epoch:16/50     Step:6|6   loss:0.5373229384422302  \n","Epoch:16/50     Step:7|6   loss:0.5542692542076111  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:17/50     Step:1|6   loss:0.507428765296936  \n","Epoch:17/50     Step:2|6   loss:0.5088199377059937  \n","Epoch:17/50     Step:3|6   loss:0.49559980630874634  \n","Epoch:17/50     Step:4|6   loss:0.5435540676116943  \n","Epoch:17/50     Step:5|6   loss:0.5222598314285278  \n","Epoch:17/50     Step:6|6   loss:0.5396327972412109  \n","Epoch:17/50     Step:7|6   loss:0.5276665687561035  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:18/50     Step:1|6   loss:0.5028363466262817  \n","Epoch:18/50     Step:2|6   loss:0.5058819055557251  \n","Epoch:18/50     Step:3|6   loss:0.4976920783519745  \n","Epoch:18/50     Step:4|6   loss:0.5055994987487793  \n","Epoch:18/50     Step:5|6   loss:0.5383360981941223  \n","Epoch:18/50     Step:6|6   loss:0.5280715227127075  \n","Epoch:18/50     Step:7|6   loss:0.5622243881225586  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:19/50     Step:1|6   loss:0.5377301573753357  \n","Epoch:19/50     Step:2|6   loss:0.5029501914978027  \n","Epoch:19/50     Step:3|6   loss:0.5249281525611877  \n","Epoch:19/50     Step:4|6   loss:0.5168188214302063  \n","Epoch:19/50     Step:5|6   loss:0.5275629758834839  \n","Epoch:19/50     Step:6|6   loss:0.49425721168518066  \n","Epoch:19/50     Step:7|6   loss:0.5074437856674194  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:20/50     Step:1|6   loss:0.5138283967971802  \n","Epoch:20/50     Step:2|6   loss:0.5029435753822327  \n","Epoch:20/50     Step:3|6   loss:0.5125254392623901  \n","Epoch:20/50     Step:4|6   loss:0.5231363773345947  \n","Epoch:20/50     Step:5|6   loss:0.517591118812561  \n","Epoch:20/50     Step:6|6   loss:0.49973803758621216  \n","Epoch:20/50     Step:7|6   loss:0.5374934077262878  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:21/50     Step:1|6   loss:0.5006235837936401  \n","Epoch:21/50     Step:2|6   loss:0.5018808245658875  \n","Epoch:21/50     Step:3|6   loss:0.524712324142456  \n","Epoch:21/50     Step:4|6   loss:0.5253106951713562  \n","Epoch:21/50     Step:5|6   loss:0.5183449387550354  \n","Epoch:21/50     Step:6|6   loss:0.5001950263977051  \n","Epoch:21/50     Step:7|6   loss:0.5218337178230286  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:22/50     Step:1|6   loss:0.511289656162262  \n","Epoch:22/50     Step:2|6   loss:0.5221458673477173  \n","Epoch:22/50     Step:3|6   loss:0.4897955060005188  \n","Epoch:22/50     Step:4|6   loss:0.5199447274208069  \n","Epoch:22/50     Step:5|6   loss:0.5107673406600952  \n","Epoch:22/50     Step:6|6   loss:0.5175118446350098  \n","Epoch:22/50     Step:7|6   loss:0.5056371092796326  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:23/50     Step:1|6   loss:0.5007036328315735  \n","Epoch:23/50     Step:2|6   loss:0.49038445949554443  \n","Epoch:23/50     Step:3|6   loss:0.5085770487785339  \n","Epoch:23/50     Step:4|6   loss:0.5293328762054443  \n","Epoch:23/50     Step:5|6   loss:0.5178501605987549  \n","Epoch:23/50     Step:6|6   loss:0.5143918395042419  \n","Epoch:23/50     Step:7|6   loss:0.5048179030418396  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:24/50     Step:1|6   loss:0.5237312316894531  \n","Epoch:24/50     Step:2|6   loss:0.5167467594146729  \n","Epoch:24/50     Step:3|6   loss:0.5082905292510986  \n","Epoch:24/50     Step:4|6   loss:0.5060452818870544  \n","Epoch:24/50     Step:5|6   loss:0.49828141927719116  \n","Epoch:24/50     Step:6|6   loss:0.5083177089691162  \n","Epoch:24/50     Step:7|6   loss:0.49164897203445435  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:95.33%\t train set:96.72%\n","Epoch:25/50     Step:1|6   loss:0.5070189237594604  \n","Epoch:25/50     Step:2|6   loss:0.5214880704879761  \n","Epoch:25/50     Step:3|6   loss:0.5044271945953369  \n","Epoch:25/50     Step:4|6   loss:0.4997560381889343  \n","Epoch:25/50     Step:5|6   loss:0.5117246508598328  \n","Epoch:25/50     Step:6|6   loss:0.497814416885376  \n","Epoch:25/50     Step:7|6   loss:0.4990285634994507  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:96.26%\t train set:97.42%\n","Epoch:26/50     Step:1|6   loss:0.5087951421737671  \n","Epoch:26/50     Step:2|6   loss:0.517094612121582  \n","Epoch:26/50     Step:3|6   loss:0.5053395628929138  \n","Epoch:26/50     Step:4|6   loss:0.5034961104393005  \n","Epoch:26/50     Step:5|6   loss:0.48921364545822144  \n","Epoch:26/50     Step:6|6   loss:0.5078161954879761  \n","Epoch:26/50     Step:7|6   loss:0.49270913004875183  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:27/50     Step:1|6   loss:0.501426100730896  \n","Epoch:27/50     Step:2|6   loss:0.49442389607429504  \n","Epoch:27/50     Step:3|6   loss:0.5075065493583679  \n","Epoch:27/50     Step:4|6   loss:0.5001819133758545  \n","Epoch:27/50     Step:5|6   loss:0.5025500059127808  \n","Epoch:27/50     Step:6|6   loss:0.48902422189712524  \n","Epoch:27/50     Step:7|6   loss:0.5227926969528198  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.506931722164154  \n","Epoch:28/50     Step:2|6   loss:0.493762731552124  \n","Epoch:28/50     Step:3|6   loss:0.49898916482925415  \n","Epoch:28/50     Step:4|6   loss:0.48931145668029785  \n","Epoch:28/50     Step:5|6   loss:0.4947203993797302  \n","Epoch:28/50     Step:6|6   loss:0.51539146900177  \n","Epoch:28/50     Step:7|6   loss:0.5021259784698486  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.4944470524787903  \n","Epoch:29/50     Step:2|6   loss:0.5002166032791138  \n","Epoch:29/50     Step:3|6   loss:0.5075157284736633  \n","Epoch:29/50     Step:4|6   loss:0.49992936849594116  \n","Epoch:29/50     Step:5|6   loss:0.4942357540130615  \n","Epoch:29/50     Step:6|6   loss:0.5020215511322021  \n","Epoch:29/50     Step:7|6   loss:0.4924823045730591  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4937739372253418  \n","Epoch:30/50     Step:2|6   loss:0.49774986505508423  \n","Epoch:30/50     Step:3|6   loss:0.48741817474365234  \n","Epoch:30/50     Step:4|6   loss:0.5079818367958069  \n","Epoch:30/50     Step:5|6   loss:0.4935440421104431  \n","Epoch:30/50     Step:6|6   loss:0.5051769614219666  \n","Epoch:30/50     Step:7|6   loss:0.5001991391181946  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.4969886839389801  \n","Epoch:31/50     Step:2|6   loss:0.48874902725219727  \n","Epoch:31/50     Step:3|6   loss:0.4963575303554535  \n","Epoch:31/50     Step:4|6   loss:0.5001469850540161  \n","Epoch:31/50     Step:5|6   loss:0.5105046629905701  \n","Epoch:31/50     Step:6|6   loss:0.4871210753917694  \n","Epoch:31/50     Step:7|6   loss:0.5002281665802002  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4942774772644043  \n","Epoch:32/50     Step:2|6   loss:0.4963832497596741  \n","Epoch:32/50     Step:3|6   loss:0.4996841549873352  \n","Epoch:32/50     Step:4|6   loss:0.5004708766937256  \n","Epoch:32/50     Step:5|6   loss:0.49678659439086914  \n","Epoch:32/50     Step:6|6   loss:0.4956762492656708  \n","Epoch:32/50     Step:7|6   loss:0.48789018392562866  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4929701089859009  \n","Epoch:33/50     Step:2|6   loss:0.5029889941215515  \n","Epoch:33/50     Step:3|6   loss:0.49970561265945435  \n","Epoch:33/50     Step:4|6   loss:0.4912174344062805  \n","Epoch:33/50     Step:5|6   loss:0.48840421438217163  \n","Epoch:33/50     Step:6|6   loss:0.496188759803772  \n","Epoch:33/50     Step:7|6   loss:0.49747341871261597  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4911171793937683  \n","Epoch:34/50     Step:2|6   loss:0.49609386920928955  \n","Epoch:34/50     Step:3|6   loss:0.494127094745636  \n","Epoch:34/50     Step:4|6   loss:0.4909803867340088  \n","Epoch:34/50     Step:5|6   loss:0.4872588813304901  \n","Epoch:34/50     Step:6|6   loss:0.5040960311889648  \n","Epoch:34/50     Step:7|6   loss:0.4959670305252075  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.4962294101715088  \n","Epoch:35/50     Step:2|6   loss:0.48717325925827026  \n","Epoch:35/50     Step:3|6   loss:0.4923972487449646  \n","Epoch:35/50     Step:4|6   loss:0.4922345280647278  \n","Epoch:35/50     Step:5|6   loss:0.49373894929885864  \n","Epoch:35/50     Step:6|6   loss:0.4977290630340576  \n","Epoch:35/50     Step:7|6   loss:0.4866468906402588  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.489498108625412  \n","Epoch:36/50     Step:2|6   loss:0.49022385478019714  \n","Epoch:36/50     Step:3|6   loss:0.4915136694908142  \n","Epoch:36/50     Step:4|6   loss:0.49209022521972656  \n","Epoch:36/50     Step:5|6   loss:0.4896318316459656  \n","Epoch:36/50     Step:6|6   loss:0.49473029375076294  \n","Epoch:36/50     Step:7|6   loss:0.4967085123062134  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4960745573043823  \n","Epoch:37/50     Step:2|6   loss:0.49320465326309204  \n","Epoch:37/50     Step:3|6   loss:0.4906821548938751  \n","Epoch:37/50     Step:4|6   loss:0.49335309863090515  \n","Epoch:37/50     Step:5|6   loss:0.48921307921409607  \n","Epoch:37/50     Step:6|6   loss:0.4877351224422455  \n","Epoch:37/50     Step:7|6   loss:0.4891442656517029  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.4945598244667053  \n","Epoch:38/50     Step:2|6   loss:0.49088865518569946  \n","Epoch:38/50     Step:3|6   loss:0.4874769151210785  \n","Epoch:38/50     Step:4|6   loss:0.4887787699699402  \n","Epoch:38/50     Step:5|6   loss:0.4895556569099426  \n","Epoch:38/50     Step:6|6   loss:0.4933299720287323  \n","Epoch:38/50     Step:7|6   loss:0.49239975214004517  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4936615526676178  \n","Epoch:39/50     Step:2|6   loss:0.4919993281364441  \n","Epoch:39/50     Step:3|6   loss:0.48864108324050903  \n","Epoch:39/50     Step:4|6   loss:0.4916951060295105  \n","Epoch:39/50     Step:5|6   loss:0.49008601903915405  \n","Epoch:39/50     Step:6|6   loss:0.4894236922264099  \n","Epoch:39/50     Step:7|6   loss:0.486878901720047  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.4893239736557007  \n","Epoch:40/50     Step:2|6   loss:0.48999184370040894  \n","Epoch:40/50     Step:3|6   loss:0.48613595962524414  \n","Epoch:40/50     Step:4|6   loss:0.49047404527664185  \n","Epoch:40/50     Step:5|6   loss:0.48979389667510986  \n","Epoch:40/50     Step:6|6   loss:0.4945332109928131  \n","Epoch:40/50     Step:7|6   loss:0.48897016048431396  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4899398684501648  \n","Epoch:41/50     Step:2|6   loss:0.4862923324108124  \n","Epoch:41/50     Step:3|6   loss:0.48947209119796753  \n","Epoch:41/50     Step:4|6   loss:0.49480968713760376  \n","Epoch:41/50     Step:5|6   loss:0.49089300632476807  \n","Epoch:41/50     Step:6|6   loss:0.48805302381515503  \n","Epoch:41/50     Step:7|6   loss:0.4863995313644409  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.48734962940216064  \n","Epoch:42/50     Step:2|6   loss:0.48710235953330994  \n","Epoch:42/50     Step:3|6   loss:0.49049457907676697  \n","Epoch:42/50     Step:4|6   loss:0.49043893814086914  \n","Epoch:42/50     Step:5|6   loss:0.4915032982826233  \n","Epoch:42/50     Step:6|6   loss:0.4878750443458557  \n","Epoch:42/50     Step:7|6   loss:0.49004673957824707  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4876174330711365  \n","Epoch:43/50     Step:2|6   loss:0.4917113184928894  \n","Epoch:43/50     Step:3|6   loss:0.49095261096954346  \n","Epoch:43/50     Step:4|6   loss:0.4874562919139862  \n","Epoch:43/50     Step:5|6   loss:0.4870568513870239  \n","Epoch:43/50     Step:6|6   loss:0.48968222737312317  \n","Epoch:43/50     Step:7|6   loss:0.48733046650886536  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.4903309941291809  \n","Epoch:44/50     Step:2|6   loss:0.48881104588508606  \n","Epoch:44/50     Step:3|6   loss:0.48619696497917175  \n","Epoch:44/50     Step:4|6   loss:0.48951977491378784  \n","Epoch:44/50     Step:5|6   loss:0.48781558871269226  \n","Epoch:44/50     Step:6|6   loss:0.48754796385765076  \n","Epoch:44/50     Step:7|6   loss:0.4885876774787903  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.48643141984939575  \n","Epoch:45/50     Step:2|6   loss:0.4875273108482361  \n","Epoch:45/50     Step:3|6   loss:0.4889526963233948  \n","Epoch:45/50     Step:4|6   loss:0.4875045418739319  \n","Epoch:45/50     Step:5|6   loss:0.4900122582912445  \n","Epoch:45/50     Step:6|6   loss:0.4866337776184082  \n","Epoch:45/50     Step:7|6   loss:0.4874093234539032  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4877559542655945  \n","Epoch:46/50     Step:2|6   loss:0.48906221985816956  \n","Epoch:46/50     Step:3|6   loss:0.48800384998321533  \n","Epoch:46/50     Step:4|6   loss:0.4871530532836914  \n","Epoch:46/50     Step:5|6   loss:0.48720070719718933  \n","Epoch:46/50     Step:6|6   loss:0.4870219826698303  \n","Epoch:46/50     Step:7|6   loss:0.48611265420913696  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48666882514953613  \n","Epoch:47/50     Step:2|6   loss:0.4883647859096527  \n","Epoch:47/50     Step:3|6   loss:0.4883916974067688  \n","Epoch:47/50     Step:4|6   loss:0.4869259297847748  \n","Epoch:47/50     Step:5|6   loss:0.48804035782814026  \n","Epoch:47/50     Step:6|6   loss:0.48647481203079224  \n","Epoch:47/50     Step:7|6   loss:0.48676201701164246  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4874914586544037  \n","Epoch:48/50     Step:2|6   loss:0.4865589141845703  \n","Epoch:48/50     Step:3|6   loss:0.48637154698371887  \n","Epoch:48/50     Step:4|6   loss:0.48723265528678894  \n","Epoch:48/50     Step:5|6   loss:0.48716312646865845  \n","Epoch:48/50     Step:6|6   loss:0.4888911247253418  \n","Epoch:48/50     Step:7|6   loss:0.48704129457473755  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48806825280189514  \n","Epoch:49/50     Step:2|6   loss:0.48636889457702637  \n","Epoch:49/50     Step:3|6   loss:0.485612690448761  \n","Epoch:49/50     Step:4|6   loss:0.4877941608428955  \n","Epoch:49/50     Step:5|6   loss:0.4883681833744049  \n","Epoch:49/50     Step:6|6   loss:0.4856409430503845  \n","Epoch:49/50     Step:7|6   loss:0.48880451917648315  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4880295395851135  \n","Epoch:50/50     Step:2|6   loss:0.4864637851715088  \n","Epoch:50/50     Step:3|6   loss:0.4862149953842163  \n","Epoch:50/50     Step:4|6   loss:0.4880693554878235  \n","Epoch:50/50     Step:5|6   loss:0.4869186282157898  \n","Epoch:50/50     Step:6|6   loss:0.48754245042800903  \n","Epoch:50/50     Step:7|6   loss:0.48563411831855774  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","2\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1035488843917847  \n","Epoch:1/50     Step:2|6   loss:1.3764832019805908  \n","Epoch:1/50     Step:3|6   loss:0.9124733209609985  \n","Epoch:1/50     Step:4|6   loss:0.7635030746459961  \n","Epoch:1/50     Step:5|6   loss:0.9418922662734985  \n","Epoch:1/50     Step:6|6   loss:0.7909338474273682  \n","Epoch:1/50     Step:7|6   loss:0.7577656507492065  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 82.20 %\n","current max accuracy\t test set:85.05%\t train set:82.2%\n","Epoch:2/50     Step:1|6   loss:0.7283506393432617  \n","Epoch:2/50     Step:2|6   loss:0.7322008609771729  \n","Epoch:2/50     Step:3|6   loss:0.7381480932235718  \n","Epoch:2/50     Step:4|6   loss:0.7523218989372253  \n","Epoch:2/50     Step:5|6   loss:0.7315614819526672  \n","Epoch:2/50     Step:6|6   loss:0.7677122354507446  \n","Epoch:2/50     Step:7|6   loss:0.7134300470352173  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 84.07 %\n","current max accuracy\t test set:85.05%\t train set:84.07%\n","Epoch:3/50     Step:1|6   loss:0.6810688972473145  \n","Epoch:3/50     Step:2|6   loss:0.7179136872291565  \n","Epoch:3/50     Step:3|6   loss:0.6995269060134888  \n","Epoch:3/50     Step:4|6   loss:0.6689856052398682  \n","Epoch:3/50     Step:5|6   loss:0.7088963985443115  \n","Epoch:3/50     Step:6|6   loss:0.6386191844940186  \n","Epoch:3/50     Step:7|6   loss:0.6622129678726196  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 86.18 %\n","current max accuracy\t test set:85.05%\t train set:86.18%\n","Epoch:4/50     Step:1|6   loss:0.6781373620033264  \n","Epoch:4/50     Step:2|6   loss:0.689852774143219  \n","Epoch:4/50     Step:3|6   loss:0.6903918981552124  \n","Epoch:4/50     Step:4|6   loss:0.6130883097648621  \n","Epoch:4/50     Step:5|6   loss:0.6139566898345947  \n","Epoch:4/50     Step:6|6   loss:0.6575325131416321  \n","Epoch:4/50     Step:7|6   loss:0.6061270236968994  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:88.79%\t train set:93.91%\n","Epoch:5/50     Step:1|6   loss:0.5965944528579712  \n","Epoch:5/50     Step:2|6   loss:0.5702242851257324  \n","Epoch:5/50     Step:3|6   loss:0.6252138614654541  \n","Epoch:5/50     Step:4|6   loss:0.587157130241394  \n","Epoch:5/50     Step:5|6   loss:0.5796402096748352  \n","Epoch:5/50     Step:6|6   loss:0.60077965259552  \n","Epoch:5/50     Step:7|6   loss:0.5850058794021606  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:93.46%\t train set:95.78%\n","Epoch:6/50     Step:1|6   loss:0.5643749833106995  \n","Epoch:6/50     Step:2|6   loss:0.5498827695846558  \n","Epoch:6/50     Step:3|6   loss:0.5819169282913208  \n","Epoch:6/50     Step:4|6   loss:0.5829839706420898  \n","Epoch:6/50     Step:5|6   loss:0.5631427764892578  \n","Epoch:6/50     Step:6|6   loss:0.5418880581855774  \n","Epoch:6/50     Step:7|6   loss:0.6031725406646729  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:95.33%\t train set:96.96%\n","Epoch:7/50     Step:1|6   loss:0.548167884349823  \n","Epoch:7/50     Step:2|6   loss:0.5724914073944092  \n","Epoch:7/50     Step:3|6   loss:0.5526846647262573  \n","Epoch:7/50     Step:4|6   loss:0.534399151802063  \n","Epoch:7/50     Step:5|6   loss:0.5664946436882019  \n","Epoch:7/50     Step:6|6   loss:0.5358269214630127  \n","Epoch:7/50     Step:7|6   loss:0.5370707511901855  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:95.33%\t train set:98.36%\n","Epoch:8/50     Step:1|6   loss:0.5304945111274719  \n","Epoch:8/50     Step:2|6   loss:0.5674337148666382  \n","Epoch:8/50     Step:3|6   loss:0.5489329099655151  \n","Epoch:8/50     Step:4|6   loss:0.5153682827949524  \n","Epoch:8/50     Step:5|6   loss:0.530406653881073  \n","Epoch:8/50     Step:6|6   loss:0.5619608163833618  \n","Epoch:8/50     Step:7|6   loss:0.5409229397773743  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:95.33%\t train set:98.83%\n","Epoch:9/50     Step:1|6   loss:0.5361289381980896  \n","Epoch:9/50     Step:2|6   loss:0.53431636095047  \n","Epoch:9/50     Step:3|6   loss:0.5443249940872192  \n","Epoch:9/50     Step:4|6   loss:0.5210086703300476  \n","Epoch:9/50     Step:5|6   loss:0.5354112386703491  \n","Epoch:9/50     Step:6|6   loss:0.506070077419281  \n","Epoch:9/50     Step:7|6   loss:0.5380095839500427  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:95.33%\t train set:98.83%\n","Epoch:10/50     Step:1|6   loss:0.5426041483879089  \n","Epoch:10/50     Step:2|6   loss:0.5200641751289368  \n","Epoch:10/50     Step:3|6   loss:0.5155568718910217  \n","Epoch:10/50     Step:4|6   loss:0.5382543802261353  \n","Epoch:10/50     Step:5|6   loss:0.5315334796905518  \n","Epoch:10/50     Step:6|6   loss:0.5194296836853027  \n","Epoch:10/50     Step:7|6   loss:0.5115981101989746  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:95.33%\t train set:99.06%\n","Epoch:11/50     Step:1|6   loss:0.5267314910888672  \n","Epoch:11/50     Step:2|6   loss:0.512791097164154  \n","Epoch:11/50     Step:3|6   loss:0.5140429139137268  \n","Epoch:11/50     Step:4|6   loss:0.5131605267524719  \n","Epoch:11/50     Step:5|6   loss:0.5076819658279419  \n","Epoch:11/50     Step:6|6   loss:0.527890682220459  \n","Epoch:11/50     Step:7|6   loss:0.5159420371055603  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:12/50     Step:1|6   loss:0.4998666048049927  \n","Epoch:12/50     Step:2|6   loss:0.5135382413864136  \n","Epoch:12/50     Step:3|6   loss:0.50253826379776  \n","Epoch:12/50     Step:4|6   loss:0.5103499889373779  \n","Epoch:12/50     Step:5|6   loss:0.5079176425933838  \n","Epoch:12/50     Step:6|6   loss:0.5102587342262268  \n","Epoch:12/50     Step:7|6   loss:0.5157508850097656  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:13/50     Step:1|6   loss:0.5080775022506714  \n","Epoch:13/50     Step:2|6   loss:0.5111180543899536  \n","Epoch:13/50     Step:3|6   loss:0.5028811693191528  \n","Epoch:13/50     Step:4|6   loss:0.5086796879768372  \n","Epoch:13/50     Step:5|6   loss:0.5027360320091248  \n","Epoch:13/50     Step:6|6   loss:0.5082809329032898  \n","Epoch:13/50     Step:7|6   loss:0.5056812763214111  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/50     Step:1|6   loss:0.5089946985244751  \n","Epoch:14/50     Step:2|6   loss:0.4960472285747528  \n","Epoch:14/50     Step:3|6   loss:0.4962603449821472  \n","Epoch:14/50     Step:4|6   loss:0.49939996004104614  \n","Epoch:14/50     Step:5|6   loss:0.49697795510292053  \n","Epoch:14/50     Step:6|6   loss:0.5133495926856995  \n","Epoch:14/50     Step:7|6   loss:0.49699723720550537  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/50     Step:1|6   loss:0.4943496286869049  \n","Epoch:15/50     Step:2|6   loss:0.5029563903808594  \n","Epoch:15/50     Step:3|6   loss:0.49586591124534607  \n","Epoch:15/50     Step:4|6   loss:0.493629515171051  \n","Epoch:15/50     Step:5|6   loss:0.4982062578201294  \n","Epoch:15/50     Step:6|6   loss:0.5017797350883484  \n","Epoch:15/50     Step:7|6   loss:0.49485522508621216  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/50     Step:1|6   loss:0.49138617515563965  \n","Epoch:16/50     Step:2|6   loss:0.4945906102657318  \n","Epoch:16/50     Step:3|6   loss:0.49497586488723755  \n","Epoch:16/50     Step:4|6   loss:0.5017461776733398  \n","Epoch:16/50     Step:5|6   loss:0.4980235695838928  \n","Epoch:16/50     Step:6|6   loss:0.4975627064704895  \n","Epoch:16/50     Step:7|6   loss:0.49196359515190125  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/50     Step:1|6   loss:0.495064377784729  \n","Epoch:17/50     Step:2|6   loss:0.4955473244190216  \n","Epoch:17/50     Step:3|6   loss:0.4931221902370453  \n","Epoch:17/50     Step:4|6   loss:0.49424248933792114  \n","Epoch:17/50     Step:5|6   loss:0.5004055500030518  \n","Epoch:17/50     Step:6|6   loss:0.49255824089050293  \n","Epoch:17/50     Step:7|6   loss:0.4934372901916504  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/50     Step:1|6   loss:0.4937729835510254  \n","Epoch:18/50     Step:2|6   loss:0.49325668811798096  \n","Epoch:18/50     Step:3|6   loss:0.49495235085487366  \n","Epoch:18/50     Step:4|6   loss:0.49410995841026306  \n","Epoch:18/50     Step:5|6   loss:0.4905128479003906  \n","Epoch:18/50     Step:6|6   loss:0.49047085642814636  \n","Epoch:18/50     Step:7|6   loss:0.4907832145690918  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/50     Step:1|6   loss:0.4907483756542206  \n","Epoch:19/50     Step:2|6   loss:0.4909246265888214  \n","Epoch:19/50     Step:3|6   loss:0.493389368057251  \n","Epoch:19/50     Step:4|6   loss:0.49052542448043823  \n","Epoch:19/50     Step:5|6   loss:0.49199289083480835  \n","Epoch:19/50     Step:6|6   loss:0.48996490240097046  \n","Epoch:19/50     Step:7|6   loss:0.49830496311187744  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/50     Step:1|6   loss:0.48978370428085327  \n","Epoch:20/50     Step:2|6   loss:0.4922424554824829  \n","Epoch:20/50     Step:3|6   loss:0.4913613200187683  \n","Epoch:20/50     Step:4|6   loss:0.4939049482345581  \n","Epoch:20/50     Step:5|6   loss:0.49151962995529175  \n","Epoch:20/50     Step:6|6   loss:0.49017539620399475  \n","Epoch:20/50     Step:7|6   loss:0.489752858877182  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/50     Step:1|6   loss:0.49242645502090454  \n","Epoch:21/50     Step:2|6   loss:0.4900020956993103  \n","Epoch:21/50     Step:3|6   loss:0.4922575354576111  \n","Epoch:21/50     Step:4|6   loss:0.49015745520591736  \n","Epoch:21/50     Step:5|6   loss:0.48907995223999023  \n","Epoch:21/50     Step:6|6   loss:0.49001437425613403  \n","Epoch:21/50     Step:7|6   loss:0.4940119981765747  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/50     Step:1|6   loss:0.49383699893951416  \n","Epoch:22/50     Step:2|6   loss:0.4884841740131378  \n","Epoch:22/50     Step:3|6   loss:0.4896063208580017  \n","Epoch:22/50     Step:4|6   loss:0.4895058274269104  \n","Epoch:22/50     Step:5|6   loss:0.4890023469924927  \n","Epoch:22/50     Step:6|6   loss:0.4897570013999939  \n","Epoch:22/50     Step:7|6   loss:0.4904612898826599  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/50     Step:1|6   loss:0.490765780210495  \n","Epoch:23/50     Step:2|6   loss:0.4887193441390991  \n","Epoch:23/50     Step:3|6   loss:0.48914313316345215  \n","Epoch:23/50     Step:4|6   loss:0.4900134205818176  \n","Epoch:23/50     Step:5|6   loss:0.4908915162086487  \n","Epoch:23/50     Step:6|6   loss:0.4904002547264099  \n","Epoch:23/50     Step:7|6   loss:0.4881853759288788  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/50     Step:1|6   loss:0.4889484643936157  \n","Epoch:24/50     Step:2|6   loss:0.4900607764720917  \n","Epoch:24/50     Step:3|6   loss:0.48915719985961914  \n","Epoch:24/50     Step:4|6   loss:0.4904485046863556  \n","Epoch:24/50     Step:5|6   loss:0.4884297847747803  \n","Epoch:24/50     Step:6|6   loss:0.4877464473247528  \n","Epoch:24/50     Step:7|6   loss:0.49319443106651306  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/50     Step:1|6   loss:0.4896166920661926  \n","Epoch:25/50     Step:2|6   loss:0.4908990263938904  \n","Epoch:25/50     Step:3|6   loss:0.4882745146751404  \n","Epoch:25/50     Step:4|6   loss:0.48787420988082886  \n","Epoch:25/50     Step:5|6   loss:0.4921671152114868  \n","Epoch:25/50     Step:6|6   loss:0.4875001311302185  \n","Epoch:25/50     Step:7|6   loss:0.4905165731906891  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/50     Step:1|6   loss:0.4881506562232971  \n","Epoch:26/50     Step:2|6   loss:0.4897286593914032  \n","Epoch:26/50     Step:3|6   loss:0.48981407284736633  \n","Epoch:26/50     Step:4|6   loss:0.4889487028121948  \n","Epoch:26/50     Step:5|6   loss:0.4875287115573883  \n","Epoch:26/50     Step:6|6   loss:0.4870308041572571  \n","Epoch:26/50     Step:7|6   loss:0.48749783635139465  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/50     Step:1|6   loss:0.4872153103351593  \n","Epoch:27/50     Step:2|6   loss:0.48722216486930847  \n","Epoch:27/50     Step:3|6   loss:0.48717001080513  \n","Epoch:27/50     Step:4|6   loss:0.48856401443481445  \n","Epoch:27/50     Step:5|6   loss:0.4882700741291046  \n","Epoch:27/50     Step:6|6   loss:0.4886119067668915  \n","Epoch:27/50     Step:7|6   loss:0.4896203875541687  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/50     Step:1|6   loss:0.48728668689727783  \n","Epoch:28/50     Step:2|6   loss:0.4880381226539612  \n","Epoch:28/50     Step:3|6   loss:0.4881860613822937  \n","Epoch:28/50     Step:4|6   loss:0.4872327148914337  \n","Epoch:28/50     Step:5|6   loss:0.4867577850818634  \n","Epoch:28/50     Step:6|6   loss:0.48842287063598633  \n","Epoch:28/50     Step:7|6   loss:0.48688334226608276  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/50     Step:1|6   loss:0.48704689741134644  \n","Epoch:29/50     Step:2|6   loss:0.48706310987472534  \n","Epoch:29/50     Step:3|6   loss:0.4871571362018585  \n","Epoch:29/50     Step:4|6   loss:0.48817676305770874  \n","Epoch:29/50     Step:5|6   loss:0.48675400018692017  \n","Epoch:29/50     Step:6|6   loss:0.48754680156707764  \n","Epoch:29/50     Step:7|6   loss:0.48851868510246277  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/50     Step:1|6   loss:0.4868571162223816  \n","Epoch:30/50     Step:2|6   loss:0.4872080683708191  \n","Epoch:30/50     Step:3|6   loss:0.4869563579559326  \n","Epoch:30/50     Step:4|6   loss:0.48660823702812195  \n","Epoch:30/50     Step:5|6   loss:0.4865582287311554  \n","Epoch:30/50     Step:6|6   loss:0.4874999523162842  \n","Epoch:30/50     Step:7|6   loss:0.49022501707077026  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:31/50     Step:1|6   loss:0.48653095960617065  \n","Epoch:31/50     Step:2|6   loss:0.487213134765625  \n","Epoch:31/50     Step:3|6   loss:0.48677459359169006  \n","Epoch:31/50     Step:4|6   loss:0.4883255958557129  \n","Epoch:31/50     Step:5|6   loss:0.4870465099811554  \n","Epoch:31/50     Step:6|6   loss:0.4865427017211914  \n","Epoch:31/50     Step:7|6   loss:0.48607805371284485  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:32/50     Step:1|6   loss:0.4866088628768921  \n","Epoch:32/50     Step:2|6   loss:0.48772308230400085  \n","Epoch:32/50     Step:3|6   loss:0.4863392412662506  \n","Epoch:32/50     Step:4|6   loss:0.48731520771980286  \n","Epoch:32/50     Step:5|6   loss:0.48641437292099  \n","Epoch:32/50     Step:6|6   loss:0.4868604242801666  \n","Epoch:32/50     Step:7|6   loss:0.48689815402030945  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:33/50     Step:1|6   loss:0.4871886670589447  \n","Epoch:33/50     Step:2|6   loss:0.48640111088752747  \n","Epoch:33/50     Step:3|6   loss:0.4874474108219147  \n","Epoch:33/50     Step:4|6   loss:0.4872256815433502  \n","Epoch:33/50     Step:5|6   loss:0.4863397777080536  \n","Epoch:33/50     Step:6|6   loss:0.48587504029273987  \n","Epoch:33/50     Step:7|6   loss:0.4862041175365448  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:34/50     Step:1|6   loss:0.4864817261695862  \n","Epoch:34/50     Step:2|6   loss:0.4861772358417511  \n","Epoch:34/50     Step:3|6   loss:0.48675718903541565  \n","Epoch:34/50     Step:4|6   loss:0.4865245223045349  \n","Epoch:34/50     Step:5|6   loss:0.4859871566295624  \n","Epoch:34/50     Step:6|6   loss:0.48780009150505066  \n","Epoch:34/50     Step:7|6   loss:0.4865274429321289  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.48613011837005615  \n","Epoch:35/50     Step:2|6   loss:0.4864650070667267  \n","Epoch:35/50     Step:3|6   loss:0.48643213510513306  \n","Epoch:35/50     Step:4|6   loss:0.48639681935310364  \n","Epoch:35/50     Step:5|6   loss:0.4869655966758728  \n","Epoch:35/50     Step:6|6   loss:0.48654818534851074  \n","Epoch:35/50     Step:7|6   loss:0.48582756519317627  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.4871741533279419  \n","Epoch:36/50     Step:2|6   loss:0.48626476526260376  \n","Epoch:36/50     Step:3|6   loss:0.4863987863063812  \n","Epoch:36/50     Step:4|6   loss:0.4862046539783478  \n","Epoch:36/50     Step:5|6   loss:0.4864695370197296  \n","Epoch:36/50     Step:6|6   loss:0.4861855208873749  \n","Epoch:36/50     Step:7|6   loss:0.4863678812980652  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.4862244725227356  \n","Epoch:37/50     Step:2|6   loss:0.48586907982826233  \n","Epoch:37/50     Step:3|6   loss:0.48641109466552734  \n","Epoch:37/50     Step:4|6   loss:0.4858907163143158  \n","Epoch:37/50     Step:5|6   loss:0.4861127734184265  \n","Epoch:37/50     Step:6|6   loss:0.48705920577049255  \n","Epoch:37/50     Step:7|6   loss:0.48605161905288696  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.48594048619270325  \n","Epoch:38/50     Step:2|6   loss:0.4864109754562378  \n","Epoch:38/50     Step:3|6   loss:0.4860011339187622  \n","Epoch:38/50     Step:4|6   loss:0.4858317971229553  \n","Epoch:38/50     Step:5|6   loss:0.4857602119445801  \n","Epoch:38/50     Step:6|6   loss:0.48597222566604614  \n","Epoch:38/50     Step:7|6   loss:0.4877445697784424  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.4861070513725281  \n","Epoch:39/50     Step:2|6   loss:0.4859360456466675  \n","Epoch:39/50     Step:3|6   loss:0.48576977849006653  \n","Epoch:39/50     Step:4|6   loss:0.4866919219493866  \n","Epoch:39/50     Step:5|6   loss:0.4865906536579132  \n","Epoch:39/50     Step:6|6   loss:0.48577284812927246  \n","Epoch:39/50     Step:7|6   loss:0.4857312738895416  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.48572659492492676  \n","Epoch:40/50     Step:2|6   loss:0.4862588942050934  \n","Epoch:40/50     Step:3|6   loss:0.4859657287597656  \n","Epoch:40/50     Step:4|6   loss:0.4857286214828491  \n","Epoch:40/50     Step:5|6   loss:0.4862190783023834  \n","Epoch:40/50     Step:6|6   loss:0.48598146438598633  \n","Epoch:40/50     Step:7|6   loss:0.48667216300964355  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.4862617254257202  \n","Epoch:41/50     Step:2|6   loss:0.4856213927268982  \n","Epoch:41/50     Step:3|6   loss:0.48626744747161865  \n","Epoch:41/50     Step:4|6   loss:0.4857769310474396  \n","Epoch:41/50     Step:5|6   loss:0.48586761951446533  \n","Epoch:41/50     Step:6|6   loss:0.48587602376937866  \n","Epoch:41/50     Step:7|6   loss:0.4858402609825134  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4858827292919159  \n","Epoch:42/50     Step:2|6   loss:0.4866899847984314  \n","Epoch:42/50     Step:3|6   loss:0.4857819080352783  \n","Epoch:42/50     Step:4|6   loss:0.48577237129211426  \n","Epoch:42/50     Step:5|6   loss:0.48561498522758484  \n","Epoch:42/50     Step:6|6   loss:0.48616886138916016  \n","Epoch:42/50     Step:7|6   loss:0.48558831214904785  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.4862099289894104  \n","Epoch:43/50     Step:2|6   loss:0.48626571893692017  \n","Epoch:43/50     Step:3|6   loss:0.4860461950302124  \n","Epoch:43/50     Step:4|6   loss:0.4855799376964569  \n","Epoch:43/50     Step:5|6   loss:0.48570480942726135  \n","Epoch:43/50     Step:6|6   loss:0.48578745126724243  \n","Epoch:43/50     Step:7|6   loss:0.4855198860168457  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48598745465278625  \n","Epoch:44/50     Step:2|6   loss:0.48577168583869934  \n","Epoch:44/50     Step:3|6   loss:0.48646458983421326  \n","Epoch:44/50     Step:4|6   loss:0.4858306050300598  \n","Epoch:44/50     Step:5|6   loss:0.4857754111289978  \n","Epoch:44/50     Step:6|6   loss:0.4855867624282837  \n","Epoch:44/50     Step:7|6   loss:0.48566529154777527  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4859052300453186  \n","Epoch:45/50     Step:2|6   loss:0.486038476228714  \n","Epoch:45/50     Step:3|6   loss:0.4856037497520447  \n","Epoch:45/50     Step:4|6   loss:0.485805481672287  \n","Epoch:45/50     Step:5|6   loss:0.4855865240097046  \n","Epoch:45/50     Step:6|6   loss:0.485914945602417  \n","Epoch:45/50     Step:7|6   loss:0.48555877804756165  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.4857110381126404  \n","Epoch:46/50     Step:2|6   loss:0.4858267307281494  \n","Epoch:46/50     Step:3|6   loss:0.4856688678264618  \n","Epoch:46/50     Step:4|6   loss:0.48568084836006165  \n","Epoch:46/50     Step:5|6   loss:0.4856216311454773  \n","Epoch:46/50     Step:6|6   loss:0.4855411648750305  \n","Epoch:46/50     Step:7|6   loss:0.4866809844970703  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48582732677459717  \n","Epoch:47/50     Step:2|6   loss:0.4855925440788269  \n","Epoch:47/50     Step:3|6   loss:0.48567110300064087  \n","Epoch:47/50     Step:4|6   loss:0.48554059863090515  \n","Epoch:47/50     Step:5|6   loss:0.4856049120426178  \n","Epoch:47/50     Step:6|6   loss:0.4861915409564972  \n","Epoch:47/50     Step:7|6   loss:0.48574987053871155  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.48595619201660156  \n","Epoch:48/50     Step:2|6   loss:0.48562705516815186  \n","Epoch:48/50     Step:3|6   loss:0.4855256676673889  \n","Epoch:48/50     Step:4|6   loss:0.48560184240341187  \n","Epoch:48/50     Step:5|6   loss:0.4856909513473511  \n","Epoch:48/50     Step:6|6   loss:0.48535189032554626  \n","Epoch:48/50     Step:7|6   loss:0.4861055612564087  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.48624351620674133  \n","Epoch:49/50     Step:2|6   loss:0.48573067784309387  \n","Epoch:49/50     Step:3|6   loss:0.48537105321884155  \n","Epoch:49/50     Step:4|6   loss:0.4856022298336029  \n","Epoch:49/50     Step:5|6   loss:0.4856325387954712  \n","Epoch:49/50     Step:6|6   loss:0.48547881841659546  \n","Epoch:49/50     Step:7|6   loss:0.48538738489151  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4856555461883545  \n","Epoch:50/50     Step:2|6   loss:0.4855175316333771  \n","Epoch:50/50     Step:3|6   loss:0.48566263914108276  \n","Epoch:50/50     Step:4|6   loss:0.48588597774505615  \n","Epoch:50/50     Step:5|6   loss:0.4853754937648773  \n","Epoch:50/50     Step:6|6   loss:0.4857085049152374  \n","Epoch:50/50     Step:7|6   loss:0.4854392111301422  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.100495457649231  \n","Epoch:1/50     Step:2|6   loss:2.308760166168213  \n","Epoch:1/50     Step:3|6   loss:1.8687853813171387  \n","Epoch:1/50     Step:4|6   loss:1.1711057424545288  \n","Epoch:1/50     Step:5|6   loss:1.1186869144439697  \n","Epoch:1/50     Step:6|6   loss:1.0099698305130005  \n","Epoch:1/50     Step:7|6   loss:0.9873180389404297  \n","Accuracy on test_set: 60.75 %\n","Accuracy on train_set: 66.98 %\n","current max accuracy\t test set:60.75%\t train set:66.98%\n","Epoch:2/50     Step:1|6   loss:1.0330877304077148  \n","Epoch:2/50     Step:2|6   loss:0.9684580564498901  \n","Epoch:2/50     Step:3|6   loss:0.919737696647644  \n","Epoch:2/50     Step:4|6   loss:0.8641027212142944  \n","Epoch:2/50     Step:5|6   loss:0.8730007410049438  \n","Epoch:2/50     Step:6|6   loss:0.7617970705032349  \n","Epoch:2/50     Step:7|6   loss:0.7954235076904297  \n","Accuracy on test_set: 80.37 %\n","Accuracy on train_set: 83.61 %\n","current max accuracy\t test set:80.37%\t train set:83.61%\n","Epoch:3/50     Step:1|6   loss:0.8673865795135498  \n","Epoch:3/50     Step:2|6   loss:0.734347939491272  \n","Epoch:3/50     Step:3|6   loss:0.6740453839302063  \n","Epoch:3/50     Step:4|6   loss:0.7297062873840332  \n","Epoch:3/50     Step:5|6   loss:0.657562255859375  \n","Epoch:3/50     Step:6|6   loss:0.6472064256668091  \n","Epoch:3/50     Step:7|6   loss:0.6801800727844238  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 88.06 %\n","current max accuracy\t test set:85.05%\t train set:88.06%\n","Epoch:4/50     Step:1|6   loss:0.6782317161560059  \n","Epoch:4/50     Step:2|6   loss:0.6344283819198608  \n","Epoch:4/50     Step:3|6   loss:0.6373499035835266  \n","Epoch:4/50     Step:4|6   loss:0.6811647415161133  \n","Epoch:4/50     Step:5|6   loss:0.5974961519241333  \n","Epoch:4/50     Step:6|6   loss:0.645316481590271  \n","Epoch:4/50     Step:7|6   loss:0.6745476722717285  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:86.92%\t train set:91.33%\n","Epoch:5/50     Step:1|6   loss:0.6402069330215454  \n","Epoch:5/50     Step:2|6   loss:0.6028855443000793  \n","Epoch:5/50     Step:3|6   loss:0.6489995121955872  \n","Epoch:5/50     Step:4|6   loss:0.6144702434539795  \n","Epoch:5/50     Step:5|6   loss:0.5926800966262817  \n","Epoch:5/50     Step:6|6   loss:0.6025164127349854  \n","Epoch:5/50     Step:7|6   loss:0.6791476011276245  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.10 %\n","current max accuracy\t test set:87.85%\t train set:91.33%\n","Epoch:6/50     Step:1|6   loss:0.5636186599731445  \n","Epoch:6/50     Step:2|6   loss:0.6309047937393188  \n","Epoch:6/50     Step:3|6   loss:0.633008599281311  \n","Epoch:6/50     Step:4|6   loss:0.610885500907898  \n","Epoch:6/50     Step:5|6   loss:0.6153825521469116  \n","Epoch:6/50     Step:6|6   loss:0.607230544090271  \n","Epoch:6/50     Step:7|6   loss:0.5716083645820618  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 92.74 %\n","current max accuracy\t test set:88.79%\t train set:92.74%\n","Epoch:7/50     Step:1|6   loss:0.5665329694747925  \n","Epoch:7/50     Step:2|6   loss:0.5556766986846924  \n","Epoch:7/50     Step:3|6   loss:0.5718780159950256  \n","Epoch:7/50     Step:4|6   loss:0.6076020002365112  \n","Epoch:7/50     Step:5|6   loss:0.6005859375  \n","Epoch:7/50     Step:6|6   loss:0.5917364358901978  \n","Epoch:7/50     Step:7|6   loss:0.6471039056777954  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:88.79%\t train set:94.15%\n","Epoch:8/50     Step:1|6   loss:0.5840252637863159  \n","Epoch:8/50     Step:2|6   loss:0.5629305839538574  \n","Epoch:8/50     Step:3|6   loss:0.5969127416610718  \n","Epoch:8/50     Step:4|6   loss:0.591020405292511  \n","Epoch:8/50     Step:5|6   loss:0.5602392554283142  \n","Epoch:8/50     Step:6|6   loss:0.5900915861129761  \n","Epoch:8/50     Step:7|6   loss:0.5517710447311401  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:90.65%\t train set:95.32%\n","Epoch:9/50     Step:1|6   loss:0.600368857383728  \n","Epoch:9/50     Step:2|6   loss:0.5367580652236938  \n","Epoch:9/50     Step:3|6   loss:0.5499998331069946  \n","Epoch:9/50     Step:4|6   loss:0.6065190434455872  \n","Epoch:9/50     Step:5|6   loss:0.5653162002563477  \n","Epoch:9/50     Step:6|6   loss:0.5550255179405212  \n","Epoch:9/50     Step:7|6   loss:0.5454758405685425  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:90.65%\t train set:96.02%\n","Epoch:10/50     Step:1|6   loss:0.5452440977096558  \n","Epoch:10/50     Step:2|6   loss:0.5474462509155273  \n","Epoch:10/50     Step:3|6   loss:0.5756694078445435  \n","Epoch:10/50     Step:4|6   loss:0.5570531487464905  \n","Epoch:10/50     Step:5|6   loss:0.5662274360656738  \n","Epoch:10/50     Step:6|6   loss:0.5738959908485413  \n","Epoch:10/50     Step:7|6   loss:0.5328232645988464  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:90.65%\t train set:96.02%\n","Epoch:11/50     Step:1|6   loss:0.5298547744750977  \n","Epoch:11/50     Step:2|6   loss:0.5778206586837769  \n","Epoch:11/50     Step:3|6   loss:0.5451127290725708  \n","Epoch:11/50     Step:4|6   loss:0.5245651006698608  \n","Epoch:11/50     Step:5|6   loss:0.5759750008583069  \n","Epoch:11/50     Step:6|6   loss:0.5635430216789246  \n","Epoch:11/50     Step:7|6   loss:0.5556832551956177  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:90.65%\t train set:97.19%\n","Epoch:12/50     Step:1|6   loss:0.5277199745178223  \n","Epoch:12/50     Step:2|6   loss:0.5515591502189636  \n","Epoch:12/50     Step:3|6   loss:0.5371081829071045  \n","Epoch:12/50     Step:4|6   loss:0.5296611785888672  \n","Epoch:12/50     Step:5|6   loss:0.5511981844902039  \n","Epoch:12/50     Step:6|6   loss:0.5349118113517761  \n","Epoch:12/50     Step:7|6   loss:0.5606328248977661  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:90.65%\t train set:97.19%\n","Epoch:13/50     Step:1|6   loss:0.5278687477111816  \n","Epoch:13/50     Step:2|6   loss:0.5628935694694519  \n","Epoch:13/50     Step:3|6   loss:0.5155802369117737  \n","Epoch:13/50     Step:4|6   loss:0.5135157704353333  \n","Epoch:13/50     Step:5|6   loss:0.5208200812339783  \n","Epoch:13/50     Step:6|6   loss:0.531978964805603  \n","Epoch:13/50     Step:7|6   loss:0.5723155736923218  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:90.65%\t train set:98.13%\n","Epoch:14/50     Step:1|6   loss:0.5285061597824097  \n","Epoch:14/50     Step:2|6   loss:0.5141175389289856  \n","Epoch:14/50     Step:3|6   loss:0.544736921787262  \n","Epoch:14/50     Step:4|6   loss:0.5475067496299744  \n","Epoch:14/50     Step:5|6   loss:0.5120291709899902  \n","Epoch:14/50     Step:6|6   loss:0.5248186588287354  \n","Epoch:14/50     Step:7|6   loss:0.5234676003456116  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:15/50     Step:1|6   loss:0.5641682147979736  \n","Epoch:15/50     Step:2|6   loss:0.518337070941925  \n","Epoch:15/50     Step:3|6   loss:0.5166012048721313  \n","Epoch:15/50     Step:4|6   loss:0.5162217617034912  \n","Epoch:15/50     Step:5|6   loss:0.5076268315315247  \n","Epoch:15/50     Step:6|6   loss:0.524359405040741  \n","Epoch:15/50     Step:7|6   loss:0.5239154100418091  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:16/50     Step:1|6   loss:0.4978621006011963  \n","Epoch:16/50     Step:2|6   loss:0.5206294059753418  \n","Epoch:16/50     Step:3|6   loss:0.5224277377128601  \n","3\n"]},{"name":"stdout","output_type":"stream","text":["Epoch:16/50     Step:4|6   loss:0.5660592913627625  \n","Epoch:16/50     Step:5|6   loss:0.5063250660896301  \n","Epoch:16/50     Step:6|6   loss:0.49887335300445557  \n","Epoch:16/50     Step:7|6   loss:0.5301251411437988  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:17/50     Step:1|6   loss:0.5288381576538086  \n","Epoch:17/50     Step:2|6   loss:0.5014550089836121  \n","Epoch:17/50     Step:3|6   loss:0.5083605051040649  \n","Epoch:17/50     Step:4|6   loss:0.5039656162261963  \n","Epoch:17/50     Step:5|6   loss:0.5516493320465088  \n","Epoch:17/50     Step:6|6   loss:0.5047496557235718  \n","Epoch:17/50     Step:7|6   loss:0.5159796476364136  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:90.65%\t train set:98.59%\n","Epoch:18/50     Step:1|6   loss:0.5297970771789551  \n","Epoch:18/50     Step:2|6   loss:0.511812686920166  \n","Epoch:18/50     Step:3|6   loss:0.5209875106811523  \n","Epoch:18/50     Step:4|6   loss:0.5037696957588196  \n","Epoch:18/50     Step:5|6   loss:0.5011059045791626  \n","Epoch:18/50     Step:6|6   loss:0.509838342666626  \n","Epoch:18/50     Step:7|6   loss:0.5240790843963623  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:19/50     Step:1|6   loss:0.5073976516723633  \n","Epoch:19/50     Step:2|6   loss:0.4978870749473572  \n","Epoch:19/50     Step:3|6   loss:0.5059335827827454  \n","Epoch:19/50     Step:4|6   loss:0.5488609075546265  \n","Epoch:19/50     Step:5|6   loss:0.4964894652366638  \n","Epoch:19/50     Step:6|6   loss:0.49659791588783264  \n","Epoch:19/50     Step:7|6   loss:0.5386184453964233  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:90.65%\t train set:99.06%\n","Epoch:20/50     Step:1|6   loss:0.5150920748710632  \n","Epoch:20/50     Step:2|6   loss:0.5037587881088257  \n","Epoch:20/50     Step:3|6   loss:0.5083613395690918  \n","Epoch:20/50     Step:4|6   loss:0.49482813477516174  \n","Epoch:20/50     Step:5|6   loss:0.5097894668579102  \n","Epoch:20/50     Step:6|6   loss:0.5234823822975159  \n","Epoch:20/50     Step:7|6   loss:0.5156125426292419  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:91.59%\t train set:99.06%\n","Epoch:21/50     Step:1|6   loss:0.5320084095001221  \n","Epoch:21/50     Step:2|6   loss:0.500465452671051  \n","Epoch:21/50     Step:3|6   loss:0.49996763467788696  \n","Epoch:21/50     Step:4|6   loss:0.5287771224975586  \n","Epoch:21/50     Step:5|6   loss:0.49845123291015625  \n","Epoch:21/50     Step:6|6   loss:0.4944426417350769  \n","Epoch:21/50     Step:7|6   loss:0.5007624626159668  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:91.59%\t train set:99.06%\n","Epoch:22/50     Step:1|6   loss:0.498796671628952  \n","Epoch:22/50     Step:2|6   loss:0.5094988346099854  \n","Epoch:22/50     Step:3|6   loss:0.504269003868103  \n","Epoch:22/50     Step:4|6   loss:0.543131947517395  \n","Epoch:22/50     Step:5|6   loss:0.49757838249206543  \n","Epoch:22/50     Step:6|6   loss:0.49391767382621765  \n","Epoch:22/50     Step:7|6   loss:0.49316632747650146  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:23/50     Step:1|6   loss:0.4963057041168213  \n","Epoch:23/50     Step:2|6   loss:0.4957898259162903  \n","Epoch:23/50     Step:3|6   loss:0.49807000160217285  \n","Epoch:23/50     Step:4|6   loss:0.4978902339935303  \n","Epoch:23/50     Step:5|6   loss:0.5306015014648438  \n","Epoch:23/50     Step:6|6   loss:0.512305736541748  \n","Epoch:23/50     Step:7|6   loss:0.499359667301178  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:24/50     Step:1|6   loss:0.4970548748970032  \n","Epoch:24/50     Step:2|6   loss:0.5002997517585754  \n","Epoch:24/50     Step:3|6   loss:0.4975876212120056  \n","Epoch:24/50     Step:4|6   loss:0.5019630193710327  \n","Epoch:24/50     Step:5|6   loss:0.5308884382247925  \n","Epoch:24/50     Step:6|6   loss:0.49337905645370483  \n","Epoch:24/50     Step:7|6   loss:0.49602174758911133  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:25/50     Step:1|6   loss:0.49422013759613037  \n","Epoch:25/50     Step:2|6   loss:0.49691241979599  \n","Epoch:25/50     Step:3|6   loss:0.49714550375938416  \n","Epoch:25/50     Step:4|6   loss:0.5197063684463501  \n","Epoch:25/50     Step:5|6   loss:0.5045052170753479  \n","Epoch:25/50     Step:6|6   loss:0.498222291469574  \n","Epoch:25/50     Step:7|6   loss:0.496917188167572  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:26/50     Step:1|6   loss:0.4971712529659271  \n","Epoch:26/50     Step:2|6   loss:0.4987863004207611  \n","Epoch:26/50     Step:3|6   loss:0.5068742036819458  \n","Epoch:26/50     Step:4|6   loss:0.5152795314788818  \n","Epoch:26/50     Step:5|6   loss:0.4950067400932312  \n","Epoch:26/50     Step:6|6   loss:0.4951518177986145  \n","Epoch:26/50     Step:7|6   loss:0.49093887209892273  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:27/50     Step:1|6   loss:0.4906047582626343  \n","Epoch:27/50     Step:2|6   loss:0.4937205910682678  \n","Epoch:27/50     Step:3|6   loss:0.4917633533477783  \n","Epoch:27/50     Step:4|6   loss:0.49313050508499146  \n","Epoch:27/50     Step:5|6   loss:0.5198909044265747  \n","Epoch:27/50     Step:6|6   loss:0.5089303851127625  \n","Epoch:27/50     Step:7|6   loss:0.4953345060348511  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:28/50     Step:1|6   loss:0.4963020384311676  \n","Epoch:28/50     Step:2|6   loss:0.4924808740615845  \n","Epoch:28/50     Step:3|6   loss:0.5094576478004456  \n","Epoch:28/50     Step:4|6   loss:0.48852211236953735  \n","Epoch:28/50     Step:5|6   loss:0.49813610315322876  \n","Epoch:28/50     Step:6|6   loss:0.5078796744346619  \n","Epoch:28/50     Step:7|6   loss:0.49106550216674805  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:29/50     Step:1|6   loss:0.49285799264907837  \n","Epoch:29/50     Step:2|6   loss:0.49314558506011963  \n","Epoch:29/50     Step:3|6   loss:0.5215021371841431  \n","Epoch:29/50     Step:4|6   loss:0.49310800433158875  \n","Epoch:29/50     Step:5|6   loss:0.49421387910842896  \n","Epoch:29/50     Step:6|6   loss:0.49018967151641846  \n","Epoch:29/50     Step:7|6   loss:0.49257898330688477  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:30/50     Step:1|6   loss:0.49439573287963867  \n","Epoch:30/50     Step:2|6   loss:0.5102853178977966  \n","Epoch:30/50     Step:3|6   loss:0.49479547142982483  \n","Epoch:30/50     Step:4|6   loss:0.49596455693244934  \n","Epoch:30/50     Step:5|6   loss:0.49352073669433594  \n","Epoch:30/50     Step:6|6   loss:0.48958489298820496  \n","Epoch:30/50     Step:7|6   loss:0.49454164505004883  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:31/50     Step:1|6   loss:0.4902711808681488  \n","Epoch:31/50     Step:2|6   loss:0.49378544092178345  \n","Epoch:31/50     Step:3|6   loss:0.49089550971984863  \n","Epoch:31/50     Step:4|6   loss:0.49680155515670776  \n","Epoch:31/50     Step:5|6   loss:0.48979872465133667  \n","Epoch:31/50     Step:6|6   loss:0.5108906626701355  \n","Epoch:31/50     Step:7|6   loss:0.496661514043808  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:32/50     Step:1|6   loss:0.48911163210868835  \n","Epoch:32/50     Step:2|6   loss:0.48998749256134033  \n","Epoch:32/50     Step:3|6   loss:0.49712276458740234  \n","Epoch:32/50     Step:4|6   loss:0.48879605531692505  \n","Epoch:32/50     Step:5|6   loss:0.49373847246170044  \n","Epoch:32/50     Step:6|6   loss:0.5003342032432556  \n","Epoch:32/50     Step:7|6   loss:0.5087718367576599  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:33/50     Step:1|6   loss:0.4943416118621826  \n","Epoch:33/50     Step:2|6   loss:0.48907870054244995  \n","Epoch:33/50     Step:3|6   loss:0.4896897077560425  \n","Epoch:33/50     Step:4|6   loss:0.49956613779067993  \n","Epoch:33/50     Step:5|6   loss:0.49844926595687866  \n","Epoch:33/50     Step:6|6   loss:0.5001327991485596  \n","Epoch:33/50     Step:7|6   loss:0.48737215995788574  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:34/50     Step:1|6   loss:0.49034178256988525  \n","Epoch:34/50     Step:2|6   loss:0.4889778196811676  \n","Epoch:34/50     Step:3|6   loss:0.49528661370277405  \n","Epoch:34/50     Step:4|6   loss:0.5063591003417969  \n","Epoch:34/50     Step:5|6   loss:0.49163490533828735  \n","Epoch:34/50     Step:6|6   loss:0.494062602519989  \n","Epoch:34/50     Step:7|6   loss:0.4889953136444092  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:35/50     Step:1|6   loss:0.49005889892578125  \n","Epoch:35/50     Step:2|6   loss:0.5049657821655273  \n","Epoch:35/50     Step:3|6   loss:0.49485599994659424  \n","Epoch:35/50     Step:4|6   loss:0.4915301203727722  \n","Epoch:35/50     Step:5|6   loss:0.4889233112335205  \n","Epoch:35/50     Step:6|6   loss:0.4902181029319763  \n","Epoch:35/50     Step:7|6   loss:0.4951310157775879  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:36/50     Step:1|6   loss:0.49407392740249634  \n","Epoch:36/50     Step:2|6   loss:0.49011939764022827  \n","Epoch:36/50     Step:3|6   loss:0.49944743514060974  \n","Epoch:36/50     Step:4|6   loss:0.4905627369880676  \n","Epoch:36/50     Step:5|6   loss:0.4900108277797699  \n","Epoch:36/50     Step:6|6   loss:0.4947550296783447  \n","Epoch:36/50     Step:7|6   loss:0.49337273836135864  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:37/50     Step:1|6   loss:0.49160945415496826  \n","Epoch:37/50     Step:2|6   loss:0.48656603693962097  \n","Epoch:37/50     Step:3|6   loss:0.49400103092193604  \n","Epoch:37/50     Step:4|6   loss:0.48878663778305054  \n","Epoch:37/50     Step:5|6   loss:0.4872370958328247  \n","Epoch:37/50     Step:6|6   loss:0.4991840422153473  \n","Epoch:37/50     Step:7|6   loss:0.5066870450973511  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:38/50     Step:1|6   loss:0.4973324239253998  \n","Epoch:38/50     Step:2|6   loss:0.49140506982803345  \n","Epoch:38/50     Step:3|6   loss:0.49573713541030884  \n","Epoch:38/50     Step:4|6   loss:0.48675501346588135  \n","Epoch:38/50     Step:5|6   loss:0.490658700466156  \n","Epoch:38/50     Step:6|6   loss:0.4954644441604614  \n","Epoch:38/50     Step:7|6   loss:0.4880622923374176  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:39/50     Step:1|6   loss:0.48981550335884094  \n","Epoch:39/50     Step:2|6   loss:0.48846670985221863  \n","Epoch:39/50     Step:3|6   loss:0.48783954977989197  \n","Epoch:39/50     Step:4|6   loss:0.4892696142196655  \n","Epoch:39/50     Step:5|6   loss:0.4958280920982361  \n","Epoch:39/50     Step:6|6   loss:0.48941391706466675  \n","Epoch:39/50     Step:7|6   loss:0.5085671544075012  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:94.39%\t train set:99.77%\n","Epoch:40/50     Step:1|6   loss:0.4867103695869446  \n","Epoch:40/50     Step:2|6   loss:0.4927562475204468  \n","Epoch:40/50     Step:3|6   loss:0.4952501654624939  \n","Epoch:40/50     Step:4|6   loss:0.4909600615501404  \n","Epoch:40/50     Step:5|6   loss:0.4903045892715454  \n","Epoch:40/50     Step:6|6   loss:0.48917055130004883  \n","Epoch:40/50     Step:7|6   loss:0.4971565008163452  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.48935508728027344  \n","Epoch:41/50     Step:2|6   loss:0.49700647592544556  \n","Epoch:41/50     Step:3|6   loss:0.49266529083251953  \n","Epoch:41/50     Step:4|6   loss:0.49354156851768494  \n","Epoch:41/50     Step:5|6   loss:0.488525927066803  \n","Epoch:41/50     Step:6|6   loss:0.48822110891342163  \n","Epoch:41/50     Step:7|6   loss:0.4886380434036255  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.4868071377277374  \n","Epoch:42/50     Step:2|6   loss:0.49039310216903687  \n","Epoch:42/50     Step:3|6   loss:0.4949498176574707  \n","Epoch:42/50     Step:4|6   loss:0.4889925718307495  \n","Epoch:42/50     Step:5|6   loss:0.4892503023147583  \n","Epoch:42/50     Step:6|6   loss:0.4980843663215637  \n","Epoch:42/50     Step:7|6   loss:0.4879097640514374  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.49298954010009766  \n","Epoch:43/50     Step:2|6   loss:0.4930119514465332  \n","Epoch:43/50     Step:3|6   loss:0.4889487624168396  \n","Epoch:43/50     Step:4|6   loss:0.4905222952365875  \n","Epoch:43/50     Step:5|6   loss:0.48821452260017395  \n","Epoch:43/50     Step:6|6   loss:0.4923623204231262  \n","Epoch:43/50     Step:7|6   loss:0.48964744806289673  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.48698753118515015  \n","Epoch:44/50     Step:2|6   loss:0.4891369938850403  \n","Epoch:44/50     Step:3|6   loss:0.49425363540649414  \n","Epoch:44/50     Step:4|6   loss:0.48759591579437256  \n","Epoch:44/50     Step:5|6   loss:0.49234288930892944  \n","Epoch:44/50     Step:6|6   loss:0.4966745376586914  \n","Epoch:44/50     Step:7|6   loss:0.4867313504219055  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.4878292381763458  \n","Epoch:45/50     Step:2|6   loss:0.5000993013381958  \n","Epoch:45/50     Step:3|6   loss:0.4882380962371826  \n","Epoch:45/50     Step:4|6   loss:0.48875153064727783  \n","Epoch:45/50     Step:5|6   loss:0.4881376624107361  \n","Epoch:45/50     Step:6|6   loss:0.4929468631744385  \n","Epoch:45/50     Step:7|6   loss:0.4870359003543854  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.48730120062828064  \n","Epoch:46/50     Step:2|6   loss:0.4889923930168152  \n","Epoch:46/50     Step:3|6   loss:0.4991403818130493  \n","Epoch:46/50     Step:4|6   loss:0.4901198744773865  \n","Epoch:46/50     Step:5|6   loss:0.48705071210861206  \n","Epoch:46/50     Step:6|6   loss:0.4927409291267395  \n","Epoch:46/50     Step:7|6   loss:0.48694953322410583  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.48714733123779297  \n","Epoch:47/50     Step:2|6   loss:0.48800647258758545  \n","Epoch:47/50     Step:3|6   loss:0.48784303665161133  \n","Epoch:47/50     Step:4|6   loss:0.4906309247016907  \n","Epoch:47/50     Step:5|6   loss:0.49277979135513306  \n","Epoch:47/50     Step:6|6   loss:0.4974660575389862  \n","Epoch:47/50     Step:7|6   loss:0.4881048798561096  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.4928666949272156  \n","Epoch:48/50     Step:2|6   loss:0.4910116195678711  \n","Epoch:48/50     Step:3|6   loss:0.48624998331069946  \n","Epoch:48/50     Step:4|6   loss:0.490813285112381  \n","Epoch:48/50     Step:5|6   loss:0.49413353204727173  \n","Epoch:48/50     Step:6|6   loss:0.4883967936038971  \n","Epoch:48/50     Step:7|6   loss:0.4878833591938019  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.49329107999801636  \n","Epoch:49/50     Step:2|6   loss:0.48689478635787964  \n","Epoch:49/50     Step:3|6   loss:0.49745887517929077  \n","Epoch:49/50     Step:4|6   loss:0.48847371339797974  \n","Epoch:49/50     Step:5|6   loss:0.4866567850112915  \n","Epoch:49/50     Step:6|6   loss:0.4874018132686615  \n","Epoch:49/50     Step:7|6   loss:0.4919673204421997  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.4955953359603882  \n","Epoch:50/50     Step:2|6   loss:0.4932810664176941  \n","Epoch:50/50     Step:3|6   loss:0.4922541379928589  \n","Epoch:50/50     Step:4|6   loss:0.48697957396507263  \n","Epoch:50/50     Step:5|6   loss:0.48717430233955383  \n","Epoch:50/50     Step:6|6   loss:0.4871198236942291  \n","Epoch:50/50     Step:7|6   loss:0.48806101083755493  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Accuracy on test_set: 94.39 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.087487816810608  \n","Epoch:1/50     Step:2|6   loss:3.0765726566314697  \n","Epoch:1/50     Step:3|6   loss:2.6076927185058594  \n","Epoch:1/50     Step:4|6   loss:3.0133135318756104  \n","Epoch:1/50     Step:5|6   loss:2.446791648864746  \n","Epoch:1/50     Step:6|6   loss:2.7758960723876953  \n","Epoch:1/50     Step:7|6   loss:2.435055732727051  \n","Accuracy on test_set: 54.21 %\n","Accuracy on train_set: 45.20 %\n","current max accuracy\t test set:54.21%\t train set:45.2%\n","Epoch:2/50     Step:1|6   loss:2.127554416656494  \n","Epoch:2/50     Step:2|6   loss:1.9960243701934814  \n","Epoch:2/50     Step:3|6   loss:1.807770848274231  \n","Epoch:2/50     Step:4|6   loss:2.243295907974243  \n","Epoch:2/50     Step:5|6   loss:1.859707236289978  \n","Epoch:2/50     Step:6|6   loss:1.5026473999023438  \n","Epoch:2/50     Step:7|6   loss:1.1882741451263428  \n","Accuracy on test_set: 52.34 %\n","Accuracy on train_set: 60.19 %\n","current max accuracy\t test set:54.21%\t train set:60.19%\n","Epoch:3/50     Step:1|6   loss:0.858619749546051  \n","Epoch:3/50     Step:2|6   loss:0.9147776365280151  \n","Epoch:3/50     Step:3|6   loss:0.9574799537658691  \n","Epoch:3/50     Step:4|6   loss:0.6869614124298096  \n","Epoch:3/50     Step:5|6   loss:0.7195905447006226  \n","Epoch:3/50     Step:6|6   loss:0.7588980197906494  \n","Epoch:3/50     Step:7|6   loss:0.7310489416122437  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 76.35 %\n","current max accuracy\t test set:79.44%\t train set:76.35%\n","Epoch:4/50     Step:1|6   loss:0.7842751741409302  \n","Epoch:4/50     Step:2|6   loss:0.7767612338066101  \n","Epoch:4/50     Step:3|6   loss:0.6933894157409668  \n","Epoch:4/50     Step:4|6   loss:0.7100497484207153  \n","Epoch:4/50     Step:5|6   loss:0.7164409756660461  \n","Epoch:4/50     Step:6|6   loss:0.6525121927261353  \n","Epoch:4/50     Step:7|6   loss:0.606198787689209  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:83.18%\t train set:90.63%\n","Epoch:5/50     Step:1|6   loss:0.6553447246551514  \n","Epoch:5/50     Step:2|6   loss:0.6494872570037842  \n","Epoch:5/50     Step:3|6   loss:0.6260960698127747  \n","Epoch:5/50     Step:4|6   loss:0.6329050064086914  \n","Epoch:5/50     Step:5|6   loss:0.6189138293266296  \n","Epoch:5/50     Step:6|6   loss:0.6335871815681458  \n","Epoch:5/50     Step:7|6   loss:0.6491842269897461  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 91.80 %\n","current max accuracy\t test set:86.92%\t train set:91.8%\n","Epoch:6/50     Step:1|6   loss:0.6491622924804688  \n","Epoch:6/50     Step:2|6   loss:0.5779752135276794  \n","Epoch:6/50     Step:3|6   loss:0.5913426876068115  \n","Epoch:6/50     Step:4|6   loss:0.6296191215515137  \n","Epoch:6/50     Step:5|6   loss:0.5711852312088013  \n","Epoch:6/50     Step:6|6   loss:0.6074075698852539  \n","Epoch:6/50     Step:7|6   loss:0.6231561303138733  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:86.92%\t train set:93.68%\n","Epoch:7/50     Step:1|6   loss:0.5838543176651001  \n","Epoch:7/50     Step:2|6   loss:0.6107687950134277  \n","Epoch:7/50     Step:3|6   loss:0.6078388094902039  \n","Epoch:7/50     Step:4|6   loss:0.571144700050354  \n","Epoch:7/50     Step:5|6   loss:0.563387930393219  \n","Epoch:7/50     Step:6|6   loss:0.5722125768661499  \n","Epoch:7/50     Step:7|6   loss:0.6231639385223389  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:88.79%\t train set:94.15%\n","Epoch:8/50     Step:1|6   loss:0.5922149419784546  \n","Epoch:8/50     Step:2|6   loss:0.5731470584869385  \n","Epoch:8/50     Step:3|6   loss:0.5259089469909668  \n","Epoch:8/50     Step:4|6   loss:0.5885066986083984  \n","Epoch:8/50     Step:5|6   loss:0.5617316365242004  \n","Epoch:8/50     Step:6|6   loss:0.5976593494415283  \n","Epoch:8/50     Step:7|6   loss:0.5574990510940552  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:88.79%\t train set:96.02%\n","Epoch:9/50     Step:1|6   loss:0.5642164349555969  \n","Epoch:9/50     Step:2|6   loss:0.5665322542190552  \n","Epoch:9/50     Step:3|6   loss:0.5427898168563843  \n","Epoch:9/50     Step:4|6   loss:0.5747300386428833  4\n","Epoch:9/50     Step:5|6   loss:0.5835680961608887  \n","Epoch:9/50     Step:6|6   loss:0.5586534738540649  \n","Epoch:9/50     Step:7|6   loss:0.5435159206390381  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:89.72%\t train set:96.02%\n","\n","Epoch:10/50     Step:1|6   loss:0.5320946574211121  \n","Epoch:10/50     Step:2|6   loss:0.5372031927108765  \n","Epoch:10/50     Step:3|6   loss:0.5948103666305542  \n","Epoch:10/50     Step:4|6   loss:0.5614640712738037  \n","Epoch:10/50     Step:5|6   loss:0.5586432218551636  \n","Epoch:10/50     Step:6|6   loss:0.5587689280509949  \n","Epoch:10/50     Step:7|6   loss:0.5198925137519836  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:89.72%\t train set:96.72%\n","Epoch:11/50     Step:1|6   loss:0.5786393880844116  \n","Epoch:11/50     Step:2|6   loss:0.5442268252372742  \n","Epoch:11/50     Step:3|6   loss:0.5356858968734741  \n","Epoch:11/50     Step:4|6   loss:0.5133416652679443  \n","Epoch:11/50     Step:5|6   loss:0.5415453314781189  \n","Epoch:11/50     Step:6|6   loss:0.5320223569869995  \n","Epoch:11/50     Step:7|6   loss:0.5724806785583496  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:12/50     Step:1|6   loss:0.5334915518760681  \n","Epoch:12/50     Step:2|6   loss:0.5580984950065613  \n","Epoch:12/50     Step:3|6   loss:0.5182971954345703  \n","Epoch:12/50     Step:4|6   loss:0.5527654886245728  \n","Epoch:12/50     Step:5|6   loss:0.5454972386360168  \n","Epoch:12/50     Step:6|6   loss:0.539081871509552  \n","Epoch:12/50     Step:7|6   loss:0.521735668182373  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:90.65%\t train set:96.96%\n","Epoch:13/50     Step:1|6   loss:0.5221436619758606  \n","Epoch:13/50     Step:2|6   loss:0.5484114289283752  \n","Epoch:13/50     Step:3|6   loss:0.5251796245574951  \n","Epoch:13/50     Step:4|6   loss:0.5804719924926758  \n","Epoch:13/50     Step:5|6   loss:0.5121955275535583  \n","Epoch:13/50     Step:6|6   loss:0.514865517616272  \n","Epoch:13/50     Step:7|6   loss:0.5608401298522949  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:93.46%\t train set:98.59%\n","Epoch:14/50     Step:1|6   loss:0.5268415212631226  \n","Epoch:14/50     Step:2|6   loss:0.5231898427009583  \n","Epoch:14/50     Step:3|6   loss:0.5137702226638794  \n","Epoch:14/50     Step:4|6   loss:0.5242015719413757  \n","Epoch:14/50     Step:5|6   loss:0.5053709745407104  \n","Epoch:14/50     Step:6|6   loss:0.5264729857444763  \n","Epoch:14/50     Step:7|6   loss:0.5682545900344849  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:93.46%\t train set:99.06%\n","Epoch:15/50     Step:1|6   loss:0.504011869430542  \n","Epoch:15/50     Step:2|6   loss:0.529866099357605  \n","Epoch:15/50     Step:3|6   loss:0.5441495180130005  \n","Epoch:15/50     Step:4|6   loss:0.5571466088294983  \n","Epoch:15/50     Step:5|6   loss:0.5103288292884827  \n","Epoch:15/50     Step:6|6   loss:0.5236116647720337  \n","Epoch:15/50     Step:7|6   loss:0.5166810154914856  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:16/50     Step:1|6   loss:0.5277396440505981  \n","Epoch:16/50     Step:2|6   loss:0.5040347576141357  \n","Epoch:16/50     Step:3|6   loss:0.5318729877471924  \n","Epoch:16/50     Step:4|6   loss:0.5088965892791748  \n","Epoch:16/50     Step:5|6   loss:0.514990508556366  \n","Epoch:16/50     Step:6|6   loss:0.5170148015022278  \n","Epoch:16/50     Step:7|6   loss:0.505854606628418  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:17/50     Step:1|6   loss:0.5135477185249329  \n","Epoch:17/50     Step:2|6   loss:0.5065281391143799  \n","Epoch:17/50     Step:3|6   loss:0.5221052169799805  \n","Epoch:17/50     Step:4|6   loss:0.5081409215927124  \n","Epoch:17/50     Step:5|6   loss:0.5055741667747498  \n","Epoch:17/50     Step:6|6   loss:0.5284101366996765  \n","Epoch:17/50     Step:7|6   loss:0.5125732421875  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:18/50     Step:1|6   loss:0.5107554197311401  \n","Epoch:18/50     Step:2|6   loss:0.5229361057281494  \n","Epoch:18/50     Step:3|6   loss:0.5167095065116882  \n","Epoch:18/50     Step:4|6   loss:0.5188595652580261  \n","Epoch:18/50     Step:5|6   loss:0.5003507137298584  \n","Epoch:18/50     Step:6|6   loss:0.5018488764762878  \n","Epoch:18/50     Step:7|6   loss:0.5146823525428772  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:19/50     Step:1|6   loss:0.5245914459228516  \n","Epoch:19/50     Step:2|6   loss:0.5110403895378113  \n","Epoch:19/50     Step:3|6   loss:0.5026024580001831  \n","Epoch:19/50     Step:4|6   loss:0.5275057554244995  \n","Epoch:19/50     Step:5|6   loss:0.49902069568634033  \n","Epoch:19/50     Step:6|6   loss:0.4985392391681671  \n","Epoch:19/50     Step:7|6   loss:0.5086467862129211  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:20/50     Step:1|6   loss:0.5033973455429077  \n","Epoch:20/50     Step:2|6   loss:0.5048898458480835  \n","Epoch:20/50     Step:3|6   loss:0.5028160214424133  \n","Epoch:20/50     Step:4|6   loss:0.5181280970573425  \n","Epoch:20/50     Step:5|6   loss:0.5166911482810974  \n","Epoch:20/50     Step:6|6   loss:0.503774106502533  \n","Epoch:20/50     Step:7|6   loss:0.49536460638046265  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:21/50     Step:1|6   loss:0.5016357898712158  \n","Epoch:21/50     Step:2|6   loss:0.499727338552475  \n","Epoch:21/50     Step:3|6   loss:0.4958164095878601  \n","Epoch:21/50     Step:4|6   loss:0.5215859413146973  \n","Epoch:21/50     Step:5|6   loss:0.49907177686691284  \n","Epoch:21/50     Step:6|6   loss:0.5178227424621582  \n","Epoch:21/50     Step:7|6   loss:0.5026683211326599  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:22/50     Step:1|6   loss:0.5205893516540527  \n","Epoch:22/50     Step:2|6   loss:0.49241477251052856  \n","Epoch:22/50     Step:3|6   loss:0.5042572021484375  \n","Epoch:22/50     Step:4|6   loss:0.528439998626709  \n","Epoch:22/50     Step:5|6   loss:0.4927765130996704  \n","Epoch:22/50     Step:6|6   loss:0.4984120726585388  \n","Epoch:22/50     Step:7|6   loss:0.49423134326934814  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:23/50     Step:1|6   loss:0.5013980865478516  \n","Epoch:23/50     Step:2|6   loss:0.4930098056793213  \n","Epoch:23/50     Step:3|6   loss:0.5088481903076172  \n","Epoch:23/50     Step:4|6   loss:0.5161398649215698  \n","Epoch:23/50     Step:5|6   loss:0.49716293811798096  \n","Epoch:23/50     Step:6|6   loss:0.4968653917312622  \n","Epoch:23/50     Step:7|6   loss:0.5075479745864868  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:93.46%\t train set:99.53%\n","Epoch:24/50     Step:1|6   loss:0.4962286353111267  \n","Epoch:24/50     Step:2|6   loss:0.4965915083885193  \n","Epoch:24/50     Step:3|6   loss:0.5133163928985596  \n","Epoch:24/50     Step:4|6   loss:0.494575560092926  \n","Epoch:24/50     Step:5|6   loss:0.5124157667160034  \n","Epoch:24/50     Step:6|6   loss:0.5012084245681763  \n","Epoch:24/50     Step:7|6   loss:0.5067606568336487  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:25/50     Step:1|6   loss:0.5019826292991638  \n","Epoch:25/50     Step:2|6   loss:0.5103080868721008  \n","Epoch:25/50     Step:3|6   loss:0.5160423517227173  \n","Epoch:25/50     Step:4|6   loss:0.49269795417785645  \n","Epoch:25/50     Step:5|6   loss:0.4963926076889038  \n","Epoch:25/50     Step:6|6   loss:0.49438005685806274  \n","Epoch:25/50     Step:7|6   loss:0.4926554560661316  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:26/50     Step:1|6   loss:0.4935573935508728  \n","Epoch:26/50     Step:2|6   loss:0.5111222267150879  \n","Epoch:26/50     Step:3|6   loss:0.49968212842941284  \n","Epoch:26/50     Step:4|6   loss:0.49936243891716003  \n","Epoch:26/50     Step:5|6   loss:0.49256324768066406  \n","Epoch:26/50     Step:6|6   loss:0.4927985668182373  \n","Epoch:26/50     Step:7|6   loss:0.513360857963562  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:27/50     Step:1|6   loss:0.49278581142425537  \n","Epoch:27/50     Step:2|6   loss:0.5096274614334106  \n","Epoch:27/50     Step:3|6   loss:0.5085902810096741  \n","Epoch:27/50     Step:4|6   loss:0.49200108647346497  \n","Epoch:27/50     Step:5|6   loss:0.49524006247520447  \n","Epoch:27/50     Step:6|6   loss:0.49766814708709717  \n","Epoch:27/50     Step:7|6   loss:0.49299156665802  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:28/50     Step:1|6   loss:0.4931599795818329  \n","Epoch:28/50     Step:2|6   loss:0.4898304343223572  \n","Epoch:28/50     Step:3|6   loss:0.5012165307998657  \n","Epoch:28/50     Step:4|6   loss:0.49702656269073486  \n","Epoch:28/50     Step:5|6   loss:0.48997175693511963  \n","Epoch:28/50     Step:6|6   loss:0.5262030959129333  \n","Epoch:28/50     Step:7|6   loss:0.49259042739868164  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:29/50     Step:1|6   loss:0.4968225359916687  \n","Epoch:29/50     Step:2|6   loss:0.4946596324443817  \n","Epoch:29/50     Step:3|6   loss:0.5232976078987122  \n","Epoch:29/50     Step:4|6   loss:0.49638885259628296  \n","Epoch:29/50     Step:5|6   loss:0.48914533853530884  \n","Epoch:29/50     Step:6|6   loss:0.4916588068008423  \n","Epoch:29/50     Step:7|6   loss:0.48998093605041504  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:30/50     Step:1|6   loss:0.49217256903648376  \n","Epoch:30/50     Step:2|6   loss:0.5239639282226562  \n","Epoch:30/50     Step:3|6   loss:0.49363160133361816  \n","Epoch:30/50     Step:4|6   loss:0.4915742874145508  \n","Epoch:30/50     Step:5|6   loss:0.49100130796432495  \n","Epoch:30/50     Step:6|6   loss:0.48914188146591187  \n","Epoch:30/50     Step:7|6   loss:0.48891904950141907  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:31/50     Step:1|6   loss:0.49120253324508667  \n","Epoch:31/50     Step:2|6   loss:0.504578709602356  \n","Epoch:31/50     Step:3|6   loss:0.4990665316581726  \n","Epoch:31/50     Step:4|6   loss:0.4895879626274109  \n","Epoch:31/50     Step:5|6   loss:0.49085813760757446  \n","Epoch:31/50     Step:6|6   loss:0.4884282946586609  \n","Epoch:31/50     Step:7|6   loss:0.514857292175293  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:32/50     Step:1|6   loss:0.5036580562591553  \n","Epoch:32/50     Step:2|6   loss:0.5101686120033264  \n","Epoch:32/50     Step:3|6   loss:0.49060237407684326  \n","Epoch:32/50     Step:4|6   loss:0.4900408983230591  \n","Epoch:32/50     Step:5|6   loss:0.4889967441558838  \n","Epoch:32/50     Step:6|6   loss:0.4898751974105835  \n","Epoch:32/50     Step:7|6   loss:0.4947451651096344  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:33/50     Step:1|6   loss:0.4897637963294983  \n","Epoch:33/50     Step:2|6   loss:0.49193036556243896  \n","Epoch:33/50     Step:3|6   loss:0.491376131772995  \n","Epoch:33/50     Step:4|6   loss:0.4948175549507141  \n","Epoch:33/50     Step:5|6   loss:0.5038073062896729  \n","Epoch:33/50     Step:6|6   loss:0.5025907754898071  \n","Epoch:33/50     Step:7|6   loss:0.49008315801620483  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:34/50     Step:1|6   loss:0.4885920286178589  \n","Epoch:34/50     Step:2|6   loss:0.49117910861968994  \n","Epoch:34/50     Step:3|6   loss:0.49013566970825195  \n","Epoch:34/50     Step:4|6   loss:0.506588876247406  \n","Epoch:34/50     Step:5|6   loss:0.49204954504966736  \n","Epoch:34/50     Step:6|6   loss:0.5026460886001587  \n","Epoch:34/50     Step:7|6   loss:0.48760557174682617  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:35/50     Step:1|6   loss:0.48946046829223633  \n","Epoch:35/50     Step:2|6   loss:0.4890524744987488  \n","Epoch:35/50     Step:3|6   loss:0.49240580201148987  \n","Epoch:35/50     Step:4|6   loss:0.5021826028823853  \n","Epoch:35/50     Step:5|6   loss:0.5026037096977234  \n","Epoch:35/50     Step:6|6   loss:0.4887080490589142  \n","Epoch:35/50     Step:7|6   loss:0.4953188896179199  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.49011605978012085  \n","Epoch:36/50     Step:2|6   loss:0.48963773250579834  \n","Epoch:36/50     Step:3|6   loss:0.5073921084403992  \n","Epoch:36/50     Step:4|6   loss:0.5028857588768005  \n","Epoch:36/50     Step:5|6   loss:0.48963016271591187  \n","Epoch:36/50     Step:6|6   loss:0.4886287748813629  \n","Epoch:36/50     Step:7|6   loss:0.4881337285041809  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:37/50     Step:1|6   loss:0.49057209491729736  \n","Epoch:37/50     Step:2|6   loss:0.48860010504722595  \n","Epoch:37/50     Step:3|6   loss:0.5036096572875977  \n","Epoch:37/50     Step:4|6   loss:0.48823586106300354  \n","Epoch:37/50     Step:5|6   loss:0.4922332167625427  \n","Epoch:37/50     Step:6|6   loss:0.5026429295539856  \n","Epoch:37/50     Step:7|6   loss:0.4883013963699341  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:38/50     Step:1|6   loss:0.48890864849090576  \n","Epoch:38/50     Step:2|6   loss:0.4874943196773529  \n","Epoch:38/50     Step:3|6   loss:0.48849034309387207  \n","Epoch:38/50     Step:4|6   loss:0.5034297108650208  \n","Epoch:38/50     Step:5|6   loss:0.48865607380867004  \n","Epoch:38/50     Step:6|6   loss:0.48833000659942627  \n","Epoch:38/50     Step:7|6   loss:0.5167984366416931  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:39/50     Step:1|6   loss:0.49939364194869995  \n","Epoch:39/50     Step:2|6   loss:0.4900292158126831  \n","Epoch:39/50     Step:3|6   loss:0.489234983921051  \n","Epoch:39/50     Step:4|6   loss:0.5031648278236389  \n","Epoch:39/50     Step:5|6   loss:0.49479934573173523  \n","Epoch:39/50     Step:6|6   loss:0.48756855726242065  \n","Epoch:39/50     Step:7|6   loss:0.4889584183692932  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:40/50     Step:1|6   loss:0.4898136258125305  \n","Epoch:40/50     Step:2|6   loss:0.4881376028060913  \n","Epoch:40/50     Step:3|6   loss:0.48796704411506653  \n","Epoch:40/50     Step:4|6   loss:0.4919126331806183  \n","Epoch:40/50     Step:5|6   loss:0.49994075298309326  \n","Epoch:40/50     Step:6|6   loss:0.5006219148635864  \n","Epoch:40/50     Step:7|6   loss:0.4883638620376587  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:41/50     Step:1|6   loss:0.5028088092803955  \n","Epoch:41/50     Step:2|6   loss:0.48700881004333496  \n","Epoch:41/50     Step:3|6   loss:0.5027482509613037  \n","Epoch:41/50     Step:4|6   loss:0.48886507749557495  \n","Epoch:41/50     Step:5|6   loss:0.48858508467674255  \n","Epoch:41/50     Step:6|6   loss:0.4871983230113983  \n","Epoch:41/50     Step:7|6   loss:0.4862256944179535  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:42/50     Step:1|6   loss:0.5004462599754333  \n","Epoch:42/50     Step:2|6   loss:0.49069178104400635  \n","Epoch:42/50     Step:3|6   loss:0.5000863075256348  \n","Epoch:42/50     Step:4|6   loss:0.48748427629470825  \n","Epoch:42/50     Step:5|6   loss:0.48796701431274414  \n","Epoch:42/50     Step:6|6   loss:0.4867824912071228  \n","Epoch:42/50     Step:7|6   loss:0.488585501909256  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:43/50     Step:1|6   loss:0.48981624841690063  \n","Epoch:43/50     Step:2|6   loss:0.4881982207298279  \n","Epoch:43/50     Step:3|6   loss:0.5011731386184692  \n","Epoch:43/50     Step:4|6   loss:0.4878498911857605  \n","Epoch:43/50     Step:5|6   loss:0.48739388585090637  \n","Epoch:43/50     Step:6|6   loss:0.4874108135700226  \n","Epoch:43/50     Step:7|6   loss:0.5048977732658386  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:44/50     Step:1|6   loss:0.48748278617858887  \n","Epoch:44/50     Step:2|6   loss:0.4887220859527588  \n","Epoch:44/50     Step:3|6   loss:0.48888519406318665  \n","Epoch:44/50     Step:4|6   loss:0.48739194869995117  \n","Epoch:44/50     Step:5|6   loss:0.5129904747009277  \n","Epoch:44/50     Step:6|6   loss:0.4873594641685486  \n","Epoch:44/50     Step:7|6   loss:0.4858148396015167  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:45/50     Step:1|6   loss:0.499287486076355  \n","Epoch:45/50     Step:2|6   loss:0.4869208335876465  \n","Epoch:45/50     Step:3|6   loss:0.48733651638031006  \n","Epoch:45/50     Step:4|6   loss:0.48661008477211  \n","Epoch:45/50     Step:5|6   loss:0.48690101504325867  \n","Epoch:45/50     Step:6|6   loss:0.4876649081707001  \n","Epoch:45/50     Step:7|6   loss:0.5112940669059753  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:46/50     Step:1|6   loss:0.49965935945510864  \n","Epoch:46/50     Step:2|6   loss:0.4874064028263092  \n","Epoch:46/50     Step:3|6   loss:0.48789945244789124  \n","Epoch:46/50     Step:4|6   loss:0.49887198209762573  \n","Epoch:46/50     Step:5|6   loss:0.4864102303981781  \n","Epoch:46/50     Step:6|6   loss:0.48748546838760376  \n","Epoch:46/50     Step:7|6   loss:0.4913131594657898  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:47/50     Step:1|6   loss:0.5004178285598755  \n","Epoch:47/50     Step:2|6   loss:0.4877447485923767  \n","Epoch:47/50     Step:3|6   loss:0.49993690848350525  \n","Epoch:47/50     Step:4|6   loss:0.49041610956192017  \n","Epoch:47/50     Step:5|6   loss:0.4865878224372864  \n","Epoch:47/50     Step:6|6   loss:0.48700636625289917  \n","Epoch:47/50     Step:7|6   loss:0.4863927662372589  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:48/50     Step:1|6   loss:0.4857620894908905  \n","Epoch:48/50     Step:2|6   loss:0.4864879250526428  \n","Epoch:48/50     Step:3|6   loss:0.48900309205055237  \n","Epoch:48/50     Step:4|6   loss:0.49997347593307495  \n","Epoch:48/50     Step:5|6   loss:0.5020272731781006  \n","Epoch:48/50     Step:6|6   loss:0.4871335029602051  \n","Epoch:48/50     Step:7|6   loss:0.4864557385444641  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:49/50     Step:1|6   loss:0.4998079538345337  \n","Epoch:49/50     Step:2|6   loss:0.5002776980400085  \n","Epoch:49/50     Step:3|6   loss:0.48919233679771423  \n","Epoch:49/50     Step:4|6   loss:0.4865041971206665  \n","Epoch:49/50     Step:5|6   loss:0.4867148697376251  \n","Epoch:49/50     Step:6|6   loss:0.4871389865875244  \n","Epoch:49/50     Step:7|6   loss:0.4870079457759857  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Epoch:50/50     Step:1|6   loss:0.48651060461997986  \n","Epoch:50/50     Step:2|6   loss:0.4881676137447357  \n","Epoch:50/50     Step:3|6   loss:0.4995450973510742  \n","Epoch:50/50     Step:4|6   loss:0.49877026677131653  \n","Epoch:50/50     Step:5|6   loss:0.4868905544281006  \n","Epoch:50/50     Step:6|6   loss:0.48842349648475647  \n","Epoch:50/50     Step:7|6   loss:0.48632898926734924  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:94.39%\t train set:99.53%\n","Accuracy on test_set: 94.39 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_one_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_one_stream(\n","  (feature_extractor_1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (feature_extractor_2): Sequential(\n","    (0): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier_1): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n","  (classifier_2): Sequential(\n","    (0): Linear(in_features=376320, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1079049110412598  \n","Epoch:1/50     Step:2|6   loss:2.473771572113037  \n","Epoch:1/50     Step:3|6   loss:2.1428775787353516  \n","Epoch:1/50     Step:4|6   loss:2.101551055908203  \n","Epoch:1/50     Step:5|6   loss:2.1011528968811035  \n","Epoch:1/50     Step:6|6   loss:1.9878952503204346  \n","Epoch:1/50     Step:7|6   loss:1.6299570798873901  \n","Accuracy on test_set: 66.36 %\n","Accuracy on train_set: 64.17 %\n","current max accuracy\t test set:66.36%\t train set:64.17%\n","Epoch:2/50     Step:1|6   loss:1.5575584173202515  \n","Epoch:2/50     Step:2|6   loss:1.733567714691162  \n","Epoch:2/50     Step:3|6   loss:1.7554545402526855  \n","Epoch:2/50     Step:4|6   loss:1.2544059753417969  \n","Epoch:2/50     Step:5|6   loss:1.058945655822754  \n","Epoch:2/50     Step:6|6   loss:0.8297699689865112  \n","Epoch:2/50     Step:7|6   loss:0.9579507112503052  \n","Accuracy on test_set: 72.90 %\n","Accuracy on train_set: 72.60 %\n","current max accuracy\t test set:72.9%\t train set:72.6%\n","Epoch:3/50     Step:1|6   loss:0.8893528580665588  \n","Epoch:3/50     Step:2|6   loss:0.787295401096344  \n","Epoch:3/50     Step:3|6   loss:0.8061323165893555  \n","Epoch:3/50     Step:4|6   loss:0.8756881356239319  \n","Epoch:3/50     Step:5|6   loss:0.7965060472488403  \n","Epoch:3/50     Step:6|6   loss:0.7582552433013916  \n","Epoch:3/50     Step:7|6   loss:0.7640515565872192  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 88.29 %\n","current max accuracy\t test set:88.79%\t train set:88.29%\n","Epoch:4/50     Step:1|6   loss:0.6845512986183167  \n","Epoch:4/50     Step:2|6   loss:0.7298529148101807  \n","Epoch:4/50     Step:3|6   loss:0.7770476341247559  \n","Epoch:4/50     Step:4|6   loss:0.7693963050842285  \n","Epoch:4/50     Step:5|6   loss:0.6990551948547363  \n","Epoch:4/50     Step:6|6   loss:0.6927008032798767  \n","Epoch:4/50     Step:7|6   loss:0.6765545606613159  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:88.79%\t train set:90.87%\n","Epoch:5/50     Step:1|6   loss:0.6816352605819702  \n","Epoch:5/50     Step:2|6   loss:0.6705634593963623  \n","Epoch:5/50     Step:3|6   loss:0.6508843898773193  \n","Epoch:5/50     Step:4|6   loss:0.652303159236908  \n","Epoch:5/50     Step:5|6   loss:0.6318647861480713  \n","Epoch:5/50     Step:6|6   loss:0.671554446220398  \n","Epoch:5/50     Step:7|6   loss:0.6806867718696594  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:91.59%\t train set:93.21%\n","Epoch:6/50     Step:1|6   loss:0.7125564813613892  \n","Epoch:6/50     Step:2|6   loss:0.6057422161102295  \n","Epoch:6/50     Step:3|6   loss:0.6405531167984009  \n","Epoch:6/50     Step:4|6   loss:0.690725564956665  \n","Epoch:6/50     Step:5|6   loss:0.5669825077056885  \n","Epoch:6/50     Step:6|6   loss:0.5809131860733032  \n","Epoch:6/50     Step:7|6   loss:0.6332963705062866  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.44 %\n","current max accuracy\t test set:91.59%\t train set:93.44%\n","Epoch:7/50     Step:1|6   loss:0.6232373714447021  \n","Epoch:7/50     Step:2|6   loss:0.6279838681221008  \n","Epoch:7/50     Step:3|6   loss:0.5476577281951904  \n","Epoch:7/50     Step:4|6   loss:0.6007237434387207  \n","Epoch:7/50     Step:5|6   loss:0.5912189483642578  \n","Epoch:7/50     Step:6|6   loss:0.6233152747154236  \n","Epoch:7/50     Step:7|6   loss:0.5545970797538757  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:92.52%\t train set:95.32%\n","Epoch:8/50     Step:1|6   loss:0.5575435161590576  \n","Epoch:8/50     Step:2|6   loss:0.549355149269104  \n","Epoch:8/50     Step:3|6   loss:0.6363093256950378  \n","Epoch:8/50     Step:4|6   loss:0.5819672346115112  \n","Epoch:8/50     Step:5|6   loss:0.5834416151046753  \n","Epoch:8/50     Step:6|6   loss:0.6082489490509033  \n","Epoch:8/50     Step:7|6   loss:0.5347104072570801  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.91 %\n","current max accuracy\t test set:92.52%\t train set:95.32%\n","Epoch:9/50     Step:1|6   loss:0.5670337080955505  \n","Epoch:9/50     Step:2|6   loss:0.561900794506073  \n","Epoch:9/50     Step:3|6   loss:0.5769758224487305  \n","Epoch:9/50     Step:4|6   loss:0.5280576944351196  \n","Epoch:9/50     Step:5|6   loss:0.5512220859527588  \n","Epoch:9/50     Step:6|6   loss:0.6170047521591187  \n","Epoch:9/50     Step:7|6   loss:0.6120405197143555  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:93.46%\t train set:96.49%\n","Epoch:10/50     Step:1|6   loss:0.5903910398483276  \n","Epoch:10/50     Step:2|6   loss:0.5362670421600342  \n","Epoch:10/50     Step:3|6   loss:0.5883457064628601  \n","Epoch:10/50     Step:4|6   loss:0.5234875679016113  \n","Epoch:10/50     Step:5|6   loss:0.5182991623878479  \n","Epoch:10/50     Step:6|6   loss:0.5726922154426575  \n","Epoch:10/50     Step:7|6   loss:0.5619592666625977  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:93.46%\t train set:96.49%\n","Epoch:11/50     Step:1|6   loss:0.5862470865249634  \n","Epoch:11/50     Step:2|6   loss:0.5218999981880188  \n","Epoch:11/50     Step:3|6   loss:0.5657402276992798  \n","Epoch:11/50     Step:4|6   loss:0.5555565357208252  \n","Epoch:11/50     Step:5|6   loss:0.5527201890945435  \n","Epoch:11/50     Step:6|6   loss:0.5511687994003296  \n","Epoch:11/50     Step:7|6   loss:0.5058940649032593  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 94.85 %\n","current max accuracy\t test set:93.46%\t train set:96.49%\n","Epoch:12/50     Step:1|6   loss:0.5719155669212341  \n","Epoch:12/50     Step:2|6   loss:0.5474653244018555  \n","Epoch:12/50     Step:3|6   loss:0.5242902636528015  \n","Epoch:12/50     Step:4|6   loss:0.5208712220191956  \n","Epoch:12/50     Step:5|6   loss:0.5281246900558472  \n","Epoch:12/50     Step:6|6   loss:0.5522609949111938  \n","Epoch:12/50     Step:7|6   loss:0.5823854804039001  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:93.46%\t train set:96.49%\n","Epoch:13/50     Step:1|6   loss:0.5242076516151428  \n","Epoch:13/50     Step:2|6   loss:0.5599761009216309  \n","Epoch:13/50     Step:3|6   loss:0.5494334697723389  \n","Epoch:13/50     Step:4|6   loss:0.5440189838409424  \n","Epoch:13/50     Step:5|6   loss:0.5461713671684265  \n","Epoch:13/50     Step:6|6   loss:0.5375826954841614  \n","Epoch:13/50     Step:7|6   loss:0.5738704800605774  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:93.46%\t train set:96.72%\n","Epoch:14/50     Step:1|6   loss:0.5310942530632019  \n","Epoch:14/50     Step:2|6   loss:0.5344796776771545  \n","Epoch:14/50     Step:3|6   loss:0.5350285768508911  \n","Epoch:14/50     Step:4|6   loss:0.5500470995903015  \n","Epoch:14/50     Step:5|6   loss:0.5403538942337036  \n","Epoch:14/50     Step:6|6   loss:0.5128012895584106  \n","Epoch:14/50     Step:7|6   loss:0.5707628726959229  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:93.46%\t train set:96.72%\n","Epoch:15/50     Step:1|6   loss:0.5257708430290222  \n","Epoch:15/50     Step:2|6   loss:0.5518390536308289  \n","Epoch:15/50     Step:3|6   loss:0.5136992931365967  \n","Epoch:15/50     Step:4|6   loss:0.5429463386535645  \n","Epoch:15/50     Step:5|6   loss:0.5423563122749329  \n","Epoch:15/50     Step:6|6   loss:0.5295382142066956  \n","Epoch:15/50     Step:7|6   loss:0.5178272128105164  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:93.46%\t train set:96.72%\n","Epoch:16/50     Step:1|6   loss:0.5086647868156433  \n","Epoch:16/50     Step:2|6   loss:0.5436045527458191  \n","Epoch:16/50     Step:3|6   loss:0.5315750241279602  \n","Epoch:16/50     Step:4|6   loss:0.5141564011573792  \n","Epoch:16/50     Step:5|6   loss:0.5353242754936218  \n","Epoch:16/50     Step:6|6   loss:0.5275866389274597  \n","Epoch:16/50     Step:7|6   loss:0.5436800718307495  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:93.46%\t train set:96.72%\n","Epoch:17/50     Step:1|6   loss:0.5410851836204529  \n","Epoch:17/50     Step:2|6   loss:0.5279182195663452  \n","Epoch:17/50     Step:3|6   loss:0.5425426959991455  \n","Epoch:17/50     Step:4|6   loss:0.5255966186523438  \n","Epoch:17/50     Step:5|6   loss:0.5382047295570374  \n","Epoch:17/50     Step:6|6   loss:0.5150350332260132  \n","Epoch:17/50     Step:7|6   loss:0.49040430784225464  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:18/50     Step:1|6   loss:0.5491439700126648  \n","Epoch:18/50     Step:2|6   loss:0.5185889601707458  \n","Epoch:18/50     Step:3|6   loss:0.5112836360931396  \n","Epoch:18/50     Step:4|6   loss:0.5402119159698486  \n","Epoch:18/50     Step:5|6   loss:0.5095339417457581  \n","Epoch:18/50     Step:6|6   loss:0.5245550870895386  \n","Epoch:18/50     Step:7|6   loss:0.5389712452888489  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:19/50     Step:1|6   loss:0.5089302659034729  \n","Epoch:19/50     Step:2|6   loss:0.49290087819099426  \n","Epoch:19/50     Step:3|6   loss:0.5335977077484131  \n","Epoch:19/50     Step:4|6   loss:0.5526226162910461  \n","Epoch:19/50     Step:5|6   loss:0.505662202835083  \n","Epoch:19/50     Step:6|6   loss:0.5394970774650574  \n","Epoch:19/50     Step:7|6   loss:0.5383790731430054  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:20/50     Step:1|6   loss:0.536865770816803  \n","Epoch:20/50     Step:2|6   loss:0.5224043726921082  \n","Epoch:20/50     Step:3|6   loss:0.49230313301086426  \n","Epoch:20/50     Step:4|6   loss:0.5237090587615967  \n","Epoch:20/50     Step:5|6   loss:0.5207744836807251  \n","Epoch:20/50     Step:6|6   loss:0.5254653096199036  \n","Epoch:20/50     Step:7|6   loss:0.5444113612174988  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:21/50     Step:1|6   loss:0.5215068459510803  \n","Epoch:21/50     Step:2|6   loss:0.5511157512664795  \n","Epoch:21/50     Step:3|6   loss:0.5082635879516602  \n","Epoch:21/50     Step:4|6   loss:0.5341023206710815  \n","Epoch:21/50     Step:5|6   loss:0.5133806467056274  \n","Epoch:21/50     Step:6|6   loss:0.5063021779060364  \n","Epoch:21/50     Step:7|6   loss:0.51225745677948  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:22/50     Step:1|6   loss:0.5494563579559326  \n","Epoch:22/50     Step:2|6   loss:0.4888816773891449  \n","Epoch:22/50     Step:3|6   loss:0.505496621131897  \n","Epoch:22/50     Step:4|6   loss:0.5380849242210388  \n","Epoch:22/50     Step:5|6   loss:0.5346862077713013  \n","Epoch:22/50     Step:6|6   loss:0.513160765171051  \n","Epoch:22/50     Step:7|6   loss:0.5111599564552307  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:23/50     Step:1|6   loss:0.4895003139972687  \n","Epoch:23/50     Step:2|6   loss:0.521393358707428  \n","Epoch:23/50     Step:3|6   loss:0.5050835609436035  \n","Epoch:23/50     Step:4|6   loss:0.5178229212760925  \n","Epoch:23/50     Step:5|6   loss:0.5188759565353394  \n","Epoch:23/50     Step:6|6   loss:0.5638249516487122  \n","Epoch:23/50     Step:7|6   loss:0.5233012437820435  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:24/50     Step:1|6   loss:0.4907618761062622  \n","Epoch:24/50     Step:2|6   loss:0.5481922030448914  \n","Epoch:24/50     Step:3|6   loss:0.5760264992713928  \n","Epoch:24/50     Step:4|6   loss:0.5089714527130127  \n","Epoch:24/50     Step:5|6   loss:0.5199804902076721  \n","Epoch:24/50     Step:6|6   loss:0.48942553997039795  \n","Epoch:24/50     Step:7|6   loss:0.49047619104385376  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:25/50     Step:1|6   loss:0.48927807807922363  \n","Epoch:25/50     Step:2|6   loss:0.5025468468666077  \n","Epoch:25/50     Step:3|6   loss:0.5593568682670593  \n","Epoch:25/50     Step:4|6   loss:0.5210304260253906  \n","Epoch:25/50     Step:5|6   loss:0.5373044610023499  \n","Epoch:25/50     Step:6|6   loss:0.4911874532699585  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch:25/50     Step:7|6   loss:0.5337345600128174  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:26/50     Step:1|6   loss:0.5174496173858643  \n","Epoch:26/50     Step:2|6   loss:0.518671989440918  \n","Epoch:26/50     Step:3|6   loss:0.48872774839401245  \n","Epoch:26/50     Step:4|6   loss:0.546807050704956  \n","Epoch:26/50     Step:5|6   loss:0.5212997794151306  \n","Epoch:26/50     Step:6|6   loss:0.5179481506347656  \n","Epoch:26/50     Step:7|6   loss:0.511195182800293  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:27/50     Step:1|6   loss:0.536239743232727  \n","Epoch:27/50     Step:2|6   loss:0.5045648813247681  \n","Epoch:27/50     Step:3|6   loss:0.48755112290382385  \n","Epoch:27/50     Step:4|6   loss:0.5601552724838257  \n","Epoch:27/50     Step:5|6   loss:0.5028546452522278  \n","Epoch:27/50     Step:6|6   loss:0.5023220181465149  \n","Epoch:27/50     Step:7|6   loss:0.5306804180145264  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:28/50     Step:1|6   loss:0.5435097217559814  \n","Epoch:28/50     Step:2|6   loss:0.5017380714416504  \n","Epoch:28/50     Step:3|6   loss:0.49434894323349  \n","Epoch:28/50     Step:4|6   loss:0.5017903447151184  \n","Epoch:28/50     Step:5|6   loss:0.5176427960395813  \n","Epoch:28/50     Step:6|6   loss:0.5012716054916382  \n","Epoch:28/50     Step:7|6   loss:0.5739855170249939  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:29/50     Step:1|6   loss:0.5281891822814941  \n","Epoch:29/50     Step:2|6   loss:0.48827123641967773  \n","Epoch:29/50     Step:3|6   loss:0.5436843633651733  \n","Epoch:29/50     Step:4|6   loss:0.48897284269332886  \n","Epoch:29/50     Step:5|6   loss:0.48790663480758667  \n","Epoch:29/50     Step:6|6   loss:0.5104355216026306  \n","Epoch:29/50     Step:7|6   loss:0.5866008400917053  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:30/50     Step:1|6   loss:0.5158304572105408  \n","Epoch:30/50     Step:2|6   loss:0.5141490697860718  \n","Epoch:30/50     Step:3|6   loss:0.5150654315948486  \n","Epoch:30/50     Step:4|6   loss:0.514738917350769  \n","Epoch:30/50     Step:5|6   loss:0.5207237601280212  \n","Epoch:30/50     Step:6|6   loss:0.5294486284255981  \n","Epoch:30/50     Step:7|6   loss:0.48808562755584717  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:31/50     Step:1|6   loss:0.5035975575447083  \n","Epoch:31/50     Step:2|6   loss:0.5160213112831116  \n","Epoch:31/50     Step:3|6   loss:0.48818591237068176  \n","Epoch:31/50     Step:4|6   loss:0.5256640315055847  \n","Epoch:31/50     Step:5|6   loss:0.5276391506195068  \n","Epoch:31/50     Step:6|6   loss:0.513624370098114  \n","Epoch:31/50     Step:7|6   loss:0.5339818596839905  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:32/50     Step:1|6   loss:0.528982400894165  \n","Epoch:32/50     Step:2|6   loss:0.5171843767166138  \n","Epoch:32/50     Step:3|6   loss:0.513116180896759  \n","Epoch:32/50     Step:4|6   loss:0.5009769201278687  \n","Epoch:32/50     Step:5|6   loss:0.5283365845680237  \n","Epoch:32/50     Step:6|6   loss:0.514258861541748  \n","Epoch:32/50     Step:7|6   loss:0.4872003197669983  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:33/50     Step:1|6   loss:0.5373706817626953  \n","Epoch:33/50     Step:2|6   loss:0.5150254964828491  \n","Epoch:33/50     Step:3|6   loss:0.5005853176116943  \n","Epoch:33/50     Step:4|6   loss:0.5006731152534485  \n","Epoch:33/50     Step:5|6   loss:0.5125897526741028  \n","Epoch:33/50     Step:6|6   loss:0.5034968256950378  \n","Epoch:33/50     Step:7|6   loss:0.530321478843689  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:34/50     Step:1|6   loss:0.5011978149414062  \n","Epoch:34/50     Step:2|6   loss:0.5247070789337158  \n","Epoch:34/50     Step:3|6   loss:0.5285824537277222  \n","Epoch:34/50     Step:4|6   loss:0.5003873109817505  \n","Epoch:34/50     Step:5|6   loss:0.5114294290542603  \n","Epoch:34/50     Step:6|6   loss:0.5039182901382446  \n","Epoch:34/50     Step:7|6   loss:0.5235324501991272  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:35/50     Step:1|6   loss:0.5242445468902588  \n","Epoch:35/50     Step:2|6   loss:0.5110021829605103  \n","Epoch:35/50     Step:3|6   loss:0.48931246995925903  \n","Epoch:35/50     Step:4|6   loss:0.5234017372131348  \n","Epoch:35/50     Step:5|6   loss:0.5240578055381775  \n","Epoch:35/50     Step:6|6   loss:0.48732778429985046  \n","Epoch:35/50     Step:7|6   loss:0.5345040559768677  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:36/50     Step:1|6   loss:0.5223602652549744  \n","Epoch:36/50     Step:2|6   loss:0.5115978717803955  \n","Epoch:36/50     Step:3|6   loss:0.49902868270874023  \n","Epoch:36/50     Step:4|6   loss:0.5383618474006653  \n","Epoch:36/50     Step:5|6   loss:0.5025184154510498  \n","Epoch:36/50     Step:6|6   loss:0.5138713717460632  \n","Epoch:36/50     Step:7|6   loss:0.48703259229660034  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:37/50     Step:1|6   loss:0.48667675256729126  \n","Epoch:37/50     Step:2|6   loss:0.48810797929763794  \n","Epoch:37/50     Step:3|6   loss:0.5167312026023865  \n","Epoch:37/50     Step:4|6   loss:0.5137782096862793  \n","Epoch:37/50     Step:5|6   loss:0.5318207740783691  \n","Epoch:37/50     Step:6|6   loss:0.5325438976287842  \n","Epoch:37/50     Step:7|6   loss:0.5045692920684814  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:38/50     Step:1|6   loss:0.4900130033493042  \n","Epoch:38/50     Step:2|6   loss:0.5272922515869141  \n","Epoch:38/50     Step:3|6   loss:0.5088093876838684  \n","Epoch:38/50     Step:4|6   loss:0.5227253437042236  \n","Epoch:38/50     Step:5|6   loss:0.5094296932220459  \n","Epoch:38/50     Step:6|6   loss:0.49807173013687134  \n","Epoch:38/50     Step:7|6   loss:0.518513023853302  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:39/50     Step:1|6   loss:0.5100507736206055  \n","Epoch:39/50     Step:2|6   loss:0.5005488991737366  \n","Epoch:39/50     Step:3|6   loss:0.5338228344917297  \n","Epoch:39/50     Step:4|6   loss:0.5290839672088623  \n","Epoch:39/50     Step:5|6   loss:0.5011537671089172  \n","Epoch:39/50     Step:6|6   loss:0.4988941252231598  \n","Epoch:39/50     Step:7|6   loss:0.4861903786659241  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:40/50     Step:1|6   loss:0.5109213590621948  \n","Epoch:40/50     Step:2|6   loss:0.5241496562957764  \n","Epoch:40/50     Step:3|6   loss:0.48759493231773376  \n","Epoch:40/50     Step:4|6   loss:0.49750155210494995  \n","Epoch:40/50     Step:5|6   loss:0.5177217125892639  \n","Epoch:40/50     Step:6|6   loss:0.5071841478347778  \n","Epoch:40/50     Step:7|6   loss:0.516990065574646  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:41/50     Step:1|6   loss:0.4970599412918091  \n","Epoch:41/50     Step:2|6   loss:0.5070492029190063  \n","Epoch:41/50     Step:3|6   loss:0.5305008292198181  \n","Epoch:41/50     Step:4|6   loss:0.5201364755630493  \n","Epoch:41/50     Step:5|6   loss:0.4869646430015564  \n","Epoch:41/50     Step:6|6   loss:0.506538987159729  \n","Epoch:41/50     Step:7|6   loss:0.5064038634300232  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:42/50     Step:1|6   loss:0.4974554777145386  \n","Epoch:42/50     Step:2|6   loss:0.4971490502357483  \n","Epoch:42/50     Step:3|6   loss:0.5160036683082581  \n","Epoch:42/50     Step:4|6   loss:0.5096653699874878  \n","Epoch:42/50     Step:5|6   loss:0.5269837379455566  \n","Epoch:42/50     Step:6|6   loss:0.5017094612121582  \n","Epoch:42/50     Step:7|6   loss:0.501126766204834  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:43/50     Step:1|6   loss:0.506020188331604  \n","Epoch:43/50     Step:2|6   loss:0.4982694983482361  \n","Epoch:43/50     Step:3|6   loss:0.5304568409919739  \n","Epoch:43/50     Step:4|6   loss:0.4864792227745056  \n","Epoch:43/50     Step:5|6   loss:0.5066007375717163  \n","Epoch:43/50     Step:6|6   loss:0.5189226865768433  \n","Epoch:43/50     Step:7|6   loss:0.5005898475646973  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:44/50     Step:1|6   loss:0.5150872468948364  \n","Epoch:44/50     Step:2|6   loss:0.520487368106842  \n","Epoch:44/50     Step:3|6   loss:0.49590492248535156  \n","Epoch:44/50     Step:4|6   loss:0.48838067054748535  \n","Epoch:44/50     Step:5|6   loss:0.505254328250885  \n","Epoch:44/50     Step:6|6   loss:0.500156581401825  \n","Epoch:44/50     Step:7|6   loss:0.5285542607307434  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:45/50     Step:1|6   loss:0.5146694183349609  \n","Epoch:45/50     Step:2|6   loss:0.5102798938751221  \n","Epoch:45/50     Step:3|6   loss:0.4971887469291687  \n","Epoch:45/50     Step:4|6   loss:0.5055080652236938  \n","Epoch:45/50     Step:5|6   loss:0.5183160901069641  \n","Epoch:45/50     Step:6|6   loss:0.4865874648094177  \n","Epoch:45/50     Step:7|6   loss:0.5143516659736633  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:46/50     Step:1|6   loss:0.5046166181564331  \n","Epoch:46/50     Step:2|6   loss:0.49066638946533203  \n","Epoch:46/50     Step:3|6   loss:0.5168259143829346  \n","Epoch:46/50     Step:4|6   loss:0.5076924562454224  \n","Epoch:46/50     Step:5|6   loss:0.5234023332595825  \n","Epoch:46/50     Step:6|6   loss:0.49692103266716003  \n","Epoch:46/50     Step:7|6   loss:0.4997325539588928  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:47/50     Step:1|6   loss:0.5152661800384521  \n","Epoch:47/50     Step:2|6   loss:0.5050207376480103  \n","Epoch:47/50     Step:3|6   loss:0.49551403522491455  \n","Epoch:47/50     Step:4|6   loss:0.5045379996299744  \n","Epoch:47/50     Step:5|6   loss:0.4984780251979828  \n","Epoch:47/50     Step:6|6   loss:0.5181357264518738  \n","Epoch:47/50     Step:7|6   loss:0.4994155466556549  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:48/50     Step:1|6   loss:0.4954853653907776  \n","Epoch:48/50     Step:2|6   loss:0.5130637884140015  \n","Epoch:48/50     Step:3|6   loss:0.5149070620536804  \n","Epoch:48/50     Step:4|6   loss:0.5046106576919556  \n","Epoch:48/50     Step:5|6   loss:0.5044904351234436  \n","Epoch:48/50     Step:6|6   loss:0.5078304409980774  \n","Epoch:48/50     Step:7|6   loss:0.48961886763572693  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:94.39%\t train set:96.96%\n","Epoch:49/50     Step:1|6   loss:0.49582648277282715  \n","Epoch:49/50     Step:2|6   loss:0.4949556589126587  \n","Epoch:49/50     Step:3|6   loss:0.5022609829902649  \n","Epoch:49/50     Step:4|6   loss:0.5069835186004639  \n","Epoch:49/50     Step:5|6   loss:0.5145760774612427  \n","Epoch:49/50     Step:6|6   loss:0.5083492994308472  \n","Epoch:49/50     Step:7|6   loss:0.49615952372550964  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:94.39%\t train set:97.66%\n","Epoch:50/50     Step:1|6   loss:0.5062997341156006  \n","Epoch:50/50     Step:2|6   loss:0.49181464314460754  \n","Epoch:50/50     Step:3|6   loss:0.5068387985229492  \n","Epoch:50/50     Step:4|6   loss:0.48887330293655396  \n","Epoch:50/50     Step:5|6   loss:0.4881713390350342  \n","Epoch:50/50     Step:6|6   loss:0.5152425169944763  \n","Epoch:50/50     Step:7|6   loss:0.5170969367027283  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:94.39%\t train set:98.83%\n","Accuracy on test_set: 91.59 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model LeNet5_one_stream --mode both --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":18,"id":"622e472c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_two_stream(\n","  (stream1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (stream2): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=752640, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1040074825286865  \n","Epoch:1/50     Step:2|6   loss:2.4838509559631348  \n","Epoch:1/50     Step:3|6   loss:2.8894731998443604  \n","Epoch:1/50     Step:4|6   loss:2.735914468765259  \n","Epoch:1/50     Step:5|6   loss:2.5234322547912598  \n","Epoch:1/50     Step:6|6   loss:2.8309662342071533  \n","Epoch:1/50     Step:7|6   loss:2.779491901397705  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:2/50     Step:1|6   loss:2.371088743209839  \n","Epoch:2/50     Step:2|6   loss:2.9210455417633057  \n","Epoch:2/50     Step:3|6   loss:2.674199104309082  \n","Epoch:2/50     Step:4|6   loss:2.841771125793457  \n","Epoch:2/50     Step:5|6   loss:2.8037049770355225  \n","Epoch:2/50     Step:6|6   loss:2.6846425533294678  \n","Epoch:2/50     Step:7|6   loss:2.539215564727783  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:3/50     Step:1|6   loss:2.5497825145721436  \n","Epoch:3/50     Step:2|6   loss:2.475661277770996  \n","Epoch:3/50     Step:3|6   loss:2.562166213989258  \n","Epoch:3/50     Step:4|6   loss:2.6770362854003906  \n","Epoch:3/50     Step:5|6   loss:2.4596946239471436  \n","Epoch:3/50     Step:6|6   loss:2.6544528007507324  \n","Epoch:3/50     Step:7|6   loss:3.2351510524749756  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:4/50     Step:1|6   loss:2.9917242527008057  \n","Epoch:4/50     Step:2|6   loss:2.4552180767059326  \n","Epoch:4/50     Step:3|6   loss:2.362785816192627  \n","Epoch:4/50     Step:4|6   loss:2.57904314994812  \n","Epoch:4/50     Step:5|6   loss:2.721900701522827  \n","Epoch:4/50     Step:6|6   loss:2.31441330909729  \n","Epoch:4/50     Step:7|6   loss:2.4150965213775635  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:5/50     Step:1|6   loss:2.496683120727539  \n","Epoch:5/50     Step:2|6   loss:2.310007095336914  \n","Epoch:5/50     Step:3|6   loss:2.5841002464294434  \n","Epoch:5/50     Step:4|6   loss:2.604890823364258  \n","Epoch:5/50     Step:5|6   loss:2.551926374435425  \n","Epoch:5/50     Step:6|6   loss:2.5708279609680176  \n","Epoch:5/50     Step:7|6   loss:2.883690357208252  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:6/50     Step:1|6   loss:2.4421608448028564  \n","Epoch:6/50     Step:2|6   loss:2.882931709289551  \n","Epoch:6/50     Step:3|6   loss:2.0919084548950195  \n","Epoch:6/50     Step:4|6   loss:2.3339037895202637  \n","Epoch:6/50     Step:5|6   loss:2.2071502208709717  \n","Epoch:6/50     Step:6|6   loss:2.6349377632141113  \n","Epoch:6/50     Step:7|6   loss:2.4881298542022705  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:7/50     Step:1|6   loss:2.8921446800231934  \n","Epoch:7/50     Step:2|6   loss:2.1838555335998535  \n","Epoch:7/50     Step:3|6   loss:2.3736958503723145  \n","Epoch:7/50     Step:4|6   loss:2.35237717628479  \n","Epoch:7/50     Step:5|6   loss:2.1972591876983643  \n","Epoch:7/50     Step:6|6   loss:2.2042243480682373  \n","Epoch:7/50     Step:7|6   loss:2.53658390045166  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:8/50     Step:1|6   loss:2.62188720703125  \n","Epoch:8/50     Step:2|6   loss:2.511601209640503  \n","Epoch:8/50     Step:3|6   loss:2.3747715950012207  \n","Epoch:8/50     Step:4|6   loss:2.514263868331909  \n","Epoch:8/50     Step:5|6   loss:1.9720555543899536  \n","Epoch:8/50     Step:6|6   loss:2.1425981521606445  \n","Epoch:8/50     Step:7|6   loss:2.244889259338379  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:9/50     Step:1|6   loss:2.1439437866210938  \n","Epoch:9/50     Step:2|6   loss:2.2610321044921875  \n","Epoch:9/50     Step:3|6   loss:2.5836691856384277  \n","Epoch:9/50     Step:4|6   loss:2.055084228515625  \n","Epoch:9/50     Step:5|6   loss:2.6289854049682617  \n","Epoch:9/50     Step:6|6   loss:1.9330456256866455  \n","Epoch:9/50     Step:7|6   loss:2.3775317668914795  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:10/50     Step:1|6   loss:1.9388211965560913  \n","Epoch:10/50     Step:2|6   loss:2.2921032905578613  \n","Epoch:10/50     Step:3|6   loss:2.4259181022644043  \n","Epoch:10/50     Step:4|6   loss:2.1616530418395996  \n","Epoch:10/50     Step:5|6   loss:2.332692861557007  \n","Epoch:10/50     Step:6|6   loss:2.1721253395080566  \n","Epoch:10/50     Step:7|6   loss:2.202181577682495  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:11/50     Step:1|6   loss:2.002074718475342  \n","Epoch:11/50     Step:2|6   loss:2.5605287551879883  \n","Epoch:11/50     Step:3|6   loss:1.9074158668518066  \n","Epoch:11/50     Step:4|6   loss:2.27359676361084  \n","Epoch:11/50     Step:5|6   loss:2.278073787689209  \n","Epoch:11/50     Step:6|6   loss:2.110894203186035  \n","Epoch:11/50     Step:7|6   loss:1.8670668601989746  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:12/50     Step:1|6   loss:2.0895509719848633  \n","Epoch:12/50     Step:2|6   loss:2.0107030868530273  \n","Epoch:12/50     Step:3|6   loss:2.3037679195404053  \n","Epoch:12/50     Step:4|6   loss:2.0109355449676514  \n","Epoch:12/50     Step:5|6   loss:2.0103349685668945  \n","Epoch:12/50     Step:6|6   loss:2.137787342071533  \n","Epoch:12/50     Step:7|6   loss:2.2814135551452637  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:13/50     Step:1|6   loss:2.2676687240600586  \n","Epoch:13/50     Step:2|6   loss:1.9817627668380737  \n","Epoch:13/50     Step:3|6   loss:1.9123892784118652  \n","Epoch:13/50     Step:4|6   loss:2.008944511413574  \n","Epoch:13/50     Step:5|6   loss:2.097787380218506  \n","Epoch:13/50     Step:6|6   loss:2.0691864490509033  \n","Epoch:13/50     Step:7|6   loss:2.1799957752227783  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:14/50     Step:1|6   loss:1.6569569110870361  \n","Epoch:14/50     Step:2|6   loss:1.9107666015625  \n","Epoch:14/50     Step:3|6   loss:2.252150535583496  \n","Epoch:14/50     Step:4|6   loss:2.24558424949646  \n","Epoch:14/50     Step:5|6   loss:1.9444425106048584  \n","Epoch:14/50     Step:6|6   loss:1.9466230869293213  \n","Epoch:14/50     Step:7|6   loss:2.0546700954437256  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:15/50     Step:1|6   loss:1.9428431987762451  \n","Epoch:15/50     Step:2|6   loss:2.0470826625823975  \n","Epoch:15/50     Step:3|6   loss:2.2513628005981445  \n","Epoch:15/50     Step:4|6   loss:2.002899169921875  \n","Epoch:15/50     Step:5|6   loss:1.911167025566101  \n","Epoch:15/50     Step:6|6   loss:1.7524070739746094  \n","Epoch:15/50     Step:7|6   loss:1.9759738445281982  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:16/50     Step:1|6   loss:2.0156710147857666  \n","Epoch:16/50     Step:2|6   loss:1.8617855310440063  \n","Epoch:16/50     Step:3|6   loss:1.747597336769104  \n","Epoch:16/50     Step:4|6   loss:2.0176732540130615  \n","Epoch:16/50     Step:5|6   loss:2.0895323753356934  \n","Epoch:16/50     Step:6|6   loss:1.9635417461395264  \n","Epoch:16/50     Step:7|6   loss:1.9702163934707642  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:17/50     Step:1|6   loss:1.943009614944458  \n","Epoch:17/50     Step:2|6   loss:1.6932342052459717  \n","Epoch:17/50     Step:3|6   loss:2.003214120864868  \n","Epoch:17/50     Step:4|6   loss:1.9372317790985107  \n","Epoch:17/50     Step:5|6   loss:1.8843340873718262  \n","Epoch:17/50     Step:6|6   loss:1.9445818662643433  \n","Epoch:17/50     Step:7|6   loss:1.921331524848938  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:18/50     Step:1|6   loss:1.7572215795516968  \n","Epoch:18/50     Step:2|6   loss:1.9504776000976562  \n","Epoch:18/50     Step:3|6   loss:1.995861291885376  \n","Epoch:18/50     Step:4|6   loss:1.713449478149414  \n","Epoch:18/50     Step:5|6   loss:1.9374839067459106  \n","Epoch:18/50     Step:6|6   loss:1.6983990669250488  \n","Epoch:18/50     Step:7|6   loss:1.6443084478378296  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:19/50     Step:1|6   loss:1.4865384101867676  \n","Epoch:19/50     Step:2|6   loss:1.7765995264053345  \n","Epoch:19/50     Step:3|6   loss:1.903631567955017  \n","Epoch:19/50     Step:4|6   loss:1.6917476654052734  \n","Epoch:19/50     Step:5|6   loss:2.06772780418396  \n","Epoch:19/50     Step:6|6   loss:1.764859676361084  \n","Epoch:19/50     Step:7|6   loss:1.9743461608886719  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:20/50     Step:1|6   loss:1.7499208450317383  \n","Epoch:20/50     Step:2|6   loss:1.5386250019073486  \n","Epoch:20/50     Step:3|6   loss:1.6946768760681152  \n","Epoch:20/50     Step:4|6   loss:1.8655908107757568  \n","Epoch:20/50     Step:5|6   loss:1.7543931007385254  \n","Epoch:20/50     Step:6|6   loss:1.8739064931869507  \n","Epoch:20/50     Step:7|6   loss:1.8338608741760254  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:21/50     Step:1|6   loss:1.7309101819992065  \n","Epoch:21/50     Step:2|6   loss:1.9147239923477173  \n","Epoch:21/50     Step:3|6   loss:1.746595859527588  \n","Epoch:21/50     Step:4|6   loss:1.5920804738998413  \n","Epoch:21/50     Step:5|6   loss:1.7504298686981201  \n","Epoch:21/50     Step:6|6   loss:1.616706371307373  \n","Epoch:21/50     Step:7|6   loss:1.5564615726470947  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:22/50     Step:1|6   loss:1.7595945596694946  \n","Epoch:22/50     Step:2|6   loss:1.7060341835021973  \n","Epoch:22/50     Step:3|6   loss:1.5536472797393799  \n","Epoch:22/50     Step:4|6   loss:1.8699920177459717  \n","Epoch:22/50     Step:5|6   loss:1.6247615814208984  \n","Epoch:22/50     Step:6|6   loss:1.6350462436676025  \n","Epoch:22/50     Step:7|6   loss:1.7488319873809814  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:23/50     Step:1|6   loss:1.7165114879608154  \n","Epoch:23/50     Step:2|6   loss:1.8100613355636597  \n","Epoch:23/50     Step:3|6   loss:1.532450556755066  \n","Epoch:23/50     Step:4|6   loss:1.6262261867523193  \n","Epoch:23/50     Step:5|6   loss:1.6684622764587402  \n","Epoch:23/50     Step:6|6   loss:1.498788833618164  \n","Epoch:23/50     Step:7|6   loss:1.8591526746749878  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:24/50     Step:1|6   loss:1.6354598999023438  \n","Epoch:24/50     Step:2|6   loss:1.6409296989440918  \n","Epoch:24/50     Step:3|6   loss:1.6349258422851562  \n","Epoch:24/50     Step:4|6   loss:1.4665549993515015  \n","Epoch:24/50     Step:5|6   loss:1.8109040260314941  \n","Epoch:24/50     Step:6|6   loss:1.6736823320388794  \n","Epoch:24/50     Step:7|6   loss:1.5259655714035034  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:25/50     Step:1|6   loss:1.7277659177780151  \n","Epoch:25/50     Step:2|6   loss:1.3018765449523926  \n","Epoch:25/50     Step:3|6   loss:1.7382420301437378  \n","Epoch:25/50     Step:4|6   loss:1.7027835845947266  \n","Epoch:25/50     Step:5|6   loss:1.7178548574447632  \n","Epoch:25/50     Step:6|6   loss:1.363379955291748  \n","Epoch:25/50     Step:7|6   loss:1.6318566799163818  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:26/50     Step:1|6   loss:1.5662096738815308  \n","Epoch:26/50     Step:2|6   loss:1.5328950881958008  \n","Epoch:26/50     Step:3|6   loss:1.645045280456543  \n","Epoch:26/50     Step:4|6   loss:1.465858817100525  \n","Epoch:26/50     Step:5|6   loss:1.7116516828536987  \n","Epoch:26/50     Step:6|6   loss:1.604641079902649  \n","Epoch:26/50     Step:7|6   loss:1.5005543231964111  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:27/50     Step:1|6   loss:1.6469647884368896  \n","Epoch:27/50     Step:2|6   loss:1.4739326238632202  \n","Epoch:27/50     Step:3|6   loss:1.5787361860275269  \n","Epoch:27/50     Step:4|6   loss:1.598883867263794  \n","Epoch:27/50     Step:5|6   loss:1.389007806777954  \n","Epoch:27/50     Step:6|6   loss:1.4894814491271973  \n","Epoch:27/50     Step:7|6   loss:1.5542480945587158  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:28/50     Step:1|6   loss:1.6482951641082764  \n","Epoch:28/50     Step:2|6   loss:1.8579188585281372  1\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:28/50     Step:3|6   loss:1.436812400817871  \n","Epoch:28/50     Step:4|6   loss:1.4063923358917236  \n","Epoch:28/50     Step:5|6   loss:1.4456887245178223  \n","Epoch:28/50     Step:6|6   loss:1.450934648513794  \n","Epoch:28/50     Step:7|6   loss:1.5147311687469482  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:29/50     Step:1|6   loss:1.4755860567092896  \n","Epoch:29/50     Step:2|6   loss:1.3686847686767578  \n","Epoch:29/50     Step:3|6   loss:1.5181158781051636  \n","Epoch:29/50     Step:4|6   loss:1.7278125286102295  \n","Epoch:29/50     Step:5|6   loss:1.16621994972229  \n","Epoch:29/50     Step:6|6   loss:1.4803900718688965  \n","Epoch:29/50     Step:7|6   loss:1.3924531936645508  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:30/50     Step:1|6   loss:1.5240181684494019  \n","Epoch:30/50     Step:2|6   loss:1.5297993421554565  \n","Epoch:30/50     Step:3|6   loss:1.4686799049377441  \n","Epoch:30/50     Step:4|6   loss:1.4070241451263428  \n","Epoch:30/50     Step:5|6   loss:1.380165934562683  \n","Epoch:30/50     Step:6|6   loss:1.3854900598526  \n","Epoch:30/50     Step:7|6   loss:1.6100553274154663  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:31/50     Step:1|6   loss:1.4054609537124634  \n","Epoch:31/50     Step:2|6   loss:1.4150117635726929  \n","Epoch:31/50     Step:3|6   loss:1.5001227855682373  \n","Epoch:31/50     Step:4|6   loss:1.4062721729278564  \n","Epoch:31/50     Step:5|6   loss:1.522128939628601  \n","Epoch:31/50     Step:6|6   loss:1.5799156427383423  \n","Epoch:31/50     Step:7|6   loss:1.342871904373169  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:32/50     Step:1|6   loss:1.4244635105133057  \n","Epoch:32/50     Step:2|6   loss:1.5957947969436646  \n","Epoch:32/50     Step:3|6   loss:1.1805788278579712  \n","Epoch:32/50     Step:4|6   loss:1.539519190788269  \n","Epoch:32/50     Step:5|6   loss:1.5692142248153687  \n","Epoch:32/50     Step:6|6   loss:1.468762993812561  \n","Epoch:32/50     Step:7|6   loss:1.3141839504241943  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:33/50     Step:1|6   loss:1.3198344707489014  \n","Epoch:33/50     Step:2|6   loss:1.3621392250061035  \n","Epoch:33/50     Step:3|6   loss:1.4453301429748535  \n","Epoch:33/50     Step:4|6   loss:1.4734978675842285  \n","Epoch:33/50     Step:5|6   loss:1.6333096027374268  \n","Epoch:33/50     Step:6|6   loss:1.2592496871948242  \n","Epoch:33/50     Step:7|6   loss:1.3485661745071411  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:34/50     Step:1|6   loss:1.3163025379180908  \n","Epoch:34/50     Step:2|6   loss:1.1908289194107056  \n","Epoch:34/50     Step:3|6   loss:1.5704293251037598  \n","Epoch:34/50     Step:4|6   loss:1.351263165473938  \n","Epoch:34/50     Step:5|6   loss:1.5072505474090576  \n","Epoch:34/50     Step:6|6   loss:1.3822472095489502  \n","Epoch:34/50     Step:7|6   loss:1.5106027126312256  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:35/50     Step:1|6   loss:1.4959862232208252  \n","Epoch:35/50     Step:2|6   loss:1.2771550416946411  \n","Epoch:35/50     Step:3|6   loss:1.3179278373718262  \n","Epoch:35/50     Step:4|6   loss:1.6567957401275635  \n","Epoch:35/50     Step:5|6   loss:1.2777819633483887  \n","Epoch:35/50     Step:6|6   loss:1.2679027318954468  \n","Epoch:35/50     Step:7|6   loss:1.3588192462921143  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:36/50     Step:1|6   loss:1.201073169708252  \n","Epoch:36/50     Step:2|6   loss:1.3897616863250732  \n","Epoch:36/50     Step:3|6   loss:1.3925806283950806  \n","Epoch:36/50     Step:4|6   loss:1.2098697423934937  \n","Epoch:36/50     Step:5|6   loss:1.321138858795166  \n","Epoch:36/50     Step:6|6   loss:1.2927277088165283  \n","Epoch:36/50     Step:7|6   loss:1.453320860862732  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:37/50     Step:1|6   loss:1.3408026695251465  \n","Epoch:37/50     Step:2|6   loss:1.3803248405456543  \n","Epoch:37/50     Step:3|6   loss:1.3257681131362915  \n","Epoch:37/50     Step:4|6   loss:1.279306411743164  \n","Epoch:37/50     Step:5|6   loss:1.5160861015319824  \n","Epoch:37/50     Step:6|6   loss:1.4415524005889893  \n","Epoch:37/50     Step:7|6   loss:1.1310440301895142  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:38/50     Step:1|6   loss:1.3799166679382324  \n","Epoch:38/50     Step:2|6   loss:1.4100714921951294  \n","Epoch:38/50     Step:3|6   loss:1.240195631980896  \n","Epoch:38/50     Step:4|6   loss:1.2905195951461792  \n","Epoch:38/50     Step:5|6   loss:1.3244476318359375  \n","Epoch:38/50     Step:6|6   loss:1.362388014793396  \n","Epoch:38/50     Step:7|6   loss:1.2600808143615723  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:39/50     Step:1|6   loss:1.4839868545532227  \n","Epoch:39/50     Step:2|6   loss:1.3737438917160034  \n","Epoch:39/50     Step:3|6   loss:1.3940601348876953  \n","Epoch:39/50     Step:4|6   loss:1.2330340147018433  \n","Epoch:39/50     Step:5|6   loss:1.1868295669555664  \n","Epoch:39/50     Step:6|6   loss:1.2438445091247559  \n","Epoch:39/50     Step:7|6   loss:1.2840484380722046  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:40/50     Step:1|6   loss:1.3202264308929443  \n","Epoch:40/50     Step:2|6   loss:1.1852023601531982  \n","Epoch:40/50     Step:3|6   loss:1.3611079454421997  \n","Epoch:40/50     Step:4|6   loss:1.3142940998077393  \n","Epoch:40/50     Step:5|6   loss:1.3194286823272705  \n","Epoch:40/50     Step:6|6   loss:1.290647268295288  \n","Epoch:40/50     Step:7|6   loss:1.4333853721618652  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:41/50     Step:1|6   loss:1.2633883953094482  \n","Epoch:41/50     Step:2|6   loss:1.374962568283081  \n","Epoch:41/50     Step:3|6   loss:1.1033681631088257  \n","Epoch:41/50     Step:4|6   loss:1.2282114028930664  \n","Epoch:41/50     Step:5|6   loss:1.340811848640442  \n","Epoch:41/50     Step:6|6   loss:1.3353867530822754  \n","Epoch:41/50     Step:7|6   loss:1.482621431350708  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:42/50     Step:1|6   loss:1.3496053218841553  \n","Epoch:42/50     Step:2|6   loss:1.2677713632583618  \n","Epoch:42/50     Step:3|6   loss:1.34537935256958  \n","Epoch:42/50     Step:4|6   loss:1.1397377252578735  \n","Epoch:42/50     Step:5|6   loss:1.2003804445266724  \n","Epoch:42/50     Step:6|6   loss:1.1838645935058594  \n","Epoch:42/50     Step:7|6   loss:1.298290729522705  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:43/50     Step:1|6   loss:1.293792963027954  \n","Epoch:43/50     Step:2|6   loss:1.2132513523101807  \n","Epoch:43/50     Step:3|6   loss:1.2407500743865967  \n","Epoch:43/50     Step:4|6   loss:1.2475810050964355  \n","Epoch:43/50     Step:5|6   loss:1.427098274230957  \n","Epoch:43/50     Step:6|6   loss:1.355331540107727  \n","Epoch:43/50     Step:7|6   loss:1.2075270414352417  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:44/50     Step:1|6   loss:1.147016167640686  \n","Epoch:44/50     Step:2|6   loss:1.297309398651123  \n","Epoch:44/50     Step:3|6   loss:1.1367323398590088  \n","Epoch:44/50     Step:4|6   loss:1.2350062131881714  \n","Epoch:44/50     Step:5|6   loss:1.2501804828643799  \n","Epoch:44/50     Step:6|6   loss:1.397673487663269  \n","Epoch:44/50     Step:7|6   loss:1.449968934059143  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:45/50     Step:1|6   loss:1.282628059387207  \n","Epoch:45/50     Step:2|6   loss:1.3201446533203125  \n","Epoch:45/50     Step:3|6   loss:1.353843092918396  \n","Epoch:45/50     Step:4|6   loss:1.2086524963378906  \n","Epoch:45/50     Step:5|6   loss:1.2402007579803467  \n","Epoch:45/50     Step:6|6   loss:1.2141551971435547  \n","Epoch:45/50     Step:7|6   loss:1.2408740520477295  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:46/50     Step:1|6   loss:1.216506004333496  \n","Epoch:46/50     Step:2|6   loss:1.3071134090423584  \n","Epoch:46/50     Step:3|6   loss:1.2887389659881592  \n","Epoch:46/50     Step:4|6   loss:1.2132034301757812  \n","Epoch:46/50     Step:5|6   loss:1.215600848197937  \n","Epoch:46/50     Step:6|6   loss:1.1609594821929932  \n","Epoch:46/50     Step:7|6   loss:1.403262972831726  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:47/50     Step:1|6   loss:1.2826257944107056  \n","Epoch:47/50     Step:2|6   loss:1.07658052444458  \n","Epoch:47/50     Step:3|6   loss:1.3115043640136719  \n","Epoch:47/50     Step:4|6   loss:1.1796116828918457  \n","Epoch:47/50     Step:5|6   loss:1.24809992313385  \n","Epoch:47/50     Step:6|6   loss:1.2428107261657715  \n","Epoch:47/50     Step:7|6   loss:1.2135393619537354  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:48/50     Step:1|6   loss:1.2484184503555298  \n","Epoch:48/50     Step:2|6   loss:1.0731663703918457  \n","Epoch:48/50     Step:3|6   loss:1.1043472290039062  \n","Epoch:48/50     Step:4|6   loss:1.1829131841659546  \n","Epoch:48/50     Step:5|6   loss:1.2473485469818115  \n","Epoch:48/50     Step:6|6   loss:1.1743577718734741  \n","Epoch:48/50     Step:7|6   loss:1.2670705318450928  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:49/50     Step:1|6   loss:1.3840711116790771  \n","Epoch:49/50     Step:2|6   loss:1.2188819646835327  \n","Epoch:49/50     Step:3|6   loss:1.2908053398132324  \n","Epoch:49/50     Step:4|6   loss:1.17022705078125  \n","Epoch:49/50     Step:5|6   loss:1.0588483810424805  \n","Epoch:49/50     Step:6|6   loss:1.1385478973388672  \n","Epoch:49/50     Step:7|6   loss:1.30031418800354  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Epoch:50/50     Step:1|6   loss:1.0731581449508667  \n","Epoch:50/50     Step:2|6   loss:1.1790496110916138  \n","Epoch:50/50     Step:3|6   loss:1.247554063796997  \n","Epoch:50/50     Step:4|6   loss:1.2176403999328613  \n","Epoch:50/50     Step:5|6   loss:1.332192063331604  \n","Epoch:50/50     Step:6|6   loss:1.0804675817489624  \n","Epoch:50/50     Step:7|6   loss:1.1364269256591797  \n","Accuracy on test_set: 50.47 %\n","Accuracy on train_set: 49.41 %\n","current max accuracy\t test set:50.47%\t train set:49.41%\n","Accuracy on test_set: 50.47 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_two_stream(\n","  (stream1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (stream2): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=752640, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0890226364135742  \n","Epoch:1/50     Step:2|6   loss:1.425750494003296  \n","Epoch:1/50     Step:3|6   loss:1.318998098373413  \n","Epoch:1/50     Step:4|6   loss:1.016465425491333  \n","Epoch:1/50     Step:5|6   loss:0.9153704047203064  \n","Epoch:1/50     Step:6|6   loss:0.9229033589363098  \n","Epoch:1/50     Step:7|6   loss:0.934734582901001  \n","Accuracy on test_set: 69.16 %\n","Accuracy on train_set: 72.37 %\n","current max accuracy\t test set:69.16%\t train set:72.37%\n","Epoch:2/50     Step:1|6   loss:0.9282621741294861  \n","Epoch:2/50     Step:2|6   loss:0.8992316722869873  \n","Epoch:2/50     Step:3|6   loss:0.7920645475387573  \n","Epoch:2/50     Step:4|6   loss:0.6966593265533447  \n","Epoch:2/50     Step:5|6   loss:0.7454744577407837  \n","Epoch:2/50     Step:6|6   loss:0.747742772102356  \n","Epoch:2/50     Step:7|6   loss:0.7113200426101685  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 87.35 %\n","current max accuracy\t test set:85.98%\t train set:87.35%\n","Epoch:3/50     Step:1|6   loss:0.7574052810668945  \n","Epoch:3/50     Step:2|6   loss:0.6414388418197632  \n","Epoch:3/50     Step:3|6   loss:0.7153358459472656  \n","Epoch:3/50     Step:4|6   loss:0.6517603397369385  \n","Epoch:3/50     Step:5|6   loss:0.6369022130966187  \n","Epoch:3/50     Step:6|6   loss:0.635223388671875  \n","Epoch:3/50     Step:7|6   loss:0.702141523361206  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 91.33 %\n","current max accuracy\t test set:85.98%\t train set:91.33%\n","Epoch:4/50     Step:1|6   loss:0.646378755569458  \n","Epoch:4/50     Step:2|6   loss:0.618005633354187  \n","Epoch:4/50     Step:3|6   loss:0.6979080438613892  \n","Epoch:4/50     Step:4|6   loss:0.6304215788841248  \n","Epoch:4/50     Step:5|6   loss:0.6913324594497681  \n","Epoch:4/50     Step:6|6   loss:0.6179602146148682  \n","Epoch:4/50     Step:7|6   loss:0.6939212679862976  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:86.92%\t train set:92.04%\n","Epoch:5/50     Step:1|6   loss:0.6160185933113098  \n","Epoch:5/50     Step:2|6   loss:0.6294198036193848  \n","Epoch:5/50     Step:3|6   loss:0.5862692594528198  \n","Epoch:5/50     Step:4|6   loss:0.5890331268310547  \n","Epoch:5/50     Step:5|6   loss:0.6281763911247253  \n","Epoch:5/50     Step:6|6   loss:0.6690652370452881  \n","Epoch:5/50     Step:7|6   loss:0.6560323238372803  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:89.72%\t train set:93.68%\n","Epoch:6/50     Step:1|6   loss:0.5928512215614319  \n","Epoch:6/50     Step:2|6   loss:0.6104462146759033  \n","Epoch:6/50     Step:3|6   loss:0.59671550989151  \n","Epoch:6/50     Step:4|6   loss:0.6106836795806885  \n","Epoch:6/50     Step:5|6   loss:0.6100554466247559  \n","Epoch:6/50     Step:6|6   loss:0.5970585942268372  \n","Epoch:6/50     Step:7|6   loss:0.5590823292732239  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:91.59%\t train set:94.61%\n","Epoch:7/50     Step:1|6   loss:0.5850088596343994  \n","Epoch:7/50     Step:2|6   loss:0.6064876914024353  \n","Epoch:7/50     Step:3|6   loss:0.6081089377403259  \n","Epoch:7/50     Step:4|6   loss:0.5695228576660156  \n","Epoch:7/50     Step:5|6   loss:0.5977445244789124  \n","Epoch:7/50     Step:6|6   loss:0.5448310375213623  \n","Epoch:7/50     Step:7|6   loss:0.5580568313598633  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:8/50     Step:1|6   loss:0.5791124701499939  \n","Epoch:8/50     Step:2|6   loss:0.5923134088516235  \n","Epoch:8/50     Step:3|6   loss:0.5640639066696167  \n","Epoch:8/50     Step:4|6   loss:0.5767607688903809  \n","Epoch:8/50     Step:5|6   loss:0.5774257183074951  \n","Epoch:8/50     Step:6|6   loss:0.5328166484832764  \n","Epoch:8/50     Step:7|6   loss:0.6146847009658813  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:9/50     Step:1|6   loss:0.5840095281600952  \n","Epoch:9/50     Step:2|6   loss:0.5732382535934448  \n","Epoch:9/50     Step:3|6   loss:0.6222465634346008  \n","Epoch:9/50     Step:4|6   loss:0.5836306214332581  \n","Epoch:9/50     Step:5|6   loss:0.5526527762413025  \n","Epoch:9/50     Step:6|6   loss:0.5976006984710693  \n","Epoch:9/50     Step:7|6   loss:0.5688640475273132  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:10/50     Step:1|6   loss:0.5577126145362854  \n","Epoch:10/50     Step:2|6   loss:0.569473922252655  \n","Epoch:10/50     Step:3|6   loss:0.5608994364738464  \n","Epoch:10/50     Step:4|6   loss:0.5460716485977173  \n","Epoch:10/50     Step:5|6   loss:0.5653750896453857  \n","Epoch:10/50     Step:6|6   loss:0.5852714776992798  \n","Epoch:10/50     Step:7|6   loss:0.5523957014083862  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:96.26%\t train set:98.83%\n","Epoch:11/50     Step:1|6   loss:0.5754631161689758  \n","Epoch:11/50     Step:2|6   loss:0.533913254737854  \n","Epoch:11/50     Step:3|6   loss:0.5389798879623413  \n","Epoch:11/50     Step:4|6   loss:0.5458492040634155  \n","Epoch:11/50     Step:5|6   loss:0.5367297530174255  \n","Epoch:11/50     Step:6|6   loss:0.5681954026222229  \n","Epoch:11/50     Step:7|6   loss:0.569013237953186  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:97.2%\t train set:99.06%\n","Epoch:12/50     Step:1|6   loss:0.5606585144996643  \n","Epoch:12/50     Step:2|6   loss:0.5487342476844788  \n","Epoch:12/50     Step:3|6   loss:0.52814781665802  \n","Epoch:12/50     Step:4|6   loss:0.5363212823867798  \n","Epoch:12/50     Step:5|6   loss:0.5679411888122559  \n","Epoch:12/50     Step:6|6   loss:0.5573787093162537  \n","Epoch:12/50     Step:7|6   loss:0.5536609888076782  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:13/50     Step:1|6   loss:0.5479864478111267  \n","Epoch:13/50     Step:2|6   loss:0.5358142852783203  \n","Epoch:13/50     Step:3|6   loss:0.5620329976081848  \n","Epoch:13/50     Step:4|6   loss:0.5337005257606506  \n","Epoch:13/50     Step:5|6   loss:0.5298879742622375  \n","Epoch:13/50     Step:6|6   loss:0.5242063403129578  \n","Epoch:13/50     Step:7|6   loss:0.548156201839447  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:14/50     Step:1|6   loss:0.5535832643508911  \n","Epoch:14/50     Step:2|6   loss:0.5556563138961792  \n","Epoch:14/50     Step:3|6   loss:0.5308244228363037  \n","Epoch:14/50     Step:4|6   loss:0.535468339920044  \n","Epoch:14/50     Step:5|6   loss:0.5328895449638367  \n","Epoch:14/50     Step:6|6   loss:0.5194970369338989  \n","Epoch:14/50     Step:7|6   loss:0.5644869208335876  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:15/50     Step:1|6   loss:0.527092695236206  \n","Epoch:15/50     Step:2|6   loss:0.5377626419067383  \n","Epoch:15/50     Step:3|6   loss:0.5620880126953125  \n","Epoch:15/50     Step:4|6   loss:0.5355261564254761  \n","Epoch:15/50     Step:5|6   loss:0.5515300035476685  \n","Epoch:15/50     Step:6|6   loss:0.538629412651062  \n","Epoch:15/50     Step:7|6   loss:0.5244881510734558  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:16/50     Step:1|6   loss:0.5631414651870728  \n","Epoch:16/50     Step:2|6   loss:0.5352209210395813  \n","Epoch:16/50     Step:3|6   loss:0.5481274127960205  \n","Epoch:16/50     Step:4|6   loss:0.5351271629333496  \n","Epoch:16/50     Step:5|6   loss:0.5280404090881348  \n","Epoch:16/50     Step:6|6   loss:0.5494755506515503  \n","Epoch:16/50     Step:7|6   loss:0.5180976986885071  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:17/50     Step:1|6   loss:0.5712426900863647  \n","Epoch:17/50     Step:2|6   loss:0.5204604864120483  \n","Epoch:17/50     Step:3|6   loss:0.5452535152435303  \n","Epoch:17/50     Step:4|6   loss:0.5308313369750977  \n","Epoch:17/50     Step:5|6   loss:0.5314485430717468  \n","Epoch:17/50     Step:6|6   loss:0.5280565023422241  \n","Epoch:17/50     Step:7|6   loss:0.5329806804656982  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:18/50     Step:1|6   loss:0.5221815705299377  \n","Epoch:18/50     Step:2|6   loss:0.5420958399772644  \n","Epoch:18/50     Step:3|6   loss:0.5322783589363098  \n","Epoch:18/50     Step:4|6   loss:0.5370317697525024  \n","Epoch:18/50     Step:5|6   loss:0.56083744764328  \n","Epoch:18/50     Step:6|6   loss:0.5231737494468689  \n","Epoch:18/50     Step:7|6   loss:0.5260252356529236  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:19/50     Step:1|6   loss:0.5297408103942871  \n","Epoch:19/50     Step:2|6   loss:0.5239384174346924  \n","Epoch:19/50     Step:3|6   loss:0.5645623803138733  \n","Epoch:19/50     Step:4|6   loss:0.5250470042228699  \n","Epoch:19/50     Step:5|6   loss:0.5314390063285828  \n","Epoch:19/50     Step:6|6   loss:0.5343661308288574  \n","Epoch:19/50     Step:7|6   loss:0.5468952059745789  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:20/50     Step:1|6   loss:0.5293307304382324  \n","Epoch:20/50     Step:2|6   loss:0.5234650373458862  \n","Epoch:20/50     Step:3|6   loss:0.5359517931938171  \n","Epoch:20/50     Step:4|6   loss:0.5436851382255554  \n","Epoch:20/50     Step:5|6   loss:0.5309455990791321  \n","Epoch:20/50     Step:6|6   loss:0.5274522304534912  \n","Epoch:20/50     Step:7|6   loss:0.5275373458862305  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:21/50     Step:1|6   loss:0.5289062261581421  \n","Epoch:21/50     Step:2|6   loss:0.549632728099823  \n","Epoch:21/50     Step:3|6   loss:0.5424250364303589  \n","Epoch:21/50     Step:4|6   loss:0.5468227863311768  \n","Epoch:21/50     Step:5|6   loss:0.5342985987663269  \n","Epoch:21/50     Step:6|6   loss:0.5218332409858704  \n","Epoch:21/50     Step:7|6   loss:0.5198606848716736  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:22/50     Step:1|6   loss:0.5437238812446594  \n","Epoch:22/50     Step:2|6   loss:0.5243054032325745  \n","Epoch:22/50     Step:3|6   loss:0.5240947008132935  \n","Epoch:22/50     Step:4|6   loss:0.5280112028121948  \n","Epoch:22/50     Step:5|6   loss:0.5376054048538208  \n","Epoch:22/50     Step:6|6   loss:0.5296556949615479  \n","Epoch:22/50     Step:7|6   loss:0.5286585092544556  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:23/50     Step:1|6   loss:0.5322025418281555  \n","Epoch:23/50     Step:2|6   loss:0.5191131830215454  \n","Epoch:23/50     Step:3|6   loss:0.5215635299682617  \n","Epoch:23/50     Step:4|6   loss:0.5275945663452148  \n","Epoch:23/50     Step:5|6   loss:0.5478476285934448  \n","Epoch:23/50     Step:6|6   loss:0.5191141963005066  \n","Epoch:23/50     Step:7|6   loss:0.5309087038040161  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:24/50     Step:1|6   loss:0.522983193397522  \n","Epoch:24/50     Step:2|6   loss:0.5269194841384888  \n","Epoch:24/50     Step:3|6   loss:0.5214471220970154  \n","Epoch:24/50     Step:4|6   loss:0.533791184425354  \n","Epoch:24/50     Step:5|6   loss:0.5378094911575317  \n","Epoch:24/50     Step:6|6   loss:0.5271894335746765  \n","Epoch:24/50     Step:7|6   loss:0.5242729187011719  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:25/50     Step:1|6   loss:0.5163018703460693  \n","Epoch:25/50     Step:2|6   loss:0.5254442691802979  \n","Epoch:25/50     Step:3|6   loss:0.5172248482704163  \n","Epoch:25/50     Step:4|6   loss:0.544585108757019  \n","Epoch:25/50     Step:5|6   loss:0.5223072171211243  \n","Epoch:25/50     Step:6|6   loss:0.5506129860877991  \n","Epoch:25/50     Step:7|6   loss:0.5188851356506348  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:26/50     Step:1|6   loss:0.5254933834075928  \n","Epoch:26/50     Step:2|6   loss:0.5205262899398804  \n","Epoch:26/50     Step:3|6   loss:0.5266302227973938  \n","Epoch:26/50     Step:4|6   loss:0.5142173171043396  \n","Epoch:26/50     Step:5|6   loss:0.5248684883117676  \n","Epoch:26/50     Step:6|6   loss:0.5263943672180176  \n","Epoch:26/50     Step:7|6   loss:0.5104078650474548  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:27/50     Step:1|6   loss:0.5141986012458801  \n","Epoch:27/50     Step:2|6   loss:0.5315815806388855  \n","Epoch:27/50     Step:3|6   loss:0.5155435800552368  \n","Epoch:27/50     Step:4|6   loss:0.5183120965957642  \n","Epoch:27/50     Step:5|6   loss:0.5217183232307434  \n","Epoch:27/50     Step:6|6   loss:0.5274182558059692  \n","Epoch:27/50     Step:7|6   loss:0.5324903726577759  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:28/50     Step:1|6   loss:0.5252444744110107  \n","Epoch:28/50     Step:2|6   loss:0.524596631526947  \n","Epoch:28/50     Step:3|6   loss:0.5410648584365845  \n","Epoch:28/50     Step:4|6   loss:0.5227397084236145  \n","Epoch:28/50     Step:5|6   loss:0.5215165019035339  \n","Epoch:28/50     Step:6|6   loss:0.5396298170089722  \n","Epoch:28/50     Step:7|6   loss:0.5241270065307617  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:29/50     Step:1|6   loss:0.5361844897270203  \n","Epoch:29/50     Step:2|6   loss:0.5256966948509216  \n","Epoch:29/50     Step:3|6   loss:0.5325711369514465  \n","Epoch:29/50     Step:4|6   loss:0.5164021849632263  \n","Epoch:29/50     Step:5|6   loss:0.5186337232589722  \n","Epoch:29/50     Step:6|6   loss:0.5222234725952148  \n","Epoch:29/50     Step:7|6   loss:0.5213717818260193  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:30/50     Step:1|6   loss:0.5190591216087341  \n","Epoch:30/50     Step:2|6   loss:0.5330410003662109  \n","Epoch:30/50     Step:3|6   loss:0.5199103951454163  \n","Epoch:30/50     Step:4|6   loss:0.5172743797302246  \n","Epoch:30/50     Step:5|6   loss:0.5222091674804688  \n","Epoch:30/50     Step:6|6   loss:0.5297183990478516  \n","Epoch:30/50     Step:7|6   loss:0.5096023678779602  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:31/50     Step:1|6   loss:0.5095887184143066  \n","Epoch:31/50     Step:2|6   loss:0.5193010568618774  \n","Epoch:31/50     Step:3|6   loss:0.532311201095581  \n","Epoch:31/50     Step:4|6   loss:0.5197771787643433  \n","Epoch:31/50     Step:5|6   loss:0.5298141241073608  \n","Epoch:31/50     Step:6|6   loss:0.5244364738464355  \n","Epoch:31/50     Step:7|6   loss:0.5095177888870239  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:32/50     Step:1|6   loss:0.532374382019043  \n","Epoch:32/50     Step:2|6   loss:0.5305368304252625  \n","Epoch:32/50     Step:3|6   loss:0.5193370580673218  \n","Epoch:32/50     Step:4|6   loss:0.5357661247253418  \n","Epoch:32/50     Step:5|6   loss:0.5222192406654358  \n","Epoch:32/50     Step:6|6   loss:0.5140312910079956  \n","Epoch:32/50     Step:7|6   loss:0.5234596729278564  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:33/50     Step:1|6   loss:0.525268018245697  \n","Epoch:33/50     Step:2|6   loss:0.5262848734855652  \n","Epoch:33/50     Step:3|6   loss:0.5191115140914917  \n","Epoch:33/50     Step:4|6   loss:0.5241305828094482  \n","Epoch:33/50     Step:5|6   loss:0.5274603366851807  \n","Epoch:33/50     Step:6|6   loss:0.5170395970344543  \n","Epoch:33/50     Step:7|6   loss:0.5210965871810913  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:34/50     Step:1|6   loss:0.5231505036354065  \n","Epoch:34/50     Step:2|6   loss:0.5208582282066345  \n","Epoch:34/50     Step:3|6   loss:0.520455539226532  \n","Epoch:34/50     Step:4|6   loss:0.5181387662887573  \n","Epoch:34/50     Step:5|6   loss:0.5290540456771851  \n","Epoch:34/50     Step:6|6   loss:0.5358717441558838  \n","Epoch:34/50     Step:7|6   loss:0.5167969465255737  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:35/50     Step:1|6   loss:0.5188561677932739  \n","Epoch:35/50     Step:2|6   loss:0.5165430903434753  \n","Epoch:35/50     Step:3|6   loss:0.5228933095932007  \n","Epoch:35/50     Step:4|6   loss:0.5354186296463013  \n","Epoch:35/50     Step:5|6   loss:0.515977680683136  \n","Epoch:35/50     Step:6|6   loss:0.5289241075515747  \n","Epoch:35/50     Step:7|6   loss:0.5118044018745422  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.5163388252258301  \n","Epoch:36/50     Step:2|6   loss:0.5185976624488831  \n","Epoch:36/50     Step:3|6   loss:0.5218055844306946  \n","Epoch:36/50     Step:4|6   loss:0.514342188835144  \n","Epoch:36/50     Step:5|6   loss:0.5245154500007629  \n","Epoch:36/50     Step:6|6   loss:0.5313521027565002  \n","Epoch:36/50     Step:7|6   loss:0.5141386389732361  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:37/50     Step:1|6   loss:0.5174981355667114  \n","Epoch:37/50     Step:2|6   loss:0.5202381610870361  \n","Epoch:37/50     Step:3|6   loss:0.512315034866333  \n","Epoch:37/50     Step:4|6   loss:0.5186910629272461  \n","Epoch:37/50     Step:5|6   loss:0.5203161239624023  \n","Epoch:37/50     Step:6|6   loss:0.5240384340286255  \n","Epoch:37/50     Step:7|6   loss:0.5356699228286743  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:38/50     Step:1|6   loss:0.5121552348136902  \n","Epoch:38/50     Step:2|6   loss:0.5252682566642761  \n","Epoch:38/50     Step:3|6   loss:0.5215972065925598  \n","Epoch:38/50     Step:4|6   loss:0.521418571472168  \n","Epoch:38/50     Step:5|6   loss:0.5244005918502808  \n","Epoch:38/50     Step:6|6   loss:0.5189752578735352  \n","Epoch:38/50     Step:7|6   loss:0.5162069797515869  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.520321249961853  \n","Epoch:39/50     Step:2|6   loss:0.5267170071601868  \n","Epoch:39/50     Step:3|6   loss:0.5234948396682739  \n","Epoch:39/50     Step:4|6   loss:0.513263463973999  \n","Epoch:39/50     Step:5|6   loss:0.5271375775337219  \n","Epoch:39/50     Step:6|6   loss:0.516249418258667  \n","Epoch:39/50     Step:7|6   loss:0.5282102823257446  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.5087000727653503  \n","Epoch:40/50     Step:2|6   loss:0.5132384300231934  \n","Epoch:40/50     Step:3|6   loss:0.5334275364875793  \n","Epoch:40/50     Step:4|6   loss:0.5232601165771484  \n","Epoch:40/50     Step:5|6   loss:0.5306214094161987  \n","Epoch:40/50     Step:6|6   loss:0.5203880071640015  \n","Epoch:40/50     Step:7|6   loss:0.518244206905365  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.5200918912887573  \n","Epoch:41/50     Step:2|6   loss:0.5162566900253296  \n","Epoch:41/50     Step:3|6   loss:0.5361931324005127  \n","Epoch:41/50     Step:4|6   loss:0.5116084814071655  \n","Epoch:41/50     Step:5|6   loss:0.5296956896781921  \n","Epoch:41/50     Step:6|6   loss:0.5116883516311646  \n","Epoch:41/50     Step:7|6   loss:0.5135599970817566  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.5199640989303589  \n","Epoch:42/50     Step:2|6   loss:0.5288845300674438  \n","Epoch:42/50     Step:3|6   loss:0.5182451605796814  \n","Epoch:42/50     Step:4|6   loss:0.5118509531021118  \n","Epoch:42/50     Step:5|6   loss:0.5178678035736084  \n","Epoch:42/50     Step:6|6   loss:0.5257604122161865  \n","Epoch:42/50     Step:7|6   loss:0.5110772848129272  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.5207856297492981  \n","Epoch:43/50     Step:2|6   loss:0.5251618027687073  \n","Epoch:43/50     Step:3|6   loss:0.5152823328971863  \n","Epoch:43/50     Step:4|6   loss:0.5180301070213318  \n","Epoch:43/50     Step:5|6   loss:0.5158559083938599  \n","Epoch:43/50     Step:6|6   loss:0.5245423913002014  \n","Epoch:43/50     Step:7|6   loss:0.519443929195404  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.5157996416091919  \n","Epoch:44/50     Step:2|6   loss:0.5166008472442627  \n","Epoch:44/50     Step:3|6   loss:0.5187045335769653  \n","Epoch:44/50     Step:4|6   loss:0.526067316532135  \n","Epoch:44/50     Step:5|6   loss:0.513288140296936  \n","Epoch:44/50     Step:6|6   loss:0.5140602588653564  \n","Epoch:44/50     Step:7|6   loss:0.5131369233131409  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5185409188270569  \n","Epoch:45/50     Step:2|6   loss:0.5175122618675232  \n","Epoch:45/50     Step:3|6   loss:0.5176333785057068  \n","Epoch:45/50     Step:4|6   loss:0.531588613986969  \n","Epoch:45/50     Step:5|6   loss:0.5327579379081726  \n","Epoch:45/50     Step:6|6   loss:0.5166626572608948  \n","Epoch:45/50     Step:7|6   loss:0.512079656124115  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5175309777259827  \n","Epoch:46/50     Step:2|6   loss:0.5251137018203735  \n","Epoch:46/50     Step:3|6   loss:0.5132910013198853  \n","Epoch:46/50     Step:4|6   loss:0.5255258083343506  \n","Epoch:46/50     Step:5|6   loss:0.5237810611724854  \n","Epoch:46/50     Step:6|6   loss:0.5168495178222656  \n","Epoch:46/50     Step:7|6   loss:0.5297051668167114  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5213907957077026  \n","Epoch:47/50     Step:2|6   loss:0.5200484395027161  \n","Epoch:47/50     Step:3|6   loss:0.5222679376602173  \n","Epoch:47/50     Step:4|6   loss:0.5254537463188171  \n","Epoch:47/50     Step:5|6   loss:0.522282600402832  \n","Epoch:47/50     Step:6|6   loss:0.5136504173278809  \n","Epoch:47/50     Step:7|6   loss:0.5298945903778076  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.535865306854248  \n","Epoch:48/50     Step:2|6   loss:0.5158500671386719  \n","Epoch:48/50     Step:3|6   loss:0.5111043453216553  \n","Epoch:48/50     Step:4|6   loss:0.5174105167388916  \n","Epoch:48/50     Step:5|6   loss:0.5178471803665161  \n","Epoch:48/50     Step:6|6   loss:0.5210026502609253  \n","Epoch:48/50     Step:7|6   loss:0.5168753862380981  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5161518454551697  \n","Epoch:49/50     Step:2|6   loss:0.5241929888725281  \n","Epoch:49/50     Step:3|6   loss:0.5126363039016724  \n","Epoch:49/50     Step:4|6   loss:0.517586886882782  \n","Epoch:49/50     Step:5|6   loss:0.5228738784790039  \n","Epoch:49/50     Step:6|6   loss:0.5216468572616577  \n","Epoch:49/50     Step:7|6   loss:0.512376070022583  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5154772996902466  \n","Epoch:50/50     Step:2|6   loss:0.5284962058067322  \n","Epoch:50/50     Step:3|6   loss:0.512446403503418  \n","Epoch:50/50     Step:4|6   loss:0.5242099165916443  \n","Epoch:50/50     Step:5|6   loss:0.511196494102478  \n","Epoch:50/50     Step:6|6   loss:0.5141113996505737  \n","Epoch:50/50     Step:7|6   loss:0.5166612863540649  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 97.20 %\n","2\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_two_stream(\n","  (stream1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (stream2): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=752640, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.0976159572601318  \n","Epoch:1/50     Step:2|6   loss:2.413623332977295  \n","Epoch:1/50     Step:3|6   loss:2.185896158218384  \n","Epoch:1/50     Step:4|6   loss:2.000011682510376  \n","Epoch:1/50     Step:5|6   loss:1.7285799980163574  \n","Epoch:1/50     Step:6|6   loss:1.8256564140319824  \n","Epoch:1/50     Step:7|6   loss:1.8562308549880981  \n","Accuracy on test_set: 48.60 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:48.6%\t train set:46.37%\n","Epoch:2/50     Step:1|6   loss:1.5248496532440186  \n","Epoch:2/50     Step:2|6   loss:1.8559070825576782  \n","Epoch:2/50     Step:3|6   loss:1.6884911060333252  \n","Epoch:2/50     Step:4|6   loss:1.321774959564209  \n","Epoch:2/50     Step:5|6   loss:1.5665111541748047  \n","Epoch:2/50     Step:6|6   loss:1.305403470993042  \n","Epoch:2/50     Step:7|6   loss:1.2003767490386963  \n","Accuracy on test_set: 48.60 %\n","Accuracy on train_set: 46.37 %\n","current max accuracy\t test set:48.6%\t train set:46.37%\n","Epoch:3/50     Step:1|6   loss:1.1021835803985596  \n","Epoch:3/50     Step:2|6   loss:1.0764206647872925  \n","Epoch:3/50     Step:3|6   loss:1.0179944038391113  \n","Epoch:3/50     Step:4|6   loss:1.1735070943832397  \n","Epoch:3/50     Step:5|6   loss:0.9598760008811951  \n","Epoch:3/50     Step:6|6   loss:0.9940448999404907  \n","Epoch:3/50     Step:7|6   loss:0.9497953653335571  \n","Accuracy on test_set: 63.55 %\n","Accuracy on train_set: 71.43 %\n","current max accuracy\t test set:63.55%\t train set:71.43%\n","Epoch:4/50     Step:1|6   loss:0.9784488677978516  \n","Epoch:4/50     Step:2|6   loss:0.8825497627258301  \n","Epoch:4/50     Step:3|6   loss:0.8981107473373413  \n","Epoch:4/50     Step:4|6   loss:0.9289505481719971  \n","Epoch:4/50     Step:5|6   loss:0.8818079233169556  \n","Epoch:4/50     Step:6|6   loss:0.7961169481277466  \n","Epoch:4/50     Step:7|6   loss:0.8271101713180542  \n","Accuracy on test_set: 85.98 %\n","Accuracy on train_set: 84.54 %\n","current max accuracy\t test set:85.98%\t train set:84.54%\n","Epoch:5/50     Step:1|6   loss:0.8366305828094482  \n","Epoch:5/50     Step:2|6   loss:0.8545129299163818  \n","Epoch:5/50     Step:3|6   loss:0.7377952933311462  \n","Epoch:5/50     Step:4|6   loss:0.7452183961868286  \n","Epoch:5/50     Step:5|6   loss:0.8419756889343262  \n","Epoch:5/50     Step:6|6   loss:0.8245272636413574  \n","Epoch:5/50     Step:7|6   loss:0.9610767364501953  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 84.31 %\n","current max accuracy\t test set:85.98%\t train set:84.54%\n","Epoch:6/50     Step:1|6   loss:0.754091739654541  \n","Epoch:6/50     Step:2|6   loss:0.7661914825439453  \n","Epoch:6/50     Step:3|6   loss:0.7928533554077148  \n","Epoch:6/50     Step:4|6   loss:0.786867082118988  \n","Epoch:6/50     Step:5|6   loss:0.7181994915008545  \n","Epoch:6/50     Step:6|6   loss:0.7553285360336304  \n","Epoch:6/50     Step:7|6   loss:0.7700993418693542  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 89.46 %\n","current max accuracy\t test set:91.59%\t train set:89.46%\n","Epoch:7/50     Step:1|6   loss:0.7727898955345154  \n","Epoch:7/50     Step:2|6   loss:0.8019272685050964  \n","Epoch:7/50     Step:3|6   loss:0.8079301118850708  \n","Epoch:7/50     Step:4|6   loss:0.7342696189880371  \n","Epoch:7/50     Step:5|6   loss:0.7300670146942139  \n","Epoch:7/50     Step:6|6   loss:0.6906245350837708  \n","Epoch:7/50     Step:7|6   loss:0.7651287317276001  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:91.59%\t train set:89.7%\n","Epoch:8/50     Step:1|6   loss:0.7329193353652954  \n","Epoch:8/50     Step:2|6   loss:0.7781707048416138  \n","Epoch:8/50     Step:3|6   loss:0.7429251670837402  \n","Epoch:8/50     Step:4|6   loss:0.7270797491073608  \n","Epoch:8/50     Step:5|6   loss:0.7042688131332397  \n","Epoch:8/50     Step:6|6   loss:0.8092857003211975  \n","Epoch:8/50     Step:7|6   loss:0.751489520072937  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 90.63 %\n","current max accuracy\t test set:92.52%\t train set:90.63%\n","Epoch:9/50     Step:1|6   loss:0.6609848737716675  \n","Epoch:9/50     Step:2|6   loss:0.7807630300521851  \n","Epoch:9/50     Step:3|6   loss:0.8240268230438232  \n","Epoch:9/50     Step:4|6   loss:0.730827808380127  \n","Epoch:9/50     Step:5|6   loss:0.6862027645111084  \n","Epoch:9/50     Step:6|6   loss:0.7056141495704651  \n","Epoch:9/50     Step:7|6   loss:0.6681607365608215  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 92.27 %\n","current max accuracy\t test set:92.52%\t train set:92.27%\n","Epoch:10/50     Step:1|6   loss:0.6963934898376465  \n","Epoch:10/50     Step:2|6   loss:0.6578159332275391  \n","Epoch:10/50     Step:3|6   loss:0.7045364379882812  \n","Epoch:10/50     Step:4|6   loss:0.7121579647064209  \n","Epoch:10/50     Step:5|6   loss:0.7438977956771851  \n","Epoch:10/50     Step:6|6   loss:0.6768940687179565  \n","Epoch:10/50     Step:7|6   loss:0.6418318748474121  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:94.39%\t train set:92.97%\n","Epoch:11/50     Step:1|6   loss:0.6057154536247253  \n","Epoch:11/50     Step:2|6   loss:0.7400684356689453  \n","Epoch:11/50     Step:3|6   loss:0.6280343532562256  \n","Epoch:11/50     Step:4|6   loss:0.6390067338943481  \n","Epoch:11/50     Step:5|6   loss:0.6499251127243042  \n","Epoch:11/50     Step:6|6   loss:0.6215029954910278  \n","Epoch:11/50     Step:7|6   loss:0.6931475400924683  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:94.39%\t train set:94.61%\n","Epoch:12/50     Step:1|6   loss:0.6321715116500854  \n","Epoch:12/50     Step:2|6   loss:0.7073850631713867  \n","Epoch:12/50     Step:3|6   loss:0.6336426734924316  \n","Epoch:12/50     Step:4|6   loss:0.6093524694442749  \n","Epoch:12/50     Step:5|6   loss:0.6521522998809814  \n","Epoch:12/50     Step:6|6   loss:0.6264601945877075  \n","Epoch:12/50     Step:7|6   loss:0.696292519569397  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:95.33%\t train set:95.08%\n","Epoch:13/50     Step:1|6   loss:0.6826680302619934  \n","Epoch:13/50     Step:2|6   loss:0.6424949169158936  \n","Epoch:13/50     Step:3|6   loss:0.6329067945480347  \n","Epoch:13/50     Step:4|6   loss:0.6383657455444336  \n","Epoch:13/50     Step:5|6   loss:0.604385256767273  \n","Epoch:13/50     Step:6|6   loss:0.6980700492858887  \n","Epoch:13/50     Step:7|6   loss:0.6875896453857422  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:95.33%\t train set:95.78%\n","Epoch:14/50     Step:1|6   loss:0.657500147819519  \n","Epoch:14/50     Step:2|6   loss:0.7046897411346436  \n","Epoch:14/50     Step:3|6   loss:0.5886330604553223  \n","Epoch:14/50     Step:4|6   loss:0.643478512763977  \n","Epoch:14/50     Step:5|6   loss:0.6417582631111145  \n","Epoch:14/50     Step:6|6   loss:0.6267673969268799  \n","Epoch:14/50     Step:7|6   loss:0.5952909588813782  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:95.33%\t train set:96.49%\n","Epoch:15/50     Step:1|6   loss:0.6036299467086792  \n","Epoch:15/50     Step:2|6   loss:0.6126487851142883  \n","Epoch:15/50     Step:3|6   loss:0.6286172866821289  \n","Epoch:15/50     Step:4|6   loss:0.6131024956703186  \n","Epoch:15/50     Step:5|6   loss:0.5992054343223572  \n","Epoch:15/50     Step:6|6   loss:0.6620603203773499  \n","Epoch:15/50     Step:7|6   loss:0.5364537239074707  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:16/50     Step:1|6   loss:0.6600762605667114  \n","Epoch:16/50     Step:2|6   loss:0.5700547695159912  \n","Epoch:16/50     Step:3|6   loss:0.6302781105041504  \n","Epoch:16/50     Step:4|6   loss:0.6394132375717163  \n","Epoch:16/50     Step:5|6   loss:0.5882704854011536  \n","Epoch:16/50     Step:6|6   loss:0.5661695599555969  \n","Epoch:16/50     Step:7|6   loss:0.5923778414726257  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 95.55 %\n","current max accuracy\t test set:96.26%\t train set:96.96%\n","Epoch:17/50     Step:1|6   loss:0.5830551385879517  \n","Epoch:17/50     Step:2|6   loss:0.5846156477928162  \n","Epoch:17/50     Step:3|6   loss:0.6085749864578247  \n","Epoch:17/50     Step:4|6   loss:0.5379399061203003  \n","Epoch:17/50     Step:5|6   loss:0.5734044313430786  \n","Epoch:17/50     Step:6|6   loss:0.654384970664978  \n","Epoch:17/50     Step:7|6   loss:0.6027154922485352  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:97.2%\t train set:97.89%\n","Epoch:18/50     Step:1|6   loss:0.6018654108047485  \n","Epoch:18/50     Step:2|6   loss:0.572033166885376  \n","Epoch:18/50     Step:3|6   loss:0.5698469877243042  \n","Epoch:18/50     Step:4|6   loss:0.6505604982376099  \n","Epoch:18/50     Step:5|6   loss:0.5868256688117981  \n","Epoch:18/50     Step:6|6   loss:0.5997714400291443  \n","Epoch:18/50     Step:7|6   loss:0.5655879974365234  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:97.2%\t train set:97.89%\n","Epoch:19/50     Step:1|6   loss:0.5533214807510376  \n","Epoch:19/50     Step:2|6   loss:0.5774343609809875  \n","Epoch:19/50     Step:3|6   loss:0.5913834571838379  \n","Epoch:19/50     Step:4|6   loss:0.5838954448699951  \n","Epoch:19/50     Step:5|6   loss:0.5651615262031555  \n","Epoch:19/50     Step:6|6   loss:0.6844601631164551  \n","Epoch:19/50     Step:7|6   loss:0.6374388933181763  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:97.2%\t train set:97.89%\n","Epoch:20/50     Step:1|6   loss:0.5930265784263611  \n","Epoch:20/50     Step:2|6   loss:0.5557037591934204  \n","Epoch:20/50     Step:3|6   loss:0.5821424126625061  \n","Epoch:20/50     Step:4|6   loss:0.5893490314483643  \n","Epoch:20/50     Step:5|6   loss:0.6128633618354797  \n","Epoch:20/50     Step:6|6   loss:0.5959295034408569  \n","Epoch:20/50     Step:7|6   loss:0.5769355893135071  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:97.89%\n","Epoch:21/50     Step:1|6   loss:0.5603207349777222  \n","Epoch:21/50     Step:2|6   loss:0.6219321489334106  \n","Epoch:21/50     Step:3|6   loss:0.6497475504875183  \n","Epoch:21/50     Step:4|6   loss:0.5562731027603149  \n","Epoch:21/50     Step:5|6   loss:0.5999666452407837  \n","Epoch:21/50     Step:6|6   loss:0.5733433365821838  \n","Epoch:21/50     Step:7|6   loss:0.5954478979110718  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:22/50     Step:1|6   loss:0.5494174361228943  \n","Epoch:22/50     Step:2|6   loss:0.5942599773406982  \n","Epoch:22/50     Step:3|6   loss:0.5546128153800964  \n","Epoch:22/50     Step:4|6   loss:0.562332272529602  \n","Epoch:22/50     Step:5|6   loss:0.5944406986236572  \n","Epoch:22/50     Step:6|6   loss:0.5736859440803528  \n","Epoch:22/50     Step:7|6   loss:0.5461346507072449  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:23/50     Step:1|6   loss:0.5576291680335999  \n","Epoch:23/50     Step:2|6   loss:0.5337313413619995  \n","Epoch:23/50     Step:3|6   loss:0.5811208486557007  \n","Epoch:23/50     Step:4|6   loss:0.5672470927238464  \n","Epoch:23/50     Step:5|6   loss:0.5347426533699036  \n","Epoch:23/50     Step:6|6   loss:0.6788172721862793  \n","Epoch:23/50     Step:7|6   loss:0.5362564921379089  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.89 %\n","current max accuracy\t test set:98.13%\t train set:98.36%\n","Epoch:24/50     Step:1|6   loss:0.5888059735298157  \n","Epoch:24/50     Step:2|6   loss:0.5894350409507751  \n","Epoch:24/50     Step:3|6   loss:0.5629236102104187  \n","Epoch:24/50     Step:4|6   loss:0.5558800101280212  \n","Epoch:24/50     Step:5|6   loss:0.5638264417648315  \n","Epoch:24/50     Step:6|6   loss:0.5330888032913208  \n","Epoch:24/50     Step:7|6   loss:0.5376676321029663  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:98.13%\t train set:98.59%\n","Epoch:25/50     Step:1|6   loss:0.5310444831848145  \n","Epoch:25/50     Step:2|6   loss:0.549338161945343  \n","Epoch:25/50     Step:3|6   loss:0.5440594553947449  \n","Epoch:25/50     Step:4|6   loss:0.565517008304596  \n","Epoch:25/50     Step:5|6   loss:0.5763867497444153  \n","Epoch:25/50     Step:6|6   loss:0.5755946040153503  \n","Epoch:25/50     Step:7|6   loss:0.5784024596214294  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:98.13%\t train set:98.59%\n","Epoch:26/50     Step:1|6   loss:0.5641494393348694  \n","Epoch:26/50     Step:2|6   loss:0.5422641038894653  \n","Epoch:26/50     Step:3|6   loss:0.5484563112258911  \n","Epoch:26/50     Step:4|6   loss:0.5836681127548218  \n","Epoch:26/50     Step:5|6   loss:0.5676469206809998  \n","Epoch:26/50     Step:6|6   loss:0.5518961548805237  \n","Epoch:26/50     Step:7|6   loss:0.539766788482666  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:27/50     Step:1|6   loss:0.5585344433784485  \n","Epoch:27/50     Step:2|6   loss:0.5632094144821167  \n","Epoch:27/50     Step:3|6   loss:0.5311470627784729  \n","Epoch:27/50     Step:4|6   loss:0.5320669412612915  \n","Epoch:27/50     Step:5|6   loss:0.5291348695755005  \n","Epoch:27/50     Step:6|6   loss:0.5313866138458252  \n","Epoch:27/50     Step:7|6   loss:0.6000247597694397  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:28/50     Step:1|6   loss:0.5710430145263672  \n","Epoch:28/50     Step:2|6   loss:0.5354067087173462  \n","Epoch:28/50     Step:3|6   loss:0.55621737241745  \n","Epoch:28/50     Step:4|6   loss:0.5921805500984192  \n","Epoch:28/50     Step:5|6   loss:0.565894365310669  \n","Epoch:28/50     Step:6|6   loss:0.5352311134338379  \n","Epoch:28/50     Step:7|6   loss:0.5343247652053833  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:29/50     Step:1|6   loss:0.5512169599533081  \n","Epoch:29/50     Step:2|6   loss:0.5607836842536926  \n","Epoch:29/50     Step:3|6   loss:0.5597703456878662  \n","Epoch:29/50     Step:4|6   loss:0.5787191390991211  \n","Epoch:29/50     Step:5|6   loss:0.5507259368896484  \n","Epoch:29/50     Step:6|6   loss:0.5450271368026733  \n","Epoch:29/50     Step:7|6   loss:0.5300666689872742  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:30/50     Step:1|6   loss:0.5495470762252808  \n","Epoch:30/50     Step:2|6   loss:0.5340367555618286  \n","Epoch:30/50     Step:3|6   loss:0.5324045419692993  \n","Epoch:30/50     Step:4|6   loss:0.5788377523422241  \n","Epoch:30/50     Step:5|6   loss:0.547081708908081  \n","Epoch:30/50     Step:6|6   loss:0.5385381579399109  \n","Epoch:30/50     Step:7|6   loss:0.5193986892700195  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:31/50     Step:1|6   loss:0.5275000929832458  \n","Epoch:31/50     Step:2|6   loss:0.5452024936676025  \n","Epoch:31/50     Step:3|6   loss:0.5535901784896851  \n","Epoch:31/50     Step:4|6   loss:0.5581092238426208  \n","Epoch:31/50     Step:5|6   loss:0.5323640704154968  \n","Epoch:31/50     Step:6|6   loss:0.5349386930465698  \n","Epoch:31/50     Step:7|6   loss:0.5532121658325195  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:32/50     Step:1|6   loss:0.5287661552429199  \n","Epoch:32/50     Step:2|6   loss:0.546248733997345  \n","Epoch:32/50     Step:3|6   loss:0.5420398116111755  \n","Epoch:32/50     Step:4|6   loss:0.5582608580589294  \n","Epoch:32/50     Step:5|6   loss:0.5291021466255188  \n","Epoch:32/50     Step:6|6   loss:0.5422409176826477  \n","Epoch:32/50     Step:7|6   loss:0.5387703776359558  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:33/50     Step:1|6   loss:0.5462954044342041  \n","Epoch:33/50     Step:2|6   loss:0.5473157167434692  \n","Epoch:33/50     Step:3|6   loss:0.552991509437561  \n","Epoch:33/50     Step:4|6   loss:0.5601195096969604  \n","Epoch:33/50     Step:5|6   loss:0.5557045340538025  \n","Epoch:33/50     Step:6|6   loss:0.5594805479049683  \n","Epoch:33/50     Step:7|6   loss:0.5231649875640869  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:34/50     Step:1|6   loss:0.5341439247131348  \n","Epoch:34/50     Step:2|6   loss:0.5278770923614502  \n","Epoch:34/50     Step:3|6   loss:0.5459785461425781  \n","Epoch:34/50     Step:4|6   loss:0.5462086200714111  \n","Epoch:34/50     Step:5|6   loss:0.5395748615264893  \n","Epoch:34/50     Step:6|6   loss:0.5441949367523193  \n","Epoch:34/50     Step:7|6   loss:0.5385295748710632  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:35/50     Step:1|6   loss:0.549345076084137  \n","Epoch:35/50     Step:2|6   loss:0.5309875011444092  \n","Epoch:35/50     Step:3|6   loss:0.5675778985023499  \n","Epoch:35/50     Step:4|6   loss:0.5739603042602539  \n","Epoch:35/50     Step:5|6   loss:0.5387936234474182  \n","Epoch:35/50     Step:6|6   loss:0.5358896255493164  \n","Epoch:35/50     Step:7|6   loss:0.5245282053947449  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.5413972735404968  \n","Epoch:36/50     Step:2|6   loss:0.5440347790718079  \n","Epoch:36/50     Step:3|6   loss:0.5437970757484436  \n","Epoch:36/50     Step:4|6   loss:0.5412865281105042  \n","Epoch:36/50     Step:5|6   loss:0.5392298698425293  \n","Epoch:36/50     Step:6|6   loss:0.5389957427978516  \n","Epoch:36/50     Step:7|6   loss:0.562445342540741  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:37/50     Step:1|6   loss:0.5226967334747314  \n","Epoch:37/50     Step:2|6   loss:0.5403348207473755  \n","Epoch:37/50     Step:3|6   loss:0.5637882351875305  \n","Epoch:37/50     Step:4|6   loss:0.5274207592010498  \n","Epoch:37/50     Step:5|6   loss:0.5379126071929932  \n","Epoch:37/50     Step:6|6   loss:0.5456327199935913  \n","Epoch:37/50     Step:7|6   loss:0.5348168015480042  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:38/50     Step:1|6   loss:0.54879230260849  \n","Epoch:38/50     Step:2|6   loss:0.5262575745582581  \n","Epoch:38/50     Step:3|6   loss:0.5341602563858032  \n","Epoch:38/50     Step:4|6   loss:0.5617544651031494  \n","Epoch:38/50     Step:5|6   loss:0.5303895473480225  \n","Epoch:38/50     Step:6|6   loss:0.5328527092933655  \n","Epoch:38/50     Step:7|6   loss:0.554410457611084  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:39/50     Step:1|6   loss:0.5356455445289612  \n","Epoch:39/50     Step:2|6   loss:0.5629217624664307  \n","Epoch:39/50     Step:3|6   loss:0.5283889770507812  \n","Epoch:39/50     Step:4|6   loss:0.5511487722396851  \n","Epoch:39/50     Step:5|6   loss:0.5334909558296204  \n","Epoch:39/50     Step:6|6   loss:0.5439214706420898  \n","Epoch:39/50     Step:7|6   loss:0.5223238468170166  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:40/50     Step:1|6   loss:0.5296813249588013  \n","Epoch:40/50     Step:2|6   loss:0.5488112568855286  \n","Epoch:40/50     Step:3|6   loss:0.5244166254997253  \n","Epoch:40/50     Step:4|6   loss:0.5356147885322571  \n","Epoch:40/50     Step:5|6   loss:0.5346640348434448  \n","Epoch:40/50     Step:6|6   loss:0.5491920709609985  \n","Epoch:40/50     Step:7|6   loss:0.5416637063026428  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:41/50     Step:1|6   loss:0.5230536460876465  \n","Epoch:41/50     Step:2|6   loss:0.5344627499580383  \n","Epoch:41/50     Step:3|6   loss:0.5333399772644043  \n","Epoch:41/50     Step:4|6   loss:0.5259790420532227  \n","Epoch:41/50     Step:5|6   loss:0.5428079962730408  \n","Epoch:41/50     Step:6|6   loss:0.5448241233825684  \n","Epoch:41/50     Step:7|6   loss:0.5259434580802917  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:42/50     Step:1|6   loss:0.5218833088874817  \n","Epoch:42/50     Step:2|6   loss:0.5341698527336121  \n","Epoch:42/50     Step:3|6   loss:0.5500655770301819  \n","Epoch:42/50     Step:4|6   loss:0.526982307434082  \n","Epoch:42/50     Step:5|6   loss:0.51936274766922  \n","Epoch:42/50     Step:6|6   loss:0.547851026058197  \n","Epoch:42/50     Step:7|6   loss:0.5460231304168701  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:43/50     Step:1|6   loss:0.5386247038841248  \n","Epoch:43/50     Step:2|6   loss:0.5394289493560791  \n","Epoch:43/50     Step:3|6   loss:0.5308919548988342  \n","Epoch:43/50     Step:4|6   loss:0.5228757858276367  \n","Epoch:43/50     Step:5|6   loss:0.5297505855560303  \n","Epoch:43/50     Step:6|6   loss:0.5352578163146973  \n","Epoch:43/50     Step:7|6   loss:0.5268464684486389  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:44/50     Step:1|6   loss:0.5404862761497498  \n","Epoch:44/50     Step:2|6   loss:0.5450301766395569  \n","Epoch:44/50     Step:3|6   loss:0.5164234638214111  \n","3Epoch:44/50     Step:4|6   loss:0.5388501286506653  \n","Epoch:44/50     Step:5|6   loss:0.5249349474906921  \n","Epoch:44/50     Step:6|6   loss:0.5346412658691406  \n","Epoch:44/50     Step:7|6   loss:0.5606735348701477  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5380545854568481  \n","Epoch:45/50     Step:2|6   loss:0.5287854075431824  \n","Epoch:45/50     Step:3|6   loss:0.5325210094451904  \n","Epoch:45/50     Step:4|6   loss:0.5347841382026672  \n","Epoch:45/50     Step:5|6   loss:0.5370574593544006  \n","Epoch:45/50     Step:6|6   loss:0.5479708313941956  \n","Epoch:45/50     Step:7|6   loss:0.5128483176231384  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5224760174751282  \n","Epoch:46/50     Step:2|6   loss:0.5203176140785217  \n","Epoch:46/50     Step:3|6   loss:0.5283874273300171  \n","Epoch:46/50     Step:4|6   loss:0.5337958931922913  \n","Epoch:46/50     Step:5|6   loss:0.5495567321777344  \n","Epoch:46/50     Step:6|6   loss:0.5358092188835144  \n","Epoch:46/50     Step:7|6   loss:0.5438549518585205  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5232529640197754  \n","Epoch:47/50     Step:2|6   loss:0.558976411819458  \n","Epoch:47/50     Step:3|6   loss:0.5357685685157776  \n","Epoch:47/50     Step:4|6   loss:0.5706673860549927  \n","Epoch:47/50     Step:5|6   loss:0.5419154167175293  \n","Epoch:47/50     Step:6|6   loss:0.5366283059120178  \n","Epoch:47/50     Step:7|6   loss:0.5273545384407043  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.5300149321556091  \n","Epoch:48/50     Step:2|6   loss:0.5336335301399231  \n","Epoch:48/50     Step:3|6   loss:0.5288879871368408  \n","Epoch:48/50     Step:4|6   loss:0.5335297584533691  \n","Epoch:48/50     Step:5|6   loss:0.5257279276847839  \n","Epoch:48/50     Step:6|6   loss:0.5911825895309448  \n","Epoch:48/50     Step:7|6   loss:0.528333306312561  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5391168594360352  \n","Epoch:49/50     Step:2|6   loss:0.5339028239250183  \n","Epoch:49/50     Step:3|6   loss:0.5172041654586792  \n","Epoch:49/50     Step:4|6   loss:0.5353325605392456  \n","Epoch:49/50     Step:5|6   loss:0.54376620054245  \n","Epoch:49/50     Step:6|6   loss:0.524600625038147  \n","Epoch:49/50     Step:7|6   loss:0.5334095358848572  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5240605473518372  \n","Epoch:50/50     Step:2|6   loss:0.5303454995155334  \n","Epoch:50/50     Step:3|6   loss:0.5639674067497253  \n","Epoch:50/50     Step:4|6   loss:0.5493360757827759  \n","Epoch:50/50     Step:5|6   loss:0.5456848740577698  \n","Epoch:50/50     Step:6|6   loss:0.5238401889801025  \n","Epoch:50/50     Step:7|6   loss:0.5185189843177795  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","Namespace(EPOCH=50, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_two_stream(\n","  (stream1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (stream2): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=752640, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1087872982025146  \n","Epoch:1/50     Step:2|6   loss:2.4834706783294678  \n","Epoch:1/50     Step:3|6   loss:2.3606677055358887  \n","Epoch:1/50     Step:4|6   loss:2.3047478199005127  \n","Epoch:1/50     Step:5|6   loss:2.004483699798584  \n","Epoch:1/50     Step:6|6   loss:2.3109846115112305  \n","Epoch:1/50     Step:7|6   loss:1.895283818244934  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:42.06%\t train set:49.18%\n","Epoch:2/50     Step:1|6   loss:1.9181439876556396  \n","Epoch:2/50     Step:2|6   loss:2.21929669380188  \n","Epoch:2/50     Step:3|6   loss:1.936026930809021  \n","Epoch:2/50     Step:4|6   loss:2.0367910861968994  \n","Epoch:2/50     Step:5|6   loss:1.6007499694824219  \n","Epoch:2/50     Step:6|6   loss:1.73820161819458  \n","Epoch:2/50     Step:7|6   loss:1.9922999143600464  \n","Accuracy on test_set: 42.06 %\n","Accuracy on train_set: 49.18 %\n","current max accuracy\t test set:42.06%\t train set:49.18%\n","Epoch:3/50     Step:1|6   loss:1.7344123125076294  \n","Epoch:3/50     Step:2|6   loss:1.5011308193206787  \n","Epoch:3/50     Step:3|6   loss:1.4555567502975464  \n","Epoch:3/50     Step:4|6   loss:1.3075827360153198  \n","Epoch:3/50     Step:5|6   loss:1.4014976024627686  \n","Epoch:3/50     Step:6|6   loss:1.3157830238342285  \n","Epoch:3/50     Step:7|6   loss:1.256983995437622  \n","Accuracy on test_set: 64.49 %\n","Accuracy on train_set: 70.02 %\n","current max accuracy\t test set:64.49%\t train set:70.02%\n","Epoch:4/50     Step:1|6   loss:0.9553539156913757  \n","Epoch:4/50     Step:2|6   loss:0.873000979423523  \n","Epoch:4/50     Step:3|6   loss:0.8702101707458496  \n","Epoch:4/50     Step:4|6   loss:1.0003588199615479  \n","Epoch:4/50     Step:5|6   loss:0.8921867609024048  \n","Epoch:4/50     Step:6|6   loss:0.8008207082748413  \n","Epoch:4/50     Step:7|6   loss:0.7482931017875671  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 81.50 %\n","current max accuracy\t test set:79.44%\t train set:81.5%\n","Epoch:5/50     Step:1|6   loss:0.7622973918914795  \n","Epoch:5/50     Step:2|6   loss:0.8250775933265686  \n","Epoch:5/50     Step:3|6   loss:0.7613121271133423  \n","Epoch:5/50     Step:4|6   loss:0.7893926501274109  \n","Epoch:5/50     Step:5|6   loss:0.7704002261161804  \n","Epoch:5/50     Step:6|6   loss:0.7223663330078125  \n","Epoch:5/50     Step:7|6   loss:0.7521967887878418  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 81.26 %\n","current max accuracy\t test set:79.44%\t train set:81.5%\n","Epoch:6/50     Step:1|6   loss:0.8468105792999268  \n","Epoch:6/50     Step:2|6   loss:0.678546667098999  \n","Epoch:6/50     Step:3|6   loss:0.6704984903335571  \n","Epoch:6/50     Step:4|6   loss:0.7606807947158813  \n","Epoch:6/50     Step:5|6   loss:0.7032899856567383  \n","Epoch:6/50     Step:6|6   loss:0.8075729608535767  \n","Epoch:6/50     Step:7|6   loss:0.6873875260353088  \n","Accuracy on test_set: 81.31 %\n","Accuracy on train_set: 85.71 %\n","current max accuracy\t test set:81.31%\t train set:85.71%\n","Epoch:7/50     Step:1|6   loss:0.7371408939361572  \n","Epoch:7/50     Step:2|6   loss:0.6919369697570801  \n","Epoch:7/50     Step:3|6   loss:0.7404532432556152  \n","Epoch:7/50     Step:4|6   loss:0.724994421005249  \n","Epoch:7/50     Step:5|6   loss:0.7078726887702942  \n","Epoch:7/50     Step:6|6   loss:0.7283792495727539  \n","Epoch:7/50     Step:7|6   loss:0.7003854513168335  \n","Accuracy on test_set: 86.92 %\n","Accuracy on train_set: 88.52 %\n","current max accuracy\t test set:86.92%\t train set:88.52%\n","Epoch:8/50     Step:1|6   loss:0.7054300308227539  \n","Epoch:8/50     Step:2|6   loss:0.6665914058685303  \n","Epoch:8/50     Step:3|6   loss:0.6786116361618042  \n","Epoch:8/50     Step:4|6   loss:0.6801124811172485  \n","Epoch:8/50     Step:5|6   loss:0.6894651651382446  \n","Epoch:8/50     Step:6|6   loss:0.7636823654174805  \n","Epoch:8/50     Step:7|6   loss:0.6881160736083984  \n","Accuracy on test_set: 82.24 %\n","Accuracy on train_set: 87.82 %\n","current max accuracy\t test set:86.92%\t train set:88.52%\n","Epoch:9/50     Step:1|6   loss:0.6746722459793091  \n","Epoch:9/50     Step:2|6   loss:0.747272253036499  \n","Epoch:9/50     Step:3|6   loss:0.6838728189468384  \n","Epoch:9/50     Step:4|6   loss:0.6962488889694214  \n","Epoch:9/50     Step:5|6   loss:0.6808160543441772  \n","Epoch:9/50     Step:6|6   loss:0.7076806426048279  \n","Epoch:9/50     Step:7|6   loss:0.6895438432693481  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 90.16 %\n","current max accuracy\t test set:86.92%\t train set:90.16%\n","Epoch:10/50     Step:1|6   loss:0.656699538230896  \n","Epoch:10/50     Step:2|6   loss:0.6699643731117249  \n","Epoch:10/50     Step:3|6   loss:0.7121413350105286  \n","Epoch:10/50     Step:4|6   loss:0.6461745500564575  \n","Epoch:10/50     Step:5|6   loss:0.6802879571914673  \n","Epoch:10/50     Step:6|6   loss:0.7008038759231567  \n","Epoch:10/50     Step:7|6   loss:0.6757980585098267  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 92.04 %\n","current max accuracy\t test set:87.85%\t train set:92.04%\n","Epoch:11/50     Step:1|6   loss:0.649988055229187  \n","Epoch:11/50     Step:2|6   loss:0.6696540117263794  \n","Epoch:11/50     Step:3|6   loss:0.6095624566078186  \n","Epoch:11/50     Step:4|6   loss:0.6377485990524292  \n","Epoch:11/50     Step:5|6   loss:0.6635195016860962  \n","Epoch:11/50     Step:6|6   loss:0.6684455275535583  \n","Epoch:11/50     Step:7|6   loss:0.6195247769355774  \n","Accuracy on test_set: 90.65 %\n","Accuracy on train_set: 93.21 %\n","current max accuracy\t test set:90.65%\t train set:93.21%\n","Epoch:12/50     Step:1|6   loss:0.6682021021842957  \n","Epoch:12/50     Step:2|6   loss:0.6245512962341309  \n","Epoch:12/50     Step:3|6   loss:0.6795961856842041  \n","Epoch:12/50     Step:4|6   loss:0.681492805480957  \n","Epoch:12/50     Step:5|6   loss:0.6718230843544006  \n","Epoch:12/50     Step:6|6   loss:0.613117516040802  \n","Epoch:12/50     Step:7|6   loss:0.5979302525520325  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:95.78%\n","Epoch:13/50     Step:1|6   loss:0.5955988764762878  \n","Epoch:13/50     Step:2|6   loss:0.6571493148803711  \n","Epoch:13/50     Step:3|6   loss:0.6202743053436279  \n","Epoch:13/50     Step:4|6   loss:0.6200745701789856  \n","Epoch:13/50     Step:5|6   loss:0.5864245891571045  \n","Epoch:13/50     Step:6|6   loss:0.6740108728408813  \n","Epoch:13/50     Step:7|6   loss:0.5704678297042847  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:98.13%\t train set:95.78%\n","Epoch:14/50     Step:1|6   loss:0.6041742563247681  \n","Epoch:14/50     Step:2|6   loss:0.6157810688018799  \n","Epoch:14/50     Step:3|6   loss:0.6352277994155884  \n","Epoch:14/50     Step:4|6   loss:0.6180654764175415  \n","Epoch:14/50     Step:5|6   loss:0.5835925340652466  \n","Epoch:14/50     Step:6|6   loss:0.611807107925415  \n","Epoch:14/50     Step:7|6   loss:0.6384971141815186  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:98.13%\t train set:95.78%\n","Epoch:15/50     Step:1|6   loss:0.5931557416915894  \n","Epoch:15/50     Step:2|6   loss:0.6296437978744507  \n","Epoch:15/50     Step:3|6   loss:0.59194415807724  \n","Epoch:15/50     Step:4|6   loss:0.587398111820221  \n","Epoch:15/50     Step:5|6   loss:0.587989866733551  \n","Epoch:15/50     Step:6|6   loss:0.5853862762451172  \n","Epoch:15/50     Step:7|6   loss:0.5594601035118103  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:98.13%\t train set:95.78%\n","Epoch:16/50     Step:1|6   loss:0.5767101645469666  \n","Epoch:16/50     Step:2|6   loss:0.5950878262519836  \n","Epoch:16/50     Step:3|6   loss:0.6178231239318848  \n","Epoch:16/50     Step:4|6   loss:0.6033453941345215  \n","Epoch:16/50     Step:5|6   loss:0.5623582601547241  \n","Epoch:16/50     Step:6|6   loss:0.6018769145011902  \n","Epoch:16/50     Step:7|6   loss:0.58089679479599  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:98.13%\t train set:97.19%\n","Epoch:17/50     Step:1|6   loss:0.5740357041358948  \n","Epoch:17/50     Step:2|6   loss:0.5475883483886719  \n","Epoch:17/50     Step:3|6   loss:0.5901716947555542  \n","Epoch:17/50     Step:4|6   loss:0.5589392781257629  \n","Epoch:17/50     Step:5|6   loss:0.5667839050292969  \n","Epoch:17/50     Step:6|6   loss:0.5949020385742188  \n","Epoch:17/50     Step:7|6   loss:0.5793649554252625  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:98.13%\t train set:98.13%\n","Epoch:18/50     Step:1|6   loss:0.5674129128456116  \n","Epoch:18/50     Step:2|6   loss:0.603320300579071  \n","Epoch:18/50     Step:3|6   loss:0.5571287870407104  \n","Epoch:18/50     Step:4|6   loss:0.5938740372657776  \n","Epoch:18/50     Step:5|6   loss:0.5809772610664368  \n","Epoch:18/50     Step:6|6   loss:0.5662790536880493  \n","Epoch:18/50     Step:7|6   loss:0.5653815269470215  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:19/50     Step:1|6   loss:0.5467832088470459  \n","Epoch:19/50     Step:2|6   loss:0.568480908870697  \n","Epoch:19/50     Step:3|6   loss:0.5583516955375671  \n","Epoch:19/50     Step:4|6   loss:0.5641840100288391  \n","Epoch:19/50     Step:5|6   loss:0.5570077896118164  \n","Epoch:19/50     Step:6|6   loss:0.5433705449104309  \n","Epoch:19/50     Step:7|6   loss:0.5640284419059753  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:20/50     Step:1|6   loss:0.598894476890564  \n","Epoch:20/50     Step:2|6   loss:0.5613797903060913  \n","Epoch:20/50     Step:3|6   loss:0.532311201095581  \n","Epoch:20/50     Step:4|6   loss:0.5390766859054565  \n","Epoch:20/50     Step:5|6   loss:0.5760977268218994  \n","Epoch:20/50     Step:6|6   loss:0.535591721534729  \n","Epoch:20/50     Step:7|6   loss:0.5741100907325745  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:21/50     Step:1|6   loss:0.5325236916542053  \n","Epoch:21/50     Step:2|6   loss:0.5708912014961243  \n","Epoch:21/50     Step:3|6   loss:0.5804536938667297  \n","Epoch:21/50     Step:4|6   loss:0.5311231017112732  \n","Epoch:21/50     Step:5|6   loss:0.5908260941505432  \n","Epoch:21/50     Step:6|6   loss:0.5553689002990723  \n","Epoch:21/50     Step:7|6   loss:0.5400086045265198  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:99.07%\t train set:99.06%\n","Epoch:22/50     Step:1|6   loss:0.5341148376464844  \n","Epoch:22/50     Step:2|6   loss:0.563710629940033  \n","Epoch:22/50     Step:3|6   loss:0.5471722483634949  \n","Epoch:22/50     Step:4|6   loss:0.5779885649681091  \n","Epoch:22/50     Step:5|6   loss:0.5456275939941406  \n","Epoch:22/50     Step:6|6   loss:0.5282548666000366  \n","Epoch:22/50     Step:7|6   loss:0.5321927070617676  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:23/50     Step:1|6   loss:0.5668246746063232  \n","Epoch:23/50     Step:2|6   loss:0.5819969773292542  \n","Epoch:23/50     Step:3|6   loss:0.5808830261230469  \n","Epoch:23/50     Step:4|6   loss:0.534040093421936  \n","Epoch:23/50     Step:5|6   loss:0.5547102093696594  \n","Epoch:23/50     Step:6|6   loss:0.5451257228851318  \n","Epoch:23/50     Step:7|6   loss:0.5583537220954895  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:24/50     Step:1|6   loss:0.5365327596664429  \n","Epoch:24/50     Step:2|6   loss:0.5287650227546692  \n","Epoch:24/50     Step:3|6   loss:0.5513588786125183  \n","Epoch:24/50     Step:4|6   loss:0.5550010800361633  \n","Epoch:24/50     Step:5|6   loss:0.5496566295623779  \n","Epoch:24/50     Step:6|6   loss:0.530942440032959  \n","Epoch:24/50     Step:7|6   loss:0.5543370246887207  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:25/50     Step:1|6   loss:0.5395009517669678  \n","Epoch:25/50     Step:2|6   loss:0.5790755748748779  \n","Epoch:25/50     Step:3|6   loss:0.5438529253005981  \n","Epoch:25/50     Step:4|6   loss:0.5433667898178101  \n","Epoch:25/50     Step:5|6   loss:0.5324259996414185  \n","Epoch:25/50     Step:6|6   loss:0.5610899925231934  \n","Epoch:25/50     Step:7|6   loss:0.5292460918426514  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:26/50     Step:1|6   loss:0.5559839010238647  \n","Epoch:26/50     Step:2|6   loss:0.5280368328094482  \n","Epoch:26/50     Step:3|6   loss:0.5305494666099548  \n","Epoch:26/50     Step:4|6   loss:0.5536278486251831  \n","Epoch:26/50     Step:5|6   loss:0.5322365164756775  \n","Epoch:26/50     Step:6|6   loss:0.5371388792991638  \n","Epoch:26/50     Step:7|6   loss:0.5732975602149963  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:27/50     Step:1|6   loss:0.5595496892929077  \n","Epoch:27/50     Step:2|6   loss:0.534797191619873  \n","Epoch:27/50     Step:3|6   loss:0.5374464988708496  \n","Epoch:27/50     Step:4|6   loss:0.537859320640564  \n","Epoch:27/50     Step:5|6   loss:0.5284276604652405  \n","Epoch:27/50     Step:6|6   loss:0.5402750372886658  \n","Epoch:27/50     Step:7|6   loss:0.5613347887992859  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.06 %\n","4\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:28/50     Step:1|6   loss:0.525435209274292  \n","Epoch:28/50     Step:2|6   loss:0.5280979871749878  \n","Epoch:28/50     Step:3|6   loss:0.5368969440460205  \n","Epoch:28/50     Step:4|6   loss:0.5591009259223938  \n","Epoch:28/50     Step:5|6   loss:0.5491114258766174  \n","Epoch:28/50     Step:6|6   loss:0.5477692484855652  \n","Epoch:28/50     Step:7|6   loss:0.5266536474227905  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.3%\n","Epoch:29/50     Step:1|6   loss:0.5528466701507568  \n","Epoch:29/50     Step:2|6   loss:0.5394695997238159  \n","Epoch:29/50     Step:3|6   loss:0.5322891473770142  \n","Epoch:29/50     Step:4|6   loss:0.542387068271637  \n","Epoch:29/50     Step:5|6   loss:0.5187716484069824  \n","Epoch:29/50     Step:6|6   loss:0.523834228515625  \n","Epoch:29/50     Step:7|6   loss:0.5535414218902588  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:30/50     Step:1|6   loss:0.5334140658378601  \n","Epoch:30/50     Step:2|6   loss:0.5550134181976318  \n","Epoch:30/50     Step:3|6   loss:0.5175316333770752  \n","Epoch:30/50     Step:4|6   loss:0.5378673672676086  \n","Epoch:30/50     Step:5|6   loss:0.5268230438232422  \n","Epoch:30/50     Step:6|6   loss:0.5262190103530884  \n","Epoch:30/50     Step:7|6   loss:0.5673571228981018  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:99.07%\t train set:99.53%\n","Epoch:31/50     Step:1|6   loss:0.532897412776947  \n","Epoch:31/50     Step:2|6   loss:0.5214464664459229  \n","Epoch:31/50     Step:3|6   loss:0.5288556218147278  \n","Epoch:31/50     Step:4|6   loss:0.5257282257080078  \n","Epoch:31/50     Step:5|6   loss:0.531974196434021  \n","Epoch:31/50     Step:6|6   loss:0.5267820358276367  \n","Epoch:31/50     Step:7|6   loss:0.5643135905265808  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:32/50     Step:1|6   loss:0.5333598852157593  \n","Epoch:32/50     Step:2|6   loss:0.5366501808166504  \n","Epoch:32/50     Step:3|6   loss:0.5221329927444458  \n","Epoch:32/50     Step:4|6   loss:0.5510828495025635  \n","Epoch:32/50     Step:5|6   loss:0.5496681928634644  \n","Epoch:32/50     Step:6|6   loss:0.5283844470977783  \n","Epoch:32/50     Step:7|6   loss:0.5252431631088257  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:33/50     Step:1|6   loss:0.5331266522407532  \n","Epoch:33/50     Step:2|6   loss:0.5358749628067017  \n","Epoch:33/50     Step:3|6   loss:0.552470862865448  \n","Epoch:33/50     Step:4|6   loss:0.5184104442596436  \n","Epoch:33/50     Step:5|6   loss:0.5318347811698914  \n","Epoch:33/50     Step:6|6   loss:0.5200537443161011  \n","Epoch:33/50     Step:7|6   loss:0.5402377843856812  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:34/50     Step:1|6   loss:0.5446066856384277  \n","Epoch:34/50     Step:2|6   loss:0.5522763133049011  \n","Epoch:34/50     Step:3|6   loss:0.5556893944740295  \n","Epoch:34/50     Step:4|6   loss:0.5170156359672546  \n","Epoch:34/50     Step:5|6   loss:0.523033857345581  \n","Epoch:34/50     Step:6|6   loss:0.5355556011199951  \n","Epoch:34/50     Step:7|6   loss:0.528792679309845  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:35/50     Step:1|6   loss:0.5261342525482178  \n","Epoch:35/50     Step:2|6   loss:0.5392305850982666  \n","Epoch:35/50     Step:3|6   loss:0.5228059887886047  \n","Epoch:35/50     Step:4|6   loss:0.5328902006149292  \n","Epoch:35/50     Step:5|6   loss:0.5420188903808594  \n","Epoch:35/50     Step:6|6   loss:0.5570367574691772  \n","Epoch:35/50     Step:7|6   loss:0.5314386487007141  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:36/50     Step:1|6   loss:0.531872034072876  \n","Epoch:36/50     Step:2|6   loss:0.5210665464401245  \n","Epoch:36/50     Step:3|6   loss:0.535054624080658  \n","Epoch:36/50     Step:4|6   loss:0.5335384607315063  \n","Epoch:36/50     Step:5|6   loss:0.5171225070953369  \n","Epoch:36/50     Step:6|6   loss:0.5251482129096985  \n","Epoch:36/50     Step:7|6   loss:0.5360504984855652  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:37/50     Step:1|6   loss:0.5152418613433838  \n","Epoch:37/50     Step:2|6   loss:0.5538917779922485  \n","Epoch:37/50     Step:3|6   loss:0.5550306439399719  \n","Epoch:37/50     Step:4|6   loss:0.5472402572631836  \n","Epoch:37/50     Step:5|6   loss:0.52239990234375  \n","Epoch:37/50     Step:6|6   loss:0.527201771736145  \n","Epoch:37/50     Step:7|6   loss:0.5277127623558044  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:38/50     Step:1|6   loss:0.5412619113922119  \n","Epoch:38/50     Step:2|6   loss:0.530759334564209  \n","Epoch:38/50     Step:3|6   loss:0.536609411239624  \n","Epoch:38/50     Step:4|6   loss:0.5296845436096191  \n","Epoch:38/50     Step:5|6   loss:0.5200471878051758  \n","Epoch:38/50     Step:6|6   loss:0.5236440300941467  \n","Epoch:38/50     Step:7|6   loss:0.5255241394042969  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:39/50     Step:1|6   loss:0.5260407328605652  \n","Epoch:39/50     Step:2|6   loss:0.5213240385055542  \n","Epoch:39/50     Step:3|6   loss:0.523235559463501  \n","Epoch:39/50     Step:4|6   loss:0.5394530296325684  \n","Epoch:39/50     Step:5|6   loss:0.5245465040206909  \n","Epoch:39/50     Step:6|6   loss:0.5248730182647705  \n","Epoch:39/50     Step:7|6   loss:0.5400023460388184  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:40/50     Step:1|6   loss:0.5256924629211426  \n","Epoch:40/50     Step:2|6   loss:0.5296784043312073  \n","Epoch:40/50     Step:3|6   loss:0.5395484566688538  \n","Epoch:40/50     Step:4|6   loss:0.5280580520629883  \n","Epoch:40/50     Step:5|6   loss:0.5211533308029175  \n","Epoch:40/50     Step:6|6   loss:0.5323787331581116  \n","Epoch:40/50     Step:7|6   loss:0.5171350836753845  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:41/50     Step:1|6   loss:0.5206384062767029  \n","Epoch:41/50     Step:2|6   loss:0.5260627865791321  \n","Epoch:41/50     Step:3|6   loss:0.5233202576637268  \n","Epoch:41/50     Step:4|6   loss:0.5207056999206543  \n","Epoch:41/50     Step:5|6   loss:0.5391947031021118  \n","Epoch:41/50     Step:6|6   loss:0.516810953617096  \n","Epoch:41/50     Step:7|6   loss:0.5239530801773071  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:42/50     Step:1|6   loss:0.5232834815979004  \n","Epoch:42/50     Step:2|6   loss:0.51129549741745  \n","Epoch:42/50     Step:3|6   loss:0.5431599617004395  \n","Epoch:42/50     Step:4|6   loss:0.524586021900177  \n","Epoch:42/50     Step:5|6   loss:0.5213101506233215  \n","Epoch:42/50     Step:6|6   loss:0.5239899754524231  \n","Epoch:42/50     Step:7|6   loss:0.5335426330566406  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:43/50     Step:1|6   loss:0.5269976258277893  \n","Epoch:43/50     Step:2|6   loss:0.5160289406776428  \n","Epoch:43/50     Step:3|6   loss:0.5243439674377441  \n","Epoch:43/50     Step:4|6   loss:0.5411907434463501  \n","Epoch:43/50     Step:5|6   loss:0.5260784029960632  \n","Epoch:43/50     Step:6|6   loss:0.5213186144828796  \n","Epoch:43/50     Step:7|6   loss:0.5158056020736694  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:44/50     Step:1|6   loss:0.5499555468559265  \n","Epoch:44/50     Step:2|6   loss:0.5350571870803833  \n","Epoch:44/50     Step:3|6   loss:0.5293434262275696  \n","Epoch:44/50     Step:4|6   loss:0.5315722227096558  \n","Epoch:44/50     Step:5|6   loss:0.5181264281272888  \n","Epoch:44/50     Step:6|6   loss:0.5217578411102295  \n","Epoch:44/50     Step:7|6   loss:0.5343003869056702  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:45/50     Step:1|6   loss:0.5193214416503906  \n","Epoch:45/50     Step:2|6   loss:0.536984920501709  \n","Epoch:45/50     Step:3|6   loss:0.5219029784202576  \n","Epoch:45/50     Step:4|6   loss:0.528785765171051  \n","Epoch:45/50     Step:5|6   loss:0.5216432809829712  \n","Epoch:45/50     Step:6|6   loss:0.537582278251648  \n","Epoch:45/50     Step:7|6   loss:0.544337272644043  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:46/50     Step:1|6   loss:0.5258482098579407  \n","Epoch:46/50     Step:2|6   loss:0.5183951258659363  \n","Epoch:46/50     Step:3|6   loss:0.5291458368301392  \n","Epoch:46/50     Step:4|6   loss:0.5222722291946411  \n","Epoch:46/50     Step:5|6   loss:0.5327800512313843  \n","Epoch:46/50     Step:6|6   loss:0.5202925205230713  \n","Epoch:46/50     Step:7|6   loss:0.5248222351074219  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:47/50     Step:1|6   loss:0.5265570878982544  \n","Epoch:47/50     Step:2|6   loss:0.5172527432441711  \n","Epoch:47/50     Step:3|6   loss:0.5472248792648315  \n","Epoch:47/50     Step:4|6   loss:0.5184276700019836  \n","Epoch:47/50     Step:5|6   loss:0.5210407376289368  \n","Epoch:47/50     Step:6|6   loss:0.5205443501472473  \n","Epoch:47/50     Step:7|6   loss:0.5198439955711365  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:48/50     Step:1|6   loss:0.5277374982833862  \n","Epoch:48/50     Step:2|6   loss:0.5235385894775391  \n","Epoch:48/50     Step:3|6   loss:0.5279772281646729  \n","Epoch:48/50     Step:4|6   loss:0.5253570675849915  \n","Epoch:48/50     Step:5|6   loss:0.5362992286682129  \n","Epoch:48/50     Step:6|6   loss:0.5218734741210938  \n","Epoch:48/50     Step:7|6   loss:0.5177639722824097  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:49/50     Step:1|6   loss:0.5240458250045776  \n","Epoch:49/50     Step:2|6   loss:0.516033947467804  \n","Epoch:49/50     Step:3|6   loss:0.523063063621521  \n","Epoch:49/50     Step:4|6   loss:0.5235992074012756  \n","Epoch:49/50     Step:5|6   loss:0.536736011505127  \n","Epoch:49/50     Step:6|6   loss:0.5210384726524353  \n","Epoch:49/50     Step:7|6   loss:0.5316360592842102  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:50/50     Step:1|6   loss:0.5358228087425232  \n","Epoch:50/50     Step:2|6   loss:0.5400176048278809  \n","Epoch:50/50     Step:3|6   loss:0.5145223140716553  \n","Epoch:50/50     Step:4|6   loss:0.5233519077301025  \n","Epoch:50/50     Step:5|6   loss:0.5185843706130981  \n","Epoch:50/50     Step:6|6   loss:0.5299454927444458  \n","Epoch:50/50     Step:7|6   loss:0.5214352011680603  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=50, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='LeNet5_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","LeNet5_two_stream(\n","  (stream1): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (stream2): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=752640, out_features=84, bias=True)\n","    (1): Tanh()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=84, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/50     Step:1|6   loss:1.1218576431274414  \n","Epoch:1/50     Step:2|6   loss:2.7941083908081055  \n","Epoch:1/50     Step:3|6   loss:2.551175117492676  \n","Epoch:1/50     Step:4|6   loss:2.142754554748535  \n","Epoch:1/50     Step:5|6   loss:2.7185683250427246  \n","Epoch:1/50     Step:6|6   loss:2.4650509357452393  \n","Epoch:1/50     Step:7|6   loss:2.0589470863342285  \n","Accuracy on test_set: 37.38 %\n","Accuracy on train_set: 43.09 %\n","current max accuracy\t test set:37.38%\t train set:43.09%\n","Epoch:2/50     Step:1|6   loss:2.1443002223968506  \n","Epoch:2/50     Step:2|6   loss:2.1183228492736816  \n","Epoch:2/50     Step:3|6   loss:2.2052736282348633  \n","Epoch:2/50     Step:4|6   loss:2.0645101070404053  \n","Epoch:2/50     Step:5|6   loss:2.07169771194458  \n","Epoch:2/50     Step:6|6   loss:1.9613381624221802  \n","Epoch:2/50     Step:7|6   loss:2.1386048793792725  \n","Accuracy on test_set: 37.38 %\n","Accuracy on train_set: 43.09 %\n","current max accuracy\t test set:37.38%\t train set:43.09%\n","Epoch:3/50     Step:1|6   loss:2.0792276859283447  \n","Epoch:3/50     Step:2|6   loss:2.17970871925354  \n","Epoch:3/50     Step:3|6   loss:2.0773491859436035  \n","Epoch:3/50     Step:4|6   loss:1.9368783235549927  \n","Epoch:3/50     Step:5|6   loss:1.795257806777954  \n","Epoch:3/50     Step:6|6   loss:1.5953028202056885  \n","Epoch:3/50     Step:7|6   loss:1.6724950075149536  \n","Accuracy on test_set: 37.38 %\n","Accuracy on train_set: 43.09 %\n","current max accuracy\t test set:37.38%\t train set:43.09%\n","Epoch:4/50     Step:1|6   loss:1.7481765747070312  \n","Epoch:4/50     Step:2|6   loss:1.6832984685897827  \n","Epoch:4/50     Step:3|6   loss:1.6981862783432007  \n","Epoch:4/50     Step:4|6   loss:1.3950839042663574  \n","Epoch:4/50     Step:5|6   loss:1.3825438022613525  \n","Epoch:4/50     Step:6|6   loss:1.6669397354125977  \n","Epoch:4/50     Step:7|6   loss:1.4404569864273071  \n","Accuracy on test_set: 57.94 %\n","Accuracy on train_set: 61.59 %\n","current max accuracy\t test set:57.94%\t train set:61.59%\n","Epoch:5/50     Step:1|6   loss:1.1772116422653198  \n","Epoch:5/50     Step:2|6   loss:1.4436566829681396  \n","Epoch:5/50     Step:3|6   loss:1.417041540145874  \n","Epoch:5/50     Step:4|6   loss:1.3932828903198242  \n","Epoch:5/50     Step:5|6   loss:1.3283331394195557  \n","Epoch:5/50     Step:6|6   loss:1.2281934022903442  \n","Epoch:5/50     Step:7|6   loss:1.2389267683029175  \n","Accuracy on test_set: 70.09 %\n","Accuracy on train_set: 73.07 %\n","current max accuracy\t test set:70.09%\t train set:73.07%\n","Epoch:6/50     Step:1|6   loss:1.188194751739502  \n","Epoch:6/50     Step:2|6   loss:0.9464037418365479  \n","Epoch:6/50     Step:3|6   loss:0.9884146451950073  \n","Epoch:6/50     Step:4|6   loss:1.0307079553604126  \n","Epoch:6/50     Step:5|6   loss:0.9899190664291382  \n","Epoch:6/50     Step:6|6   loss:0.951575517654419  \n","Epoch:6/50     Step:7|6   loss:0.8434927463531494  \n","Accuracy on test_set: 79.44 %\n","Accuracy on train_set: 80.80 %\n","current max accuracy\t test set:79.44%\t train set:80.8%\n","Epoch:7/50     Step:1|6   loss:0.8718312978744507  \n","Epoch:7/50     Step:2|6   loss:0.8825353384017944  \n","Epoch:7/50     Step:3|6   loss:0.8452906608581543  \n","Epoch:7/50     Step:4|6   loss:0.8330942392349243  \n","Epoch:7/50     Step:5|6   loss:0.8246339559555054  \n","Epoch:7/50     Step:6|6   loss:0.8350228667259216  \n","Epoch:7/50     Step:7|6   loss:0.7836189270019531  \n","Accuracy on test_set: 78.50 %\n","Accuracy on train_set: 81.50 %\n","current max accuracy\t test set:79.44%\t train set:81.5%\n","Epoch:8/50     Step:1|6   loss:0.8270914554595947  \n","Epoch:8/50     Step:2|6   loss:0.8006439805030823  \n","Epoch:8/50     Step:3|6   loss:0.8136212825775146  \n","Epoch:8/50     Step:4|6   loss:0.8329721689224243  \n","Epoch:8/50     Step:5|6   loss:0.8143978118896484  \n","Epoch:8/50     Step:6|6   loss:0.7563163042068481  \n","Epoch:8/50     Step:7|6   loss:0.8460859060287476  \n","Accuracy on test_set: 83.18 %\n","Accuracy on train_set: 87.12 %\n","current max accuracy\t test set:83.18%\t train set:87.12%\n","Epoch:9/50     Step:1|6   loss:0.8159193992614746  \n","Epoch:9/50     Step:2|6   loss:0.7499898672103882  \n","Epoch:9/50     Step:3|6   loss:0.7980564832687378  \n","Epoch:9/50     Step:4|6   loss:0.7477716207504272  \n","Epoch:9/50     Step:5|6   loss:0.8039834499359131  \n","Epoch:9/50     Step:6|6   loss:0.8435598015785217  \n","Epoch:9/50     Step:7|6   loss:0.7968366146087646  \n","Accuracy on test_set: 87.85 %\n","Accuracy on train_set: 91.57 %\n","current max accuracy\t test set:87.85%\t train set:91.57%\n","Epoch:10/50     Step:1|6   loss:0.7819303274154663  \n","Epoch:10/50     Step:2|6   loss:0.7228401899337769  \n","Epoch:10/50     Step:3|6   loss:0.6497141122817993  \n","Epoch:10/50     Step:4|6   loss:0.7716614007949829  \n","Epoch:10/50     Step:5|6   loss:0.7891762256622314  \n","Epoch:10/50     Step:6|6   loss:0.68186354637146  \n","Epoch:10/50     Step:7|6   loss:0.6980161666870117  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 94.61 %\n","current max accuracy\t test set:91.59%\t train set:94.61%\n","Epoch:11/50     Step:1|6   loss:0.7185527682304382  \n","Epoch:11/50     Step:2|6   loss:0.750743567943573  \n","Epoch:11/50     Step:3|6   loss:0.7525139451026917  \n","Epoch:11/50     Step:4|6   loss:0.7308807373046875  \n","Epoch:11/50     Step:5|6   loss:0.6868147253990173  \n","Epoch:11/50     Step:6|6   loss:0.640613317489624  \n","Epoch:11/50     Step:7|6   loss:0.664247453212738  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 95.32 %\n","current max accuracy\t test set:92.52%\t train set:95.32%\n","Epoch:12/50     Step:1|6   loss:0.7388327717781067  \n","Epoch:12/50     Step:2|6   loss:0.6535040140151978  \n","Epoch:12/50     Step:3|6   loss:0.6896889209747314  \n","Epoch:12/50     Step:4|6   loss:0.6826212406158447  \n","Epoch:12/50     Step:5|6   loss:0.7131606340408325  \n","Epoch:12/50     Step:6|6   loss:0.6648542284965515  \n","Epoch:12/50     Step:7|6   loss:0.7489853501319885  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:96.02%\n","Epoch:13/50     Step:1|6   loss:0.7273064851760864  \n","Epoch:13/50     Step:2|6   loss:0.6788286566734314  \n","Epoch:13/50     Step:3|6   loss:0.691676676273346  \n","Epoch:13/50     Step:4|6   loss:0.6648269891738892  \n","Epoch:13/50     Step:5|6   loss:0.7180215120315552  \n","Epoch:13/50     Step:6|6   loss:0.6804410219192505  \n","Epoch:13/50     Step:7|6   loss:0.675380289554596  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 96.25 %\n","current max accuracy\t test set:94.39%\t train set:96.25%\n","Epoch:14/50     Step:1|6   loss:0.6747217178344727  \n","Epoch:14/50     Step:2|6   loss:0.660103440284729  \n","Epoch:14/50     Step:3|6   loss:0.6514469385147095  \n","Epoch:14/50     Step:4|6   loss:0.6549131870269775  \n","Epoch:14/50     Step:5|6   loss:0.6504288911819458  \n","Epoch:14/50     Step:6|6   loss:0.656612753868103  \n","Epoch:14/50     Step:7|6   loss:0.6757687926292419  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.19 %\n","current max accuracy\t test set:94.39%\t train set:97.19%\n","Epoch:15/50     Step:1|6   loss:0.6212488412857056  \n","Epoch:15/50     Step:2|6   loss:0.6473046541213989  \n","Epoch:15/50     Step:3|6   loss:0.6598913669586182  \n","Epoch:15/50     Step:4|6   loss:0.6249780654907227  \n","Epoch:15/50     Step:5|6   loss:0.6262984275817871  \n","Epoch:15/50     Step:6|6   loss:0.7383678555488586  \n","Epoch:15/50     Step:7|6   loss:0.6526303291320801  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 96.02 %\n","current max accuracy\t test set:94.39%\t train set:97.19%\n","Epoch:16/50     Step:1|6   loss:0.6012086868286133  \n","Epoch:16/50     Step:2|6   loss:0.6196272373199463  \n","Epoch:16/50     Step:3|6   loss:0.6279634237289429  \n","Epoch:16/50     Step:4|6   loss:0.6206644773483276  \n","Epoch:16/50     Step:5|6   loss:0.6086049675941467  \n","Epoch:16/50     Step:6|6   loss:0.5763933658599854  \n","Epoch:16/50     Step:7|6   loss:0.7161361575126648  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 96.96 %\n","current max accuracy\t test set:95.33%\t train set:97.19%\n","Epoch:17/50     Step:1|6   loss:0.592876136302948  \n","Epoch:17/50     Step:2|6   loss:0.6113543510437012  \n","Epoch:17/50     Step:3|6   loss:0.6060343980789185  \n","Epoch:17/50     Step:4|6   loss:0.5744873285293579  \n","Epoch:17/50     Step:5|6   loss:0.6074237823486328  \n","Epoch:17/50     Step:6|6   loss:0.5946916341781616  \n","Epoch:17/50     Step:7|6   loss:0.5929878950119019  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:95.33%\t train set:97.42%\n","Epoch:18/50     Step:1|6   loss:0.5954873561859131  \n","Epoch:18/50     Step:2|6   loss:0.5876652598381042  \n","Epoch:18/50     Step:3|6   loss:0.5811405777931213  \n","Epoch:18/50     Step:4|6   loss:0.5819497108459473  \n","Epoch:18/50     Step:5|6   loss:0.623781681060791  \n","Epoch:18/50     Step:6|6   loss:0.5901279449462891  \n","Epoch:18/50     Step:7|6   loss:0.5901257991790771  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.36 %\n","current max accuracy\t test set:97.2%\t train set:98.36%\n","Epoch:19/50     Step:1|6   loss:0.5440348982810974  \n","Epoch:19/50     Step:2|6   loss:0.607134222984314  \n","Epoch:19/50     Step:3|6   loss:0.641714334487915  \n","Epoch:19/50     Step:4|6   loss:0.5958510041236877  \n","Epoch:19/50     Step:5|6   loss:0.594963014125824  \n","Epoch:19/50     Step:6|6   loss:0.6048436164855957  \n","Epoch:19/50     Step:7|6   loss:0.5742433071136475  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 98.83 %\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:20/50     Step:1|6   loss:0.5708936452865601  \n","Epoch:20/50     Step:2|6   loss:0.5906710624694824  \n","Epoch:20/50     Step:3|6   loss:0.5939902067184448  \n","Epoch:20/50     Step:4|6   loss:0.6362987756729126  \n","Epoch:20/50     Step:5|6   loss:0.5584773421287537  \n","Epoch:20/50     Step:6|6   loss:0.6090953350067139  \n","Epoch:20/50     Step:7|6   loss:0.5912504196166992  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:21/50     Step:1|6   loss:0.5927203893661499  \n","Epoch:21/50     Step:2|6   loss:0.5693671703338623  \n","Epoch:21/50     Step:3|6   loss:0.5736113786697388  \n","Epoch:21/50     Step:4|6   loss:0.7084754705429077  \n","Epoch:21/50     Step:5|6   loss:0.5717623233795166  \n","Epoch:21/50     Step:6|6   loss:0.596929669380188  \n","Epoch:21/50     Step:7|6   loss:0.6082994937896729  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.78 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:22/50     Step:1|6   loss:0.5797378420829773  \n","Epoch:22/50     Step:2|6   loss:0.5707333087921143  \n","Epoch:22/50     Step:3|6   loss:0.5649251937866211  \n","Epoch:22/50     Step:4|6   loss:0.5894858837127686  \n","Epoch:22/50     Step:5|6   loss:0.5698204040527344  \n","Epoch:22/50     Step:6|6   loss:0.5885751247406006  \n","Epoch:22/50     Step:7|6   loss:0.5800175666809082  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:23/50     Step:1|6   loss:0.6007970571517944  \n","Epoch:23/50     Step:2|6   loss:0.5576415061950684  \n","Epoch:23/50     Step:3|6   loss:0.6072684526443481  \n","Epoch:23/50     Step:4|6   loss:0.5795280337333679  \n","Epoch:23/50     Step:5|6   loss:0.5731952786445618  \n","Epoch:23/50     Step:6|6   loss:0.5621543526649475  \n","Epoch:23/50     Step:7|6   loss:0.5724120140075684  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:24/50     Step:1|6   loss:0.5978950262069702  \n","Epoch:24/50     Step:2|6   loss:0.5620738863945007  \n","Epoch:24/50     Step:3|6   loss:0.545716404914856  \n","Epoch:24/50     Step:4|6   loss:0.6028814911842346  \n","Epoch:24/50     Step:5|6   loss:0.5649806261062622  \n","Epoch:24/50     Step:6|6   loss:0.562653124332428  \n","Epoch:24/50     Step:7|6   loss:0.5531765818595886  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:97.2%\t train set:98.83%\n","Epoch:25/50     Step:1|6   loss:0.5646569132804871  \n","Epoch:25/50     Step:2|6   loss:0.5988990068435669  \n","Epoch:25/50     Step:3|6   loss:0.5617557764053345  \n","Epoch:25/50     Step:4|6   loss:0.5476065278053284  \n","Epoch:25/50     Step:5|6   loss:0.5564008951187134  \n","Epoch:25/50     Step:6|6   loss:0.5674792528152466  \n","Epoch:25/50     Step:7|6   loss:0.5811915993690491  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:97.2%\t train set:99.06%\n","Epoch:26/50     Step:1|6   loss:0.5482747554779053  \n","Epoch:26/50     Step:2|6   loss:0.5363460183143616  \n","Epoch:26/50     Step:3|6   loss:0.5507420301437378  \n","Epoch:26/50     Step:4|6   loss:0.5419808626174927  \n","Epoch:26/50     Step:5|6   loss:0.541723370552063  \n","Epoch:26/50     Step:6|6   loss:0.5757260322570801  \n","Epoch:26/50     Step:7|6   loss:0.5601089596748352  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:27/50     Step:1|6   loss:0.574840247631073  \n","Epoch:27/50     Step:2|6   loss:0.5705887079238892  \n","Epoch:27/50     Step:3|6   loss:0.5476365089416504  \n","Epoch:27/50     Step:4|6   loss:0.5545340180397034  \n","Epoch:27/50     Step:5|6   loss:0.5398381948471069  \n","Epoch:27/50     Step:6|6   loss:0.5622642040252686  \n","Epoch:27/50     Step:7|6   loss:0.5434359312057495  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:28/50     Step:1|6   loss:0.5428984761238098  \n","Epoch:28/50     Step:2|6   loss:0.5376918315887451  \n","Epoch:28/50     Step:3|6   loss:0.5584473013877869  \n","Epoch:28/50     Step:4|6   loss:0.5419828295707703  \n","Epoch:28/50     Step:5|6   loss:0.5624222755432129  \n","Epoch:28/50     Step:6|6   loss:0.5538042783737183  \n","Epoch:28/50     Step:7|6   loss:0.5569652915000916  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:29/50     Step:1|6   loss:0.5499380230903625  \n","Epoch:29/50     Step:2|6   loss:0.5453991889953613  \n","Epoch:29/50     Step:3|6   loss:0.5548126101493835  \n","Epoch:29/50     Step:4|6   loss:0.5731765031814575  \n","Epoch:29/50     Step:5|6   loss:0.5940520167350769  \n","Epoch:29/50     Step:6|6   loss:0.5433164834976196  \n","Epoch:29/50     Step:7|6   loss:0.5383118987083435  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:30/50     Step:1|6   loss:0.5579172968864441  \n","Epoch:30/50     Step:2|6   loss:0.5446634888648987  \n","Epoch:30/50     Step:3|6   loss:0.5518874526023865  \n","Epoch:30/50     Step:4|6   loss:0.5512753129005432  \n","Epoch:30/50     Step:5|6   loss:0.5394712090492249  \n","Epoch:30/50     Step:6|6   loss:0.5418825745582581  \n","Epoch:30/50     Step:7|6   loss:0.5818618535995483  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:31/50     Step:1|6   loss:0.5467208623886108  \n","Epoch:31/50     Step:2|6   loss:0.5433809161186218  \n","Epoch:31/50     Step:3|6   loss:0.554036021232605  \n","Epoch:31/50     Step:4|6   loss:0.5558437705039978  \n","Epoch:31/50     Step:5|6   loss:0.5502418279647827  \n","Epoch:31/50     Step:6|6   loss:0.5437042713165283  \n","Epoch:31/50     Step:7|6   loss:0.5232571363449097  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:32/50     Step:1|6   loss:0.5507597923278809  \n","Epoch:32/50     Step:2|6   loss:0.5710675716400146  \n","Epoch:32/50     Step:3|6   loss:0.5379183888435364  \n","Epoch:32/50     Step:4|6   loss:0.5504659414291382  \n","Epoch:32/50     Step:5|6   loss:0.5343407988548279  \n","Epoch:32/50     Step:6|6   loss:0.5297708511352539  \n","Epoch:32/50     Step:7|6   loss:0.5500234365463257  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:33/50     Step:1|6   loss:0.5380225777626038  \n","Epoch:33/50     Step:2|6   loss:0.5350622534751892  \n","Epoch:33/50     Step:3|6   loss:0.5624492764472961  \n","Epoch:33/50     Step:4|6   loss:0.5607630610466003  \n","Epoch:33/50     Step:5|6   loss:0.5369299054145813  \n","Epoch:33/50     Step:6|6   loss:0.5402136445045471  \n","Epoch:33/50     Step:7|6   loss:0.5507245063781738  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:34/50     Step:1|6   loss:0.538366973400116  \n","Epoch:34/50     Step:2|6   loss:0.5401887893676758  \n","Epoch:34/50     Step:3|6   loss:0.5399397611618042  \n","Epoch:34/50     Step:4|6   loss:0.5326102375984192  \n","Epoch:34/50     Step:5|6   loss:0.5485546588897705  \n","Epoch:34/50     Step:6|6   loss:0.5617356300354004  \n","Epoch:34/50     Step:7|6   loss:0.5394638180732727  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:35/50     Step:1|6   loss:0.5511009097099304  \n","Epoch:35/50     Step:2|6   loss:0.5339332222938538  \n","Epoch:35/50     Step:3|6   loss:0.5504926443099976  \n","Epoch:35/50     Step:4|6   loss:0.5243654251098633  \n","Epoch:35/50     Step:5|6   loss:0.5496312975883484  \n","Epoch:35/50     Step:6|6   loss:0.5467989444732666  \n","Epoch:35/50     Step:7|6   loss:0.531690776348114  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:36/50     Step:1|6   loss:0.5299051403999329  \n","Epoch:36/50     Step:2|6   loss:0.540848433971405  \n","Epoch:36/50     Step:3|6   loss:0.5337596535682678  \n","Epoch:36/50     Step:4|6   loss:0.5599072575569153  \n","Epoch:36/50     Step:5|6   loss:0.5531052350997925  \n","Epoch:36/50     Step:6|6   loss:0.5395395755767822  \n","Epoch:36/50     Step:7|6   loss:0.5327462553977966  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:37/50     Step:1|6   loss:0.5248993039131165  \n","Epoch:37/50     Step:2|6   loss:0.5297405123710632  \n","Epoch:37/50     Step:3|6   loss:0.538927435874939  \n","Epoch:37/50     Step:4|6   loss:0.5198056101799011  \n","Epoch:37/50     Step:5|6   loss:0.5686829090118408  \n","Epoch:37/50     Step:6|6   loss:0.5507556796073914  \n","Epoch:37/50     Step:7|6   loss:0.5253719091415405  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:38/50     Step:1|6   loss:0.5354523062705994  \n","Epoch:38/50     Step:2|6   loss:0.5359150767326355  \n","Epoch:38/50     Step:3|6   loss:0.5302215218544006  \n","Epoch:38/50     Step:4|6   loss:0.530792236328125  \n","Epoch:38/50     Step:5|6   loss:0.560297966003418  \n","Epoch:38/50     Step:6|6   loss:0.5511386394500732  \n","Epoch:38/50     Step:7|6   loss:0.5361772775650024  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:39/50     Step:1|6   loss:0.5470279455184937  \n","Epoch:39/50     Step:2|6   loss:0.540696382522583  \n","Epoch:39/50     Step:3|6   loss:0.5788984298706055  \n","Epoch:39/50     Step:4|6   loss:0.5391058921813965  \n","Epoch:39/50     Step:5|6   loss:0.5316290259361267  \n","Epoch:39/50     Step:6|6   loss:0.5267238020896912  \n","Epoch:39/50     Step:7|6   loss:0.5231032371520996  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:40/50     Step:1|6   loss:0.5291930437088013  \n","Epoch:40/50     Step:2|6   loss:0.5466569066047668  \n","Epoch:40/50     Step:3|6   loss:0.5323094129562378  \n","Epoch:40/50     Step:4|6   loss:0.5561018586158752  \n","Epoch:40/50     Step:5|6   loss:0.5415453910827637  \n","Epoch:40/50     Step:6|6   loss:0.5453038215637207  \n","Epoch:40/50     Step:7|6   loss:0.5432114005088806  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:41/50     Step:1|6   loss:0.5397301316261292  \n","Epoch:41/50     Step:2|6   loss:0.538441002368927  \n","Epoch:41/50     Step:3|6   loss:0.543520987033844  \n","Epoch:41/50     Step:4|6   loss:0.5330806970596313  \n","Epoch:41/50     Step:5|6   loss:0.5275263786315918  \n","Epoch:41/50     Step:6|6   loss:0.5447354316711426  \n","Epoch:41/50     Step:7|6   loss:0.5236409306526184  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:42/50     Step:1|6   loss:0.5410815477371216  \n","Epoch:42/50     Step:2|6   loss:0.549236536026001  \n","Epoch:42/50     Step:3|6   loss:0.5605219006538391  \n","Epoch:42/50     Step:4|6   loss:0.5427442789077759  \n","Epoch:42/50     Step:5|6   loss:0.5317862629890442  \n","Epoch:42/50     Step:6|6   loss:0.5323864817619324  \n","Epoch:42/50     Step:7|6   loss:0.5507997870445251  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:43/50     Step:1|6   loss:0.5337530374526978  \n","Epoch:43/50     Step:2|6   loss:0.5239911675453186  \n","Epoch:43/50     Step:3|6   loss:0.526262640953064  \n","Epoch:43/50     Step:4|6   loss:0.5405867695808411  \n","Epoch:43/50     Step:5|6   loss:0.5257638692855835  \n","Epoch:43/50     Step:6|6   loss:0.5452463030815125  \n","Epoch:43/50     Step:7|6   loss:0.5384423136711121  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:44/50     Step:1|6   loss:0.5389192700386047  \n","Epoch:44/50     Step:2|6   loss:0.5281667113304138  \n","Epoch:44/50     Step:3|6   loss:0.555279552936554  \n","Epoch:44/50     Step:4|6   loss:0.53443443775177  \n","Epoch:44/50     Step:5|6   loss:0.5544446706771851  \n","Epoch:44/50     Step:6|6   loss:0.5260400176048279  \n","Epoch:44/50     Step:7|6   loss:0.5370527505874634  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:45/50     Step:1|6   loss:0.5232828259468079  \n","Epoch:45/50     Step:2|6   loss:0.5157961249351501  \n","Epoch:45/50     Step:3|6   loss:0.5351274609565735  \n","Epoch:45/50     Step:4|6   loss:0.5568984746932983  \n","Epoch:45/50     Step:5|6   loss:0.5340553522109985  \n","Epoch:45/50     Step:6|6   loss:0.5335148572921753  \n","Epoch:45/50     Step:7|6   loss:0.5302146673202515  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:46/50     Step:1|6   loss:0.5144951343536377  \n","Epoch:46/50     Step:2|6   loss:0.5632017850875854  \n","Epoch:46/50     Step:3|6   loss:0.5440585613250732  \n","Epoch:46/50     Step:4|6   loss:0.5266714096069336  \n","Epoch:46/50     Step:5|6   loss:0.5259236097335815  \n","Epoch:46/50     Step:6|6   loss:0.5293442606925964  \n","Epoch:46/50     Step:7|6   loss:0.5305681228637695  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:47/50     Step:1|6   loss:0.5461164116859436  \n","Epoch:47/50     Step:2|6   loss:0.5414448976516724  \n","Epoch:47/50     Step:3|6   loss:0.555079460144043  \n","Epoch:47/50     Step:4|6   loss:0.5314340591430664  \n","Epoch:47/50     Step:5|6   loss:0.5317097902297974  \n","Epoch:47/50     Step:6|6   loss:0.5283195376396179  \n","Epoch:47/50     Step:7|6   loss:0.5267652273178101  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:48/50     Step:1|6   loss:0.5297814011573792  \n","Epoch:48/50     Step:2|6   loss:0.5401176810264587  \n","Epoch:48/50     Step:3|6   loss:0.5465904474258423  \n","Epoch:48/50     Step:4|6   loss:0.5455658435821533  \n","Epoch:48/50     Step:5|6   loss:0.5262777805328369  \n","Epoch:48/50     Step:6|6   loss:0.5254411101341248  \n","Epoch:48/50     Step:7|6   loss:0.5268270373344421  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:49/50     Step:1|6   loss:0.5216487050056458  \n","Epoch:49/50     Step:2|6   loss:0.5314936637878418  \n","Epoch:49/50     Step:3|6   loss:0.5392530560493469  \n","Epoch:49/50     Step:4|6   loss:0.5308799743652344  \n","Epoch:49/50     Step:5|6   loss:0.5263633131980896  \n","Epoch:49/50     Step:6|6   loss:0.5340989828109741  \n","Epoch:49/50     Step:7|6   loss:0.530210554599762  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:50/50     Step:1|6   loss:0.5354602336883545  \n","Epoch:50/50     Step:2|6   loss:0.5221666693687439  \n","Epoch:50/50     Step:3|6   loss:0.5205338597297668  \n","Epoch:50/50     Step:4|6   loss:0.5396379232406616  \n","Epoch:50/50     Step:5|6   loss:0.535752534866333  \n","Epoch:50/50     Step:6|6   loss:0.532466471195221  \n","Epoch:50/50     Step:7|6   loss:0.5251436233520508  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Accuracy on test_set: 96.26 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model LeNet5_two_stream --mode both --index {i} --EPOCH 50"},{"cell_type":"code","execution_count":19,"id":"34955ead","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1051579713821411  \n","Epoch:1/30     Step:2|6   loss:0.7177908420562744  \n","Epoch:1/30     Step:3|6   loss:0.6117172241210938  \n","Epoch:1/30     Step:4|6   loss:0.6093599796295166  \n","Epoch:1/30     Step:5|6   loss:0.5921460390090942  \n","Epoch:1/30     Step:6|6   loss:0.5637452006340027  \n","Epoch:1/30     Step:7|6   loss:0.5986766219139099  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:2/30     Step:1|6   loss:0.5788537859916687  \n","Epoch:2/30     Step:2|6   loss:0.562564492225647  \n","Epoch:2/30     Step:3|6   loss:0.5372318625450134  \n","Epoch:2/30     Step:4|6   loss:0.5333067178726196  \n","Epoch:2/30     Step:5|6   loss:0.5265531539916992  \n","Epoch:2/30     Step:6|6   loss:0.5331174731254578  \n","Epoch:2/30     Step:7|6   loss:0.5237404108047485  \n","Accuracy on test_set: 85.05 %\n","Accuracy on train_set: 92.97 %\n","current max accuracy\t test set:93.46%\t train set:98.13%\n","Epoch:3/30     Step:1|6   loss:0.5194876790046692  \n","Epoch:3/30     Step:2|6   loss:0.5047007203102112  \n","Epoch:3/30     Step:3|6   loss:0.5153238773345947  \n","Epoch:3/30     Step:4|6   loss:0.5343508720397949  \n","Epoch:3/30     Step:5|6   loss:0.5373332500457764  \n","Epoch:3/30     Step:6|6   loss:0.509253740310669  \n","Epoch:3/30     Step:7|6   loss:0.5046249628067017  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.504932701587677  \n","Epoch:4/30     Step:2|6   loss:0.4988451600074768  \n","Epoch:4/30     Step:3|6   loss:0.5027196407318115  \n","Epoch:4/30     Step:4|6   loss:0.5029417276382446  \n","Epoch:4/30     Step:5|6   loss:0.4978901445865631  \n","Epoch:4/30     Step:6|6   loss:0.5003650784492493  \n","Epoch:4/30     Step:7|6   loss:0.49637556076049805  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.4938259720802307  \n","Epoch:5/30     Step:2|6   loss:0.49620068073272705  \n","Epoch:5/30     Step:3|6   loss:0.4933733344078064  \n","Epoch:5/30     Step:4|6   loss:0.49923425912857056  \n","Epoch:5/30     Step:5|6   loss:0.49526455998420715  \n","Epoch:5/30     Step:6|6   loss:0.4920578598976135  \n","Epoch:5/30     Step:7|6   loss:0.5059693455696106  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4944191575050354  \n","Epoch:6/30     Step:2|6   loss:0.4900999069213867  \n","Epoch:6/30     Step:3|6   loss:0.4931275248527527  \n","Epoch:6/30     Step:4|6   loss:0.4914398789405823  \n","Epoch:6/30     Step:5|6   loss:0.49112582206726074  \n","Epoch:6/30     Step:6|6   loss:0.5005024075508118  \n","Epoch:6/30     Step:7|6   loss:0.490959107875824  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4915808141231537  \n","Epoch:7/30     Step:2|6   loss:0.48946183919906616  \n","Epoch:7/30     Step:3|6   loss:0.48862165212631226  \n","Epoch:7/30     Step:4|6   loss:0.49207183718681335  \n","Epoch:7/30     Step:5|6   loss:0.48871558904647827  \n","Epoch:7/30     Step:6|6   loss:0.49394500255584717  \n","Epoch:7/30     Step:7|6   loss:0.4909243881702423  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.48948541283607483  \n","Epoch:8/30     Step:2|6   loss:0.4941786527633667  \n","Epoch:8/30     Step:3|6   loss:0.4946137070655823  \n","Epoch:8/30     Step:4|6   loss:0.48844680190086365  \n","Epoch:8/30     Step:5|6   loss:0.49701127409935  \n","Epoch:8/30     Step:6|6   loss:0.5008471012115479  \n","Epoch:8/30     Step:7|6   loss:0.4952969551086426  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49761301279067993  \n","Epoch:9/30     Step:2|6   loss:0.4966033697128296  \n","Epoch:9/30     Step:3|6   loss:0.490456759929657  \n","Epoch:9/30     Step:4|6   loss:0.5002351999282837  \n","Epoch:9/30     Step:5|6   loss:0.4986107349395752  \n","Epoch:9/30     Step:6|6   loss:0.4965169131755829  \n","Epoch:9/30     Step:7|6   loss:0.5063157081604004  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4893709421157837  \n","Epoch:10/30     Step:2|6   loss:0.4903979003429413  \n","Epoch:10/30     Step:3|6   loss:0.4888867139816284  \n","Epoch:10/30     Step:4|6   loss:0.49247950315475464  \n","Epoch:10/30     Step:5|6   loss:0.49542340636253357  \n","Epoch:10/30     Step:6|6   loss:0.4908597469329834  \n","Epoch:10/30     Step:7|6   loss:0.5219758749008179  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4893891513347626  \n","Epoch:11/30     Step:2|6   loss:0.48696473240852356  \n","Epoch:11/30     Step:3|6   loss:0.49946853518486023  \n","Epoch:11/30     Step:4|6   loss:0.48766088485717773  \n","Epoch:11/30     Step:5|6   loss:0.4884595274925232  \n","Epoch:11/30     Step:6|6   loss:0.48733600974082947  \n","Epoch:11/30     Step:7|6   loss:0.5213473439216614  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48820775747299194  \n","Epoch:12/30     Step:2|6   loss:0.49266189336776733  \n","Epoch:12/30     Step:3|6   loss:0.48876121640205383  \n","Epoch:12/30     Step:4|6   loss:0.492020845413208  \n","Epoch:12/30     Step:5|6   loss:0.5110527873039246  \n","Epoch:12/30     Step:6|6   loss:0.49026554822921753  \n","Epoch:12/30     Step:7|6   loss:0.4963683485984802  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.48838886618614197  \n","Epoch:13/30     Step:2|6   loss:0.48776233196258545  \n","Epoch:13/30     Step:3|6   loss:0.4898661971092224  \n","Epoch:13/30     Step:4|6   loss:0.4920715093612671  \n","Epoch:13/30     Step:5|6   loss:0.4900367856025696  \n","Epoch:13/30     Step:6|6   loss:0.49022725224494934  \n","Epoch:13/30     Step:7|6   loss:0.48816511034965515  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.49221354722976685  \n","Epoch:14/30     Step:2|6   loss:0.48996075987815857  \n","Epoch:14/30     Step:3|6   loss:0.48789405822753906  \n","Epoch:14/30     Step:4|6   loss:0.4950072765350342  \n","Epoch:14/30     Step:5|6   loss:0.4983275234699249  \n","Epoch:14/30     Step:6|6   loss:0.4903230369091034  \n","Epoch:14/30     Step:7|6   loss:0.4888937175273895  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48857051134109497  \n","Epoch:15/30     Step:2|6   loss:0.4909001886844635  \n","Epoch:15/30     Step:3|6   loss:0.48955655097961426  \n","Epoch:15/30     Step:4|6   loss:0.4893341362476349  \n","Epoch:15/30     Step:5|6   loss:0.48764434456825256  \n","Epoch:15/30     Step:6|6   loss:0.48841726779937744  \n","Epoch:15/30     Step:7|6   loss:0.4960617423057556  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48764723539352417  \n","Epoch:16/30     Step:2|6   loss:0.4874909520149231  \n","Epoch:16/30     Step:3|6   loss:0.4891014099121094  \n","Epoch:16/30     Step:4|6   loss:0.48774659633636475  \n","Epoch:16/30     Step:5|6   loss:0.4910386800765991  \n","Epoch:16/30     Step:6|6   loss:0.48757368326187134  \n","Epoch:16/30     Step:7|6   loss:0.4892418384552002  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48709943890571594  \n","Epoch:17/30     Step:2|6   loss:0.48977869749069214  \n","Epoch:17/30     Step:3|6   loss:0.49142563343048096  \n","Epoch:17/30     Step:4|6   loss:0.48868411779403687  \n","Epoch:17/30     Step:5|6   loss:0.4879416823387146  \n","Epoch:17/30     Step:6|6   loss:0.48821666836738586  \n","Epoch:17/30     Step:7|6   loss:0.4982728958129883  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48806312680244446  \n","Epoch:18/30     Step:2|6   loss:0.4879057705402374  \n","Epoch:18/30     Step:3|6   loss:0.49133017659187317  \n","Epoch:18/30     Step:4|6   loss:0.48868528008461  \n","Epoch:18/30     Step:5|6   loss:0.4888019859790802  \n","Epoch:18/30     Step:6|6   loss:0.49422261118888855  \n","Epoch:18/30     Step:7|6   loss:0.490375280380249  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.49401798844337463  \n","Epoch:19/30     Step:2|6   loss:0.4876529276371002  \n","Epoch:19/30     Step:3|6   loss:0.49004846811294556  \n","Epoch:19/30     Step:4|6   loss:0.4874969720840454  \n","Epoch:19/30     Step:5|6   loss:0.4888652563095093  \n","Epoch:19/30     Step:6|6   loss:0.4901307225227356  \n","Epoch:19/30     Step:7|6   loss:0.492304265499115  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48794251680374146  \n","Epoch:20/30     Step:2|6   loss:0.4868634343147278  \n","Epoch:20/30     Step:3|6   loss:0.49465951323509216  \n","Epoch:20/30     Step:4|6   loss:0.48844170570373535  \n","Epoch:20/30     Step:5|6   loss:0.4901353418827057  \n","Epoch:20/30     Step:6|6   loss:0.4861479103565216  \n","Epoch:20/30     Step:7|6   loss:0.4885043799877167  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48736411333084106  \n","Epoch:21/30     Step:2|6   loss:0.4896560311317444  \n","Epoch:21/30     Step:3|6   loss:0.4886685907840729  \n","Epoch:21/30     Step:4|6   loss:0.49545130133628845  \n","Epoch:21/30     Step:5|6   loss:0.48738858103752136  \n","Epoch:21/30     Step:6|6   loss:0.48797306418418884  \n","Epoch:21/30     Step:7|6   loss:0.4874494969844818  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4891068935394287  \n","Epoch:22/30     Step:2|6   loss:0.4941553771495819  \n","Epoch:22/30     Step:3|6   loss:0.4870378077030182  \n","Epoch:22/30     Step:4|6   loss:0.48951825499534607  \n","Epoch:22/30     Step:5|6   loss:0.48887985944747925  \n","Epoch:22/30     Step:6|6   loss:0.4883430302143097  \n","Epoch:22/30     Step:7|6   loss:0.4912274479866028  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4879516661167145  \n","Epoch:23/30     Step:2|6   loss:0.48670080304145813  \n","Epoch:23/30     Step:3|6   loss:0.5031189918518066  \n","Epoch:23/30     Step:4|6   loss:0.4920724928379059  \n","Epoch:23/30     Step:5|6   loss:0.4906039834022522  \n","Epoch:23/30     Step:6|6   loss:0.49671560525894165  \n","Epoch:23/30     Step:7|6   loss:0.49161043763160706  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48817548155784607  \n","Epoch:24/30     Step:2|6   loss:0.4886792004108429  \n","Epoch:24/30     Step:3|6   loss:0.48721927404403687  \n","Epoch:24/30     Step:4|6   loss:0.4883360266685486  \n","Epoch:24/30     Step:5|6   loss:0.48843279480934143  \n","Epoch:24/30     Step:6|6   loss:0.4861534833908081  \n","Epoch:24/30     Step:7|6   loss:0.49072718620300293  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48819494247436523  \n","Epoch:25/30     Step:2|6   loss:0.49397802352905273  \n","Epoch:25/30     Step:3|6   loss:0.48781758546829224  \n","Epoch:25/30     Step:4|6   loss:0.4986863136291504  \n","Epoch:25/30     Step:5|6   loss:0.4880639612674713  \n","Epoch:25/30     Step:6|6   loss:0.4877786934375763  \n","Epoch:25/30     Step:7|6   loss:0.4918115437030792  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4877461791038513  \n","Epoch:26/30     Step:2|6   loss:0.48803651332855225  \n","Epoch:26/30     Step:3|6   loss:0.4890892505645752  \n","Epoch:26/30     Step:4|6   loss:0.49074697494506836  \n","Epoch:26/30     Step:5|6   loss:0.4913637638092041  \n","Epoch:26/30     Step:6|6   loss:0.4867312014102936  \n","Epoch:26/30     Step:7|6   loss:0.4973302483558655  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4969685673713684  \n","Epoch:27/30     Step:2|6   loss:0.48848021030426025  \n","Epoch:27/30     Step:3|6   loss:0.48904043436050415  \n","Epoch:27/30     Step:4|6   loss:0.49136507511138916  \n","Epoch:27/30     Step:5|6   loss:0.48930808901786804  \n","Epoch:27/30     Step:6|6   loss:0.4902687966823578  \n","Epoch:27/30     Step:7|6   loss:0.4904208779335022  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4897691309452057  \n","Epoch:28/30     Step:2|6   loss:0.4928627610206604  \n","Epoch:28/30     Step:3|6   loss:0.48944541811943054  \n","Epoch:28/30     Step:4|6   loss:0.4873155355453491  \n","Epoch:28/30     Step:5|6   loss:0.4901205003261566  \n","Epoch:28/30     Step:6|6   loss:0.493289053440094  \n","Epoch:28/30     Step:7|6   loss:0.4878346621990204  1\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4960944652557373  \n","Epoch:29/30     Step:2|6   loss:0.4870683550834656  \n","Epoch:29/30     Step:3|6   loss:0.4881429672241211  \n","Epoch:29/30     Step:4|6   loss:0.48955824971199036  \n","Epoch:29/30     Step:5|6   loss:0.4885315001010895  \n","Epoch:29/30     Step:6|6   loss:0.48953497409820557  \n","Epoch:29/30     Step:7|6   loss:0.48673197627067566  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4862132668495178  \n","Epoch:30/30     Step:2|6   loss:0.4924246072769165  \n","Epoch:30/30     Step:3|6   loss:0.48723649978637695  \n","Epoch:30/30     Step:4|6   loss:0.48915860056877136  \n","Epoch:30/30     Step:5|6   loss:0.4871951639652252  \n","Epoch:30/30     Step:6|6   loss:0.49242281913757324  \n","Epoch:30/30     Step:7|6   loss:0.48953527212142944  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.358484148979187  \n","Epoch:1/30     Step:2|6   loss:0.8492269515991211  \n","Epoch:1/30     Step:3|6   loss:0.7166311740875244  \n","Epoch:1/30     Step:4|6   loss:0.6553968191146851  \n","Epoch:1/30     Step:5|6   loss:0.6187998652458191  \n","Epoch:1/30     Step:6|6   loss:0.5884385108947754  \n","Epoch:1/30     Step:7|6   loss:0.6260138154029846  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:98.13%\t train set:99.06%\n","Epoch:2/30     Step:1|6   loss:0.6028442978858948  \n","Epoch:2/30     Step:2|6   loss:0.598999559879303  \n","Epoch:2/30     Step:3|6   loss:0.5872464776039124  \n","Epoch:2/30     Step:4|6   loss:0.5609805583953857  \n","Epoch:2/30     Step:5|6   loss:0.5898000597953796  \n","Epoch:2/30     Step:6|6   loss:0.5416542887687683  \n","Epoch:2/30     Step:7|6   loss:0.5503659248352051  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:3/30     Step:1|6   loss:0.5292950868606567  \n","Epoch:3/30     Step:2|6   loss:0.5207541584968567  \n","Epoch:3/30     Step:3|6   loss:0.508029043674469  \n","Epoch:3/30     Step:4|6   loss:0.5206095576286316  \n","Epoch:3/30     Step:5|6   loss:0.5188496112823486  \n","Epoch:3/30     Step:6|6   loss:0.510765552520752  \n","Epoch:3/30     Step:7|6   loss:0.51045823097229  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5095326900482178  \n","Epoch:4/30     Step:2|6   loss:0.5148306488990784  \n","Epoch:4/30     Step:3|6   loss:0.500871479511261  \n","Epoch:4/30     Step:4|6   loss:0.5133702158927917  \n","Epoch:4/30     Step:5|6   loss:0.5011035203933716  \n","Epoch:4/30     Step:6|6   loss:0.4977555572986603  \n","Epoch:4/30     Step:7|6   loss:0.5030123591423035  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5005364418029785  \n","Epoch:5/30     Step:2|6   loss:0.4925549626350403  \n","Epoch:5/30     Step:3|6   loss:0.49236124753952026  \n","Epoch:5/30     Step:4|6   loss:0.4972311854362488  \n","Epoch:5/30     Step:5|6   loss:0.4928392767906189  \n","Epoch:5/30     Step:6|6   loss:0.4915078580379486  \n","Epoch:5/30     Step:7|6   loss:0.497447669506073  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.493135929107666  \n","Epoch:6/30     Step:2|6   loss:0.4936148524284363  \n","Epoch:6/30     Step:3|6   loss:0.5014138221740723  \n","Epoch:6/30     Step:4|6   loss:0.49241071939468384  \n","Epoch:6/30     Step:5|6   loss:0.49097108840942383  \n","Epoch:6/30     Step:6|6   loss:0.5173724293708801  \n","Epoch:6/30     Step:7|6   loss:0.5229734182357788  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4984639286994934  \n","Epoch:7/30     Step:2|6   loss:0.5061932802200317  \n","Epoch:7/30     Step:3|6   loss:0.5031182169914246  \n","Epoch:7/30     Step:4|6   loss:0.49887555837631226  \n","Epoch:7/30     Step:5|6   loss:0.49761417508125305  \n","Epoch:7/30     Step:6|6   loss:0.4942283034324646  \n","Epoch:7/30     Step:7|6   loss:0.4931492209434509  2\n","\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4963313937187195  \n","Epoch:8/30     Step:2|6   loss:0.49435994029045105  \n","Epoch:8/30     Step:3|6   loss:0.49019962549209595  \n","Epoch:8/30     Step:4|6   loss:0.5028587579727173  \n","Epoch:8/30     Step:5|6   loss:0.4925697445869446  \n","Epoch:8/30     Step:6|6   loss:0.49455660581588745  \n","Epoch:8/30     Step:7|6   loss:0.4918700158596039  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49150264263153076  \n","Epoch:9/30     Step:2|6   loss:0.5009938478469849  \n","Epoch:9/30     Step:3|6   loss:0.4897107481956482  \n","Epoch:9/30     Step:4|6   loss:0.49030959606170654  \n","Epoch:9/30     Step:5|6   loss:0.49222415685653687  \n","Epoch:9/30     Step:6|6   loss:0.4898090362548828  \n","Epoch:9/30     Step:7|6   loss:0.49614793062210083  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4917239844799042  \n","Epoch:10/30     Step:2|6   loss:0.48869431018829346  \n","Epoch:10/30     Step:3|6   loss:0.4937589168548584  \n","Epoch:10/30     Step:4|6   loss:0.4880658984184265  \n","Epoch:10/30     Step:5|6   loss:0.4910317063331604  \n","Epoch:10/30     Step:6|6   loss:0.4934207499027252  \n","Epoch:10/30     Step:7|6   loss:0.48813408613204956  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49135416746139526  \n","Epoch:11/30     Step:2|6   loss:0.49565646052360535  \n","Epoch:11/30     Step:3|6   loss:0.4896438419818878  \n","Epoch:11/30     Step:4|6   loss:0.4894323945045471  \n","Epoch:11/30     Step:5|6   loss:0.4880366921424866  \n","Epoch:11/30     Step:6|6   loss:0.48908567428588867  \n","Epoch:11/30     Step:7|6   loss:0.4874424934387207  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48924076557159424  \n","Epoch:12/30     Step:2|6   loss:0.4922814667224884  \n","Epoch:12/30     Step:3|6   loss:0.48602426052093506  \n","Epoch:12/30     Step:4|6   loss:0.4912647306919098  \n","Epoch:12/30     Step:5|6   loss:0.48734933137893677  \n","Epoch:12/30     Step:6|6   loss:0.486554354429245  \n","Epoch:12/30     Step:7|6   loss:0.49053955078125  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.48712682723999023  \n","Epoch:13/30     Step:2|6   loss:0.4886131286621094  \n","Epoch:13/30     Step:3|6   loss:0.4972997307777405  \n","Epoch:13/30     Step:4|6   loss:0.4871646761894226  \n","Epoch:13/30     Step:5|6   loss:0.4872283637523651  \n","Epoch:13/30     Step:6|6   loss:0.49172544479370117  \n","Epoch:13/30     Step:7|6   loss:0.48862120509147644  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4876801073551178  \n","Epoch:14/30     Step:2|6   loss:0.4864077866077423  \n","Epoch:14/30     Step:3|6   loss:0.488186776638031  \n","Epoch:14/30     Step:4|6   loss:0.48878729343414307  \n","Epoch:14/30     Step:5|6   loss:0.4867866635322571  \n","Epoch:14/30     Step:6|6   loss:0.4883818030357361  \n","Epoch:14/30     Step:7|6   loss:0.4885226786136627  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4879465103149414  \n","Epoch:15/30     Step:2|6   loss:0.48700767755508423  \n","Epoch:15/30     Step:3|6   loss:0.490776002407074  \n","Epoch:15/30     Step:4|6   loss:0.4947349429130554  \n","Epoch:15/30     Step:5|6   loss:0.48895540833473206  \n","Epoch:15/30     Step:6|6   loss:0.48686152696609497  \n","Epoch:15/30     Step:7|6   loss:0.49430903792381287  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48711636662483215  \n","Epoch:16/30     Step:2|6   loss:0.487024188041687  \n","Epoch:16/30     Step:3|6   loss:0.4869415760040283  \n","Epoch:16/30     Step:4|6   loss:0.4871513247489929  \n","Epoch:16/30     Step:5|6   loss:0.4887539744377136  \n","Epoch:16/30     Step:6|6   loss:0.48632633686065674  \n","Epoch:16/30     Step:7|6   loss:0.486383318901062  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4907568097114563  \n","Epoch:17/30     Step:2|6   loss:0.4864177703857422  \n","Epoch:17/30     Step:3|6   loss:0.4914698600769043  \n","Epoch:17/30     Step:4|6   loss:0.4866167902946472  \n","Epoch:17/30     Step:5|6   loss:0.486995130777359  \n","Epoch:17/30     Step:6|6   loss:0.48671871423721313  \n","Epoch:17/30     Step:7|6   loss:0.48824769258499146  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4910832643508911  \n","Epoch:18/30     Step:2|6   loss:0.4865266978740692  \n","Epoch:18/30     Step:3|6   loss:0.48696646094322205  \n","Epoch:18/30     Step:4|6   loss:0.4877700209617615  \n","Epoch:18/30     Step:5|6   loss:0.4895497262477875  \n","Epoch:18/30     Step:6|6   loss:0.4875835180282593  \n","Epoch:18/30     Step:7|6   loss:0.4911676049232483  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4878493547439575  \n","Epoch:19/30     Step:2|6   loss:0.48781073093414307  \n","Epoch:19/30     Step:3|6   loss:0.4892082214355469  \n","Epoch:19/30     Step:4|6   loss:0.48894351720809937  \n","Epoch:19/30     Step:5|6   loss:0.5055974721908569  \n","Epoch:19/30     Step:6|6   loss:0.4879319965839386  \n","Epoch:19/30     Step:7|6   loss:0.4876261055469513  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4895724654197693  \n","Epoch:20/30     Step:2|6   loss:0.48816239833831787  \n","Epoch:20/30     Step:3|6   loss:0.48808062076568604  \n","Epoch:20/30     Step:4|6   loss:0.48839518427848816  \n","Epoch:20/30     Step:5|6   loss:0.4891238510608673  \n","Epoch:20/30     Step:6|6   loss:0.4882170855998993  \n","Epoch:20/30     Step:7|6   loss:0.5105767846107483  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48735693097114563  \n","Epoch:21/30     Step:2|6   loss:0.49115219712257385  \n","Epoch:21/30     Step:3|6   loss:0.49133557081222534  \n","Epoch:21/30     Step:4|6   loss:0.4909149706363678  \n","Epoch:21/30     Step:5|6   loss:0.48966366052627563  \n","Epoch:21/30     Step:6|6   loss:0.4879974126815796  \n","Epoch:21/30     Step:7|6   loss:0.4877126216888428  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48818957805633545  \n","Epoch:22/30     Step:2|6   loss:0.4889870584011078  \n","Epoch:22/30     Step:3|6   loss:0.48821356892585754  \n","Epoch:22/30     Step:4|6   loss:0.48731887340545654  \n","Epoch:22/30     Step:5|6   loss:0.48801130056381226  \n","Epoch:22/30     Step:6|6   loss:0.4912392199039459  \n","Epoch:22/30     Step:7|6   loss:0.48824042081832886  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48802003264427185  \n","Epoch:23/30     Step:2|6   loss:0.4911775588989258  \n","Epoch:23/30     Step:3|6   loss:0.49063044786453247  \n","Epoch:23/30     Step:4|6   loss:0.4876173436641693  \n","Epoch:23/30     Step:5|6   loss:0.4872799515724182  \n","Epoch:23/30     Step:6|6   loss:0.4872521758079529  \n","Epoch:23/30     Step:7|6   loss:0.4902219772338867  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49128493666648865  \n","Epoch:24/30     Step:2|6   loss:0.49428093433380127  \n","Epoch:24/30     Step:3|6   loss:0.48720601201057434  \n","Epoch:24/30     Step:4|6   loss:0.48833930492401123  \n","Epoch:24/30     Step:5|6   loss:0.48776328563690186  \n","Epoch:24/30     Step:6|6   loss:0.4861331880092621  \n","Epoch:24/30     Step:7|6   loss:0.487687349319458  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48931241035461426  \n","Epoch:25/30     Step:2|6   loss:0.48724934458732605  \n","Epoch:25/30     Step:3|6   loss:0.4873647689819336  \n","Epoch:25/30     Step:4|6   loss:0.48822107911109924  \n","Epoch:25/30     Step:5|6   loss:0.4868115782737732  \n","Epoch:25/30     Step:6|6   loss:0.49198073148727417  \n","Epoch:25/30     Step:7|6   loss:0.48874837160110474  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.48729926347732544  \n","Epoch:26/30     Step:2|6   loss:0.4864004850387573  \n","Epoch:26/30     Step:3|6   loss:0.4864896535873413  \n","Epoch:26/30     Step:4|6   loss:0.4876362979412079  \n","Epoch:26/30     Step:5|6   loss:0.4858645796775818  \n","Epoch:26/30     Step:6|6   loss:0.48658525943756104  \n","Epoch:26/30     Step:7|6   loss:0.493438184261322  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48607587814331055  \n","Epoch:27/30     Step:2|6   loss:0.487579345703125  \n","Epoch:27/30     Step:3|6   loss:0.4892823398113251  \n","Epoch:27/30     Step:4|6   loss:0.4898483157157898  \n","Epoch:27/30     Step:5|6   loss:0.4873338043689728  \n","Epoch:27/30     Step:6|6   loss:0.49223384261131287  \n","Epoch:27/30     Step:7|6   loss:0.4896199107170105  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.49033063650131226  \n","Epoch:28/30     Step:2|6   loss:0.4888175427913666  \n","Epoch:28/30     Step:3|6   loss:0.4872462749481201  \n","Epoch:28/30     Step:4|6   loss:0.4891899824142456  \n","Epoch:28/30     Step:5|6   loss:0.49081945419311523  \n","Epoch:28/30     Step:6|6   loss:0.4921497106552124  \n","Epoch:28/30     Step:7|6   loss:0.48789888620376587  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49059879779815674  \n","Epoch:29/30     Step:2|6   loss:0.4889139235019684  \n","Epoch:29/30     Step:3|6   loss:0.48899632692337036  \n","Epoch:29/30     Step:4|6   loss:0.4894392490386963  \n","Epoch:29/30     Step:5|6   loss:0.48964187502861023  \n","Epoch:29/30     Step:6|6   loss:0.4861721992492676  \n","Epoch:29/30     Step:7|6   loss:0.488510400056839  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.48693010210990906  \n","Epoch:30/30     Step:2|6   loss:0.48848193883895874  \n","Epoch:30/30     Step:3|6   loss:0.4884922504425049  \n","Epoch:30/30     Step:4|6   loss:0.4888724386692047  \n","Epoch:30/30     Step:5|6   loss:0.48735323548316956  \n","Epoch:30/30     Step:6|6   loss:0.4865780770778656  \n","Epoch:30/30     Step:7|6   loss:0.48758774995803833  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.3270289897918701  \n","Epoch:1/30     Step:2|6   loss:0.8408997058868408  \n","Epoch:1/30     Step:3|6   loss:0.6428465843200684  \n","Epoch:1/30     Step:4|6   loss:0.6429488062858582  \n","Epoch:1/30     Step:5|6   loss:0.5785548686981201  \n","Epoch:1/30     Step:6|6   loss:0.5852946043014526  \n","Epoch:1/30     Step:7|6   loss:0.6619242429733276  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 98.83 %\n","current max accuracy\t test set:100.0%\t train set:98.83%\n","Epoch:2/30     Step:1|6   loss:0.6057880520820618  \n","Epoch:2/30     Step:2|6   loss:0.5848954916000366  \n","Epoch:2/30     Step:3|6   loss:0.551019012928009  \n","Epoch:2/30     Step:4|6   loss:0.5550528764724731  \n","Epoch:2/30     Step:5|6   loss:0.5287664532661438  \n","Epoch:2/30     Step:6|6   loss:0.5286564826965332  \n","Epoch:2/30     Step:7|6   loss:0.5174720883369446  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:3/30     Step:1|6   loss:0.5137059688568115  \n","Epoch:3/30     Step:2|6   loss:0.5123987793922424  \n","Epoch:3/30     Step:3|6   loss:0.5237635970115662  \n","Epoch:3/30     Step:4|6   loss:0.5121658444404602  \n","Epoch:3/30     Step:5|6   loss:0.5273758172988892  \n","Epoch:3/30     Step:6|6   loss:0.5132091045379639  \n","Epoch:3/30     Step:7|6   loss:0.5189940929412842  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5000823140144348  \n","Epoch:4/30     Step:2|6   loss:0.5080140829086304  \n","Epoch:4/30     Step:3|6   loss:0.49988898634910583  \n","Epoch:4/30     Step:4|6   loss:0.5060591101646423  \n","Epoch:4/30     Step:5|6   loss:0.4977225661277771  \n","Epoch:4/30     Step:6|6   loss:0.4974779486656189  \n","Epoch:4/30     Step:7|6   loss:0.5030785799026489  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.4949817657470703  \n","Epoch:5/30     Step:2|6   loss:0.4932200610637665  \n","Epoch:5/30     Step:3|6   loss:0.49443402886390686  \n","Epoch:5/30     Step:4|6   loss:0.4966263175010681  \n","Epoch:5/30     Step:5|6   loss:0.49210110306739807  \n","Epoch:5/30     Step:6|6   loss:0.49696117639541626  \n","Epoch:5/30     Step:7|6   loss:0.49132347106933594  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4932838976383209  \n","Epoch:6/30     Step:2|6   loss:0.500038743019104  \n","Epoch:6/30     Step:3|6   loss:0.49421653151512146  \n","Epoch:6/30     Step:4|6   loss:0.511345386505127  \n","Epoch:6/30     Step:5|6   loss:0.48883819580078125  \n","Epoch:6/30     Step:6|6   loss:0.49783971905708313  \n","Epoch:6/30     Step:7|6   loss:0.4972202777862549  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4914827346801758  \n","Epoch:7/30     Step:2|6   loss:0.4971316456794739  \n","Epoch:7/30     Step:3|6   loss:0.4913955628871918  \n","Epoch:7/30     Step:4|6   loss:0.4987781047821045  \n","Epoch:7/30     Step:5|6   loss:0.4990568161010742  \n","Epoch:7/30     Step:6|6   loss:0.4922943115234375  \n","Epoch:7/30     Step:7|6   loss:0.5011839866638184  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49080201983451843  \n","Epoch:8/30     Step:2|6   loss:0.48784634470939636  \n","Epoch:8/30     Step:3|6   loss:0.48984482884407043  \n","Epoch:8/30     Step:4|6   loss:0.48853257298469543  \n","Epoch:8/30     Step:5|6   loss:0.487647145986557  \n","Epoch:8/30     Step:6|6   loss:0.48822224140167236  \n","Epoch:8/30     Step:7|6   loss:0.4881107211112976  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.48768240213394165  \n","Epoch:9/30     Step:2|6   loss:0.4896788001060486  \n","Epoch:9/30     Step:3|6   loss:0.48913490772247314  \n","Epoch:9/30     Step:4|6   loss:0.48992156982421875  \n","Epoch:9/30     Step:5|6   loss:0.4900052547454834  \n","Epoch:9/30     Step:6|6   loss:0.4930341839790344  \n","Epoch:9/30     Step:7|6   loss:0.4898308515548706  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48760712146759033  \n","Epoch:10/30     Step:2|6   loss:0.4940877854824066  \n","Epoch:10/30     Step:3|6   loss:0.49034613370895386  \n","Epoch:10/30     Step:4|6   loss:0.4892524778842926  \n","Epoch:10/30     Step:5|6   loss:0.4926157593727112  \n","Epoch:10/30     Step:6|6   loss:0.4897777736186981  \n","Epoch:10/30     Step:7|6   loss:0.48905542492866516  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4893451929092407  \n","Epoch:11/30     Step:2|6   loss:0.48817160725593567  \n","Epoch:11/30     Step:3|6   loss:0.4900020658969879  \n","Epoch:11/30     Step:4|6   loss:0.4886588156223297  \n","Epoch:11/30     Step:5|6   loss:0.4869225025177002  \n","Epoch:11/30     Step:6|6   loss:0.48950719833374023  \n","Epoch:11/30     Step:7|6   loss:0.4878792464733124  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4923166036605835  \n","Epoch:12/30     Step:2|6   loss:0.48721060156822205  \n","Epoch:12/30     Step:3|6   loss:0.4875538647174835  \n","Epoch:12/30     Step:4|6   loss:0.49399498105049133  \n","Epoch:12/30     Step:5|6   loss:0.5033408403396606  \n","Epoch:12/30     Step:6|6   loss:0.48974180221557617  \n","Epoch:12/30     Step:7|6   loss:0.4990708827972412  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.493990033864975  \n","Epoch:13/30     Step:2|6   loss:0.4916971027851105  \n","Epoch:13/30     Step:3|6   loss:0.48852917551994324  \n","Epoch:13/30     Step:4|6   loss:0.4893839359283447  \n","Epoch:13/30     Step:5|6   loss:0.487423837184906  \n","Epoch:13/30     Step:6|6   loss:0.5014686584472656  \n","Epoch:13/30     Step:7|6   loss:0.49171796441078186  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48755690455436707  \n","Epoch:14/30     Step:2|6   loss:0.48899564146995544  \n","Epoch:14/30     Step:3|6   loss:0.4886281490325928  \n","Epoch:14/30     Step:4|6   loss:0.48636090755462646  \n","Epoch:14/30     Step:5|6   loss:0.4941396117210388  \n","Epoch:14/30     Step:6|6   loss:0.48721688985824585  \n","Epoch:14/30     Step:7|6   loss:0.4913971424102783  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4880789518356323  \n","Epoch:15/30     Step:2|6   loss:0.49114322662353516  \n","Epoch:15/30     Step:3|6   loss:0.49726974964141846  \n","Epoch:15/30     Step:4|6   loss:0.4890185296535492  \n","Epoch:15/30     Step:5|6   loss:0.49131467938423157  \n","Epoch:15/30     Step:6|6   loss:0.490222305059433  \n","Epoch:15/30     Step:7|6   loss:0.4891933500766754  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4902476370334625  \n","Epoch:16/30     Step:2|6   loss:0.4868740439414978  \n","Epoch:16/30     Step:3|6   loss:0.49554988741874695  \n","Epoch:16/30     Step:4|6   loss:0.4945284426212311  \n","Epoch:16/30     Step:5|6   loss:0.4876352846622467  \n","Epoch:16/30     Step:6|6   loss:0.4868779480457306  \n","Epoch:16/30     Step:7|6   loss:0.489122211933136  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48766767978668213  \n","Epoch:17/30     Step:2|6   loss:0.4889472723007202  \n","Epoch:17/30     Step:3|6   loss:0.48654189705848694  \n","Epoch:17/30     Step:4|6   loss:0.49343395233154297  \n","Epoch:17/30     Step:5|6   loss:0.4880126416683197  \n","Epoch:17/30     Step:6|6   loss:0.48673561215400696  \n","Epoch:17/30     Step:7|6   loss:0.5066467523574829  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4880584180355072  \n","Epoch:18/30     Step:2|6   loss:0.48910677433013916  \n","Epoch:18/30     Step:3|6   loss:0.48740148544311523  \n","Epoch:18/30     Step:4|6   loss:0.4881246089935303  \n","Epoch:18/30     Step:5|6   loss:0.49446049332618713  \n","Epoch:18/30     Step:6|6   loss:0.4892624616622925  \n","Epoch:18/30     Step:7|6   loss:0.4913600981235504  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.48680567741394043  \n","Epoch:19/30     Step:2|6   loss:0.48640763759613037  \n","Epoch:19/30     Step:3|6   loss:0.48682132363319397  \n","Epoch:19/30     Step:4|6   loss:0.48715102672576904  \n","Epoch:19/30     Step:5|6   loss:0.4878723621368408  \n","Epoch:19/30     Step:6|6   loss:0.4875146150588989  \n","Epoch:19/30     Step:7|6   loss:0.4911409020423889  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.48736777901649475  \n","Epoch:20/30     Step:2|6   loss:0.4919937252998352  \n","Epoch:20/30     Step:3|6   loss:0.4873187243938446  \n","Epoch:20/30     Step:4|6   loss:0.48900285363197327  \n","Epoch:20/30     Step:5|6   loss:0.4869575500488281  \n","Epoch:20/30     Step:6|6   loss:0.48817193508148193  \n","Epoch:20/30     Step:7|6   loss:0.48919677734375  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4883004426956177  \n","Epoch:21/30     Step:2|6   loss:0.48721593618392944  \n","Epoch:21/30     Step:3|6   loss:0.495991051197052  \n","Epoch:21/30     Step:4|6   loss:0.48682403564453125  \n","Epoch:21/30     Step:5|6   loss:0.4894123375415802  \n","Epoch:21/30     Step:6|6   loss:0.4927234649658203  \n","Epoch:21/30     Step:7|6   loss:0.49482661485671997  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4890686571598053  \n","Epoch:22/30     Step:2|6   loss:0.48626285791397095  \n","Epoch:22/30     Step:3|6   loss:0.4883040487766266  \n","Epoch:22/30     Step:4|6   loss:0.49112796783447266  \n","Epoch:22/30     Step:5|6   loss:0.4876529574394226  \n","Epoch:22/30     Step:6|6   loss:0.4909839332103729  \n","Epoch:22/30     Step:7|6   loss:0.49176257848739624  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48718008399009705  \n","Epoch:23/30     Step:2|6   loss:0.48737820982933044  \n","Epoch:23/30     Step:3|6   loss:0.48891255259513855  \n","Epoch:23/30     Step:4|6   loss:0.4869430363178253  \n","Epoch:23/30     Step:5|6   loss:0.48884710669517517  \n","Epoch:23/30     Step:6|6   loss:0.48804476857185364  \n","Epoch:23/30     Step:7|6   loss:0.49432694911956787  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48616254329681396  \n","Epoch:24/30     Step:2|6   loss:0.48967811465263367  \n","Epoch:24/30     Step:3|6   loss:0.49049508571624756  \n","Epoch:24/30     Step:4|6   loss:0.4908336400985718  \n","Epoch:24/30     Step:5|6   loss:0.48761075735092163  \n","Epoch:24/30     Step:6|6   loss:0.4922240078449249  \n","Epoch:24/30     Step:7|6   loss:0.49360448122024536  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.49204060435295105  \n","Epoch:25/30     Step:2|6   loss:0.4872460961341858  \n","Epoch:25/30     Step:3|6   loss:0.4889068603515625  \n","Epoch:25/30     Step:4|6   loss:0.48677799105644226  \n","Epoch:25/30     Step:5|6   loss:0.4911307692527771  \n","Epoch:25/30     Step:6|6   loss:0.48716118931770325  \n","Epoch:25/30     Step:7|6   loss:0.5046592354774475  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4899005591869354  \n","Epoch:26/30     Step:2|6   loss:0.4892114996910095  \n","Epoch:26/30     Step:3|6   loss:0.48845231533050537  \n","Epoch:26/30     Step:4|6   loss:0.488749235868454  \n","Epoch:26/30     Step:5|6   loss:0.48748210072517395  \n","Epoch:26/30     Step:6|6   loss:0.48947033286094666  \n","Epoch:26/30     Step:7|6   loss:0.5021840929985046  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.487077534198761  \n","Epoch:27/30     Step:2|6   loss:0.4880881905555725  \n","Epoch:27/30     Step:3|6   loss:0.4897354245185852  \n","Epoch:27/30     Step:4|6   loss:0.48821398615837097  \n","Epoch:27/30     Step:5|6   loss:0.48844683170318604  \n","Epoch:27/30     Step:6|6   loss:0.48881232738494873  \n","Epoch:27/30     Step:7|6   loss:0.4869905710220337  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.48780664801597595  \n","Epoch:28/30     Step:2|6   loss:0.4875839054584503  \n","Epoch:28/30     Step:3|6   loss:0.488788366317749  \n","Epoch:28/30     Step:4|6   loss:0.48822087049484253  \n","Epoch:28/30     Step:5|6   loss:0.4902861714363098  \n","Epoch:28/30     Step:6|6   loss:0.4910452365875244  \n","Epoch:28/30     Step:7|6   loss:0.4879165589809418  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49110764265060425  \n","Epoch:29/30     Step:2|6   loss:0.4904116988182068  \n","Epoch:29/30     Step:3|6   loss:0.4873924255371094  \n","Epoch:29/30     Step:4|6   loss:0.4873506426811218  \n","Epoch:29/30     Step:5|6   loss:0.4925283193588257  \n","Epoch:29/30     Step:6|6   loss:0.48686498403549194  \n","Epoch:29/30     Step:7|6   loss:0.48648735880851746  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4893176853656769  \n","Epoch:30/30     Step:2|6   loss:0.48742473125457764  \n","Epoch:30/30     Step:3|6   loss:0.489482045173645  \n","Epoch:30/30     Step:4|6   loss:0.4880296587944031  \n","Epoch:30/30     Step:5|6   loss:0.5002003312110901  \n","Epoch:30/30     Step:6|6   loss:0.4864767789840698  \n","Epoch:30/30     Step:7|6   loss:0.4945785403251648  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 99.07 %\n","3\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.2356539964675903  \n","Epoch:1/30     Step:2|6   loss:0.8886672258377075  \n","Epoch:1/30     Step:3|6   loss:0.5970913171768188  \n","Epoch:1/30     Step:4|6   loss:0.60447096824646  \n","Epoch:1/30     Step:5|6   loss:0.618854820728302  \n","Epoch:1/30     Step:6|6   loss:0.5664065480232239  \n","Epoch:1/30     Step:7|6   loss:0.6059743762016296  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:96.26%\t train set:99.06%\n","Epoch:2/30     Step:1|6   loss:0.5837816596031189  \n","Epoch:2/30     Step:2|6   loss:0.5509907007217407  \n","Epoch:2/30     Step:3|6   loss:0.5443495512008667  \n","Epoch:2/30     Step:4|6   loss:0.5393972992897034  \n","Epoch:2/30     Step:5|6   loss:0.5365666747093201  \n","Epoch:2/30     Step:6|6   loss:0.533962070941925  \n","Epoch:2/30     Step:7|6   loss:0.5582975149154663  \n","Accuracy on test_set: 93.46 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:96.26%\t train set:99.06%\n","Epoch:3/30     Step:1|6   loss:0.5166821479797363  \n","Epoch:3/30     Step:2|6   loss:0.5166193842887878  \n","Epoch:3/30     Step:3|6   loss:0.508796751499176  \n","Epoch:3/30     Step:4|6   loss:0.5186377167701721  \n","Epoch:3/30     Step:5|6   loss:0.5209819078445435  \n","Epoch:3/30     Step:6|6   loss:0.5111643671989441  \n","Epoch:3/30     Step:7|6   loss:0.5006515979766846  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.49696609377861023  \n","Epoch:4/30     Step:2|6   loss:0.5015158653259277  \n","Epoch:4/30     Step:3|6   loss:0.49893608689308167  \n","Epoch:4/30     Step:4|6   loss:0.5062869787216187  \n","Epoch:4/30     Step:5|6   loss:0.5097905397415161  \n","Epoch:4/30     Step:6|6   loss:0.5087143182754517  \n","Epoch:4/30     Step:7|6   loss:0.4985637366771698  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49616143107414246  \n","Epoch:5/30     Step:2|6   loss:0.49624109268188477  \n","Epoch:5/30     Step:3|6   loss:0.4947362244129181  \n","Epoch:5/30     Step:4|6   loss:0.49804624915122986  \n","Epoch:5/30     Step:5|6   loss:0.5012655258178711  \n","Epoch:5/30     Step:6|6   loss:0.49295029044151306  \n","Epoch:5/30     Step:7|6   loss:0.4939054846763611  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49220404028892517  \n","Epoch:6/30     Step:2|6   loss:0.4904722273349762  \n","Epoch:6/30     Step:3|6   loss:0.4930357336997986  \n","Epoch:6/30     Step:4|6   loss:0.49503493309020996  \n","Epoch:6/30     Step:5|6   loss:0.49658986926078796  \n","Epoch:6/30     Step:6|6   loss:0.4917370676994324  \n","Epoch:6/30     Step:7|6   loss:0.49430373311042786  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.48936647176742554  \n","Epoch:7/30     Step:2|6   loss:0.4924202263355255  \n","Epoch:7/30     Step:3|6   loss:0.48977741599082947  \n","Epoch:7/30     Step:4|6   loss:0.48942306637763977  \n","Epoch:7/30     Step:5|6   loss:0.48904117941856384  \n","Epoch:7/30     Step:6|6   loss:0.5005908012390137  \n","Epoch:7/30     Step:7|6   loss:0.49143874645233154  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49499112367630005  \n","Epoch:8/30     Step:2|6   loss:0.48968347907066345  \n","Epoch:8/30     Step:3|6   loss:0.491839200258255  \n","Epoch:8/30     Step:4|6   loss:0.4882851243019104  \n","Epoch:8/30     Step:5|6   loss:0.4917285144329071  \n","Epoch:8/30     Step:6|6   loss:0.4887946844100952  \n","Epoch:8/30     Step:7|6   loss:0.49773067235946655  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4977833032608032  \n","Epoch:9/30     Step:2|6   loss:0.49066901206970215  \n","Epoch:9/30     Step:3|6   loss:0.4886188805103302  \n","Epoch:9/30     Step:4|6   loss:0.4886297881603241  \n","Epoch:9/30     Step:5|6   loss:0.4917217493057251  \n","Epoch:9/30     Step:6|6   loss:0.4950437843799591  \n","Epoch:9/30     Step:7|6   loss:0.4905949831008911  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4878446161746979  \n","Epoch:10/30     Step:2|6   loss:0.4921691417694092  \n","Epoch:10/30     Step:3|6   loss:0.4896154999732971  \n","Epoch:10/30     Step:4|6   loss:0.4885203540325165  \n","Epoch:10/30     Step:5|6   loss:0.486476868391037  \n","Epoch:10/30     Step:6|6   loss:0.48745957016944885  \n","Epoch:10/30     Step:7|6   loss:0.4887247681617737  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.49032148718833923  \n","Epoch:11/30     Step:2|6   loss:0.4885946810245514  \n","Epoch:11/30     Step:3|6   loss:0.4892520308494568  \n","Epoch:11/30     Step:4|6   loss:0.4883180260658264  \n","Epoch:11/30     Step:5|6   loss:0.4931425154209137  \n","Epoch:11/30     Step:6|6   loss:0.4872013032436371  \n","Epoch:11/30     Step:7|6   loss:0.4878814220428467  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.5136882662773132  \n","Epoch:12/30     Step:2|6   loss:0.4883714020252228  \n","Epoch:12/30     Step:3|6   loss:0.49721217155456543  \n","Epoch:12/30     Step:4|6   loss:0.49447405338287354  \n","Epoch:12/30     Step:5|6   loss:0.4873138666152954  \n","Epoch:12/30     Step:6|6   loss:0.4992802143096924  \n","Epoch:12/30     Step:7|6   loss:0.4892670214176178  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.49208545684814453  \n","Epoch:13/30     Step:2|6   loss:0.48742079734802246  \n","Epoch:13/30     Step:3|6   loss:0.5045576095581055  \n","Epoch:13/30     Step:4|6   loss:0.4872949719429016  \n","Epoch:13/30     Step:5|6   loss:0.4905703365802765  \n","Epoch:13/30     Step:6|6   loss:0.4891239404678345  \n","Epoch:13/30     Step:7|6   loss:0.4879828095436096  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4944261312484741  \n","Epoch:14/30     Step:2|6   loss:0.4944199323654175  \n","Epoch:14/30     Step:3|6   loss:0.48963072896003723  \n","Epoch:14/30     Step:4|6   loss:0.5000748634338379  \n","Epoch:14/30     Step:5|6   loss:0.498016357421875  \n","Epoch:14/30     Step:6|6   loss:0.48960375785827637  \n","Epoch:14/30     Step:7|6   loss:0.4930408298969269  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48769882321357727  \n","Epoch:15/30     Step:2|6   loss:0.4895519018173218  \n","Epoch:15/30     Step:3|6   loss:0.48967263102531433  \n","Epoch:15/30     Step:4|6   loss:0.4889744222164154  \n","Epoch:15/30     Step:5|6   loss:0.48825231194496155  \n","Epoch:15/30     Step:6|6   loss:0.5008338093757629  \n","Epoch:15/30     Step:7|6   loss:0.4890892207622528  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4870850145816803  \n","Epoch:16/30     Step:2|6   loss:0.4879957437515259  \n","Epoch:16/30     Step:3|6   loss:0.48827239871025085  \n","Epoch:16/30     Step:4|6   loss:0.5022594332695007  \n","Epoch:16/30     Step:5|6   loss:0.4916859269142151  \n","Epoch:16/30     Step:6|6   loss:0.4888349175453186  \n","Epoch:16/30     Step:7|6   loss:0.4930315613746643  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4901289939880371  \n","Epoch:17/30     Step:2|6   loss:0.48710694909095764  \n","Epoch:17/30     Step:3|6   loss:0.49335676431655884  \n","Epoch:17/30     Step:4|6   loss:0.48689600825309753  \n","Epoch:17/30     Step:5|6   loss:0.4876180589199066  \n","Epoch:17/30     Step:6|6   loss:0.48790204524993896  \n","Epoch:17/30     Step:7|6   loss:0.5003635883331299  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48993390798568726  \n","Epoch:18/30     Step:2|6   loss:0.48857352137565613  \n","Epoch:18/30     Step:3|6   loss:0.4872993230819702  \n","Epoch:18/30     Step:4|6   loss:0.48833122849464417  \n","Epoch:18/30     Step:5|6   loss:0.48736342787742615  \n","Epoch:18/30     Step:6|6   loss:0.48893263936042786  \n","Epoch:18/30     Step:7|6   loss:0.493257611989975  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.48723334074020386  \n","Epoch:19/30     Step:2|6   loss:0.4870638847351074  \n","Epoch:19/30     Step:3|6   loss:0.48794737458229065  \n","Epoch:19/30     Step:4|6   loss:0.4963129162788391  \n","Epoch:19/30     Step:5|6   loss:0.48992910981178284  \n","Epoch:19/30     Step:6|6   loss:0.48739904165267944  \n","Epoch:19/30     Step:7|6   loss:0.48749008774757385  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4929858148097992  \n","Epoch:20/30     Step:2|6   loss:0.4867621660232544  \n","Epoch:20/30     Step:3|6   loss:0.4872806966304779  \n","Epoch:20/30     Step:4|6   loss:0.4886592626571655  \n","Epoch:20/30     Step:5|6   loss:0.4863683581352234  \n","Epoch:20/30     Step:6|6   loss:0.4866671562194824  \n","Epoch:20/30     Step:7|6   loss:0.49434778094291687  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4889317452907562  \n","Epoch:21/30     Step:2|6   loss:0.48652955889701843  \n","Epoch:21/30     Step:3|6   loss:0.48784634470939636  \n","Epoch:21/30     Step:4|6   loss:0.4888218939304352  \n","Epoch:21/30     Step:5|6   loss:0.486799418926239  \n","Epoch:21/30     Step:6|6   loss:0.49075552821159363  \n","Epoch:21/30     Step:7|6   loss:0.49305155873298645  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4883612096309662  \n","Epoch:22/30     Step:2|6   loss:0.49166831374168396  \n","Epoch:22/30     Step:3|6   loss:0.4931662082672119  \n","Epoch:22/30     Step:4|6   loss:0.48838895559310913  \n","Epoch:22/30     Step:5|6   loss:0.4886281490325928  \n","Epoch:22/30     Step:6|6   loss:0.49905699491500854  \n","Epoch:22/30     Step:7|6   loss:0.5066179037094116  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.486576110124588  \n","Epoch:23/30     Step:2|6   loss:0.4872196912765503  \n","Epoch:23/30     Step:3|6   loss:0.4894863963127136  \n","Epoch:23/30     Step:4|6   loss:0.491355299949646  \n","Epoch:23/30     Step:5|6   loss:0.4905286431312561  \n","Epoch:23/30     Step:6|6   loss:0.4924687147140503  \n","Epoch:23/30     Step:7|6   loss:0.48740077018737793  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.48737192153930664  \n","Epoch:24/30     Step:2|6   loss:0.4867347180843353  \n","Epoch:24/30     Step:3|6   loss:0.4885040521621704  \n","Epoch:24/30     Step:4|6   loss:0.4918597638607025  \n","Epoch:24/30     Step:5|6   loss:0.4878527820110321  \n","Epoch:24/30     Step:6|6   loss:0.4915509819984436  \n","Epoch:24/30     Step:7|6   loss:0.49114367365837097  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4867112934589386  \n","Epoch:25/30     Step:2|6   loss:0.49193498492240906  \n","Epoch:25/30     Step:3|6   loss:0.49057650566101074  \n","Epoch:25/30     Step:4|6   loss:0.49515432119369507  \n","Epoch:25/30     Step:5|6   loss:0.4902072548866272  \n","Epoch:25/30     Step:6|6   loss:0.4897648096084595  \n","Epoch:25/30     Step:7|6   loss:0.48693954944610596  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.49047720432281494  \n","Epoch:26/30     Step:2|6   loss:0.489387571811676  \n","Epoch:26/30     Step:3|6   loss:0.48708632588386536  \n","Epoch:26/30     Step:4|6   loss:0.4863584041595459  \n","Epoch:26/30     Step:5|6   loss:0.48761487007141113  \n","Epoch:26/30     Step:6|6   loss:0.4953153729438782  \n","Epoch:26/30     Step:7|6   loss:0.48683321475982666  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","4Epoch:27/30     Step:1|6   loss:0.48793649673461914  \n","Epoch:27/30     Step:2|6   loss:0.4887163043022156  \n","Epoch:27/30     Step:3|6   loss:0.4868336021900177  \n","Epoch:27/30     Step:4|6   loss:0.48921406269073486  \n","Epoch:27/30     Step:5|6   loss:0.4884108304977417  \n","Epoch:27/30     Step:6|6   loss:0.4871295392513275  \n","Epoch:27/30     Step:7|6   loss:0.48690110445022583  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4864523410797119  \n","Epoch:28/30     Step:2|6   loss:0.48741382360458374  \n","Epoch:28/30     Step:3|6   loss:0.4895017147064209  \n","Epoch:28/30     Step:4|6   loss:0.48834478855133057  \n","Epoch:28/30     Step:5|6   loss:0.48779723048210144  \n","Epoch:28/30     Step:6|6   loss:0.4858679175376892  \n","Epoch:28/30     Step:7|6   loss:0.4883023500442505  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4868873655796051  \n","Epoch:29/30     Step:2|6   loss:0.48687484860420227  \n","Epoch:29/30     Step:3|6   loss:0.4869091212749481  \n","Epoch:29/30     Step:4|6   loss:0.4868905544281006  \n","Epoch:29/30     Step:5|6   loss:0.4878208637237549  \n","Epoch:29/30     Step:6|6   loss:0.48628002405166626  \n","Epoch:29/30     Step:7|6   loss:0.49089908599853516  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.48897212743759155  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:30/30     Step:2|6   loss:0.48993775248527527  \n","Epoch:30/30     Step:3|6   loss:0.48616933822631836  \n","Epoch:30/30     Step:4|6   loss:0.4899020791053772  \n","Epoch:30/30     Step:5|6   loss:0.48669055104255676  \n","Epoch:30/30     Step:6|6   loss:0.4922715425491333  \n","Epoch:30/30     Step:7|6   loss:0.4860970377922058  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 100.00 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='rgb', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.052564024925232  \n","Epoch:1/30     Step:2|6   loss:0.7262940406799316  \n","Epoch:1/30     Step:3|6   loss:0.5840262770652771  \n","Epoch:1/30     Step:4|6   loss:0.6439648866653442  \n","Epoch:1/30     Step:5|6   loss:0.6335119605064392  \n","Epoch:1/30     Step:6|6   loss:0.594436764717102  \n","Epoch:1/30     Step:7|6   loss:0.705869197845459  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:95.33%\t train set:98.59%\n","Epoch:2/30     Step:1|6   loss:0.5705127120018005  \n","Epoch:2/30     Step:2|6   loss:0.5604397058486938  \n","Epoch:2/30     Step:3|6   loss:0.536392092704773  \n","Epoch:2/30     Step:4|6   loss:0.5395907163619995  \n","Epoch:2/30     Step:5|6   loss:0.5271176099777222  \n","Epoch:2/30     Step:6|6   loss:0.5150165557861328  \n","Epoch:2/30     Step:7|6   loss:0.5271922945976257  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:3/30     Step:1|6   loss:0.5140926837921143  \n","Epoch:3/30     Step:2|6   loss:0.5151523351669312  \n","Epoch:3/30     Step:3|6   loss:0.5006788372993469  \n","Epoch:3/30     Step:4|6   loss:0.5263184309005737  \n","Epoch:3/30     Step:5|6   loss:0.5042278170585632  \n","Epoch:3/30     Step:6|6   loss:0.5009533166885376  \n","Epoch:3/30     Step:7|6   loss:0.4988473057746887  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.49767664074897766  \n","Epoch:4/30     Step:2|6   loss:0.5165528655052185  \n","Epoch:4/30     Step:3|6   loss:0.5005085468292236  \n","Epoch:4/30     Step:4|6   loss:0.49903130531311035  \n","Epoch:4/30     Step:5|6   loss:0.5147796869277954  \n","Epoch:4/30     Step:6|6   loss:0.4999522864818573  \n","Epoch:4/30     Step:7|6   loss:0.502644419670105  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49374228715896606  \n","Epoch:5/30     Step:2|6   loss:0.49724656343460083  \n","Epoch:5/30     Step:3|6   loss:0.49733686447143555  \n","Epoch:5/30     Step:4|6   loss:0.5079363584518433  \n","Epoch:5/30     Step:5|6   loss:0.4958477020263672  \n","Epoch:5/30     Step:6|6   loss:0.4914477467536926  \n","Epoch:5/30     Step:7|6   loss:0.4976035952568054  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4934823513031006  \n","Epoch:6/30     Step:2|6   loss:0.4946075975894928  \n","Epoch:6/30     Step:3|6   loss:0.4953463077545166  \n","Epoch:6/30     Step:4|6   loss:0.4916883111000061  \n","Epoch:6/30     Step:5|6   loss:0.48919206857681274  \n","Epoch:6/30     Step:6|6   loss:0.49235284328460693  \n","Epoch:6/30     Step:7|6   loss:0.49450090527534485  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.492886483669281  \n","Epoch:7/30     Step:2|6   loss:0.48937857151031494  \n","Epoch:7/30     Step:3|6   loss:0.4920673966407776  \n","Epoch:7/30     Step:4|6   loss:0.4901547431945801  \n","Epoch:7/30     Step:5|6   loss:0.4999783933162689  \n","Epoch:7/30     Step:6|6   loss:0.4899101257324219  \n","Epoch:7/30     Step:7|6   loss:0.49420440196990967  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4879497289657593  \n","Epoch:8/30     Step:2|6   loss:0.5038185119628906  \n","Epoch:8/30     Step:3|6   loss:0.48971033096313477  \n","Epoch:8/30     Step:4|6   loss:0.4899671971797943  \n","Epoch:8/30     Step:5|6   loss:0.49100789427757263  \n","Epoch:8/30     Step:6|6   loss:0.4891873002052307  \n","Epoch:8/30     Step:7|6   loss:0.4883328974246979  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.5007567405700684  \n","Epoch:9/30     Step:2|6   loss:0.4877570569515228  \n","Epoch:9/30     Step:3|6   loss:0.48788654804229736  \n","Epoch:9/30     Step:4|6   loss:0.49457764625549316  \n","Epoch:9/30     Step:5|6   loss:0.4928554594516754  \n","Epoch:9/30     Step:6|6   loss:0.4887288212776184  \n","Epoch:9/30     Step:7|6   loss:0.49042072892189026  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.490634560585022  \n","Epoch:10/30     Step:2|6   loss:0.49336501955986023  \n","Epoch:10/30     Step:3|6   loss:0.48812389373779297  \n","Epoch:10/30     Step:4|6   loss:0.4883057773113251  \n","Epoch:10/30     Step:5|6   loss:0.4937087893486023  \n","Epoch:10/30     Step:6|6   loss:0.4913581907749176  \n","Epoch:10/30     Step:7|6   loss:0.4871719181537628  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4894905090332031  \n","Epoch:11/30     Step:2|6   loss:0.49137604236602783  \n","Epoch:11/30     Step:3|6   loss:0.4874081015586853  \n","Epoch:11/30     Step:4|6   loss:0.48843204975128174  \n","Epoch:11/30     Step:5|6   loss:0.4885334074497223  \n","Epoch:11/30     Step:6|6   loss:0.49441495537757874  \n","Epoch:11/30     Step:7|6   loss:0.4890356957912445  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48755839467048645  \n","Epoch:12/30     Step:2|6   loss:0.48990052938461304  \n","Epoch:12/30     Step:3|6   loss:0.4871712028980255  \n","Epoch:12/30     Step:4|6   loss:0.4871354103088379  \n","Epoch:12/30     Step:5|6   loss:0.48862171173095703  \n","Epoch:12/30     Step:6|6   loss:0.48726707696914673  \n","Epoch:12/30     Step:7|6   loss:0.5036330819129944  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.48928558826446533  \n","Epoch:13/30     Step:2|6   loss:0.48806247115135193  \n","Epoch:13/30     Step:3|6   loss:0.4870437979698181  \n","Epoch:13/30     Step:4|6   loss:0.48828399181365967  \n","Epoch:13/30     Step:5|6   loss:0.48750704526901245  \n","Epoch:13/30     Step:6|6   loss:0.4904935956001282  \n","Epoch:13/30     Step:7|6   loss:0.4913470149040222  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48996978998184204  \n","Epoch:14/30     Step:2|6   loss:0.48902982473373413  \n","Epoch:14/30     Step:3|6   loss:0.4899282157421112  \n","Epoch:14/30     Step:4|6   loss:0.4867052435874939  \n","Epoch:14/30     Step:5|6   loss:0.48772186040878296  \n","Epoch:14/30     Step:6|6   loss:0.48929154872894287  \n","Epoch:14/30     Step:7|6   loss:0.4892222285270691  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4863714575767517  \n","Epoch:15/30     Step:2|6   loss:0.4863084554672241  \n","Epoch:15/30     Step:3|6   loss:0.48947104811668396  \n","Epoch:15/30     Step:4|6   loss:0.48634809255599976  \n","Epoch:15/30     Step:5|6   loss:0.48704636096954346  \n","Epoch:15/30     Step:6|6   loss:0.48890256881713867  \n","Epoch:15/30     Step:7|6   loss:0.49522459506988525  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.485821932554245  \n","Epoch:16/30     Step:2|6   loss:0.48717981576919556  \n","Epoch:16/30     Step:3|6   loss:0.490837037563324  \n","Epoch:16/30     Step:4|6   loss:0.4904179573059082  \n","Epoch:16/30     Step:5|6   loss:0.48885807394981384  \n","Epoch:16/30     Step:6|6   loss:0.49272656440734863  \n","Epoch:16/30     Step:7|6   loss:0.4904080629348755  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.49401021003723145  \n","Epoch:17/30     Step:2|6   loss:0.48707208037376404  \n","Epoch:17/30     Step:3|6   loss:0.48891061544418335  \n","Epoch:17/30     Step:4|6   loss:0.4928240180015564  \n","Epoch:17/30     Step:5|6   loss:0.48838579654693604  \n","Epoch:17/30     Step:6|6   loss:0.4920980930328369  \n","Epoch:17/30     Step:7|6   loss:0.4929431676864624  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48839449882507324  \n","Epoch:18/30     Step:2|6   loss:0.48854464292526245  \n","Epoch:18/30     Step:3|6   loss:0.4874995946884155  \n","Epoch:18/30     Step:4|6   loss:0.49861592054367065  \n","Epoch:18/30     Step:5|6   loss:0.487088680267334  \n","Epoch:18/30     Step:6|6   loss:0.4866775572299957  \n","Epoch:18/30     Step:7|6   loss:0.4957554042339325  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4866924583911896  \n","Epoch:19/30     Step:2|6   loss:0.4870983362197876  \n","Epoch:19/30     Step:3|6   loss:0.4865491986274719  \n","Epoch:19/30     Step:4|6   loss:0.4886547029018402  \n","Epoch:19/30     Step:5|6   loss:0.48824650049209595  \n","Epoch:19/30     Step:6|6   loss:0.48761361837387085  \n","Epoch:19/30     Step:7|6   loss:0.4868184030056  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4877704381942749  \n","Epoch:20/30     Step:2|6   loss:0.4985314905643463  \n","Epoch:20/30     Step:3|6   loss:0.49508631229400635  \n","Epoch:20/30     Step:4|6   loss:0.5033593773841858  \n","Epoch:20/30     Step:5|6   loss:0.4866374135017395  \n","Epoch:20/30     Step:6|6   loss:0.49001815915107727  \n","Epoch:20/30     Step:7|6   loss:0.4885241389274597  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48880720138549805  \n","Epoch:21/30     Step:2|6   loss:0.48783260583877563  \n","Epoch:21/30     Step:3|6   loss:0.49620506167411804  \n","Epoch:21/30     Step:4|6   loss:0.48634859919548035  \n","Epoch:21/30     Step:5|6   loss:0.48700568079948425  \n","Epoch:21/30     Step:6|6   loss:0.49819499254226685  \n","Epoch:21/30     Step:7|6   loss:0.49980390071868896  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48612940311431885  \n","Epoch:22/30     Step:2|6   loss:0.4946991801261902  \n","Epoch:22/30     Step:3|6   loss:0.4887220859527588  \n","Epoch:22/30     Step:4|6   loss:0.4915134906768799  \n","Epoch:22/30     Step:5|6   loss:0.48962733149528503  \n","Epoch:22/30     Step:6|6   loss:0.4897083342075348  \n","Epoch:22/30     Step:7|6   loss:0.48806270956993103  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4874444603919983  \n","Epoch:23/30     Step:2|6   loss:0.49373000860214233  \n","Epoch:23/30     Step:3|6   loss:0.48685818910598755  \n","Epoch:23/30     Step:4|6   loss:0.4883740544319153  \n","Epoch:23/30     Step:5|6   loss:0.4891999065876007  \n","Epoch:23/30     Step:6|6   loss:0.49218735098838806  \n","Epoch:23/30     Step:7|6   loss:0.48882952332496643  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4862448573112488  \n","Epoch:24/30     Step:2|6   loss:0.4881982207298279  \n","Epoch:24/30     Step:3|6   loss:0.49527549743652344  \n","Epoch:24/30     Step:4|6   loss:0.49679601192474365  \n","Epoch:24/30     Step:5|6   loss:0.4948711097240448  \n","Epoch:24/30     Step:6|6   loss:0.4883272349834442  \n","Epoch:24/30     Step:7|6   loss:0.48809942603111267  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4892250895500183  \n","Epoch:25/30     Step:2|6   loss:0.48803186416625977  \n","Epoch:25/30     Step:3|6   loss:0.4890839755535126  \n","Epoch:25/30     Step:4|6   loss:0.4876423180103302  \n","Epoch:25/30     Step:5|6   loss:0.48680853843688965  \n","Epoch:25/30     Step:6|6   loss:0.48807990550994873  \n","Epoch:25/30     Step:7|6   loss:0.4911234378814697  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.48763227462768555  \n","Epoch:26/30     Step:2|6   loss:0.48592448234558105  \n","Epoch:26/30     Step:3|6   loss:0.4891878366470337  \n","Epoch:26/30     Step:4|6   loss:0.49509748816490173  \n","Epoch:26/30     Step:5|6   loss:0.4880185127258301  \n","Epoch:26/30     Step:6|6   loss:0.4869846701622009  \n","Epoch:26/30     Step:7|6   loss:0.4902389943599701  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.49422141909599304  \n","Epoch:27/30     Step:2|6   loss:0.4877704679965973  \n","Epoch:27/30     Step:3|6   loss:0.4874810576438904  \n","Epoch:27/30     Step:4|6   loss:0.48677343130111694  \n","Epoch:27/30     Step:5|6   loss:0.486455500125885  \n","Epoch:27/30     Step:6|6   loss:0.48840421438217163  \n","Epoch:27/30     Step:7|6   loss:0.4872097373008728  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4866253435611725  \n","Epoch:28/30     Step:2|6   loss:0.4861404001712799  \n","Epoch:28/30     Step:3|6   loss:0.48733237385749817  \n","Epoch:28/30     Step:4|6   loss:0.488637238740921  \n","Epoch:28/30     Step:5|6   loss:0.48702046275138855  \n","Epoch:28/30     Step:6|6   loss:0.49031710624694824  \n","Epoch:28/30     Step:7|6   loss:0.49268868565559387  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4867308735847473  \n","Epoch:29/30     Step:2|6   loss:0.48688000440597534  \n","Epoch:29/30     Step:3|6   loss:0.48936253786087036  \n","Epoch:29/30     Step:4|6   loss:0.48907411098480225  \n","Epoch:29/30     Step:5|6   loss:0.4864898920059204  \n","Epoch:29/30     Step:6|6   loss:0.48871275782585144  \n","Epoch:29/30     Step:7|6   loss:0.48785343766212463  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.48710280656814575  \n","Epoch:30/30     Step:2|6   loss:0.48635900020599365  \n","Epoch:30/30     Step:3|6   loss:0.48665016889572144  \n","Epoch:30/30     Step:4|6   loss:0.4868582487106323  \n","Epoch:30/30     Step:5|6   loss:0.48751169443130493  \n","Epoch:30/30     Step:6|6   loss:0.49022072553634644  \n","Epoch:30/30     Step:7|6   loss:0.4871314764022827  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 100.00 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model Resnet18 --mode rgb --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":20,"id":"2471bf58","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.5465431213378906  \n","Epoch:1/30     Step:2|6   loss:1.1175874471664429  \n","Epoch:1/30     Step:3|6   loss:1.0301322937011719  \n","Epoch:1/30     Step:4|6   loss:0.7931456565856934  \n","Epoch:1/30     Step:5|6   loss:0.7568449974060059  \n","Epoch:1/30     Step:6|6   loss:0.794508695602417  \n","Epoch:1/30     Step:7|6   loss:0.749174952507019  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 93.68 %\n","current max accuracy\t test set:94.39%\t train set:93.68%\n","Epoch:2/30     Step:1|6   loss:0.6206067204475403  \n","Epoch:2/30     Step:2|6   loss:0.6277030110359192  \n","Epoch:2/30     Step:3|6   loss:0.6518687009811401  \n","Epoch:2/30     Step:4|6   loss:0.6119986772537231  \n","Epoch:2/30     Step:5|6   loss:0.6204826235771179  \n","1Epoch:2/30     Step:6|6   loss:0.6103338599205017  \n","Epoch:2/30     Step:7|6   loss:0.5901867151260376  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:95.33%\t train set:98.59%\n","Epoch:3/30     Step:1|6   loss:0.5610905885696411  \n","Epoch:3/30     Step:2|6   loss:0.544740617275238  \n","Epoch:3/30     Step:3|6   loss:0.5383734107017517  \n","Epoch:3/30     Step:4|6   loss:0.5396198034286499  \n","Epoch:3/30     Step:5|6   loss:0.5446982383728027  \n","Epoch:3/30     Step:6|6   loss:0.5554147958755493  \n","Epoch:3/30     Step:7|6   loss:0.5376220345497131  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5331924557685852  \n","Epoch:4/30     Step:2|6   loss:0.523523211479187  \n","Epoch:4/30     Step:3|6   loss:0.5246092081069946  \n","Epoch:4/30     Step:4|6   loss:0.5223150253295898  \n","Epoch:4/30     Step:5|6   loss:0.5126660466194153  \n","Epoch:4/30     Step:6|6   loss:0.5094523429870605  \n","Epoch:4/30     Step:7|6   loss:0.5179413557052612  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5086672306060791  \n","Epoch:5/30     Step:2|6   loss:0.5027947425842285  \n","Epoch:5/30     Step:3|6   loss:0.5041446089744568  \n","Epoch:5/30     Step:4|6   loss:0.504984974861145  \n","Epoch:5/30     Step:5|6   loss:0.5061410665512085  \n","Epoch:5/30     Step:6|6   loss:0.5049968957901001  \n","Epoch:5/30     Step:7|6   loss:0.5138915181159973  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49667438864707947  \n","Epoch:6/30     Step:2|6   loss:0.49854007363319397  \n","Epoch:6/30     Step:3|6   loss:0.5040803551673889  \n","Epoch:6/30     Step:4|6   loss:0.492464154958725  \n","Epoch:6/30     Step:5|6   loss:0.49633848667144775  \n","Epoch:6/30     Step:6|6   loss:0.49418139457702637  \n","Epoch:6/30     Step:7|6   loss:0.5002384781837463  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.5019079446792603  \n","Epoch:7/30     Step:2|6   loss:0.49631208181381226  \n","Epoch:7/30     Step:3|6   loss:0.4920036792755127  \n","Epoch:7/30     Step:4|6   loss:0.49462220072746277  \n","Epoch:7/30     Step:5|6   loss:0.49222177267074585  \n","Epoch:7/30     Step:6|6   loss:0.48999136686325073  \n","Epoch:7/30     Step:7|6   loss:0.499204158782959  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.5140970349311829  \n","Epoch:8/30     Step:2|6   loss:0.49294111132621765  \n","Epoch:8/30     Step:3|6   loss:0.49473848938941956  \n","Epoch:8/30     Step:4|6   loss:0.4895784556865692  \n","Epoch:8/30     Step:5|6   loss:0.5078808665275574  \n","Epoch:8/30     Step:6|6   loss:0.4936945140361786  \n","Epoch:8/30     Step:7|6   loss:0.4914427697658539  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49448543787002563  \n","Epoch:9/30     Step:2|6   loss:0.49465930461883545  \n","Epoch:9/30     Step:3|6   loss:0.49351003766059875  \n","Epoch:9/30     Step:4|6   loss:0.49084779620170593  \n","Epoch:9/30     Step:5|6   loss:0.49624764919281006  \n","Epoch:9/30     Step:6|6   loss:0.4895898997783661  \n","Epoch:9/30     Step:7|6   loss:0.49308323860168457  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4913749098777771  \n","Epoch:10/30     Step:2|6   loss:0.4932757318019867  \n","Epoch:10/30     Step:3|6   loss:0.4913095235824585  \n","Epoch:10/30     Step:4|6   loss:0.4952419400215149  \n","Epoch:10/30     Step:5|6   loss:0.4897546172142029  \n","Epoch:10/30     Step:6|6   loss:0.5063173770904541  \n","Epoch:10/30     Step:7|6   loss:0.48956596851348877  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4904329478740692  \n","Epoch:11/30     Step:2|6   loss:0.4895283579826355  \n","Epoch:11/30     Step:3|6   loss:0.49769142270088196  \n","Epoch:11/30     Step:4|6   loss:0.5043426156044006  \n","Epoch:11/30     Step:5|6   loss:0.49054837226867676  \n","Epoch:11/30     Step:6|6   loss:0.48936960101127625  \n","Epoch:11/30     Step:7|6   loss:0.4928947389125824  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.48731955885887146  \n","Epoch:12/30     Step:2|6   loss:0.4878765940666199  \n","Epoch:12/30     Step:3|6   loss:0.4919125437736511  \n","Epoch:12/30     Step:4|6   loss:0.49258556962013245  \n","Epoch:12/30     Step:5|6   loss:0.4927830100059509  \n","Epoch:12/30     Step:6|6   loss:0.4913271963596344  \n","Epoch:12/30     Step:7|6   loss:0.4903097152709961  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4914233088493347  \n","Epoch:13/30     Step:2|6   loss:0.5007566213607788  \n","Epoch:13/30     Step:3|6   loss:0.4907359480857849  \n","Epoch:13/30     Step:4|6   loss:0.49138084053993225  \n","Epoch:13/30     Step:5|6   loss:0.48785728216171265  \n","Epoch:13/30     Step:6|6   loss:0.4943942427635193  \n","Epoch:13/30     Step:7|6   loss:0.4902627468109131  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4908038377761841  \n","Epoch:14/30     Step:2|6   loss:0.4919532537460327  \n","Epoch:14/30     Step:3|6   loss:0.48732975125312805  \n","Epoch:14/30     Step:4|6   loss:0.4904738962650299  \n","Epoch:14/30     Step:5|6   loss:0.4904737174510956  \n","Epoch:14/30     Step:6|6   loss:0.4944283366203308  \n","Epoch:14/30     Step:7|6   loss:0.4958323836326599  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4900096654891968  \n","Epoch:15/30     Step:2|6   loss:0.49296343326568604  \n","Epoch:15/30     Step:3|6   loss:0.49015891551971436  \n","Epoch:15/30     Step:4|6   loss:0.4953957200050354  \n","Epoch:15/30     Step:5|6   loss:0.4911854863166809  \n","Epoch:15/30     Step:6|6   loss:0.4902407228946686  \n","Epoch:15/30     Step:7|6   loss:0.4888445734977722  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4879574179649353  \n","Epoch:16/30     Step:2|6   loss:0.4922438859939575  \n","Epoch:16/30     Step:3|6   loss:0.48767316341400146  \n","Epoch:16/30     Step:4|6   loss:0.49123045802116394  \n","Epoch:16/30     Step:5|6   loss:0.4913276433944702  \n","Epoch:16/30     Step:6|6   loss:0.48739859461784363  \n","Epoch:16/30     Step:7|6   loss:0.4865770936012268  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.491155207157135  \n","Epoch:17/30     Step:2|6   loss:0.487615704536438  \n","Epoch:17/30     Step:3|6   loss:0.4885738492012024  \n","Epoch:17/30     Step:4|6   loss:0.4889371991157532  \n","Epoch:17/30     Step:5|6   loss:0.4875530004501343  \n","Epoch:17/30     Step:6|6   loss:0.4952845573425293  \n","Epoch:17/30     Step:7|6   loss:0.4872700870037079  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4898691475391388  \n","Epoch:18/30     Step:2|6   loss:0.4880843162536621  \n","Epoch:18/30     Step:3|6   loss:0.4878515899181366  \n","Epoch:18/30     Step:4|6   loss:0.49390989542007446  \n","Epoch:18/30     Step:5|6   loss:0.4893687069416046  \n","Epoch:18/30     Step:6|6   loss:0.48720842599868774  \n","Epoch:18/30     Step:7|6   loss:0.4892312288284302  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4903598725795746  \n","Epoch:19/30     Step:2|6   loss:0.49032163619995117  \n","Epoch:19/30     Step:3|6   loss:0.4873504042625427  \n","Epoch:19/30     Step:4|6   loss:0.4867570400238037  \n","Epoch:19/30     Step:5|6   loss:0.48752686381340027  \n","Epoch:19/30     Step:6|6   loss:0.48834967613220215  \n","Epoch:19/30     Step:7|6   loss:0.48851507902145386  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4974571466445923  \n","Epoch:20/30     Step:2|6   loss:0.4913691282272339  \n","Epoch:20/30     Step:3|6   loss:0.4903758764266968  \n","Epoch:20/30     Step:4|6   loss:0.4884583652019501  \n","Epoch:20/30     Step:5|6   loss:0.4938327372074127  \n","Epoch:20/30     Step:6|6   loss:0.4889928996562958  \n","Epoch:20/30     Step:7|6   loss:0.48763519525527954  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48717695474624634  \n","Epoch:21/30     Step:2|6   loss:0.48768121004104614  \n","Epoch:21/30     Step:3|6   loss:0.48782485723495483  \n","Epoch:21/30     Step:4|6   loss:0.48727405071258545  \n","Epoch:21/30     Step:5|6   loss:0.4992522895336151  \n","Epoch:21/30     Step:6|6   loss:0.4884330630302429  \n","Epoch:21/30     Step:7|6   loss:0.48923125863075256  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4886510968208313  \n","Epoch:22/30     Step:2|6   loss:0.4874214231967926  \n","Epoch:22/30     Step:3|6   loss:0.4872700870037079  \n","Epoch:22/30     Step:4|6   loss:0.48787176609039307  \n","Epoch:22/30     Step:5|6   loss:0.48757725954055786  \n","Epoch:22/30     Step:6|6   loss:0.48797833919525146  \n","Epoch:22/30     Step:7|6   loss:0.49749070405960083  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.48820286989212036  \n","Epoch:23/30     Step:2|6   loss:0.4889664947986603  \n","Epoch:23/30     Step:3|6   loss:0.4960756301879883  \n","Epoch:23/30     Step:4|6   loss:0.4894930422306061  \n","Epoch:23/30     Step:5|6   loss:0.48720023036003113  \n","Epoch:23/30     Step:6|6   loss:0.4899386167526245  \n","Epoch:23/30     Step:7|6   loss:0.4890808165073395  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49172747135162354  \n","Epoch:24/30     Step:2|6   loss:0.4885222911834717  \n","Epoch:24/30     Step:3|6   loss:0.4886054992675781  \n","Epoch:24/30     Step:4|6   loss:0.4874185621738434  \n","Epoch:24/30     Step:5|6   loss:0.4885578155517578  \n","Epoch:24/30     Step:6|6   loss:0.49697476625442505  \n","Epoch:24/30     Step:7|6   loss:0.4903223514556885  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4882791042327881  \n","Epoch:25/30     Step:2|6   loss:0.4874466061592102  \n","Epoch:25/30     Step:3|6   loss:0.4951002597808838  \n","Epoch:25/30     Step:4|6   loss:0.49269264936447144  \n","Epoch:25/30     Step:5|6   loss:0.4913475811481476  \n","Epoch:25/30     Step:6|6   loss:0.4865436255931854  \n","Epoch:25/30     Step:7|6   loss:0.48687872290611267  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.49027514457702637  \n","Epoch:26/30     Step:2|6   loss:0.4905921220779419  \n","Epoch:26/30     Step:3|6   loss:0.48859065771102905  \n","Epoch:26/30     Step:4|6   loss:0.48808419704437256  \n","Epoch:26/30     Step:5|6   loss:0.4917251467704773  \n","Epoch:26/30     Step:6|6   loss:0.4905129075050354  \n","Epoch:26/30     Step:7|6   loss:0.4910013675689697  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48740512132644653  \n","Epoch:27/30     Step:2|6   loss:0.4865705668926239  \n","Epoch:27/30     Step:3|6   loss:0.48791784048080444  \n","Epoch:27/30     Step:4|6   loss:0.48797962069511414  \n","Epoch:27/30     Step:5|6   loss:0.4859844446182251  \n","Epoch:27/30     Step:6|6   loss:0.4927961528301239  \n","Epoch:27/30     Step:7|6   loss:0.4864557385444641  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4909679591655731  \n","Epoch:28/30     Step:2|6   loss:0.4880352318286896  \n","Epoch:28/30     Step:3|6   loss:0.4890289306640625  \n","Epoch:28/30     Step:4|6   loss:0.48692259192466736  \n","Epoch:28/30     Step:5|6   loss:0.49007803201675415  \n","Epoch:28/30     Step:6|6   loss:0.48682430386543274  \n","Epoch:28/30     Step:7|6   loss:0.4971175193786621  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49423837661743164  \n","Epoch:29/30     Step:2|6   loss:0.4864250123500824  \n","Epoch:29/30     Step:3|6   loss:0.49103018641471863  \n","Epoch:29/30     Step:4|6   loss:0.4910331964492798  \n","Epoch:29/30     Step:5|6   loss:0.4864417612552643  \n","Epoch:29/30     Step:6|6   loss:0.4933903217315674  \n","Epoch:29/30     Step:7|6   loss:0.49208927154541016  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.48796769976615906  \n","Epoch:30/30     Step:2|6   loss:0.4874143600463867  \n","Epoch:30/30     Step:3|6   loss:0.48727214336395264  \n","Epoch:30/30     Step:4|6   loss:0.48819613456726074  \n","Epoch:30/30     Step:5|6   loss:0.4925459623336792  \n","Epoch:30/30     Step:6|6   loss:0.48678040504455566  \n","Epoch:30/30     Step:7|6   loss:0.4938286244869232  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 96.26 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )2\n","\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1813325881958008  \n","Epoch:1/30     Step:2|6   loss:0.8340868353843689  \n","Epoch:1/30     Step:3|6   loss:0.6413538455963135  \n","Epoch:1/30     Step:4|6   loss:0.6281635761260986  \n","Epoch:1/30     Step:5|6   loss:0.6253818869590759  \n","Epoch:1/30     Step:6|6   loss:0.7762106657028198  \n","Epoch:1/30     Step:7|6   loss:0.6263860464096069  \n","Accuracy on test_set: 89.72 %\n","Accuracy on train_set: 94.15 %\n","current max accuracy\t test set:89.72%\t train set:94.15%\n","Epoch:2/30     Step:1|6   loss:0.5548624396324158  \n","Epoch:2/30     Step:2|6   loss:0.5574471950531006  \n","Epoch:2/30     Step:3|6   loss:0.561053454875946  \n","Epoch:2/30     Step:4|6   loss:0.5561290383338928  \n","Epoch:2/30     Step:5|6   loss:0.5237109661102295  \n","Epoch:2/30     Step:6|6   loss:0.5392599105834961  \n","Epoch:2/30     Step:7|6   loss:0.5355994701385498  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:95.33%\t train set:99.53%\n","Epoch:3/30     Step:1|6   loss:0.5299371480941772  \n","Epoch:3/30     Step:2|6   loss:0.5391430854797363  \n","Epoch:3/30     Step:3|6   loss:0.5204781889915466  \n","Epoch:3/30     Step:4|6   loss:0.5252372026443481  \n","Epoch:3/30     Step:5|6   loss:0.5153350830078125  \n","Epoch:3/30     Step:6|6   loss:0.527182936668396  \n","Epoch:3/30     Step:7|6   loss:0.5276968479156494  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5130205154418945  \n","Epoch:4/30     Step:2|6   loss:0.5081350803375244  \n","Epoch:4/30     Step:3|6   loss:0.5101768374443054  \n","Epoch:4/30     Step:4|6   loss:0.5058220028877258  \n","Epoch:4/30     Step:5|6   loss:0.5141698718070984  \n","Epoch:4/30     Step:6|6   loss:0.5052208304405212  \n","Epoch:4/30     Step:7|6   loss:0.4989459812641144  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:97.2%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5014477968215942  \n","Epoch:5/30     Step:2|6   loss:0.4975173771381378  \n","Epoch:5/30     Step:3|6   loss:0.5044410824775696  \n","Epoch:5/30     Step:4|6   loss:0.5024556517601013  \n","Epoch:5/30     Step:5|6   loss:0.4986659288406372  \n","Epoch:5/30     Step:6|6   loss:0.495418906211853  \n","Epoch:5/30     Step:7|6   loss:0.4986199736595154  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.4962899088859558  \n","Epoch:6/30     Step:2|6   loss:0.4921817183494568  \n","Epoch:6/30     Step:3|6   loss:0.4977205693721771  \n","Epoch:6/30     Step:4|6   loss:0.4973379969596863  \n","Epoch:6/30     Step:5|6   loss:0.5067729353904724  \n","Epoch:6/30     Step:6|6   loss:0.4998583495616913  \n","Epoch:6/30     Step:7|6   loss:0.5077177286148071  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.5021024942398071  \n","Epoch:7/30     Step:2|6   loss:0.49070775508880615  \n","Epoch:7/30     Step:3|6   loss:0.48966309428215027  \n","Epoch:7/30     Step:4|6   loss:0.4959411323070526  \n","Epoch:7/30     Step:5|6   loss:0.49583104252815247  \n","Epoch:7/30     Step:6|6   loss:0.48967644572257996  \n","Epoch:7/30     Step:7|6   loss:0.4964526295661926  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4945042133331299  \n","Epoch:8/30     Step:2|6   loss:0.4980747699737549  \n","Epoch:8/30     Step:3|6   loss:0.48908746242523193  \n","Epoch:8/30     Step:4|6   loss:0.48896071314811707  \n","Epoch:8/30     Step:5|6   loss:0.49405550956726074  \n","Epoch:8/30     Step:6|6   loss:0.4917241632938385  \n","Epoch:8/30     Step:7|6   loss:0.4920482635498047  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49078184366226196  \n","Epoch:9/30     Step:2|6   loss:0.5132373571395874  \n","Epoch:9/30     Step:3|6   loss:0.49617117643356323  \n","Epoch:9/30     Step:4|6   loss:0.4952079951763153  \n","Epoch:9/30     Step:5|6   loss:0.4884052276611328  \n","Epoch:9/30     Step:6|6   loss:0.4909064769744873  \n","Epoch:9/30     Step:7|6   loss:0.4911152422428131  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.4949267506599426  \n","Epoch:10/30     Step:2|6   loss:0.4934176504611969  \n","Epoch:10/30     Step:3|6   loss:0.48740577697753906  \n","Epoch:10/30     Step:4|6   loss:0.48738062381744385  \n","Epoch:10/30     Step:5|6   loss:0.49730247259140015  \n","Epoch:10/30     Step:6|6   loss:0.49011290073394775  \n","Epoch:10/30     Step:7|6   loss:0.4932626485824585  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4941820502281189  \n","Epoch:11/30     Step:2|6   loss:0.49154654145240784  \n","Epoch:11/30     Step:3|6   loss:0.49550431966781616  \n","Epoch:11/30     Step:4|6   loss:0.4964904189109802  \n","Epoch:11/30     Step:5|6   loss:0.4876452386379242  \n","Epoch:11/30     Step:6|6   loss:0.48914116621017456  \n","Epoch:11/30     Step:7|6   loss:0.49375730752944946  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.49215614795684814  \n","Epoch:12/30     Step:2|6   loss:0.4877295196056366  \n","Epoch:12/30     Step:3|6   loss:0.4908972978591919  \n","Epoch:12/30     Step:4|6   loss:0.4902770519256592  \n","Epoch:12/30     Step:5|6   loss:0.4885655343532562  \n","Epoch:12/30     Step:6|6   loss:0.4987737536430359  \n","Epoch:12/30     Step:7|6   loss:0.49142882227897644  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4877156913280487  \n","Epoch:13/30     Step:2|6   loss:0.4911888837814331  \n","Epoch:13/30     Step:3|6   loss:0.4880824387073517  \n","Epoch:13/30     Step:4|6   loss:0.4875354468822479  \n","Epoch:13/30     Step:5|6   loss:0.4916936159133911  \n","Epoch:13/30     Step:6|6   loss:0.49152225255966187  \n","Epoch:13/30     Step:7|6   loss:0.4933398365974426  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4869278073310852  \n","Epoch:14/30     Step:2|6   loss:0.48950254917144775  \n","Epoch:14/30     Step:3|6   loss:0.4875331521034241  \n","Epoch:14/30     Step:4|6   loss:0.5059155225753784  \n","Epoch:14/30     Step:5|6   loss:0.4917250871658325  \n","Epoch:14/30     Step:6|6   loss:0.4893554449081421  \n","Epoch:14/30     Step:7|6   loss:0.48766404390335083  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48807409405708313  \n","Epoch:15/30     Step:2|6   loss:0.4888148903846741  \n","Epoch:15/30     Step:3|6   loss:0.49042680859565735  \n","Epoch:15/30     Step:4|6   loss:0.4873107969760895  \n","Epoch:15/30     Step:5|6   loss:0.4872518479824066  \n","Epoch:15/30     Step:6|6   loss:0.4863857924938202  \n","Epoch:15/30     Step:7|6   loss:0.48953449726104736  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.487213671207428  \n","Epoch:16/30     Step:2|6   loss:0.4891093373298645  \n","Epoch:16/30     Step:3|6   loss:0.4908321499824524  \n","Epoch:16/30     Step:4|6   loss:0.4873192608356476  \n","Epoch:16/30     Step:5|6   loss:0.4932553768157959  \n","Epoch:16/30     Step:6|6   loss:0.4893328845500946  \n","Epoch:16/30     Step:7|6   loss:0.5130810737609863  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.4875527322292328  \n","Epoch:17/30     Step:2|6   loss:0.4889070391654968  \n","Epoch:17/30     Step:3|6   loss:0.48878225684165955  \n","Epoch:17/30     Step:4|6   loss:0.48974043130874634  \n","Epoch:17/30     Step:5|6   loss:0.48874878883361816  \n","Epoch:17/30     Step:6|6   loss:0.4885746240615845  \n","Epoch:17/30     Step:7|6   loss:0.4886775314807892  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48704564571380615  \n","Epoch:18/30     Step:2|6   loss:0.48765406012535095  \n","Epoch:18/30     Step:3|6   loss:0.48831745982170105  \n","Epoch:18/30     Step:4|6   loss:0.4885161817073822  \n","Epoch:18/30     Step:5|6   loss:0.490168958902359  \n","Epoch:18/30     Step:6|6   loss:0.48790881037712097  \n","Epoch:18/30     Step:7|6   loss:0.49137353897094727  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4921013116836548  \n","Epoch:19/30     Step:2|6   loss:0.48825153708457947  \n","Epoch:19/30     Step:3|6   loss:0.4887254238128662  \n","Epoch:19/30     Step:4|6   loss:0.4905817210674286  \n","Epoch:19/30     Step:5|6   loss:0.4870821237564087  \n","Epoch:19/30     Step:6|6   loss:0.4872055649757385  \n","Epoch:19/30     Step:7|6   loss:0.48791539669036865  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4886172115802765  \n","Epoch:20/30     Step:2|6   loss:0.4904026389122009  \n","Epoch:20/30     Step:3|6   loss:0.4917188286781311  \n","Epoch:20/30     Step:4|6   loss:0.4903258681297302  \n","Epoch:20/30     Step:5|6   loss:0.48668187856674194  \n","Epoch:20/30     Step:6|6   loss:0.492604523897171  \n","Epoch:20/30     Step:7|6   loss:0.48800474405288696  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48659998178482056  \n","Epoch:21/30     Step:2|6   loss:0.487744003534317  \n","Epoch:21/30     Step:3|6   loss:0.4902235269546509  \n","Epoch:21/30     Step:4|6   loss:0.48644113540649414  \n","Epoch:21/30     Step:5|6   loss:0.48889195919036865  \n","Epoch:21/30     Step:6|6   loss:0.49047112464904785  \n","Epoch:21/30     Step:7|6   loss:0.4899371266365051  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.49238938093185425  \n","Epoch:22/30     Step:2|6   loss:0.48879605531692505  \n","Epoch:22/30     Step:3|6   loss:0.4876680374145508  \n","Epoch:22/30     Step:4|6   loss:0.49304673075675964  \n","Epoch:22/30     Step:5|6   loss:0.4872719347476959  \n","Epoch:22/30     Step:6|6   loss:0.49378952383995056  \n","Epoch:22/30     Step:7|6   loss:0.4890218675136566  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4878455400466919  \n","Epoch:23/30     Step:2|6   loss:0.4891103506088257  \n","Epoch:23/30     Step:3|6   loss:0.49548017978668213  \n","Epoch:23/30     Step:4|6   loss:0.4875478744506836  \n","Epoch:23/30     Step:5|6   loss:0.49022647738456726  \n","Epoch:23/30     Step:6|6   loss:0.4923447370529175  \n","Epoch:23/30     Step:7|6   loss:0.4904809594154358  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4885318875312805  \n","Epoch:24/30     Step:2|6   loss:0.48951399326324463  \n","Epoch:24/30     Step:3|6   loss:0.48805105686187744  \n","Epoch:24/30     Step:4|6   loss:0.4913344979286194  \n","Epoch:24/30     Step:5|6   loss:0.48755326867103577  \n","Epoch:24/30     Step:6|6   loss:0.48857033252716064  \n","Epoch:24/30     Step:7|6   loss:0.5000502467155457  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48881152272224426  \n","Epoch:25/30     Step:2|6   loss:0.4872974157333374  \n","Epoch:25/30     Step:3|6   loss:0.4899047315120697  \n","Epoch:25/30     Step:4|6   loss:0.49086645245552063  \n","Epoch:25/30     Step:5|6   loss:0.48876118659973145  \n","Epoch:25/30     Step:6|6   loss:0.494144469499588  \n","Epoch:25/30     Step:7|6   loss:0.48901286721229553  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.49103784561157227  \n","Epoch:26/30     Step:2|6   loss:0.48695993423461914  \n","Epoch:26/30     Step:3|6   loss:0.489516019821167  \n","Epoch:26/30     Step:4|6   loss:0.4873751699924469  \n","Epoch:26/30     Step:5|6   loss:0.49022260308265686  \n","Epoch:26/30     Step:6|6   loss:0.48923560976982117  \n","Epoch:26/30     Step:7|6   loss:0.489019513130188  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4921022057533264  \n","Epoch:27/30     Step:2|6   loss:0.49058717489242554  \n","Epoch:27/30     Step:3|6   loss:0.48999470472335815  \n","Epoch:27/30     Step:4|6   loss:0.49368616938591003  \n","Epoch:27/30     Step:5|6   loss:0.48763883113861084  \n","Epoch:27/30     Step:6|6   loss:0.4874163269996643  \n","Epoch:27/30     Step:7|6   loss:0.5201133489608765  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.49682164192199707  \n","Epoch:28/30     Step:2|6   loss:0.4886396825313568  \n","Epoch:28/30     Step:3|6   loss:0.4880942702293396  \n","Epoch:28/30     Step:4|6   loss:0.49087148904800415  \n","Epoch:28/30     Step:5|6   loss:0.4913865625858307  \n","Epoch:28/30     Step:6|6   loss:0.4889284074306488  \n","Epoch:28/30     Step:7|6   loss:0.49064701795578003  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4904882609844208  \n","Epoch:29/30     Step:2|6   loss:0.49252691864967346  \n","Epoch:29/30     Step:3|6   loss:0.488777220249176  \n","Epoch:29/30     Step:4|6   loss:0.4900842607021332  \n","Epoch:29/30     Step:5|6   loss:0.4895339012145996  \n","Epoch:29/30     Step:6|6   loss:0.48935016989707947  \n","Epoch:29/30     Step:7|6   loss:0.5084179639816284  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4877362549304962  \n","Epoch:30/30     Step:2|6   loss:0.49018844962120056  \n","Epoch:30/30     Step:3|6   loss:0.490030437707901  \n","Epoch:30/30     Step:4|6   loss:0.48968958854675293  \n","Epoch:30/30     Step:5|6   loss:0.49123430252075195  \n","Epoch:30/30     Step:6|6   loss:0.48725205659866333  \n","Epoch:30/30     Step:7|6   loss:0.49060124158859253  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 100.00 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","3\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.127011775970459  \n","Epoch:1/30     Step:2|6   loss:0.9611421823501587  \n","Epoch:1/30     Step:3|6   loss:0.780427098274231  \n","Epoch:1/30     Step:4|6   loss:0.6674677133560181  \n","Epoch:1/30     Step:5|6   loss:0.6482447981834412  \n","Epoch:1/30     Step:6|6   loss:0.6689974069595337  \n","Epoch:1/30     Step:7|6   loss:0.6280634999275208  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 96.72 %\n","current max accuracy\t test set:91.59%\t train set:96.72%\n","Epoch:2/30     Step:1|6   loss:0.6081483960151672  \n","Epoch:2/30     Step:2|6   loss:0.5893973112106323  \n","Epoch:2/30     Step:3|6   loss:0.5748854279518127  \n","Epoch:2/30     Step:4|6   loss:0.5850752592086792  \n","Epoch:2/30     Step:5|6   loss:0.5561429858207703  \n","Epoch:2/30     Step:6|6   loss:0.5539820194244385  \n","Epoch:2/30     Step:7|6   loss:0.5387989282608032  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:97.2%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.5426130294799805  \n","Epoch:3/30     Step:2|6   loss:0.5228182673454285  \n","Epoch:3/30     Step:3|6   loss:0.5414589643478394  \n","Epoch:3/30     Step:4|6   loss:0.5272272825241089  \n","Epoch:3/30     Step:5|6   loss:0.5186786651611328  \n","Epoch:3/30     Step:6|6   loss:0.5115469694137573  \n","Epoch:3/30     Step:7|6   loss:0.5100619196891785  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5187851786613464  \n","Epoch:4/30     Step:2|6   loss:0.5218990445137024  \n","Epoch:4/30     Step:3|6   loss:0.5129679441452026  \n","Epoch:4/30     Step:4|6   loss:0.5058188438415527  \n","Epoch:4/30     Step:5|6   loss:0.5043236017227173  \n","Epoch:4/30     Step:6|6   loss:0.5314126014709473  \n","Epoch:4/30     Step:7|6   loss:0.4944895803928375  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.4997318387031555  \n","Epoch:5/30     Step:2|6   loss:0.49723583459854126  \n","Epoch:5/30     Step:3|6   loss:0.49868491291999817  \n","Epoch:5/30     Step:4|6   loss:0.5090354681015015  \n","Epoch:5/30     Step:5|6   loss:0.49816638231277466  \n","Epoch:5/30     Step:6|6   loss:0.5043343305587769  \n","Epoch:5/30     Step:7|6   loss:0.49634838104248047  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49236345291137695  \n","Epoch:6/30     Step:2|6   loss:0.491943359375  \n","Epoch:6/30     Step:3|6   loss:0.4906058609485626  \n","Epoch:6/30     Step:4|6   loss:0.4933773875236511  \n","Epoch:6/30     Step:5|6   loss:0.492948055267334  \n","Epoch:6/30     Step:6|6   loss:0.49164554476737976  \n","Epoch:6/30     Step:7|6   loss:0.4923344552516937  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.4898585081100464  \n","Epoch:7/30     Step:2|6   loss:0.49207162857055664  \n","Epoch:7/30     Step:3|6   loss:0.5029897689819336  \n","Epoch:7/30     Step:4|6   loss:0.4895051121711731  \n","Epoch:7/30     Step:5|6   loss:0.4956211745738983  \n","Epoch:7/30     Step:6|6   loss:0.4972999393939972  \n","Epoch:7/30     Step:7|6   loss:0.49087950587272644  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4877828061580658  \n","Epoch:8/30     Step:2|6   loss:0.4890258014202118  \n","Epoch:8/30     Step:3|6   loss:0.49449872970581055  \n","Epoch:8/30     Step:4|6   loss:0.4950304627418518  \n","Epoch:8/30     Step:5|6   loss:0.4973350763320923  \n","Epoch:8/30     Step:6|6   loss:0.4914673864841461  \n","Epoch:8/30     Step:7|6   loss:0.4893351197242737  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.4903271794319153  \n","Epoch:9/30     Step:2|6   loss:0.490658164024353  \n","Epoch:9/30     Step:3|6   loss:0.48865634202957153  \n","Epoch:9/30     Step:4|6   loss:0.4895617961883545  \n","Epoch:9/30     Step:5|6   loss:0.4881870746612549  \n","Epoch:9/30     Step:6|6   loss:0.4917701780796051  \n","Epoch:9/30     Step:7|6   loss:0.48993903398513794  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48726072907447815  \n","Epoch:10/30     Step:2|6   loss:0.48838451504707336  \n","Epoch:10/30     Step:3|6   loss:0.4876541495323181  \n","Epoch:10/30     Step:4|6   loss:0.48786839842796326  \n","Epoch:10/30     Step:5|6   loss:0.48721712827682495  \n","Epoch:10/30     Step:6|6   loss:0.4991456866264343  \n","Epoch:10/30     Step:7|6   loss:0.48873746395111084  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4868934452533722  \n","Epoch:11/30     Step:2|6   loss:0.48864656686782837  \n","Epoch:11/30     Step:3|6   loss:0.4932268261909485  \n","Epoch:11/30     Step:4|6   loss:0.4878056049346924  \n","Epoch:11/30     Step:5|6   loss:0.493133008480072  \n","Epoch:11/30     Step:6|6   loss:0.49141907691955566  \n","Epoch:11/30     Step:7|6   loss:0.49704423546791077  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4870762526988983  \n","Epoch:12/30     Step:2|6   loss:0.4862789511680603  \n","Epoch:12/30     Step:3|6   loss:0.49153319001197815  \n","Epoch:12/30     Step:4|6   loss:0.48936623334884644  \n","Epoch:12/30     Step:5|6   loss:0.48778218030929565  \n","Epoch:12/30     Step:6|6   loss:0.48818036913871765  \n","Epoch:12/30     Step:7|6   loss:0.4970531761646271  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.48756271600723267  \n","Epoch:13/30     Step:2|6   loss:0.4906817078590393  \n","Epoch:13/30     Step:3|6   loss:0.487718790769577  \n","Epoch:13/30     Step:4|6   loss:0.4875122606754303  \n","Epoch:13/30     Step:5|6   loss:0.48887965083122253  \n","Epoch:13/30     Step:6|6   loss:0.49385589361190796  \n","Epoch:13/30     Step:7|6   loss:0.49664658308029175  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4871227741241455  \n","Epoch:14/30     Step:2|6   loss:0.49103569984436035  \n","Epoch:14/30     Step:3|6   loss:0.49197790026664734  \n","Epoch:14/30     Step:4|6   loss:0.49297720193862915  \n","Epoch:14/30     Step:5|6   loss:0.48983293771743774  \n","Epoch:14/30     Step:6|6   loss:0.4969940185546875  \n","Epoch:14/30     Step:7|6   loss:0.49883127212524414  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48899951577186584  \n","Epoch:15/30     Step:2|6   loss:0.4871610999107361  \n","Epoch:15/30     Step:3|6   loss:0.4886263608932495  \n","Epoch:15/30     Step:4|6   loss:0.4898460805416107  \n","Epoch:15/30     Step:5|6   loss:0.48864424228668213  \n","Epoch:15/30     Step:6|6   loss:0.4874044954776764  \n","Epoch:15/30     Step:7|6   loss:0.5237340331077576  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.4875633418560028  \n","Epoch:16/30     Step:2|6   loss:0.48705923557281494  \n","Epoch:16/30     Step:3|6   loss:0.48931795358657837  \n","Epoch:16/30     Step:4|6   loss:0.4892902672290802  \n","Epoch:16/30     Step:5|6   loss:0.49568164348602295  \n","Epoch:16/30     Step:6|6   loss:0.48942941427230835  \n","Epoch:16/30     Step:7|6   loss:0.4945341944694519  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.511464536190033  \n","Epoch:17/30     Step:2|6   loss:0.48912185430526733  \n","Epoch:17/30     Step:3|6   loss:0.48874178528785706  \n","Epoch:17/30     Step:4|6   loss:0.49544239044189453  \n","Epoch:17/30     Step:5|6   loss:0.48849815130233765  \n","Epoch:17/30     Step:6|6   loss:0.49876075983047485  \n","Epoch:17/30     Step:7|6   loss:0.48885226249694824  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4893401265144348  \n","Epoch:18/30     Step:2|6   loss:0.4904283881187439  \n","Epoch:18/30     Step:3|6   loss:0.4992215633392334  \n","Epoch:18/30     Step:4|6   loss:0.4895159900188446  \n","Epoch:18/30     Step:5|6   loss:0.49094709753990173  \n","Epoch:18/30     Step:6|6   loss:0.49427688121795654  \n","Epoch:18/30     Step:7|6   loss:0.5060218572616577  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.4900180995464325  \n","Epoch:19/30     Step:2|6   loss:0.4985318183898926  \n","Epoch:19/30     Step:3|6   loss:0.4896981716156006  \n","Epoch:19/30     Step:4|6   loss:0.4981197714805603  \n","Epoch:19/30     Step:5|6   loss:0.4995352625846863  \n","Epoch:19/30     Step:6|6   loss:0.49265193939208984  \n","Epoch:19/30     Step:7|6   loss:0.4901127219200134  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4884374737739563  \n","Epoch:20/30     Step:2|6   loss:0.48828935623168945  \n","Epoch:20/30     Step:3|6   loss:0.48913970589637756  \n","Epoch:20/30     Step:4|6   loss:0.4887911081314087  \n","Epoch:20/30     Step:5|6   loss:0.4881649613380432  \n","Epoch:20/30     Step:6|6   loss:0.4927746653556824  \n","Epoch:20/30     Step:7|6   loss:0.4882166087627411  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.49315541982650757  \n","Epoch:21/30     Step:2|6   loss:0.4930659532546997  \n","Epoch:21/30     Step:3|6   loss:0.48756998777389526  \n","Epoch:21/30     Step:4|6   loss:0.4887394309043884  \n","Epoch:21/30     Step:5|6   loss:0.4883371889591217  \n","Epoch:21/30     Step:6|6   loss:0.4894966781139374  \n","Epoch:21/30     Step:7|6   loss:0.492337167263031  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4883802533149719  \n","Epoch:22/30     Step:2|6   loss:0.48871955275535583  \n","Epoch:22/30     Step:3|6   loss:0.4867475628852844  \n","Epoch:22/30     Step:4|6   loss:0.4902324080467224  \n","Epoch:22/30     Step:5|6   loss:0.48672789335250854  \n","Epoch:22/30     Step:6|6   loss:0.48650938272476196  \n","Epoch:22/30     Step:7|6   loss:0.48941272497177124  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.49015718698501587  \n","Epoch:23/30     Step:2|6   loss:0.5128602385520935  \n","Epoch:23/30     Step:3|6   loss:0.48695147037506104  \n","Epoch:23/30     Step:4|6   loss:0.49390023946762085  \n","Epoch:23/30     Step:5|6   loss:0.49048569798469543  \n","Epoch:23/30     Step:6|6   loss:0.49182748794555664  \n","Epoch:23/30     Step:7|6   loss:0.49160319566726685  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.49366456270217896  \n","Epoch:24/30     Step:2|6   loss:0.48961225152015686  \n","Epoch:24/30     Step:3|6   loss:0.4927601218223572  \n","Epoch:24/30     Step:4|6   loss:0.48755913972854614  \n","Epoch:24/30     Step:5|6   loss:0.4879622757434845  \n","Epoch:24/30     Step:6|6   loss:0.4913736581802368  \n","Epoch:24/30     Step:7|6   loss:0.49895966053009033  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.4944171905517578  \n","Epoch:25/30     Step:2|6   loss:0.48714423179626465  \n","Epoch:25/30     Step:3|6   loss:0.48637914657592773  \n","Epoch:25/30     Step:4|6   loss:0.4896652102470398  \n","Epoch:25/30     Step:5|6   loss:0.48866602778434753  \n","Epoch:25/30     Step:6|6   loss:0.4909277558326721  \n","Epoch:25/30     Step:7|6   loss:0.488483726978302  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4876970052719116  \n","Epoch:26/30     Step:2|6   loss:0.4936913251876831  \n","Epoch:26/30     Step:3|6   loss:0.4871769845485687  \n","Epoch:26/30     Step:4|6   loss:0.4900391101837158  \n","Epoch:26/30     Step:5|6   loss:0.48720070719718933  \n","Epoch:26/30     Step:6|6   loss:0.49242839217185974  \n","Epoch:26/30     Step:7|6   loss:0.4907618761062622  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4871041178703308  \n","Epoch:27/30     Step:2|6   loss:0.4865659475326538  \n","Epoch:27/30     Step:3|6   loss:0.4904760718345642  \n","Epoch:27/30     Step:4|6   loss:0.4877174198627472  \n","Epoch:27/30     Step:5|6   loss:0.4890550971031189  \n","Epoch:27/30     Step:6|6   loss:0.49167490005493164  \n","Epoch:27/30     Step:7|6   loss:0.48891836404800415  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4879987835884094  \n","Epoch:28/30     Step:2|6   loss:0.4916772246360779  \n","Epoch:28/30     Step:3|6   loss:0.48804551362991333  \n","Epoch:28/30     Step:4|6   loss:0.486555278301239  \n","Epoch:28/30     Step:5|6   loss:0.4893106520175934  \n","Epoch:28/30     Step:6|6   loss:0.48956358432769775  \n","Epoch:28/30     Step:7|6   loss:0.4907369017601013  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4891258478164673  \n","Epoch:29/30     Step:2|6   loss:0.4883221387863159  \n","Epoch:29/30     Step:3|6   loss:0.4868037700653076  \n","Epoch:29/30     Step:4|6   loss:0.4871463477611542  \n","Epoch:29/30     Step:5|6   loss:0.48867255449295044  \n","Epoch:29/30     Step:6|6   loss:0.48765939474105835  \n","Epoch:29/30     Step:7|6   loss:0.4892790913581848  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.48996755480766296  \n","Epoch:30/30     Step:2|6   loss:0.48692768812179565  \n","Epoch:30/30     Step:3|6   loss:0.49175751209259033  \n","Epoch:30/30     Step:4|6   loss:0.48888078331947327  \n","Epoch:30/30     Step:5|6   loss:0.4875505268573761  \n","Epoch:30/30     Step:6|6   loss:0.4867953956127167  \n","Epoch:30/30     Step:7|6   loss:0.4956468641757965  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Accuracy on test_set: 96.26 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.4692051410675049  \n","Epoch:1/30     Step:2|6   loss:0.9606142044067383  \n","Epoch:1/30     Step:3|6   loss:0.7733498215675354  \n","Epoch:1/30     Step:4|6   loss:0.8303036689758301  \n","Epoch:1/30     Step:5|6   loss:0.7221815586090088  \n","Epoch:1/30     Step:6|6   loss:0.7427862286567688  \n","Epoch:1/30     Step:7|6   loss:0.6826125979423523  \n","Accuracy on test_set: 88.79 %\n","Accuracy on train_set: 90.87 %\n","current max accuracy\t test set:88.79%\t train set:90.87%\n","Epoch:2/30     Step:1|6   loss:0.6183456182479858  \n","Epoch:2/30     Step:2|6   loss:0.667820930480957  \n","Epoch:2/30     Step:3|6   loss:0.5848164558410645  \n","Epoch:2/30     Step:4|6   loss:0.5611422061920166  \n","Epoch:2/30     Step:5|6   loss:0.5510303974151611  \n","Epoch:2/30     Step:6|6   loss:0.5708820819854736  \n","Epoch:2/30     Step:7|6   loss:0.5714301466941833  \n","Accuracy on test_set: 92.52 %\n","Accuracy on train_set: 97.66 %\n","current max accuracy\t test set:92.52%\t train set:97.66%\n","Epoch:3/30     Step:1|6   loss:0.5237371325492859  \n","Epoch:3/30     Step:2|6   loss:0.5706667900085449  \n","Epoch:3/30     Step:3|6   loss:0.5407911539077759  \n","Epoch:3/30     Step:4|6   loss:0.5189934968948364  \n","Epoch:3/30     Step:5|6   loss:0.5402477383613586  \n","Epoch:3/30     Step:6|6   loss:0.5301163196563721  \n","Epoch:3/30     Step:7|6   loss:0.5188583135604858  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.5091496109962463  \n","Epoch:4/30     Step:2|6   loss:0.5209429264068604  \n","Epoch:4/30     Step:3|6   loss:0.5079706907272339  \n","Epoch:4/30     Step:4|6   loss:0.5034860372543335  \n","Epoch:4/30     Step:5|6   loss:0.527248740196228  \n","Epoch:4/30     Step:6|6   loss:0.5050259828567505  \n","Epoch:4/30     Step:7|6   loss:0.5042319893836975  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.5075840950012207  \n","Epoch:5/30     Step:2|6   loss:0.4969589114189148  \n","Epoch:5/30     Step:3|6   loss:0.5050581693649292  \n","Epoch:5/30     Step:4|6   loss:0.5141052007675171  \n","Epoch:5/30     Step:5|6   loss:0.5054445862770081  \n","Epoch:5/30     Step:6|6   loss:0.4967919588088989  \n","Epoch:5/30     Step:7|6   loss:0.5083202123641968  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.5019751787185669  \n","Epoch:6/30     Step:2|6   loss:0.49956512451171875  \n","Epoch:6/30     Step:3|6   loss:0.49422311782836914  \n","Epoch:6/30     Step:4|6   loss:0.4972013235092163  \n","Epoch:6/30     Step:5|6   loss:0.49465447664260864  \n","Epoch:6/30     Step:6|6   loss:0.49459534883499146  \n","Epoch:6/30     Step:7|6   loss:0.5077515840530396  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49467581510543823  \n","Epoch:7/30     Step:2|6   loss:0.49195951223373413  \n","Epoch:7/30     Step:3|6   loss:0.49442529678344727  \n","Epoch:7/30     Step:4|6   loss:0.5137359499931335  \n","Epoch:7/30     Step:5|6   loss:0.49460744857788086  \n","Epoch:7/30     Step:6|6   loss:0.5011086463928223  \n","Epoch:7/30     Step:7|6   loss:0.49395042657852173  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.49340784549713135  \n","Epoch:8/30     Step:2|6   loss:0.5040050148963928  \n","Epoch:8/30     Step:3|6   loss:0.4980107247829437  \n","Epoch:8/30     Step:4|6   loss:0.494900107383728  \n","Epoch:8/30     Step:5|6   loss:0.49130919575691223  \n","Epoch:8/30     Step:6|6   loss:0.4897754490375519  \n","Epoch:8/30     Step:7|6   loss:0.5109810829162598  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49211227893829346  \n","Epoch:9/30     Step:2|6   loss:0.49383771419525146  \n","Epoch:9/30     Step:3|6   loss:0.4967540204524994  \n","Epoch:9/30     Step:4|6   loss:0.49739348888397217  \n","Epoch:9/30     Step:5|6   loss:0.491039514541626  \n","Epoch:9/30     Step:6|6   loss:0.4925452172756195  \n","Epoch:9/30     Step:7|6   loss:0.48912644386291504  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.49222585558891296  \n","Epoch:10/30     Step:2|6   loss:0.49059489369392395  \n","Epoch:10/30     Step:3|6   loss:0.4884200394153595  \n","Epoch:10/30     Step:4|6   loss:0.4955572187900543  \n","Epoch:10/30     Step:5|6   loss:0.4945369362831116  \n","Epoch:10/30     Step:6|6   loss:0.4911001920700073  \n","Epoch:10/30     Step:7|6   loss:0.4917010962963104  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.496399462223053  \n","Epoch:11/30     Step:2|6   loss:0.4893786311149597  \n","Epoch:11/30     Step:3|6   loss:0.4894891083240509  \n","Epoch:11/30     Step:4|6   loss:0.4996749758720398  \n","Epoch:11/30     Step:5|6   loss:0.4890561103820801  \n","Epoch:11/30     Step:6|6   loss:0.4943307936191559  \n","Epoch:11/30     Step:7|6   loss:0.5075632929801941  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.487278014421463  \n","Epoch:12/30     Step:2|6   loss:0.4910832643508911  \n","Epoch:12/30     Step:3|6   loss:0.48788097500801086  \n","Epoch:12/30     Step:4|6   loss:0.49038276076316833  \n","Epoch:12/30     Step:5|6   loss:0.49347078800201416  \n","Epoch:12/30     Step:6|6   loss:0.4874512553215027  \n","Epoch:12/30     Step:7|6   loss:0.4924665689468384  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4904700517654419  \n","Epoch:13/30     Step:2|6   loss:0.48817333579063416  \n","Epoch:13/30     Step:3|6   loss:0.4910919964313507  \n","Epoch:13/30     Step:4|6   loss:0.4900899827480316  \n","Epoch:13/30     Step:5|6   loss:0.49486976861953735  \n","Epoch:13/30     Step:6|6   loss:0.4871740937232971  \n","Epoch:13/30     Step:7|6   loss:0.4890434741973877  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.4886585474014282  \n","Epoch:14/30     Step:2|6   loss:0.48978182673454285  \n","Epoch:14/30     Step:3|6   loss:0.4946686625480652  \n","Epoch:14/30     Step:4|6   loss:0.496815025806427  \n","Epoch:14/30     Step:5|6   loss:0.4872409701347351  \n","Epoch:14/30     Step:6|6   loss:0.4931755065917969  \n","Epoch:14/30     Step:7|6   loss:0.48760995268821716  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.4874593913555145  \n","Epoch:15/30     Step:2|6   loss:0.4876400828361511  \n","Epoch:15/30     Step:3|6   loss:0.4874389171600342  \n","Epoch:15/30     Step:4|6   loss:0.4887416362762451  \n","Epoch:15/30     Step:5|6   loss:0.48788854479789734  \n","Epoch:15/30     Step:6|6   loss:0.4885970652103424  \n","Epoch:15/30     Step:7|6   loss:0.48720887303352356  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.48834195733070374  \n","Epoch:16/30     Step:2|6   loss:0.48838990926742554  \n","Epoch:16/30     Step:3|6   loss:0.4886941611766815  \n","Epoch:16/30     Step:4|6   loss:0.48723673820495605  \n","Epoch:16/30     Step:5|6   loss:0.4880548119544983  \n","Epoch:16/30     Step:6|6   loss:0.48910093307495117  \n","Epoch:16/30     Step:7|6   loss:0.49084699153900146  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.487405002117157  \n","Epoch:17/30     Step:2|6   loss:0.487667977809906  \n","Epoch:17/30     Step:3|6   loss:0.5028488636016846  \n","Epoch:17/30     Step:4|6   loss:0.4906347990036011  \n","Epoch:17/30     Step:5|6   loss:0.48845839500427246  \n","Epoch:17/30     Step:6|6   loss:0.48920631408691406  \n","Epoch:17/30     Step:7|6   loss:0.4890901744365692  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.48871034383773804  \n","Epoch:18/30     Step:2|6   loss:0.4888123869895935  \n","Epoch:18/30     Step:3|6   loss:0.4900863468647003  \n","Epoch:18/30     Step:4|6   loss:0.4989009499549866  \n","Epoch:18/30     Step:5|6   loss:0.4875657558441162  \n","Epoch:18/30     Step:6|6   loss:0.49038469791412354  \n","Epoch:18/30     Step:7|6   loss:0.48933327198028564  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.49124008417129517  \n","Epoch:19/30     Step:2|6   loss:0.4870152473449707  \n","Epoch:19/30     Step:3|6   loss:0.4984603226184845  \n","Epoch:19/30     Step:4|6   loss:0.4867505133152008  \n","Epoch:19/30     Step:5|6   loss:0.49094346165657043  \n","Epoch:19/30     Step:6|6   loss:0.4881165325641632  \n","Epoch:19/30     Step:7|6   loss:0.4879385530948639  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4863811135292053  \n","Epoch:20/30     Step:2|6   loss:0.48711255192756653  \n","Epoch:20/30     Step:3|6   loss:0.48754575848579407  \n","Epoch:20/30     Step:4|6   loss:0.48921775817871094  \n","Epoch:20/30     Step:5|6   loss:0.4872641861438751  \n","Epoch:20/30     Step:6|6   loss:0.48654016852378845  \n","Epoch:20/30     Step:7|6   loss:0.4903424084186554  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.48714879155158997  \n","Epoch:21/30     Step:2|6   loss:0.4870859384536743  \n","Epoch:21/30     Step:3|6   loss:0.49102747440338135  \n","Epoch:21/30     Step:4|6   loss:0.4884854853153229  \n","Epoch:21/30     Step:5|6   loss:0.48828986287117004  \n","Epoch:21/30     Step:6|6   loss:0.4882752597332001  \n","Epoch:21/30     Step:7|6   loss:0.4893645644187927  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.4867212772369385  \n","Epoch:22/30     Step:2|6   loss:0.4866517186164856  \n","Epoch:22/30     Step:3|6   loss:0.4909275472164154  \n","Epoch:22/30     Step:4|6   loss:0.4901936650276184  \n","Epoch:22/30     Step:5|6   loss:0.48650097846984863  \n","Epoch:22/30     Step:6|6   loss:0.48685717582702637  \n","Epoch:22/30     Step:7|6   loss:0.4889110326766968  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.4885190427303314  \n","Epoch:23/30     Step:2|6   loss:0.49160900712013245  \n","Epoch:23/30     Step:3|6   loss:0.48777177929878235  \n","Epoch:23/30     Step:4|6   loss:0.48747938871383667  \n","Epoch:23/30     Step:5|6   loss:0.49566343426704407  \n","Epoch:23/30     Step:6|6   loss:0.48895972967147827  \n","Epoch:23/30     Step:7|6   loss:0.48695898056030273  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4870544672012329  \n","Epoch:24/30     Step:2|6   loss:0.48897871375083923  \n","Epoch:24/30     Step:3|6   loss:0.48623794317245483  \n","Epoch:24/30     Step:4|6   loss:0.48651987314224243  \n","Epoch:24/30     Step:5|6   loss:0.49074918031692505  \n","Epoch:24/30     Step:6|6   loss:0.4895758628845215  \n","Epoch:24/30     Step:7|6   loss:0.4866129755973816  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48734205961227417  \n","Epoch:25/30     Step:2|6   loss:0.48956888914108276  \n","Epoch:25/30     Step:3|6   loss:0.489668607711792  \n","Epoch:25/30     Step:4|6   loss:0.4874347746372223  \n","Epoch:25/30     Step:5|6   loss:0.4968164563179016  \n","Epoch:25/30     Step:6|6   loss:0.49611467123031616  \n","Epoch:25/30     Step:7|6   loss:0.49275529384613037  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.4868532419204712  \n","Epoch:26/30     Step:2|6   loss:0.48951929807662964  \n","Epoch:26/30     Step:3|6   loss:0.48790401220321655  \n","Epoch:26/30     Step:4|6   loss:0.4873617887496948  \n","Epoch:26/30     Step:5|6   loss:0.48911091685295105  \n","Epoch:26/30     Step:6|6   loss:0.4932635426521301  \n","Epoch:26/30     Step:7|6   loss:0.4896203577518463  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.48800402879714966  \n","Epoch:27/30     Step:2|6   loss:0.4870673716068268  \n","Epoch:27/30     Step:3|6   loss:0.48642146587371826  \n","Epoch:27/30     Step:4|6   loss:0.48718133568763733  \n","Epoch:27/30     Step:5|6   loss:0.48931989073753357  \n","Epoch:27/30     Step:6|6   loss:0.4864608943462372  \n","Epoch:27/30     Step:7|6   loss:0.48859161138534546  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.487408846616745  \n","Epoch:28/30     Step:2|6   loss:0.48982685804367065  \n","Epoch:28/30     Step:3|6   loss:0.4862474501132965  \n","Epoch:28/30     Step:4|6   loss:0.49421894550323486  \n","Epoch:28/30     Step:5|6   loss:0.49042364954948425  \n","Epoch:28/30     Step:6|6   loss:0.49873000383377075  \n","Epoch:28/30     Step:7|6   loss:0.4875483810901642  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.4873422384262085  \n","Epoch:29/30     Step:2|6   loss:0.4876762330532074  \n","Epoch:29/30     Step:3|6   loss:0.4873177409172058  \n","Epoch:29/30     Step:4|6   loss:0.4872138202190399  \n","Epoch:29/30     Step:5|6   loss:0.48812174797058105  \n","Epoch:29/30     Step:6|6   loss:0.4867124855518341  \n","Epoch:29/30     Step:7|6   loss:0.49024879932403564  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4886420965194702  \n","Epoch:30/30     Step:2|6   loss:0.4885038435459137  \n","Epoch:30/30     Step:3|6   loss:0.4883253276348114  \n","Epoch:30/30     Step:4|6   loss:0.48806604743003845  \n","Epoch:30/30     Step:5|6   loss:0.4879239499568939  \n","Epoch:30/30     Step:6|6   loss:0.4907659888267517  \n","Epoch:30/30     Step:7|6   loss:0.49885880947113037  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Accuracy on test_set: 95.33 %\n","4\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='ir', model='Resnet18', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1928786039352417  \n","Epoch:1/30     Step:2|6   loss:0.9212360382080078  \n","Epoch:1/30     Step:3|6   loss:0.6599762439727783  \n","Epoch:1/30     Step:4|6   loss:0.7577371597290039  \n","Epoch:1/30     Step:5|6   loss:0.621645987033844  \n","Epoch:1/30     Step:6|6   loss:0.7023024559020996  \n","Epoch:1/30     Step:7|6   loss:0.6518493294715881  \n","Accuracy on test_set: 84.11 %\n","Accuracy on train_set: 89.70 %\n","current max accuracy\t test set:84.11%\t train set:89.7%\n","Epoch:2/30     Step:1|6   loss:0.5818313956260681  \n","Epoch:2/30     Step:2|6   loss:0.5864776372909546  \n","Epoch:2/30     Step:3|6   loss:0.5652104616165161  \n","Epoch:2/30     Step:4|6   loss:0.5753006339073181  \n","Epoch:2/30     Step:5|6   loss:0.5633580684661865  \n","Epoch:2/30     Step:6|6   loss:0.5379881262779236  \n","Epoch:2/30     Step:7|6   loss:0.5225268602371216  \n","Accuracy on test_set: 91.59 %\n","Accuracy on train_set: 99.06 %\n","current max accuracy\t test set:91.59%\t train set:99.06%\n","Epoch:3/30     Step:1|6   loss:0.5333001613616943  \n","Epoch:3/30     Step:2|6   loss:0.5368304252624512  \n","Epoch:3/30     Step:3|6   loss:0.5254415273666382  \n","Epoch:3/30     Step:4|6   loss:0.5206125378608704  \n","Epoch:3/30     Step:5|6   loss:0.520989179611206  \n","Epoch:3/30     Step:6|6   loss:0.5122923254966736  \n","Epoch:3/30     Step:7|6   loss:0.5539898872375488  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:94.39%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.5025535225868225  \n","Epoch:4/30     Step:2|6   loss:0.516653299331665  \n","Epoch:4/30     Step:3|6   loss:0.513615071773529  \n","Epoch:4/30     Step:4|6   loss:0.5054856538772583  \n","Epoch:4/30     Step:5|6   loss:0.5055124759674072  \n","Epoch:4/30     Step:6|6   loss:0.5079554319381714  \n","Epoch:4/30     Step:7|6   loss:0.5099055171012878  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:95.33%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.49856650829315186  \n","Epoch:5/30     Step:2|6   loss:0.49955424666404724  \n","Epoch:5/30     Step:3|6   loss:0.4987933933734894  \n","Epoch:5/30     Step:4|6   loss:0.5000022053718567  \n","Epoch:5/30     Step:5|6   loss:0.5105684995651245  \n","Epoch:5/30     Step:6|6   loss:0.4992074966430664  \n","Epoch:5/30     Step:7|6   loss:0.5024126172065735  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.49363812804222107  \n","Epoch:6/30     Step:2|6   loss:0.5011928081512451  \n","Epoch:6/30     Step:3|6   loss:0.4919353127479553  \n","Epoch:6/30     Step:4|6   loss:0.49458032846450806  \n","Epoch:6/30     Step:5|6   loss:0.495994508266449  \n","Epoch:6/30     Step:6|6   loss:0.4929479658603668  \n","Epoch:6/30     Step:7|6   loss:0.4915701746940613  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.49046406149864197  \n","Epoch:7/30     Step:2|6   loss:0.49676617980003357  \n","Epoch:7/30     Step:3|6   loss:0.49262288212776184  \n","Epoch:7/30     Step:4|6   loss:0.49316179752349854  \n","Epoch:7/30     Step:5|6   loss:0.4910570979118347  \n","Epoch:7/30     Step:6|6   loss:0.49248388409614563  \n","Epoch:7/30     Step:7|6   loss:0.48893892765045166  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.4924129545688629  \n","Epoch:8/30     Step:2|6   loss:0.4943326711654663  \n","Epoch:8/30     Step:3|6   loss:0.4956328868865967  \n","Epoch:8/30     Step:4|6   loss:0.4902610182762146  \n","Epoch:8/30     Step:5|6   loss:0.48813679814338684  \n","Epoch:8/30     Step:6|6   loss:0.49672186374664307  \n","Epoch:8/30     Step:7|6   loss:0.488171249628067  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.49155759811401367  \n","Epoch:9/30     Step:2|6   loss:0.49303561449050903  \n","Epoch:9/30     Step:3|6   loss:0.49979710578918457  \n","Epoch:9/30     Step:4|6   loss:0.49460384249687195  \n","Epoch:9/30     Step:5|6   loss:0.49487534165382385  \n","Epoch:9/30     Step:6|6   loss:0.4892437756061554  \n","Epoch:9/30     Step:7|6   loss:0.49342337250709534  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.48894694447517395  \n","Epoch:10/30     Step:2|6   loss:0.49216610193252563  \n","Epoch:10/30     Step:3|6   loss:0.4914347529411316  \n","Epoch:10/30     Step:4|6   loss:0.4948190450668335  \n","Epoch:10/30     Step:5|6   loss:0.48746439814567566  \n","Epoch:10/30     Step:6|6   loss:0.48758313059806824  \n","Epoch:10/30     Step:7|6   loss:0.495394766330719  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.4896679222583771  \n","Epoch:11/30     Step:2|6   loss:0.4903910756111145  \n","Epoch:11/30     Step:3|6   loss:0.4895349144935608  \n","Epoch:11/30     Step:4|6   loss:0.48756566643714905  \n","Epoch:11/30     Step:5|6   loss:0.492978572845459  \n","Epoch:11/30     Step:6|6   loss:0.4876006543636322  \n","Epoch:11/30     Step:7|6   loss:0.4897056519985199  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.4871111512184143  \n","Epoch:12/30     Step:2|6   loss:0.48737871646881104  \n","Epoch:12/30     Step:3|6   loss:0.4869609475135803  \n","Epoch:12/30     Step:4|6   loss:0.4915013313293457  \n","Epoch:12/30     Step:5|6   loss:0.493221253156662  \n","Epoch:12/30     Step:6|6   loss:0.4935692548751831  \n","Epoch:12/30     Step:7|6   loss:0.4872293770313263  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.4867672324180603  \n","Epoch:13/30     Step:2|6   loss:0.48714056611061096  \n","Epoch:13/30     Step:3|6   loss:0.49474036693573  \n","Epoch:13/30     Step:4|6   loss:0.5023490190505981  \n","Epoch:13/30     Step:5|6   loss:0.48709604144096375  \n","Epoch:13/30     Step:6|6   loss:0.48665571212768555  \n","Epoch:13/30     Step:7|6   loss:0.4876466989517212  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.48681527376174927  \n","Epoch:14/30     Step:2|6   loss:0.49701613187789917  \n","Epoch:14/30     Step:3|6   loss:0.48895230889320374  \n","Epoch:14/30     Step:4|6   loss:0.49237340688705444  \n","Epoch:14/30     Step:5|6   loss:0.49278271198272705  \n","Epoch:14/30     Step:6|6   loss:0.4894694983959198  \n","Epoch:14/30     Step:7|6   loss:0.49398308992385864  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.48991531133651733  \n","Epoch:15/30     Step:2|6   loss:0.4941895306110382  \n","Epoch:15/30     Step:3|6   loss:0.48879697918891907  \n","Epoch:15/30     Step:4|6   loss:0.49805670976638794  \n","Epoch:15/30     Step:5|6   loss:0.4901149868965149  \n","Epoch:15/30     Step:6|6   loss:0.4892199635505676  \n","Epoch:15/30     Step:7|6   loss:0.4909338355064392  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.487114816904068  \n","Epoch:16/30     Step:2|6   loss:0.486936092376709  \n","Epoch:16/30     Step:3|6   loss:0.4868430495262146  \n","Epoch:16/30     Step:4|6   loss:0.4921671450138092  \n","Epoch:16/30     Step:5|6   loss:0.48614558577537537  \n","Epoch:16/30     Step:6|6   loss:0.489681601524353  \n","Epoch:16/30     Step:7|6   loss:0.48790037631988525  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.48917698860168457  \n","Epoch:17/30     Step:2|6   loss:0.48853808641433716  \n","Epoch:17/30     Step:3|6   loss:0.48761019110679626  \n","Epoch:17/30     Step:4|6   loss:0.4863930940628052  \n","Epoch:17/30     Step:5|6   loss:0.49364447593688965  \n","Epoch:17/30     Step:6|6   loss:0.501706063747406  \n","Epoch:17/30     Step:7|6   loss:0.492990106344223  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.4896177053451538  \n","Epoch:18/30     Step:2|6   loss:0.4871743321418762  \n","Epoch:18/30     Step:3|6   loss:0.48767393827438354  \n","Epoch:18/30     Step:4|6   loss:0.4870680272579193  \n","Epoch:18/30     Step:5|6   loss:0.4952459931373596  \n","Epoch:18/30     Step:6|6   loss:0.4887489676475525  \n","Epoch:18/30     Step:7|6   loss:0.5028789639472961  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.486367404460907  \n","Epoch:19/30     Step:2|6   loss:0.4864847660064697  \n","Epoch:19/30     Step:3|6   loss:0.4889541566371918  \n","Epoch:19/30     Step:4|6   loss:0.48715484142303467  \n","Epoch:19/30     Step:5|6   loss:0.48800551891326904  \n","Epoch:19/30     Step:6|6   loss:0.48851001262664795  \n","Epoch:19/30     Step:7|6   loss:0.4941185712814331  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.4864693880081177  \n","Epoch:20/30     Step:2|6   loss:0.48826485872268677  \n","Epoch:20/30     Step:3|6   loss:0.48632925748825073  \n","Epoch:20/30     Step:4|6   loss:0.48796546459198  \n","Epoch:20/30     Step:5|6   loss:0.4862576425075531  \n","Epoch:20/30     Step:6|6   loss:0.4893721342086792  \n","Epoch:20/30     Step:7|6   loss:0.5060738921165466  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.4871693253517151  \n","Epoch:21/30     Step:2|6   loss:0.48767563700675964  \n","Epoch:21/30     Step:3|6   loss:0.4929584562778473  \n","Epoch:21/30     Step:4|6   loss:0.4929175078868866  \n","Epoch:21/30     Step:5|6   loss:0.49292632937431335  \n","Epoch:21/30     Step:6|6   loss:0.4883217215538025  \n","Epoch:21/30     Step:7|6   loss:0.4877557158470154  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.48665091395378113  \n","Epoch:22/30     Step:2|6   loss:0.48701953887939453  \n","Epoch:22/30     Step:3|6   loss:0.49135565757751465  \n","Epoch:22/30     Step:4|6   loss:0.4870416820049286  \n","Epoch:22/30     Step:5|6   loss:0.49089518189430237  \n","Epoch:22/30     Step:6|6   loss:0.4880814552307129  \n","Epoch:22/30     Step:7|6   loss:0.49844425916671753  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.49070119857788086  \n","Epoch:23/30     Step:2|6   loss:0.48650163412094116  \n","Epoch:23/30     Step:3|6   loss:0.48994317650794983  \n","Epoch:23/30     Step:4|6   loss:0.49158960580825806  \n","Epoch:23/30     Step:5|6   loss:0.48698660731315613  \n","Epoch:23/30     Step:6|6   loss:0.48835453391075134  \n","Epoch:23/30     Step:7|6   loss:0.4865630269050598  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.4901352524757385  \n","Epoch:24/30     Step:2|6   loss:0.4879458248615265  \n","Epoch:24/30     Step:3|6   loss:0.4880428612232208  \n","Epoch:24/30     Step:4|6   loss:0.48779481649398804  \n","Epoch:24/30     Step:5|6   loss:0.4873586595058441  \n","Epoch:24/30     Step:6|6   loss:0.48960959911346436  \n","Epoch:24/30     Step:7|6   loss:0.4876531958580017  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.48808279633522034  \n","Epoch:25/30     Step:2|6   loss:0.4873110055923462  \n","Epoch:25/30     Step:3|6   loss:0.48913073539733887  \n","Epoch:25/30     Step:4|6   loss:0.4942055940628052  \n","Epoch:25/30     Step:5|6   loss:0.4862685203552246  \n","Epoch:25/30     Step:6|6   loss:0.4907151758670807  \n","Epoch:25/30     Step:7|6   loss:0.4933282732963562  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.48693665862083435  \n","Epoch:26/30     Step:2|6   loss:0.48637235164642334  \n","Epoch:26/30     Step:3|6   loss:0.49071669578552246  \n","Epoch:26/30     Step:4|6   loss:0.4878312349319458  \n","Epoch:26/30     Step:5|6   loss:0.4909788966178894  \n","Epoch:26/30     Step:6|6   loss:0.4865211844444275  \n","Epoch:26/30     Step:7|6   loss:0.5097174048423767  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.4889439046382904  \n","Epoch:27/30     Step:2|6   loss:0.4886358082294464  \n","Epoch:27/30     Step:3|6   loss:0.486916184425354  \n","Epoch:27/30     Step:4|6   loss:0.49264204502105713  \n","Epoch:27/30     Step:5|6   loss:0.4879751205444336  \n","Epoch:27/30     Step:6|6   loss:0.4964551329612732  \n","Epoch:27/30     Step:7|6   loss:0.4947083592414856  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.4877494275569916  \n","Epoch:28/30     Step:2|6   loss:0.4910871088504791  \n","Epoch:28/30     Step:3|6   loss:0.48985129594802856  \n","Epoch:28/30     Step:4|6   loss:0.48851609230041504  \n","Epoch:28/30     Step:5|6   loss:0.4946991801261902  \n","Epoch:28/30     Step:6|6   loss:0.48688241839408875  \n","Epoch:28/30     Step:7|6   loss:0.49015486240386963  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.49178022146224976  \n","Epoch:29/30     Step:2|6   loss:0.48953449726104736  \n","Epoch:29/30     Step:3|6   loss:0.4881289005279541  \n","Epoch:29/30     Step:4|6   loss:0.493557333946228  \n","Epoch:29/30     Step:5|6   loss:0.4897212088108063  \n","Epoch:29/30     Step:6|6   loss:0.4877426326274872  \n","Epoch:29/30     Step:7|6   loss:0.49821770191192627  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.4962162673473358  \n","Epoch:30/30     Step:2|6   loss:0.49252602458000183  \n","Epoch:30/30     Step:3|6   loss:0.48762205243110657  \n","Epoch:30/30     Step:4|6   loss:0.4931069314479828  \n","Epoch:30/30     Step:5|6   loss:0.4881157875061035  \n","Epoch:30/30     Step:6|6   loss:0.4885689616203308  \n","Epoch:30/30     Step:7|6   loss:0.4885387718677521  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:96.26%\t train set:100.0%\n","Accuracy on test_set: 96.26 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model Resnet18 --mode ir --index {i} --EPOCH 30"},{"cell_type":"code","execution_count":21,"id":"0d24eeca","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=0, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Resnet18_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Resnet18_two_stream(\n","  (stream1): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","1\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (stream2): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1456998586654663  \n","Epoch:1/30     Step:2|6   loss:0.8373730182647705  \n","Epoch:1/30     Step:3|6   loss:0.7449936866760254  \n","Epoch:1/30     Step:4|6   loss:0.768325924873352  \n","Epoch:1/30     Step:5|6   loss:0.7647977471351624  \n","Epoch:1/30     Step:6|6   loss:0.801262378692627  \n","Epoch:1/30     Step:7|6   loss:0.7670923471450806  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 97.42 %\n","current max accuracy\t test set:98.13%\t train set:97.42%\n","Epoch:2/30     Step:1|6   loss:0.8087587356567383  \n","Epoch:2/30     Step:2|6   loss:0.838411808013916  \n","Epoch:2/30     Step:3|6   loss:0.8144042491912842  \n","Epoch:2/30     Step:4|6   loss:0.7673171758651733  \n","Epoch:2/30     Step:5|6   loss:0.7895663976669312  \n","Epoch:2/30     Step:6|6   loss:0.7559897899627686  \n","Epoch:2/30     Step:7|6   loss:0.7608436346054077  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:99.07%\t train set:98.59%\n","Epoch:3/30     Step:1|6   loss:0.7754647135734558  \n","Epoch:3/30     Step:2|6   loss:0.7519194483757019  \n","Epoch:3/30     Step:3|6   loss:0.7615232467651367  \n","Epoch:3/30     Step:4|6   loss:0.7249244451522827  \n","Epoch:3/30     Step:5|6   loss:0.8079420328140259  \n","Epoch:3/30     Step:6|6   loss:0.7585899233818054  \n","Epoch:3/30     Step:7|6   loss:0.6775501370429993  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.7336018085479736  \n","Epoch:4/30     Step:2|6   loss:0.7179874181747437  \n","Epoch:4/30     Step:3|6   loss:0.7563981413841248  \n","Epoch:4/30     Step:4|6   loss:0.7555738687515259  \n","Epoch:4/30     Step:5|6   loss:0.7296783924102783  \n","Epoch:4/30     Step:6|6   loss:0.7089436650276184  \n","Epoch:4/30     Step:7|6   loss:0.7230145931243896  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.7265326976776123  \n","Epoch:5/30     Step:2|6   loss:0.7253503203392029  \n","Epoch:5/30     Step:3|6   loss:0.7082334756851196  \n","Epoch:5/30     Step:4|6   loss:0.6893734931945801  \n","Epoch:5/30     Step:5|6   loss:0.6338605880737305  \n","Epoch:5/30     Step:6|6   loss:0.7088648676872253  \n","Epoch:5/30     Step:7|6   loss:0.7299493551254272  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.6797372698783875  \n","Epoch:6/30     Step:2|6   loss:0.7084500789642334  \n","Epoch:6/30     Step:3|6   loss:0.6814874410629272  \n","Epoch:6/30     Step:4|6   loss:0.7103367447853088  \n","Epoch:6/30     Step:5|6   loss:0.7343340516090393  \n","Epoch:6/30     Step:6|6   loss:0.7119776010513306  \n","Epoch:6/30     Step:7|6   loss:0.7447613477706909  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.7115616798400879  \n","Epoch:7/30     Step:2|6   loss:0.7542755603790283  \n","Epoch:7/30     Step:3|6   loss:0.6673828363418579  \n","Epoch:7/30     Step:4|6   loss:0.6922492980957031  \n","Epoch:7/30     Step:5|6   loss:0.6873960494995117  \n","Epoch:7/30     Step:6|6   loss:0.7678954601287842  \n","Epoch:7/30     Step:7|6   loss:0.6832717657089233  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.648084819316864  \n","Epoch:8/30     Step:2|6   loss:0.7103749513626099  \n","Epoch:8/30     Step:3|6   loss:0.7063648700714111  \n","Epoch:8/30     Step:4|6   loss:0.6869133710861206  \n","Epoch:8/30     Step:5|6   loss:0.7101012468338013  \n","Epoch:8/30     Step:6|6   loss:0.7680518627166748  \n","Epoch:8/30     Step:7|6   loss:0.72981858253479  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7321188449859619  \n","Epoch:9/30     Step:2|6   loss:0.6692543625831604  \n","Epoch:9/30     Step:3|6   loss:0.660788893699646  \n","Epoch:9/30     Step:4|6   loss:0.7406513690948486  \n","Epoch:9/30     Step:5|6   loss:0.6852547526359558  \n","Epoch:9/30     Step:6|6   loss:0.7190029621124268  \n","Epoch:9/30     Step:7|6   loss:0.6705079078674316  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.6564509868621826  \n","Epoch:10/30     Step:2|6   loss:0.6726305484771729  \n","Epoch:10/30     Step:3|6   loss:0.6645596027374268  \n","Epoch:10/30     Step:4|6   loss:0.7083114385604858  \n","Epoch:10/30     Step:5|6   loss:0.708271861076355  \n","Epoch:10/30     Step:6|6   loss:0.6753442287445068  \n","Epoch:10/30     Step:7|6   loss:0.7749273777008057  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.6944490671157837  \n","Epoch:11/30     Step:2|6   loss:0.718620777130127  \n","Epoch:11/30     Step:3|6   loss:0.6944080591201782  \n","Epoch:11/30     Step:4|6   loss:0.6786410808563232  \n","Epoch:11/30     Step:5|6   loss:0.7116857767105103  \n","Epoch:11/30     Step:6|6   loss:0.6863024234771729  \n","Epoch:11/30     Step:7|6   loss:0.7784608602523804  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.7473040819168091  \n","Epoch:12/30     Step:2|6   loss:0.6897016763687134  \n","Epoch:12/30     Step:3|6   loss:0.6736245155334473  \n","Epoch:12/30     Step:4|6   loss:0.7198964357376099  \n","Epoch:12/30     Step:5|6   loss:0.7212924957275391  \n","Epoch:12/30     Step:6|6   loss:0.7068686485290527  \n","Epoch:12/30     Step:7|6   loss:0.6821115016937256  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7166907787322998  \n","Epoch:13/30     Step:2|6   loss:0.7160190343856812  \n","Epoch:13/30     Step:3|6   loss:0.7371941804885864  \n","Epoch:13/30     Step:4|6   loss:0.681922197341919  \n","Epoch:13/30     Step:5|6   loss:0.6824440956115723  \n","Epoch:13/30     Step:6|6   loss:0.7437289953231812  \n","Epoch:13/30     Step:7|6   loss:0.7236838340759277  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7244338989257812  \n","Epoch:14/30     Step:2|6   loss:0.6977707147598267  \n","Epoch:14/30     Step:3|6   loss:0.6850374341011047  \n","Epoch:14/30     Step:4|6   loss:0.6672712564468384  \n","Epoch:14/30     Step:5|6   loss:0.673005998134613  \n","Epoch:14/30     Step:6|6   loss:0.7112593054771423  \n","Epoch:14/30     Step:7|6   loss:0.708099365234375  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.7457449436187744  \n","Epoch:15/30     Step:2|6   loss:0.7564102411270142  \n","Epoch:15/30     Step:3|6   loss:0.6293314695358276  \n","Epoch:15/30     Step:4|6   loss:0.7895165681838989  \n","Epoch:15/30     Step:5|6   loss:0.7469927072525024  \n","Epoch:15/30     Step:6|6   loss:0.6925492286682129  \n","Epoch:15/30     Step:7|6   loss:0.7581337094306946  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7263405919075012  \n","Epoch:16/30     Step:2|6   loss:0.6911651492118835  \n","Epoch:16/30     Step:3|6   loss:0.7283993363380432  \n","Epoch:16/30     Step:4|6   loss:0.7191617488861084  \n","Epoch:16/30     Step:5|6   loss:0.6933845281600952  \n","Epoch:16/30     Step:6|6   loss:0.7093697786331177  \n","Epoch:16/30     Step:7|6   loss:0.7206473350524902  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.6794544458389282  \n","Epoch:17/30     Step:2|6   loss:0.7010857462882996  \n","Epoch:17/30     Step:3|6   loss:0.7190147638320923  \n","Epoch:17/30     Step:4|6   loss:0.7330501079559326  \n","Epoch:17/30     Step:5|6   loss:0.723283052444458  \n","Epoch:17/30     Step:6|6   loss:0.6957281231880188  \n","Epoch:17/30     Step:7|6   loss:0.7491269111633301  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.7274237275123596  \n","Epoch:18/30     Step:2|6   loss:0.671006977558136  \n","Epoch:18/30     Step:3|6   loss:0.6954548954963684  \n","Epoch:18/30     Step:4|6   loss:0.6805147528648376  \n","Epoch:18/30     Step:5|6   loss:0.7344887256622314  \n","Epoch:18/30     Step:6|6   loss:0.695094883441925  \n","Epoch:18/30     Step:7|6   loss:0.7005594968795776  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.7173820734024048  \n","Epoch:19/30     Step:2|6   loss:0.7346137762069702  \n","Epoch:19/30     Step:3|6   loss:0.6960115432739258  \n","Epoch:19/30     Step:4|6   loss:0.6790087223052979  \n","Epoch:19/30     Step:5|6   loss:0.6594843864440918  \n","Epoch:19/30     Step:6|6   loss:0.7243019342422485  \n","Epoch:19/30     Step:7|6   loss:0.6629846096038818  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.7203830480575562  \n","Epoch:20/30     Step:2|6   loss:0.6670851111412048  \n","Epoch:20/30     Step:3|6   loss:0.6869947910308838  \n","Epoch:20/30     Step:4|6   loss:0.6901493072509766  \n","Epoch:20/30     Step:5|6   loss:0.6896209716796875  \n","Epoch:20/30     Step:6|6   loss:0.6794897317886353  \n","Epoch:20/30     Step:7|6   loss:0.7397415637969971  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7082966566085815  \n","Epoch:21/30     Step:2|6   loss:0.6698280572891235  \n","Epoch:21/30     Step:3|6   loss:0.6561048030853271  \n","Epoch:21/30     Step:4|6   loss:0.7140729427337646  \n","Epoch:21/30     Step:5|6   loss:0.7251110672950745  \n","Epoch:21/30     Step:6|6   loss:0.6939438581466675  \n","Epoch:21/30     Step:7|6   loss:0.715835690498352  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.698129415512085  \n","Epoch:22/30     Step:2|6   loss:0.6905231475830078  \n","Epoch:22/30     Step:3|6   loss:0.7465591430664062  \n","Epoch:22/30     Step:4|6   loss:0.7516108751296997  \n","Epoch:22/30     Step:5|6   loss:0.7107313275337219  \n","Epoch:22/30     Step:6|6   loss:0.7629890441894531  \n","Epoch:22/30     Step:7|6   loss:0.7470384836196899  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.7413070201873779  \n","Epoch:23/30     Step:2|6   loss:0.7105896472930908  \n","Epoch:23/30     Step:3|6   loss:0.7198387384414673  \n","Epoch:23/30     Step:4|6   loss:0.7073807120323181  \n","Epoch:23/30     Step:5|6   loss:0.7247415781021118  \n","Epoch:23/30     Step:6|6   loss:0.731400191783905  \n","Epoch:23/30     Step:7|6   loss:0.6559716463088989  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.688399076461792  \n","Epoch:24/30     Step:2|6   loss:0.7540510892868042  \n","Epoch:24/30     Step:3|6   loss:0.7162505388259888  \n","Epoch:24/30     Step:4|6   loss:0.6817438006401062  \n","Epoch:24/30     Step:5|6   loss:0.6743179559707642  \n","Epoch:24/30     Step:6|6   loss:0.6846652030944824  \n","Epoch:24/30     Step:7|6   loss:0.7139207124710083  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7592946290969849  \n","Epoch:25/30     Step:2|6   loss:0.7360466718673706  \n","Epoch:25/30     Step:3|6   loss:0.7077463865280151  \n","Epoch:25/30     Step:4|6   loss:0.7256182432174683  \n","Epoch:25/30     Step:5|6   loss:0.7112056016921997  \n","Epoch:25/30     Step:6|6   loss:0.7335953712463379  \n","Epoch:25/30     Step:7|6   loss:0.7354685068130493  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7288908958435059  \n","Epoch:26/30     Step:2|6   loss:0.6716575622558594  \n","Epoch:26/30     Step:3|6   loss:0.6975895166397095  \n","Epoch:26/30     Step:4|6   loss:0.6921052932739258  \n","Epoch:26/30     Step:5|6   loss:0.6981117725372314  \n","Epoch:26/30     Step:6|6   loss:0.71994948387146  \n","Epoch:26/30     Step:7|6   loss:0.6662367582321167  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.6929693818092346  \n","Epoch:27/30     Step:2|6   loss:0.7061930894851685  \n","Epoch:27/30     Step:3|6   loss:0.719375729560852  \n","Epoch:27/30     Step:4|6   loss:0.7014598846435547  \n","Epoch:27/30     Step:5|6   loss:0.6692956686019897  \n","Epoch:27/30     Step:6|6   loss:0.7095855474472046  \n","Epoch:27/30     Step:7|6   loss:0.742854654788971  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.7301572561264038  \n","Epoch:28/30     Step:2|6   loss:0.7338240146636963  \n","Epoch:28/30     Step:3|6   loss:0.7271674871444702  \n","Epoch:28/30     Step:4|6   loss:0.6807169318199158  \n","Epoch:28/30     Step:5|6   loss:0.7385796904563904  \n","Epoch:28/30     Step:6|6   loss:0.7075744867324829  \n","Epoch:28/30     Step:7|6   loss:0.7342358827590942  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.6798682808876038  \n","Epoch:29/30     Step:2|6   loss:0.6973779201507568  \n","Epoch:29/30     Step:3|6   loss:0.7157729864120483  \n","Epoch:29/30     Step:4|6   loss:0.6957310438156128  \n","Epoch:29/30     Step:5|6   loss:0.6773585081100464  \n","Epoch:29/30     Step:6|6   loss:0.7278656959533691  \n","Epoch:29/30     Step:7|6   loss:0.6625993251800537  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.7200000286102295  \n","Epoch:30/30     Step:2|6   loss:0.7210248708724976  \n","Epoch:30/30     Step:3|6   loss:0.7202768921852112  \n","Epoch:30/30     Step:4|6   loss:0.7128381729125977  \n","Epoch:30/30     Step:5|6   loss:0.7117778062820435  \n","Epoch:30/30     Step:6|6   loss:0.7022804021835327  \n","Epoch:30/30     Step:7|6   loss:0.6901758909225464  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=1, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Resnet18_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Resnet18_two_stream(\n","  (stream1): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (stream2): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1602087020874023  \n","Epoch:1/30     Step:2|6   loss:0.8370874524116516  \n","Epoch:1/30     Step:3|6   loss:0.7655072212219238  \n","Epoch:1/30     Step:4|6   loss:0.7816323637962341  \n","Epoch:1/30     Step:5|6   loss:0.8058982491493225  \n","Epoch:1/30     Step:6|6   loss:0.7338505387306213  \n","Epoch:1/30     Step:7|6   loss:0.8169983625411987  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 96.49 %\n","current max accuracy\t test set:97.2%\t train set:96.49%\n","Epoch:2/30     Step:1|6   loss:0.7833877801895142  \n","Epoch:2/30     Step:2|6   loss:0.7575004696846008  \n","Epoch:2/30     Step:3|6   loss:0.7892380952835083  \n","Epoch:2/30     Step:4|6   loss:0.7976338863372803  \n","Epoch:2/30     Step:5|6   loss:0.787050724029541  \n","Epoch:2/30     Step:6|6   loss:0.7435979843139648  \n","Epoch:2/30     Step:7|6   loss:0.7176581621170044  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:100.0%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.7397568821907043  \n","Epoch:3/30     Step:2|6   loss:0.6954069137573242  \n","Epoch:3/30     Step:3|6   loss:0.6745257377624512  \n","Epoch:3/30     Step:4|6   loss:0.6640194654464722  \n","Epoch:3/30     Step:5|6   loss:0.7316845655441284  \n","Epoch:3/30     Step:6|6   loss:0.7275649905204773  \n","Epoch:3/30     Step:7|6   loss:0.7236630916595459  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:100.0%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.7401344180107117  \n","Epoch:4/30     Step:2|6   loss:0.7169222235679626  \n","Epoch:4/30     Step:3|6   loss:0.7093753814697266  \n","Epoch:4/30     Step:4|6   loss:0.7728148698806763  \n","Epoch:4/30     Step:5|6   loss:0.739989161491394  \n","Epoch:4/30     Step:6|6   loss:0.7687420845031738  \n","Epoch:4/30     Step:7|6   loss:0.7590298652648926  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:100.0%\t train set:99.77%\n","Epoch:5/30     Step:1|6   loss:0.7267657518386841  \n","Epoch:5/30     Step:2|6   loss:0.7282262444496155  \n","Epoch:5/30     Step:3|6   loss:0.6992501616477966  \n","Epoch:5/30     Step:4|6   loss:0.7056770324707031  \n","Epoch:5/30     Step:5|6   loss:0.7172224521636963  \n","Epoch:5/30     Step:6|6   loss:0.7156516909599304  \n","Epoch:5/30     Step:7|6   loss:0.8101160526275635  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.703708291053772  \n","Epoch:6/30     Step:2|6   loss:0.6913723945617676  \n","Epoch:6/30     Step:3|6   loss:0.7253175973892212  \n","Epoch:6/30     Step:4|6   loss:0.7232712507247925  \n","Epoch:6/30     Step:5|6   loss:0.7186118364334106  \n","Epoch:6/30     Step:6|6   loss:0.6551453471183777  \n","Epoch:6/30     Step:7|6   loss:0.698154628276825  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.6887779831886292  \n","Epoch:7/30     Step:2|6   loss:0.6823873519897461  \n","Epoch:7/30     Step:3|6   loss:0.7112606763839722  \n","Epoch:7/30     Step:4|6   loss:0.7704786658287048  \n","Epoch:7/30     Step:5|6   loss:0.7089695334434509  \n","Epoch:7/30     Step:6|6   loss:0.7623792290687561  \n","Epoch:7/30     Step:7|6   loss:0.7035204768180847  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.7006286978721619  \n","Epoch:8/30     Step:2|6   loss:0.6739866137504578  \n","Epoch:8/30     Step:3|6   loss:0.7136425971984863  \n","Epoch:8/30     Step:4|6   loss:0.7297059297561646  \n","Epoch:8/30     Step:5|6   loss:0.7236515283584595  \n","Epoch:8/30     Step:6|6   loss:0.6875526309013367  \n","Epoch:8/30     Step:7|6   loss:0.7404712438583374  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7006807327270508  \n","Epoch:9/30     Step:2|6   loss:0.7110966444015503  \n","Epoch:9/30     Step:3|6   loss:0.6630164384841919  \n","Epoch:9/30     Step:4|6   loss:0.7245084047317505  \n","Epoch:9/30     Step:5|6   loss:0.6708869934082031  \n","Epoch:9/30     Step:6|6   loss:0.7202315926551819  \n","Epoch:9/30     Step:7|6   loss:0.7035341262817383  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7084685564041138  \n","Epoch:10/30     Step:2|6   loss:0.700847864151001  \n","Epoch:10/30     Step:3|6   loss:0.7057853937149048  \n","Epoch:10/30     Step:4|6   loss:0.7072936296463013  \n","Epoch:10/30     Step:5|6   loss:0.6840221285820007  \n","Epoch:10/30     Step:6|6   loss:0.7854547500610352  \n","Epoch:10/30     Step:7|6   loss:0.6608389616012573  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.680300235748291  \n","Epoch:11/30     Step:2|6   loss:0.7369871139526367  \n","Epoch:11/30     Step:3|6   loss:0.6711708307266235  \n","Epoch:11/30     Step:4|6   loss:0.6616895198822021  \n","Epoch:11/30     Step:5|6   loss:0.6820295453071594  \n","Epoch:11/30     Step:6|6   loss:0.7257595658302307  \n","Epoch:11/30     Step:7|6   loss:0.6928785443305969  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6702378988265991  \n","Epoch:12/30     Step:2|6   loss:0.7046322822570801  \n","Epoch:12/30     Step:3|6   loss:0.6887134909629822  \n","Epoch:12/30     Step:4|6   loss:0.7113775014877319  \n","Epoch:12/30     Step:5|6   loss:0.7521246671676636  \n","Epoch:12/30     Step:6|6   loss:0.6713345050811768  \n","Epoch:12/30     Step:7|6   loss:0.7193343639373779  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7157467603683472  \n","Epoch:13/30     Step:2|6   loss:0.6646028757095337  \n","Epoch:13/30     Step:3|6   loss:0.7308578491210938  \n","Epoch:13/30     Step:4|6   loss:0.7117154598236084  \n","Epoch:13/30     Step:5|6   loss:0.7282856106758118  \n","Epoch:13/30     Step:6|6   loss:0.7037376165390015  \n","Epoch:13/30     Step:7|6   loss:0.7135360240936279  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.6854898929595947  \n","Epoch:14/30     Step:2|6   loss:0.7148911952972412  \n","Epoch:14/30     Step:3|6   loss:0.7307800054550171  \n","Epoch:14/30     Step:4|6   loss:0.739963948726654  \n","Epoch:14/30     Step:5|6   loss:0.7226420640945435  \n","Epoch:14/30     Step:6|6   loss:0.7154107093811035  \n","Epoch:14/30     Step:7|6   loss:0.7281967997550964  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.7256855368614197  \n","Epoch:15/30     Step:2|6   loss:0.7297472953796387  \n","Epoch:15/30     Step:3|6   loss:0.7288118600845337  \n","Epoch:15/30     Step:4|6   loss:0.7083430290222168  \n","Epoch:15/30     Step:5|6   loss:0.7110698223114014  \n","Epoch:15/30     Step:6|6   loss:0.7037511467933655  \n","Epoch:15/30     Step:7|6   loss:0.767031192779541  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.6862810850143433  \n","Epoch:16/30     Step:2|6   loss:0.7152570486068726  \n","Epoch:16/30     Step:3|6   loss:0.7046113014221191  \n","Epoch:16/30     Step:4|6   loss:0.6872439384460449  \n","Epoch:16/30     Step:5|6   loss:0.6976499557495117  \n","Epoch:16/30     Step:6|6   loss:0.6943351030349731  \n","Epoch:16/30     Step:7|6   loss:0.669237494468689  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.73443603515625  \n","Epoch:17/30     Step:2|6   loss:0.6847114562988281  \n","Epoch:17/30     Step:3|6   loss:0.7338308691978455  \n","Epoch:17/30     Step:4|6   loss:0.6839523315429688  \n","Epoch:17/30     Step:5|6   loss:0.7077056169509888  \n","Epoch:17/30     Step:6|6   loss:0.6796088218688965  \n","Epoch:17/30     Step:7|6   loss:0.7075337171554565  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.6950019598007202  \n","Epoch:18/30     Step:2|6   loss:0.7017166614532471  \n","Epoch:18/30     Step:3|6   loss:0.6830564737319946  \n","Epoch:18/30     Step:4|6   loss:0.7132986783981323  \n","Epoch:18/30     Step:5|6   loss:0.6939756870269775  \n","Epoch:18/30     Step:6|6   loss:0.7362653613090515  \n","Epoch:18/30     Step:7|6   loss:0.7223535776138306  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.6924590468406677  \n","Epoch:19/30     Step:2|6   loss:0.6964726448059082  \n","Epoch:19/30     Step:3|6   loss:0.6730997562408447  \n","Epoch:19/30     Step:4|6   loss:0.6483079195022583  \n","Epoch:19/30     Step:5|6   loss:0.7148013710975647  \n","Epoch:19/30     Step:6|6   loss:0.7613692283630371  \n","Epoch:19/30     Step:7|6   loss:0.666586697101593  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.7375186681747437  \n","Epoch:20/30     Step:2|6   loss:0.6604317426681519  \n","Epoch:20/30     Step:3|6   loss:0.6521137952804565  \n","Epoch:20/30     Step:4|6   loss:0.6681933403015137  \n","Epoch:20/30     Step:5|6   loss:0.6394129395484924  \n","Epoch:20/30     Step:6|6   loss:0.698501706123352  \n","Epoch:20/30     Step:7|6   loss:0.7709968090057373  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.7596274614334106  \n","Epoch:21/30     Step:2|6   loss:0.7052421569824219  \n","Epoch:21/30     Step:3|6   loss:0.7023931741714478  \n","Epoch:21/30     Step:4|6   loss:0.724830150604248  \n","Epoch:21/30     Step:5|6   loss:0.6823115348815918  \n","Epoch:21/30     Step:6|6   loss:0.7541400194168091  \n","Epoch:21/30     Step:7|6   loss:0.6662569046020508  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.6688003540039062  \n","Epoch:22/30     Step:2|6   loss:0.6896480321884155  2\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:22/30     Step:3|6   loss:0.7316498756408691  \n","Epoch:22/30     Step:4|6   loss:0.7226523160934448  \n","Epoch:22/30     Step:5|6   loss:0.7294024229049683  \n","Epoch:22/30     Step:6|6   loss:0.6929017305374146  \n","Epoch:22/30     Step:7|6   loss:0.6993699669837952  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.686469316482544  \n","Epoch:23/30     Step:2|6   loss:0.7059881687164307  \n","Epoch:23/30     Step:3|6   loss:0.7027417421340942  \n","Epoch:23/30     Step:4|6   loss:0.7393155097961426  \n","Epoch:23/30     Step:5|6   loss:0.6833431124687195  \n","Epoch:23/30     Step:6|6   loss:0.6591917276382446  \n","Epoch:23/30     Step:7|6   loss:0.6887149214744568  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.7096972465515137  \n","Epoch:24/30     Step:2|6   loss:0.6780343055725098  \n","Epoch:24/30     Step:3|6   loss:0.664675772190094  \n","Epoch:24/30     Step:4|6   loss:0.6817010045051575  \n","Epoch:24/30     Step:5|6   loss:0.6943557262420654  \n","Epoch:24/30     Step:6|6   loss:0.7315718531608582  \n","Epoch:24/30     Step:7|6   loss:0.737206220626831  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7210405468940735  \n","Epoch:25/30     Step:2|6   loss:0.7659991979598999  \n","Epoch:25/30     Step:3|6   loss:0.7475494742393494  \n","Epoch:25/30     Step:4|6   loss:0.6799558401107788  \n","Epoch:25/30     Step:5|6   loss:0.6999577879905701  \n","Epoch:25/30     Step:6|6   loss:0.735649824142456  \n","Epoch:25/30     Step:7|6   loss:0.7490487694740295  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.703973114490509  \n","Epoch:26/30     Step:2|6   loss:0.7293601036071777  \n","Epoch:26/30     Step:3|6   loss:0.7141398191452026  \n","Epoch:26/30     Step:4|6   loss:0.6777675747871399  \n","Epoch:26/30     Step:5|6   loss:0.6957203149795532  \n","Epoch:26/30     Step:6|6   loss:0.6766694784164429  \n","Epoch:26/30     Step:7|6   loss:0.6994589567184448  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.7045735120773315  \n","Epoch:27/30     Step:2|6   loss:0.7141887545585632  \n","Epoch:27/30     Step:3|6   loss:0.6550073623657227  \n","Epoch:27/30     Step:4|6   loss:0.6977975964546204  \n","Epoch:27/30     Step:5|6   loss:0.6864490509033203  \n","Epoch:27/30     Step:6|6   loss:0.6749368906021118  \n","Epoch:27/30     Step:7|6   loss:0.7025395631790161  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.6865781545639038  \n","Epoch:28/30     Step:2|6   loss:0.6979295015335083  \n","Epoch:28/30     Step:3|6   loss:0.6815545558929443  \n","Epoch:28/30     Step:4|6   loss:0.6521896123886108  \n","Epoch:28/30     Step:5|6   loss:0.675387978553772  \n","Epoch:28/30     Step:6|6   loss:0.7076352834701538  \n","Epoch:28/30     Step:7|6   loss:0.6893133521080017  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.6935815811157227  \n","Epoch:29/30     Step:2|6   loss:0.6640931963920593  \n","Epoch:29/30     Step:3|6   loss:0.7212589979171753  \n","Epoch:29/30     Step:4|6   loss:0.7103462219238281  \n","Epoch:29/30     Step:5|6   loss:0.6790086030960083  \n","Epoch:29/30     Step:6|6   loss:0.6885892152786255  \n","Epoch:29/30     Step:7|6   loss:0.683100700378418  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.7375304698944092  \n","Epoch:30/30     Step:2|6   loss:0.6846147179603577  \n","Epoch:30/30     Step:3|6   loss:0.7041121125221252  \n","Epoch:30/30     Step:4|6   loss:0.7373831272125244  \n","Epoch:30/30     Step:5|6   loss:0.7349041700363159  \n","Epoch:30/30     Step:6|6   loss:0.7323367595672607  \n","Epoch:30/30     Step:7|6   loss:0.7204124927520752  \n","Accuracy on test_set: 100.00 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:100.0%\t train set:100.0%\n","Accuracy on test_set: 100.00 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=2, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Resnet18_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Resnet18_two_stream(\n","  (stream1): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (stream2): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.1342204809188843  \n","Epoch:1/30     Step:2|6   loss:0.9210402965545654  \n","Epoch:1/30     Step:3|6   loss:0.8586101531982422  \n","Epoch:1/30     Step:4|6   loss:0.791167140007019  \n","Epoch:1/30     Step:5|6   loss:0.8074448108673096  \n","Epoch:1/30     Step:6|6   loss:0.7581759691238403  \n","Epoch:1/30     Step:7|6   loss:0.7260529398918152  \n","Accuracy on test_set: 94.39 %\n","Accuracy on train_set: 95.08 %\n","current max accuracy\t test set:94.39%\t train set:95.08%\n","Epoch:2/30     Step:1|6   loss:0.7562642097473145  \n","Epoch:2/30     Step:2|6   loss:0.7315829992294312  \n","Epoch:2/30     Step:3|6   loss:0.7774492502212524  \n","Epoch:2/30     Step:4|6   loss:0.7183414697647095  \n","Epoch:2/30     Step:5|6   loss:0.7601373195648193  \n","Epoch:2/30     Step:6|6   loss:0.7476072311401367  \n","Epoch:2/30     Step:7|6   loss:0.746749758720398  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.30 %\n","current max accuracy\t test set:97.2%\t train set:99.3%\n","Epoch:3/30     Step:1|6   loss:0.7229960560798645  \n","Epoch:3/30     Step:2|6   loss:0.7169234156608582  \n","Epoch:3/30     Step:3|6   loss:0.6954436302185059  \n","Epoch:3/30     Step:4|6   loss:0.7842448949813843  \n","Epoch:3/30     Step:5|6   loss:0.7279855012893677  \n","Epoch:3/30     Step:6|6   loss:0.7398813962936401  \n","Epoch:3/30     Step:7|6   loss:0.7407170534133911  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.53 %3\n"]},{"name":"stdout","output_type":"stream","text":["\n","current max accuracy\t test set:98.13%\t train set:99.53%\n","Epoch:4/30     Step:1|6   loss:0.7264030575752258  \n","Epoch:4/30     Step:2|6   loss:0.6866693496704102  \n","Epoch:4/30     Step:3|6   loss:0.7461038827896118  \n","Epoch:4/30     Step:4|6   loss:0.7940647602081299  \n","Epoch:4/30     Step:5|6   loss:0.7675721645355225  \n","Epoch:4/30     Step:6|6   loss:0.7023086547851562  \n","Epoch:4/30     Step:7|6   loss:0.7114970684051514  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:5/30     Step:1|6   loss:0.7097786068916321  \n","Epoch:5/30     Step:2|6   loss:0.7307853698730469  \n","Epoch:5/30     Step:3|6   loss:0.7218116521835327  \n","Epoch:5/30     Step:4|6   loss:0.7646657824516296  \n","Epoch:5/30     Step:5|6   loss:0.7027552127838135  \n","Epoch:5/30     Step:6|6   loss:0.6953918933868408  \n","Epoch:5/30     Step:7|6   loss:0.711936354637146  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7308383584022522  \n","Epoch:6/30     Step:2|6   loss:0.6961749792098999  \n","Epoch:6/30     Step:3|6   loss:0.6846237182617188  \n","Epoch:6/30     Step:4|6   loss:0.7228614091873169  \n","Epoch:6/30     Step:5|6   loss:0.7048625946044922  \n","Epoch:6/30     Step:6|6   loss:0.7514594197273254  \n","Epoch:6/30     Step:7|6   loss:0.7313873767852783  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.7292338609695435  \n","Epoch:7/30     Step:2|6   loss:0.7207427620887756  \n","Epoch:7/30     Step:3|6   loss:0.7099491953849792  \n","Epoch:7/30     Step:4|6   loss:0.7173341512680054  \n","Epoch:7/30     Step:5|6   loss:0.7087877988815308  \n","Epoch:7/30     Step:6|6   loss:0.693225622177124  \n","Epoch:7/30     Step:7|6   loss:0.6692485809326172  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.6847196817398071  \n","Epoch:8/30     Step:2|6   loss:0.7602456212043762  \n","Epoch:8/30     Step:3|6   loss:0.6617005467414856  \n","Epoch:8/30     Step:4|6   loss:0.7623124122619629  \n","Epoch:8/30     Step:5|6   loss:0.7226516008377075  \n","Epoch:8/30     Step:6|6   loss:0.7039251327514648  \n","Epoch:8/30     Step:7|6   loss:0.6996409296989441  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7179973125457764  \n","Epoch:9/30     Step:2|6   loss:0.758804202079773  \n","Epoch:9/30     Step:3|6   loss:0.6696922779083252  \n","Epoch:9/30     Step:4|6   loss:0.6741902828216553  \n","Epoch:9/30     Step:5|6   loss:0.7062788009643555  \n","Epoch:9/30     Step:6|6   loss:0.7071585059165955  \n","Epoch:9/30     Step:7|6   loss:0.745267927646637  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7091164588928223  \n","Epoch:10/30     Step:2|6   loss:0.692613959312439  \n","Epoch:10/30     Step:3|6   loss:0.7274042367935181  \n","Epoch:10/30     Step:4|6   loss:0.7086195945739746  \n","Epoch:10/30     Step:5|6   loss:0.6905227303504944  \n","Epoch:10/30     Step:6|6   loss:0.7164471745491028  \n","Epoch:10/30     Step:7|6   loss:0.7460231781005859  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.6782468557357788  \n","Epoch:11/30     Step:2|6   loss:0.7104008793830872  \n","Epoch:11/30     Step:3|6   loss:0.6904003024101257  \n","Epoch:11/30     Step:4|6   loss:0.650675892829895  \n","Epoch:11/30     Step:5|6   loss:0.7304072380065918  \n","Epoch:11/30     Step:6|6   loss:0.7421302795410156  \n","Epoch:11/30     Step:7|6   loss:0.6972870826721191  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.7340524196624756  \n","Epoch:12/30     Step:2|6   loss:0.6861046552658081  \n","Epoch:12/30     Step:3|6   loss:0.6894391179084778  \n","Epoch:12/30     Step:4|6   loss:0.6822441816329956  \n","Epoch:12/30     Step:5|6   loss:0.748619794845581  \n","Epoch:12/30     Step:6|6   loss:0.6783557534217834  \n","Epoch:12/30     Step:7|6   loss:0.6968318223953247  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7179150581359863  \n","Epoch:13/30     Step:2|6   loss:0.7111260890960693  \n","Epoch:13/30     Step:3|6   loss:0.7026739716529846  \n","Epoch:13/30     Step:4|6   loss:0.6916859149932861  \n","Epoch:13/30     Step:5|6   loss:0.7403701543807983  \n","Epoch:13/30     Step:6|6   loss:0.6862061023712158  \n","Epoch:13/30     Step:7|6   loss:0.6570572853088379  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7191689014434814  \n","Epoch:14/30     Step:2|6   loss:0.7053723335266113  \n","Epoch:14/30     Step:3|6   loss:0.7071664929389954  \n","Epoch:14/30     Step:4|6   loss:0.7200988531112671  \n","Epoch:14/30     Step:5|6   loss:0.682797908782959  \n","Epoch:14/30     Step:6|6   loss:0.6683845520019531  \n","Epoch:14/30     Step:7|6   loss:0.6711184978485107  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.6976660490036011  \n","Epoch:15/30     Step:2|6   loss:0.6957331299781799  \n","Epoch:15/30     Step:3|6   loss:0.6988748908042908  \n","Epoch:15/30     Step:4|6   loss:0.7050976753234863  \n","Epoch:15/30     Step:5|6   loss:0.6664972901344299  \n","Epoch:15/30     Step:6|6   loss:0.7414149045944214  \n","Epoch:15/30     Step:7|6   loss:0.7276298999786377  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.6529146432876587  \n","Epoch:16/30     Step:2|6   loss:0.7227662801742554  \n","Epoch:16/30     Step:3|6   loss:0.6680265069007874  \n","Epoch:16/30     Step:4|6   loss:0.6868761777877808  \n","Epoch:16/30     Step:5|6   loss:0.7025307416915894  \n","Epoch:16/30     Step:6|6   loss:0.6877307891845703  \n","Epoch:16/30     Step:7|6   loss:0.7009573578834534  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.7114207148551941  \n","Epoch:17/30     Step:2|6   loss:0.7489557266235352  \n","Epoch:17/30     Step:3|6   loss:0.7025126218795776  \n","Epoch:17/30     Step:4|6   loss:0.6618660688400269  \n","Epoch:17/30     Step:5|6   loss:0.7038714289665222  \n","Epoch:17/30     Step:6|6   loss:0.698078453540802  \n","Epoch:17/30     Step:7|6   loss:0.7249971628189087  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.7334314584732056  \n","Epoch:18/30     Step:2|6   loss:0.7202816009521484  \n","Epoch:18/30     Step:3|6   loss:0.6738086938858032  \n","Epoch:18/30     Step:4|6   loss:0.6708865761756897  \n","Epoch:18/30     Step:5|6   loss:0.6900732517242432  \n","Epoch:18/30     Step:6|6   loss:0.6981852054595947  \n","Epoch:18/30     Step:7|6   loss:0.7291447520256042  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.7276080846786499  \n","Epoch:19/30     Step:2|6   loss:0.6967863440513611  \n","Epoch:19/30     Step:3|6   loss:0.7322887778282166  \n","Epoch:19/30     Step:4|6   loss:0.6670286655426025  \n","Epoch:19/30     Step:5|6   loss:0.6954630613327026  \n","Epoch:19/30     Step:6|6   loss:0.6654791831970215  \n","Epoch:19/30     Step:7|6   loss:0.7352720499038696  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.6567283868789673  \n","Epoch:20/30     Step:2|6   loss:0.6836165189743042  \n","Epoch:20/30     Step:3|6   loss:0.7005327939987183  \n","Epoch:20/30     Step:4|6   loss:0.7501507997512817  \n","Epoch:20/30     Step:5|6   loss:0.7077484130859375  \n","Epoch:20/30     Step:6|6   loss:0.7260825037956238  \n","Epoch:20/30     Step:7|6   loss:0.691827654838562  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.6780487298965454  \n","Epoch:21/30     Step:2|6   loss:0.6674892902374268  \n","Epoch:21/30     Step:3|6   loss:0.7157065868377686  \n","Epoch:21/30     Step:4|6   loss:0.7148868441581726  \n","Epoch:21/30     Step:5|6   loss:0.7564389109611511  \n","Epoch:21/30     Step:6|6   loss:0.7310939431190491  \n","Epoch:21/30     Step:7|6   loss:0.676884651184082  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.6837226152420044  \n","Epoch:22/30     Step:2|6   loss:0.70075523853302  \n","Epoch:22/30     Step:3|6   loss:0.7111696004867554  \n","Epoch:22/30     Step:4|6   loss:0.7111856937408447  \n","Epoch:22/30     Step:5|6   loss:0.731545090675354  \n","Epoch:22/30     Step:6|6   loss:0.6673786640167236  \n","Epoch:22/30     Step:7|6   loss:0.761138916015625  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.7024726867675781  \n","Epoch:23/30     Step:2|6   loss:0.686448335647583  \n","Epoch:23/30     Step:3|6   loss:0.7138489484786987  \n","Epoch:23/30     Step:4|6   loss:0.691175639629364  \n","Epoch:23/30     Step:5|6   loss:0.7182953357696533  \n","Epoch:23/30     Step:6|6   loss:0.6590191721916199  \n","Epoch:23/30     Step:7|6   loss:0.7619515657424927  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.6818342208862305  \n","Epoch:24/30     Step:2|6   loss:0.7236721515655518  \n","Epoch:24/30     Step:3|6   loss:0.6868565082550049  \n","Epoch:24/30     Step:4|6   loss:0.7202713489532471  \n","Epoch:24/30     Step:5|6   loss:0.7185128331184387  \n","Epoch:24/30     Step:6|6   loss:0.7065845727920532  \n","Epoch:24/30     Step:7|6   loss:0.6910398006439209  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7227835655212402  \n","Epoch:25/30     Step:2|6   loss:0.7118674516677856  \n","Epoch:25/30     Step:3|6   loss:0.6479089856147766  \n","Epoch:25/30     Step:4|6   loss:0.7428675889968872  \n","Epoch:25/30     Step:5|6   loss:0.6958511471748352  \n","Epoch:25/30     Step:6|6   loss:0.7151832580566406  \n","Epoch:25/30     Step:7|6   loss:0.6611825227737427  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7152029275894165  \n","Epoch:26/30     Step:2|6   loss:0.6713389754295349  \n","Epoch:26/30     Step:3|6   loss:0.6748489737510681  \n","Epoch:26/30     Step:4|6   loss:0.6561036109924316  \n","Epoch:26/30     Step:5|6   loss:0.7071394920349121  \n","Epoch:26/30     Step:6|6   loss:0.7447683215141296  \n","Epoch:26/30     Step:7|6   loss:0.7005181312561035  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.6753426790237427  \n","Epoch:27/30     Step:2|6   loss:0.7278752326965332  \n","Epoch:27/30     Step:3|6   loss:0.7503620386123657  \n","Epoch:27/30     Step:4|6   loss:0.7058283686637878  \n","Epoch:27/30     Step:5|6   loss:0.6739421486854553  \n","Epoch:27/30     Step:6|6   loss:0.7266242504119873  \n","Epoch:27/30     Step:7|6   loss:0.6550801396369934  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.6984472870826721  \n","Epoch:28/30     Step:2|6   loss:0.7454078197479248  \n","Epoch:28/30     Step:3|6   loss:0.6956955194473267  \n","Epoch:28/30     Step:4|6   loss:0.7284059524536133  \n","Epoch:28/30     Step:5|6   loss:0.6516208648681641  \n","Epoch:28/30     Step:6|6   loss:0.6960971355438232  \n","Epoch:28/30     Step:7|6   loss:0.7049091458320618  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.6825552582740784  \n","Epoch:29/30     Step:2|6   loss:0.6297898292541504  \n","Epoch:29/30     Step:3|6   loss:0.7258156538009644  \n","Epoch:29/30     Step:4|6   loss:0.7034574747085571  \n","Epoch:29/30     Step:5|6   loss:0.738652229309082  \n","Epoch:29/30     Step:6|6   loss:0.726650059223175  \n","Epoch:29/30     Step:7|6   loss:0.7024455666542053  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.6933952569961548  \n","Epoch:30/30     Step:2|6   loss:0.714645266532898  \n","Epoch:30/30     Step:3|6   loss:0.7236510515213013  \n","Epoch:30/30     Step:4|6   loss:0.678276538848877  \n","Epoch:30/30     Step:5|6   loss:0.7295629382133484  \n","Epoch:30/30     Step:6|6   loss:0.7205663919448853  \n","Epoch:30/30     Step:7|6   loss:0.7472435235977173  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 96.26 %\n"]},{"name":"stdout","output_type":"stream","text":["Namespace(EPOCH=30, batch_size=64, classes_num=3, index=3, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Resnet18_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Resnet18_two_stream(\n","  (stream1): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (stream2): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.251769781112671  \n","Epoch:1/30     Step:2|6   loss:0.9092586636543274  \n","Epoch:1/30     Step:3|6   loss:0.8062202334403992  \n","Epoch:1/30     Step:4|6   loss:0.7768437266349792  \n","Epoch:1/30     Step:5|6   loss:0.7966628670692444  \n","Epoch:1/30     Step:6|6   loss:0.8412905931472778  \n","Epoch:1/30     Step:7|6   loss:0.8043012022972107  \n","Accuracy on test_set: 95.33 %\n","Accuracy on train_set: 98.59 %\n","current max accuracy\t test set:95.33%\t train set:98.59%\n","Epoch:2/30     Step:1|6   loss:0.7883817553520203  \n","Epoch:2/30     Step:2|6   loss:0.9043929576873779  \n","Epoch:2/30     Step:3|6   loss:0.7715587615966797  \n","Epoch:2/30     Step:4|6   loss:0.7814019918441772  \n","Epoch:2/30     Step:5|6   loss:0.814704179763794  \n","Epoch:2/30     Step:6|6   loss:0.7856020927429199  \n","Epoch:2/30     Step:7|6   loss:0.7183942794799805  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 99.53 %\n","current max accuracy\t test set:97.2%\t train set:99.53%\n","Epoch:3/30     Step:1|6   loss:0.7747107744216919  \n","Epoch:3/30     Step:2|6   loss:0.7633163928985596  \n","Epoch:3/30     Step:3|6   loss:0.7479329705238342  \n","Epoch:3/30     Step:4|6   loss:0.7675379514694214  \n","Epoch:3/30     Step:5|6   loss:0.7515906691551208  \n","Epoch:3/30     Step:6|6   loss:0.7284349203109741  \n","Epoch:3/30     Step:7|6   loss:0.7911807298660278  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:99.07%\t train set:99.77%\n","Epoch:4/30     Step:1|6   loss:0.7311131358146667  \n","Epoch:4/30     Step:2|6   loss:0.755286455154419  \n","Epoch:4/30     Step:3|6   loss:0.7090109586715698  \n","Epoch:4/30     Step:4|6   loss:0.7385003566741943  \n","Epoch:4/30     Step:5|6   loss:0.7563238143920898  \n","Epoch:4/30     Step:6|6   loss:0.7018084526062012  \n","Epoch:4/30     Step:7|6   loss:0.7230517268180847  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.7255568504333496  \n","Epoch:5/30     Step:2|6   loss:0.7076261043548584  \n","Epoch:5/30     Step:3|6   loss:0.7254018783569336  \n","Epoch:5/30     Step:4|6   loss:0.6632055044174194  \n","Epoch:5/30     Step:5|6   loss:0.7293896079063416  \n","Epoch:5/30     Step:6|6   loss:0.7396514415740967  \n","Epoch:5/30     Step:7|6   loss:0.7612165212631226  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7531306743621826  \n","Epoch:6/30     Step:2|6   loss:0.7362059950828552  \n","Epoch:6/30     Step:3|6   loss:0.747994065284729  \n","Epoch:6/30     Step:4|6   loss:0.7441038489341736  \n","Epoch:6/30     Step:5|6   loss:0.6916830539703369  \n","Epoch:6/30     Step:6|6   loss:0.687047004699707  \n","Epoch:6/30     Step:7|6   loss:0.7073830962181091  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.6998817920684814  \n","Epoch:7/30     Step:2|6   loss:0.7268961668014526  \n","Epoch:7/30     Step:3|6   loss:0.657875657081604  \n","Epoch:7/30     Step:4|6   loss:0.7137911319732666  \n","Epoch:7/30     Step:5|6   loss:0.7155410647392273  \n","Epoch:7/30     Step:6|6   loss:0.6436135768890381  \n","Epoch:7/30     Step:7|6   loss:0.6803457736968994  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.6972373723983765  \n","Epoch:8/30     Step:2|6   loss:0.6423782110214233  \n","Epoch:8/30     Step:3|6   loss:0.6939883232116699  \n","Epoch:8/30     Step:4|6   loss:0.7361547350883484  \n","Epoch:8/30     Step:5|6   loss:0.7380712032318115  \n","Epoch:8/30     Step:6|6   loss:0.7148787379264832  \n","Epoch:8/30     Step:7|6   loss:0.6671739816665649  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.7222127914428711  \n","Epoch:9/30     Step:2|6   loss:0.7251855134963989  \n","Epoch:9/30     Step:3|6   loss:0.694927453994751  \n","Epoch:9/30     Step:4|6   loss:0.68974769115448  \n","Epoch:9/30     Step:5|6   loss:0.7365745306015015  \n","Epoch:9/30     Step:6|6   loss:0.663644015789032  \n","Epoch:9/30     Step:7|6   loss:0.7504611015319824  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7264411449432373  \n","Epoch:10/30     Step:2|6   loss:0.664018988609314  \n","Epoch:10/30     Step:3|6   loss:0.6731196641921997  \n","Epoch:10/30     Step:4|6   loss:0.6735386848449707  \n","Epoch:10/30     Step:5|6   loss:0.6775052547454834  \n","Epoch:10/30     Step:6|6   loss:0.6953506469726562  \n","Epoch:10/30     Step:7|6   loss:0.6696181893348694  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.7448785901069641  \n","Epoch:11/30     Step:2|6   loss:0.717984676361084  \n","Epoch:11/30     Step:3|6   loss:0.7006000280380249  \n","Epoch:11/30     Step:4|6   loss:0.7007769346237183  \n","Epoch:11/30     Step:5|6   loss:0.6350575089454651  \n","Epoch:11/30     Step:6|6   loss:0.6632481217384338  \n","Epoch:11/30     Step:7|6   loss:0.6863340139389038  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.7156710624694824  \n","Epoch:12/30     Step:2|6   loss:0.723214864730835  \n","Epoch:12/30     Step:3|6   loss:0.712385356426239  \n","Epoch:12/30     Step:4|6   loss:0.6636008620262146  \n","Epoch:12/30     Step:5|6   loss:0.6927787065505981  \n","Epoch:12/30     Step:6|6   loss:0.7155479788780212  \n","Epoch:12/30     Step:7|6   loss:0.7483249306678772  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7002052068710327  \n","Epoch:13/30     Step:2|6   loss:0.7491130232810974  \n","Epoch:13/30     Step:3|6   loss:0.696537971496582  \n","Epoch:13/30     Step:4|6   loss:0.7201442122459412  \n","Epoch:13/30     Step:5|6   loss:0.7089250087738037  \n","Epoch:13/30     Step:6|6   loss:0.7001469135284424  \n","Epoch:13/30     Step:7|6   loss:0.7039467096328735  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.6923699975013733  \n","Epoch:14/30     Step:2|6   loss:0.691550612449646  \n","Epoch:14/30     Step:3|6   loss:0.6777752637863159  \n","Epoch:14/30     Step:4|6   loss:0.7077033519744873  \n","Epoch:14/30     Step:5|6   loss:0.6929067969322205  \n","Epoch:14/30     Step:6|6   loss:0.7148329019546509  \n","Epoch:14/30     Step:7|6   loss:0.6761717200279236  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.6718569993972778  \n","Epoch:15/30     Step:2|6   loss:0.6714496612548828  \n","Epoch:15/30     Step:3|6   loss:0.6784027814865112  \n","Epoch:15/30     Step:4|6   loss:0.7100754976272583  \n","Epoch:15/30     Step:5|6   loss:0.7013816833496094  \n","Epoch:15/30     Step:6|6   loss:0.7280296087265015  \n","Epoch:15/30     Step:7|6   loss:0.7586822509765625  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.6945726871490479  \n","Epoch:16/30     Step:2|6   loss:0.726577639579773  \n","Epoch:16/30     Step:3|6   loss:0.703779935836792  \n","Epoch:16/30     Step:4|6   loss:0.7465282082557678  \n","Epoch:16/30     Step:5|6   loss:0.7030305862426758  \n","Epoch:16/30     Step:6|6   loss:0.713972806930542  \n","Epoch:16/30     Step:7|6   loss:0.6547544002532959  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.6900748610496521  \n","Epoch:17/30     Step:2|6   loss:0.6802780032157898  \n","Epoch:17/30     Step:3|6   loss:0.752975583076477  \n","Epoch:17/30     Step:4|6   loss:0.7419778108596802  \n","Epoch:17/30     Step:5|6   loss:0.7148702144622803  \n","Epoch:17/30     Step:6|6   loss:0.6700619459152222  \n","Epoch:17/30     Step:7|6   loss:0.7196425199508667  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.6564462184906006  \n","Epoch:18/30     Step:2|6   loss:0.6916948556900024  \n","Epoch:18/30     Step:3|6   loss:0.7312779426574707  \n","Epoch:18/30     Step:4|6   loss:0.6929640769958496  \n","Epoch:18/30     Step:5|6   loss:0.6710300445556641  \n","Epoch:18/30     Step:6|6   loss:0.680608868598938  \n","Epoch:18/30     Step:7|6   loss:0.6461607813835144  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.7265523672103882  \n","Epoch:19/30     Step:2|6   loss:0.7227053642272949  \n","Epoch:19/30     Step:3|6   loss:0.7396405339241028  \n","Epoch:19/30     Step:4|6   loss:0.7324407696723938  \n","Epoch:19/30     Step:5|6   loss:0.7029200792312622  \n","Epoch:19/30     Step:6|6   loss:0.7101465463638306  \n","Epoch:19/30     Step:7|6   loss:0.7050154209136963  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.6676020622253418  \n","Epoch:20/30     Step:2|6   loss:0.7302534580230713  \n","Epoch:20/30     Step:3|6   loss:0.6911513805389404  \n","Epoch:20/30     Step:4|6   loss:0.7087949514389038  \n","Epoch:20/30     Step:5|6   loss:0.6581814289093018  \n","Epoch:20/30     Step:6|6   loss:0.7027350664138794  \n","Epoch:20/30     Step:7|6   loss:0.6822400093078613  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.6911416053771973  \n","Epoch:21/30     Step:2|6   loss:0.6808996796607971  \n","Epoch:21/30     Step:3|6   loss:0.7296922206878662  \n","Epoch:21/30     Step:4|6   loss:0.7284286022186279  \n","Epoch:21/30     Step:5|6   loss:0.7464699745178223  \n","Epoch:21/30     Step:6|6   loss:0.7222055196762085  \n","Epoch:21/30     Step:7|6   loss:0.7241548299789429  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.7330441474914551  \n","4Epoch:22/30     Step:2|6   loss:0.7235096096992493  \n","Epoch:22/30     Step:3|6   loss:0.6450912952423096  \n","Epoch:22/30     Step:4|6   loss:0.729391872882843  \n","Epoch:22/30     Step:5|6   loss:0.6980917453765869  \n","Epoch:22/30     Step:6|6   loss:0.7412282228469849  \n","Epoch:22/30     Step:7|6   loss:0.7517744898796082  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.662795901298523  \n","Epoch:23/30     Step:2|6   loss:0.7370823621749878  \n","Epoch:23/30     Step:3|6   loss:0.6754869222640991  \n","Epoch:23/30     Step:4|6   loss:0.7139790058135986  \n","Epoch:23/30     Step:5|6   loss:0.7428248524665833  \n","Epoch:23/30     Step:6|6   loss:0.6686437129974365  \n","Epoch:23/30     Step:7|6   loss:0.7291567325592041  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.6977217197418213  \n","Epoch:24/30     Step:2|6   loss:0.7295049428939819  \n","Epoch:24/30     Step:3|6   loss:0.6783573627471924  \n","Epoch:24/30     Step:4|6   loss:0.7067732214927673  \n","Epoch:24/30     Step:5|6   loss:0.6806463003158569  \n","Epoch:24/30     Step:6|6   loss:0.713537335395813  \n","Epoch:24/30     Step:7|6   loss:0.6818420886993408  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.6988403797149658  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch:25/30     Step:2|6   loss:0.6791858673095703  \n","Epoch:25/30     Step:3|6   loss:0.7269629240036011  \n","Epoch:25/30     Step:4|6   loss:0.6792398691177368  \n","Epoch:25/30     Step:5|6   loss:0.7079790830612183  \n","Epoch:25/30     Step:6|6   loss:0.6899422407150269  \n","Epoch:25/30     Step:7|6   loss:0.7009990215301514  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7001602649688721  \n","Epoch:26/30     Step:2|6   loss:0.670024037361145  \n","Epoch:26/30     Step:3|6   loss:0.7117836475372314  \n","Epoch:26/30     Step:4|6   loss:0.737887978553772  \n","Epoch:26/30     Step:5|6   loss:0.7095531225204468  \n","Epoch:26/30     Step:6|6   loss:0.7322223782539368  \n","Epoch:26/30     Step:7|6   loss:0.6799353361129761  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.7013356685638428  \n","Epoch:27/30     Step:2|6   loss:0.7141273617744446  \n","Epoch:27/30     Step:3|6   loss:0.6773724555969238  \n","Epoch:27/30     Step:4|6   loss:0.6856540441513062  \n","Epoch:27/30     Step:5|6   loss:0.6766617298126221  \n","Epoch:27/30     Step:6|6   loss:0.6948602199554443  \n","Epoch:27/30     Step:7|6   loss:0.7003018856048584  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.7279245853424072  \n","Epoch:28/30     Step:2|6   loss:0.7350776791572571  \n","Epoch:28/30     Step:3|6   loss:0.7117884755134583  \n","Epoch:28/30     Step:4|6   loss:0.6792678833007812  \n","Epoch:28/30     Step:5|6   loss:0.6911638975143433  \n","Epoch:28/30     Step:6|6   loss:0.689980149269104  \n","Epoch:28/30     Step:7|6   loss:0.7438393831253052  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.6629343628883362  \n","Epoch:29/30     Step:2|6   loss:0.7003471851348877  \n","Epoch:29/30     Step:3|6   loss:0.6805984377861023  \n","Epoch:29/30     Step:4|6   loss:0.6374694108963013  \n","Epoch:29/30     Step:5|6   loss:0.7306423187255859  \n","Epoch:29/30     Step:6|6   loss:0.769220769405365  \n","Epoch:29/30     Step:7|6   loss:0.6782040596008301  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.6887896060943604  \n","Epoch:30/30     Step:2|6   loss:0.7416569590568542  \n","Epoch:30/30     Step:3|6   loss:0.703764796257019  \n","Epoch:30/30     Step:4|6   loss:0.7127212285995483  \n","Epoch:30/30     Step:5|6   loss:0.6653505563735962  \n","Epoch:30/30     Step:6|6   loss:0.7334514856338501  \n","Epoch:30/30     Step:7|6   loss:0.7039324045181274  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n","Namespace(EPOCH=30, batch_size=64, classes_num=3, index=4, log_loss_path='./log/', log_path='./log/results.csv', lr=0.0001, mode='both', model='Resnet18_two_stream', path_ir='./254p Thermal Images/', path_rgb='./254p RGB Images/', subset_rate=0.01, test_interval=1, trainset_rate=0.8)\n","use device: cuda:0\n","use device: cuda:0\n","Resnet18_two_stream(\n","  (stream1): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (stream2): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential(\n","      (0): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=512, out_features=3, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch:1/30     Step:1|6   loss:1.253392219543457  \n","Epoch:1/30     Step:2|6   loss:0.9438719153404236  \n","Epoch:1/30     Step:3|6   loss:0.8847824335098267  \n","Epoch:1/30     Step:4|6   loss:0.7953547239303589  \n","Epoch:1/30     Step:5|6   loss:0.7469937801361084  \n","Epoch:1/30     Step:6|6   loss:0.7730824947357178  \n","Epoch:1/30     Step:7|6   loss:0.8093099594116211  \n","Accuracy on test_set: 96.26 %\n","Accuracy on train_set: 98.13 %\n","current max accuracy\t test set:96.26%\t train set:98.13%\n","Epoch:2/30     Step:1|6   loss:0.7592931389808655  \n","Epoch:2/30     Step:2|6   loss:0.7653616070747375  \n","Epoch:2/30     Step:3|6   loss:0.7695600986480713  \n","Epoch:2/30     Step:4|6   loss:0.8095711469650269  \n","Epoch:2/30     Step:5|6   loss:0.7790675163269043  \n","Epoch:2/30     Step:6|6   loss:0.7986663579940796  \n","Epoch:2/30     Step:7|6   loss:0.742896556854248  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:99.77%\n","Epoch:3/30     Step:1|6   loss:0.7642285823822021  \n","Epoch:3/30     Step:2|6   loss:0.7039785385131836  \n","Epoch:3/30     Step:3|6   loss:0.738839864730835  \n","Epoch:3/30     Step:4|6   loss:0.7388124465942383  \n","Epoch:3/30     Step:5|6   loss:0.747789204120636  \n","Epoch:3/30     Step:6|6   loss:0.7806596755981445  \n","Epoch:3/30     Step:7|6   loss:0.7410398721694946  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:4/30     Step:1|6   loss:0.710187554359436  \n","Epoch:4/30     Step:2|6   loss:0.7402235865592957  \n","Epoch:4/30     Step:3|6   loss:0.7529790997505188  \n","Epoch:4/30     Step:4|6   loss:0.7278584241867065  \n","Epoch:4/30     Step:5|6   loss:0.7490535974502563  \n","Epoch:4/30     Step:6|6   loss:0.7561306953430176  \n","Epoch:4/30     Step:7|6   loss:0.6989116668701172  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 99.77 %\n","current max accuracy\t test set:98.13%\t train set:100.0%\n","Epoch:5/30     Step:1|6   loss:0.7524202466011047  \n","Epoch:5/30     Step:2|6   loss:0.7303782105445862  \n","Epoch:5/30     Step:3|6   loss:0.7088121175765991  \n","Epoch:5/30     Step:4|6   loss:0.7275673151016235  \n","Epoch:5/30     Step:5|6   loss:0.7561025619506836  \n","Epoch:5/30     Step:6|6   loss:0.7485767602920532  \n","Epoch:5/30     Step:7|6   loss:0.7301660776138306  \n","Accuracy on test_set: 99.07 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:6/30     Step:1|6   loss:0.7248096466064453  \n","Epoch:6/30     Step:2|6   loss:0.7445967197418213  \n","Epoch:6/30     Step:3|6   loss:0.7254719734191895  \n","Epoch:6/30     Step:4|6   loss:0.6586596965789795  \n","Epoch:6/30     Step:5|6   loss:0.7082250714302063  \n","Epoch:6/30     Step:6|6   loss:0.7499699592590332  \n","Epoch:6/30     Step:7|6   loss:0.7488144636154175  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:7/30     Step:1|6   loss:0.7372012734413147  \n","Epoch:7/30     Step:2|6   loss:0.7079476714134216  \n","Epoch:7/30     Step:3|6   loss:0.784927487373352  \n","Epoch:7/30     Step:4|6   loss:0.6857926845550537  \n","Epoch:7/30     Step:5|6   loss:0.7328558564186096  \n","Epoch:7/30     Step:6|6   loss:0.726393461227417  \n","Epoch:7/30     Step:7|6   loss:0.7615303993225098  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:8/30     Step:1|6   loss:0.7263063192367554  \n","Epoch:8/30     Step:2|6   loss:0.7154355645179749  \n","Epoch:8/30     Step:3|6   loss:0.6913484334945679  \n","Epoch:8/30     Step:4|6   loss:0.7056818604469299  \n","Epoch:8/30     Step:5|6   loss:0.7332013249397278  \n","Epoch:8/30     Step:6|6   loss:0.7090681791305542  \n","Epoch:8/30     Step:7|6   loss:0.7094554305076599  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:9/30     Step:1|6   loss:0.6666090488433838  \n","Epoch:9/30     Step:2|6   loss:0.6515568494796753  \n","Epoch:9/30     Step:3|6   loss:0.7106064558029175  \n","Epoch:9/30     Step:4|6   loss:0.7160295844078064  \n","Epoch:9/30     Step:5|6   loss:0.6993080377578735  \n","Epoch:9/30     Step:6|6   loss:0.6479597091674805  \n","Epoch:9/30     Step:7|6   loss:0.7282511591911316  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:10/30     Step:1|6   loss:0.7086156606674194  \n","Epoch:10/30     Step:2|6   loss:0.7094639539718628  \n","Epoch:10/30     Step:3|6   loss:0.6607187986373901  \n","Epoch:10/30     Step:4|6   loss:0.6923824548721313  \n","Epoch:10/30     Step:5|6   loss:0.6965615153312683  \n","Epoch:10/30     Step:6|6   loss:0.6717023849487305  \n","Epoch:10/30     Step:7|6   loss:0.7113248109817505  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:11/30     Step:1|6   loss:0.7071341872215271  \n","Epoch:11/30     Step:2|6   loss:0.7226175665855408  \n","Epoch:11/30     Step:3|6   loss:0.7107536792755127  \n","Epoch:11/30     Step:4|6   loss:0.7207356691360474  \n","Epoch:11/30     Step:5|6   loss:0.705182671546936  \n","Epoch:11/30     Step:6|6   loss:0.7142415046691895  \n","Epoch:11/30     Step:7|6   loss:0.7005317211151123  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:12/30     Step:1|6   loss:0.6693817377090454  \n","Epoch:12/30     Step:2|6   loss:0.705799400806427  \n","Epoch:12/30     Step:3|6   loss:0.715084433555603  \n","Epoch:12/30     Step:4|6   loss:0.6921045780181885  \n","Epoch:12/30     Step:5|6   loss:0.7162959575653076  \n","Epoch:12/30     Step:6|6   loss:0.7283160090446472  \n","Epoch:12/30     Step:7|6   loss:0.7668689489364624  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:13/30     Step:1|6   loss:0.7509616613388062  \n","Epoch:13/30     Step:2|6   loss:0.6819727420806885  \n","Epoch:13/30     Step:3|6   loss:0.7200665473937988  \n","Epoch:13/30     Step:4|6   loss:0.7042925357818604  \n","Epoch:13/30     Step:5|6   loss:0.7587430477142334  \n","Epoch:13/30     Step:6|6   loss:0.673025369644165  \n","Epoch:13/30     Step:7|6   loss:0.690676212310791  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:14/30     Step:1|6   loss:0.7144765853881836  \n","Epoch:14/30     Step:2|6   loss:0.6984635591506958  \n","Epoch:14/30     Step:3|6   loss:0.6902589797973633  \n","Epoch:14/30     Step:4|6   loss:0.6624796390533447  \n","Epoch:14/30     Step:5|6   loss:0.7310769557952881  \n","Epoch:14/30     Step:6|6   loss:0.728347659111023  \n","Epoch:14/30     Step:7|6   loss:0.7061166167259216  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:15/30     Step:1|6   loss:0.6821793913841248  \n","Epoch:15/30     Step:2|6   loss:0.711009681224823  \n","Epoch:15/30     Step:3|6   loss:0.7237926721572876  \n","Epoch:15/30     Step:4|6   loss:0.7357136011123657  \n","Epoch:15/30     Step:5|6   loss:0.7288507223129272  \n","Epoch:15/30     Step:6|6   loss:0.7484548091888428  \n","Epoch:15/30     Step:7|6   loss:0.7273926734924316  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:16/30     Step:1|6   loss:0.7025811672210693  \n","Epoch:16/30     Step:2|6   loss:0.6981067657470703  \n","Epoch:16/30     Step:3|6   loss:0.6750670671463013  \n","Epoch:16/30     Step:4|6   loss:0.7204661965370178  \n","Epoch:16/30     Step:5|6   loss:0.6945281028747559  \n","Epoch:16/30     Step:6|6   loss:0.691834568977356  \n","Epoch:16/30     Step:7|6   loss:0.7036622762680054  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n"]},{"name":"stdout","output_type":"stream","text":["current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:17/30     Step:1|6   loss:0.6916781663894653  \n","Epoch:17/30     Step:2|6   loss:0.7238494157791138  \n","Epoch:17/30     Step:3|6   loss:0.7133246660232544  \n","Epoch:17/30     Step:4|6   loss:0.7279855012893677  \n","Epoch:17/30     Step:5|6   loss:0.7296322584152222  \n","Epoch:17/30     Step:6|6   loss:0.679664134979248  \n","Epoch:17/30     Step:7|6   loss:0.6925891637802124  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:18/30     Step:1|6   loss:0.722154974937439  \n","Epoch:18/30     Step:2|6   loss:0.7110293507575989  \n","Epoch:18/30     Step:3|6   loss:0.6758582592010498  \n","Epoch:18/30     Step:4|6   loss:0.73063063621521  \n","Epoch:18/30     Step:5|6   loss:0.6911272406578064  \n","Epoch:18/30     Step:6|6   loss:0.6853495836257935  \n","Epoch:18/30     Step:7|6   loss:0.6170823574066162  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:19/30     Step:1|6   loss:0.7389647960662842  \n","Epoch:19/30     Step:2|6   loss:0.620857298374176  \n","Epoch:19/30     Step:3|6   loss:0.7064241170883179  \n","Epoch:19/30     Step:4|6   loss:0.7113070487976074  \n","Epoch:19/30     Step:5|6   loss:0.7358971238136292  \n","Epoch:19/30     Step:6|6   loss:0.7516260147094727  \n","Epoch:19/30     Step:7|6   loss:0.7339377403259277  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:20/30     Step:1|6   loss:0.6298220753669739  \n","Epoch:20/30     Step:2|6   loss:0.6952139139175415  \n","Epoch:20/30     Step:3|6   loss:0.6695048809051514  \n","Epoch:20/30     Step:4|6   loss:0.7364933490753174  \n","Epoch:20/30     Step:5|6   loss:0.6692534685134888  \n","Epoch:20/30     Step:6|6   loss:0.7022672891616821  \n","Epoch:20/30     Step:7|6   loss:0.7277222871780396  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:21/30     Step:1|6   loss:0.6911340355873108  \n","Epoch:21/30     Step:2|6   loss:0.7598276138305664  \n","Epoch:21/30     Step:3|6   loss:0.6726893186569214  \n","Epoch:21/30     Step:4|6   loss:0.7388507723808289  \n","Epoch:21/30     Step:5|6   loss:0.720659613609314  \n","Epoch:21/30     Step:6|6   loss:0.7102044820785522  \n","Epoch:21/30     Step:7|6   loss:0.7624725103378296  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:22/30     Step:1|6   loss:0.7020480632781982  \n","Epoch:22/30     Step:2|6   loss:0.7136101126670837  \n","Epoch:22/30     Step:3|6   loss:0.7078421115875244  \n","Epoch:22/30     Step:4|6   loss:0.6669074296951294  \n","Epoch:22/30     Step:5|6   loss:0.7179044485092163  \n","Epoch:22/30     Step:6|6   loss:0.7260699272155762  \n","Epoch:22/30     Step:7|6   loss:0.779367208480835  \n","Accuracy on test_set: 97.20 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:23/30     Step:1|6   loss:0.7165427803993225  \n","Epoch:23/30     Step:2|6   loss:0.6989564895629883  \n","Epoch:23/30     Step:3|6   loss:0.6594825983047485  \n","Epoch:23/30     Step:4|6   loss:0.6782429218292236  \n","Epoch:23/30     Step:5|6   loss:0.764514684677124  \n","Epoch:23/30     Step:6|6   loss:0.6951398849487305  \n","Epoch:23/30     Step:7|6   loss:0.714531660079956  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:24/30     Step:1|6   loss:0.7074543237686157  \n","Epoch:24/30     Step:2|6   loss:0.6953842639923096  \n","Epoch:24/30     Step:3|6   loss:0.7480601072311401  \n","Epoch:24/30     Step:4|6   loss:0.7219845056533813  \n","Epoch:24/30     Step:5|6   loss:0.7078529596328735  \n","Epoch:24/30     Step:6|6   loss:0.7177215814590454  \n","Epoch:24/30     Step:7|6   loss:0.6898396015167236  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:25/30     Step:1|6   loss:0.7042766809463501  \n","Epoch:25/30     Step:2|6   loss:0.7283807992935181  \n","Epoch:25/30     Step:3|6   loss:0.7216517925262451  \n","Epoch:25/30     Step:4|6   loss:0.6833890080451965  \n","Epoch:25/30     Step:5|6   loss:0.6621025800704956  \n","Epoch:25/30     Step:6|6   loss:0.7148387432098389  \n","Epoch:25/30     Step:7|6   loss:0.7243510484695435  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:26/30     Step:1|6   loss:0.7404520511627197  \n","Epoch:26/30     Step:2|6   loss:0.6707473993301392  \n","Epoch:26/30     Step:3|6   loss:0.6917931437492371  \n","Epoch:26/30     Step:4|6   loss:0.6645629405975342  \n","Epoch:26/30     Step:5|6   loss:0.722419798374176  \n","Epoch:26/30     Step:6|6   loss:0.7466225624084473  \n","Epoch:26/30     Step:7|6   loss:0.6864283084869385  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:27/30     Step:1|6   loss:0.6928451061248779  \n","Epoch:27/30     Step:2|6   loss:0.7195667028427124  \n","Epoch:27/30     Step:3|6   loss:0.7321004867553711  \n","Epoch:27/30     Step:4|6   loss:0.7653183937072754  \n","Epoch:27/30     Step:5|6   loss:0.7125594019889832  \n","Epoch:27/30     Step:6|6   loss:0.720055341720581  \n","Epoch:27/30     Step:7|6   loss:0.6639436483383179  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:28/30     Step:1|6   loss:0.7156912088394165  \n","Epoch:28/30     Step:2|6   loss:0.7345624566078186  \n","Epoch:28/30     Step:3|6   loss:0.6516388654708862  \n","Epoch:28/30     Step:4|6   loss:0.6963376998901367  \n","Epoch:28/30     Step:5|6   loss:0.6560672521591187  \n","Epoch:28/30     Step:6|6   loss:0.6579453945159912  \n","Epoch:28/30     Step:7|6   loss:0.6902905106544495  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:29/30     Step:1|6   loss:0.6628334522247314  \n","Epoch:29/30     Step:2|6   loss:0.6883354783058167  \n","Epoch:29/30     Step:3|6   loss:0.7112912535667419  \n","Epoch:29/30     Step:4|6   loss:0.6997924447059631  \n","Epoch:29/30     Step:5|6   loss:0.6843050122261047  \n","Epoch:29/30     Step:6|6   loss:0.6708855628967285  \n","Epoch:29/30     Step:7|6   loss:0.7281023263931274  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Epoch:30/30     Step:1|6   loss:0.6974595189094543  \n","Epoch:30/30     Step:2|6   loss:0.7033119797706604  \n","Epoch:30/30     Step:3|6   loss:0.6632381677627563  \n","Epoch:30/30     Step:4|6   loss:0.6929429769515991  \n","Epoch:30/30     Step:5|6   loss:0.7368999719619751  \n","Epoch:30/30     Step:6|6   loss:0.6794717311859131  \n","Epoch:30/30     Step:7|6   loss:0.7252190113067627  \n","Accuracy on test_set: 98.13 %\n","Accuracy on train_set: 100.00 %\n","current max accuracy\t test set:99.07%\t train set:100.0%\n","Accuracy on test_set: 98.13 %\n"]}],"source":"for i in index_list:\n    print(i)\n    !python train.py --lr 1e-4 --model Resnet18_two_stream --mode both --index {i} --EPOCH 30"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}